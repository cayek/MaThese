# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:6 author:nil email:nil creator:nil timestamp:nil skip:nil toc:t ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(g!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


#+LaTeX_CLASS: these
# #+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \renewcommand{\proofname}{Preuve}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM hyperparamètre

# #+BEGIN_QUOTE
# In Code we trust, all others bring data.
# –William Edwards Deming (1900-1993).
# #+END_QUOTE

#+BEGIN_EXPORT latex
%% to review
\baselineskip 0.8cm
#+END_EXPORT

* Workenv                                                          :noexport:
** R
#+BEGIN_SRC R
  ## CRAN
  install.packages("tidyverse")
  install.packages("extrafont")
  install.packages("Devtools")
  install.packages("testthat")
  install.packages("foreach")
  install.packages("RSpectra")
  install.packages("doParallel")
  install.packages("DescTools")
  install.packages("roxygen2")
  install.packages("VennDiagram")
  install.packages("ggmap")
  install.packages("rvest")
  install.packages("raster")
    ## bioconductor
  source("https://bioconductor.org/biocLite.R")
  biocLite("matter", ask = FALSE)
  biocLite("qvalue",ask = FALSE)
  biocLite("biomaRt",ask = FALSE)
  biocLite("LEA",ask = FALSE)
  biocLite("impute",ask = FALSE)
  biocLite("sva",ask = FALSE)

  install.packages("cate")
  install.packages("FAMT")
  install.packages("xgboost")
  install.packages("knitr")


  ## github
  devtools::install_github("privefl/bigsnpr")
#+END_SRC
** Ligne de commande
*** ms
*** plink
** python
* Introduction
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-07-20 Thu 17:52]
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:11] \\
  une remarque en passant: l'intro est pour moi la place pour définir le contexte
  général, les mots du titre, la pbq et le plan qui y répond ! 
  Ce n'est pas la que je fait un état de l'art. L'état de l'art est dans les deux
  grosse partis ! C'est deux grosse parties sont indépendantes l'une de l'autre !
  Donc si il y a des répétition, tant pis !!
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
** Contexte
:LOGBOOK:
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:
*** COMMENT 
Cette dernière décennie a été marquée par une accumulation des données dans tous les
domaines de la sciences. Cette accumulation de données est une aubaine pour les
scientifiques. Cependant, que faire d'autant de données et comment en tirer
l'information qui permettrait de mieux comprendre le monde qui nous entoure ? Il
s'agit là d'un défi majeur pour les statistiques cite:slides_sfds2015_saporta. 

Les grandes données posent plusieurs problèmes. En effet, si l'on est capable d'obtenir
des données rapidement, on veut pouvoir les analyser rapidement. Cependant de
nombreux modèle statistiques classiques ne passent pas l'échelle des grands jeux
de données. Il est donc nécessaire de repenser les modèles et algorithmes afin
de les adapter au nous volumes des données. 
... parler de l'inversement du processus d'aquisition des données .. cf
seminaire Bosson



Dans le cadre de cette thèse nous nous sommes intéressé a développer des méthodes
statistiques utiles à deux problématique scientifiques. Le premier est l'estimation
de la structure de population à partir de données génomique. Le deuxièmes est les
problèmes des test d'association multiple. Toutes les méthodes statistiques
developper lors de cette thèse repose sur la factorisation de matrice. Nous
allons maintenant introduire plus en détails les problématiques ainsi que la
factorisation de matrice en statistique.


** La génomique des populations
:LOGBOOK:
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc

 En faite je ne vais def ca ici ! c'est juste le genet des pops ici !!
  - ewas: refactor
  - gwas: gemma etc
  - eas: ...
:END:
** Test d'association
** La factorisation de matrice en statistique
:LOGBOOK:
- Note taken on [2017-07-18 Tue 08:55] \\
  Kenneth lange, factorisation de matrice = avenir des stat ! a retrouver !
:END:
** Problématique et objectifs de la thèse
* Données
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
:END:

Nous décrivons dans cette partie les données réelles qui sont analysées dans la
thèse. Afin de rendre les analyses le plus possible reproductibles, nous
décrivons les étapes de pré traitement qui ont été affectées sur ces jeux de
données. Les scripts sont disponible dans la version de la thèse avec le code.
** TODO Arabidopsis Thaliana Regional Mapping Lines               :noexport:
:LOGBOOK:
- State "TODO"       from              [2017-07-27 jeu. 17:02]
:END:
** TODO 1001 genome                                               :noexport:
:LOGBOOK:
- State "TODO"       from              [2017-07-27 jeu. 17:01]
:END:
** TODO Celiac GWAS                                               :noexport:
:LOGBOOK:
- Note taken on [2017-07-11 mar. 09:32] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
- State "TODO"       from              [2017-07-11 mar. 09:27]
:END:
*** Téléchargement des données
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=


*** Contrôle qualité
*** Filtrage des individus trop apparenté
*** Imputation des données manquantes
Avec bigsnpr et xgboost
*** Élagage
*** Conversion au format R et scaling
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
**** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
*** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
*** CANCELLED Conversion au format =bigmatrix=
CLOSED: [2017-07-23 Sun 15:46]
:LOGBOOK:
- Note taken on [2017-07-23 Sun 15:46] \\
  MDRRRRR: 
  Error in SetMatrixElements(x@address, as.double(j), as.double(i), as.double(value)) : 
  long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
  In addition: Warning message:
  In filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  No descriptor file given, it will be named G.big.bin.desc
- State "CANCELLED"  from              [2017-07-23 Sun 15:46]
- State "TODO"       from              [2017-07-23 Sun 15:29]
:END:
#+BEGIN_SRC R
  library(bigmemory)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "./Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.big.bin")
  colnames(G.big) <- colnames(G)
  rownames(G.big) <- rownames(G)
  saveRDS(G.big, "./Data/ThesisDataset/3Article/Celiac/G.big.rds")
#+END_SRC
** DONE AT EWAS                                                   :noexport:
CLOSED: [2017-07-27 jeu. 17:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 17:01]
- State "TODO"       from              [2017-07-27 jeu. 17:01]
:END:
*** Téléchargement des données

#+NAME: code:ewas_ddl
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC
*** Formatage
#+NAME: code:ewas_format
#+CAPTION: Dépend de [[code:ewas_ddl]]
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC
*** Preprocessing
Nour avons reproduit le preprocessing expliqué dans cite:Zou_2014.
#+NAME: code:ewas_prepross
#+CAPTION: Dépend de [[code:ewas_format]]
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC
*** Scaling des données
Pour certaine analyse il est important de scaler les données. 

#+NAME: code:ewas_G_X
#+CAPTION: Dépend de [[code:ewas_prepross]]
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

* Inférence des coefficients de métissage à l'aide de données géographiques
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:07] \\
  Non je ne vais pas avoir le temps, je vais traduire l'article, étoffer un peu
  et basta. Je mettrais en perspective le traitement des données manquantes pour
  tess3r et sur un très gros dataset si j'ai le temps (1001 genome, avec une
  analyse de la population et une association environmental, pour ilustrer les
  deux feature gros dataset et NA)
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
* Estimation de facteurs latents pour corriger les tests d'association
** Introduction
*** Les études d'association
Au cours de la dernière décennie, les études d'association à grande échelle ont
été largement utilisées pour identifier les gènes candidats associés à une
maladie particulière ou un trait phénotypique d'intérêt. Selon le type de
marqueurs moléculaires examinés dans les génomes ou dans les cellules, plusieurs
catégories d'études d'association ont été menées pour détecter des corrélations
significatives de ses marqueurs avec le phénotype. Par exemple, les études
d'association à l'échelle du génome (GWAS genome-wide association studies) se
concentrent sur les polymorphismes à un seul nucléotide (SNP pour
single-nucleotide polymorphisms) en examinant des variants génétiques chez
différents individus cite:Balding_2006. Les GWAS ont été étendus à des études
d'association à l'échelle de l'épigenome (EWAS epigenome-wide association
studies) qui mesurent les niveaux de méthylation de l'ADN chez différents
individus pour des associations entre la variation épigénétique et les
phénotypes cite:Rakyan_2011. Des approches similaires ont été appliquées à la
caractérisation de la variation observée dans l'ARN par rapport à différents
environnements, traitements, phénotypes ou maladies cite:Slonim_2002. D'autres
exemples d'études d'association incluent des études d'association
génétique-environnement (GEAS) dans lesquelles les sites génétiques sont testés
pour leur corrélation avec des gradients écologiques afin de détecter les
signatures de sélection naturelle cite:rellstab15_pract_guide_to_envir_assoc.
Dans un court laps de temps, les études d'association ont permis des progrès
considérables dans l'identification des variants de gènes qui confèrent une
susceptibilité aux maladies ainsi qu'une compréhension plus approfondie de
l'évolution des génomes en réponse à la sélection naturelle.

*** Les facteurs confusions
<<sec:fact_conf>>

Basée sur l'analyse de la corrélation, les études d'association sont confrontées
aux problèmes des facteurs de confusion et de causalité. En effet lorsque l'on
détecte de la corrélation entre deux variables cela n'implique pas qu'il y a
lien de causalité entre celle-ci. Le lien de causalité entre ces deux variables
peut être bien plus complexe et notamment impliquer des lien avec d'autres
variables non observées. En particulier, il est possible de conclure une
association entre deux variables alors qu'elles sont en faite chacune associé à
une autre variable non considéré dans l'étude. On appelle alors cette variable
non observé un facteur de confusion. La figure [[graph:conf_factor]] illustre cette
situation. Le problème des facteurs de confusion est connue depuis longtemps. En
effet, on le retrouve déjà dans l'ouvrage /The Design of Experiement/ de Ronald
Fisher qui introduisit entre autre le concept de d'hypothèse nulle en
statistique cite:fisher1937design. Dans cette thèse nous nous intéressons aux
études d'association à très grande échelle. C'est a dire que nous avons d'une
part les observations de $\Ycol$ variables sur $\Yrow$ individus qui sont
rassemblées dans une matrice $\Y$ de taille $\Yrow \times \Ycol$, en général
$\Ycol$ est très grand devant $\Yrow$. Nous avons d'autre part l'observation
d'une variable sur les mêmes $\Xrow$ individus que l'on rassemble dans la
matrice $\X$ de taille $\Xrow \times 1$. L'objectif est alors de trouver parmi
les $\Ycol$ variables $\Y$ celles qui sont associées à $\X$. Nous supposons de
plus qu'il existe un certain nombre de variables non observées qui permettent
d'expliquer les variations de $\Y$. Ces variables non observées, que l'on
appellera variables latentes, sont potentiellement des facteurs de confusion
pour l'étude d'association entre $\Y$ et $\X$. C'est a dire que les variables
latentes sont potentiellement corrélées à $\X$, il faut donc les prendre en compte
dans l'étude d'association.

#+NAME: code:conf_factor
#+BEGIN_SRC dot :file conf_factor.png :exports results :eval no-export
  graph {
    graph [fontname = "serif"];
    node [fontname = "serif"];
    edge [fontname = "serif"];
    u -- y;
    u -- x;
  }
#+END_SRC

#+NAME: graph:conf_factor
#+CAPTION: Graphe de corrélation entre la variable $y$ la variable $x$ et le facteur de confusion $u$. Dans cette situation si on ne prend pas en compte $u$ dans l'étude d'association alors $x$ et $y$ apparaitrons comme étant associées.
#+ATTR_LATEX: :width 5cm
#+RESULTS: code:conf_factor
[[file:conf_factor.png]]
*** Simulation numérique d'une association avec facteurs de confusions
<<sec:simu_ex>>

Dans cette partie nous proposons de montrer l'intérêt de prendre en
considération les facteurs de confusion dans les études d'association. Pour cela
nous simulation une variable $\X$ et une variable latente de sorte que leur
corrélation vaille $0.6$. Nous simulons ensuite une matrice de bruit gaussien
$\E$. La matrice des effets de la variable latente sur $\Y$ est aussi calculé a
l'aide de la loi normale, nous notons cette matrice $\V$. La matrice des effets
de $\X$ sur $\Y$, noté $\B$, est simulé de sorte que $1 \%$ de ses lignes soit
non nulle. Enfin, \Y est calculé tel que 
\begin{equation} 
\Y = \U \V^{T} + \X \B^{T} + \E. 
\end{equation} 
Cette simulation correspond a une situation où 1 \% des variables $\Y$ sont
associé avec $\X$ et la variable latente est bien facteur de confusion pour
cette étude d'association car $\U$ est corrélé avec $\X$. Afin de détecter les
variables expliquées associés à la variables explicative, nous avons réalisé une
régression linéaire classique avec seulement la variable $\X$ en variable
explicative de la régression. Nous effectuons une autre régression linéaire avec
cette fois la variable $\X$ ainsi que la variable latente $\U$ comme variable
explicatives de la régression. Nous avons ensuite réalisé un test de Student
pour tester la nullité des coefficient associé à la variable $\X$ dans chacune
des deux régressions. La figure ref:fig:simu_intro montre que quand on ne prend
pas en compte la variable latente plus de 40 \% des \pvalues sont proche de
zéro, on détecte alors beaucoup de candidats pour l'association avec la variable
explicative. Alors que quand on prend en compte les facteurs latents la
distribution des \pvalues est bien uniforme comme on s'y attend. On s'attend
bien a une distribution uniforme des \pvaleur car la majorité des variables $\Y$
ne sont pas associé avec la variable $\X$. Dans le cas de cette simulation il
est impossible de ne pas prendre en compte la variable latente, sans celle-ci on
détecte presque la moitié des variables expliquée comme étant associé à $\X$.

<<sec:simu_conf>>

#+NAME: code:confusion_plot
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(scales)

  dat <- ExpRsampler_generativeData(n = 200,
                                    p = 5000,
                                    K = 1,
                                    outlier.prop = 0.01,
                                    cs = c(0.6)) %>%
    ExpRmouline()

  ## lm
  lm.res <- method_lm() %>% ExpRmouline(dat)
  toplot <- data.frame(Régression = "Y ~ X",
                   pvalue = lm.res$pvalue)

  ## lm with U
  oracle.res <- method_oracle() %>% ExpRmouline(dat)


  ## qqplot
  toplot <- data.frame(Régression = "Y ~ X + U",
                       pvalue = oracle.res$pvalue) %>%
    rbind(toplot)
  toplot <- as_tibble(toplot)
  pl <- ggplot(toplot, aes(pvalue, fill = Régression)) +
    geom_histogram(position = "dodge", aes(y = (..count..)/sum(..count..))) +
    MaTheseR.params$gtheme +
    xlab("P-valeur") +
    ylab("Pourcentage") +
    scale_y_continuous(labels=percent)
  save_plot_MaTheseR(pl, "simu_intro.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/simu_intro.png}
\caption{Histogramme des \pvalues du test de nullité des coefficients
  de régression de la régression sans et avec le facteur de
  confusion.}
\label{fig:simu_intro}
\end{figure}
#+END_EXPORT


*** Méthodes de correction pour les facteurs latents
:LOGBOOK:
- Note taken on [2017-08-01 mar. 18:14] \\
  un exemple ici ?? lm, lm + PCA, lm + les facteurs latents comme dans stephens et
  2017 dans son intro,
:END:
Nous nous plaçons dans le cadre méthodologique des modèles de régression
linéaire. Il s'agit d'un cadre très utilisé en étude d'association que nous
pouvons formaliser de la façon suivante
\begin{equation}
\label{eq:statReg}
\Y_{j} = \X b_{j} + \E_{j}
\end{equation}
où $\Y_{j}$ est la matrice des observation de la variable d'indice $j$ sur
$\Yrow$ individus. Le coefficient $b_{j}$ représente l'effet de $\X$ sur
$\Y_{j}$. La matrice $\E_{j}$ est la matrice de l'erreur résiduelle. Il arrive
parfois que l'on fasse la régression dans l'autre sens, la régression s'écrit
alors
\begin{equation}
\label{eq:statRegRevers}
\X = \Y_{j} a_{j} + \E^{'}_{j},
\end{equation}
où $\a_{j}$ représente l'effet de $\Y_{j}$ sur $\X$. De plus, si nous avons
observé des variables supplémentaires qui sont des facteurs de confusion pour
notre étude, celle si sont ajoutées au coté des variables explicatives du modèle
de régression. Dans la suite nous ne parlerons de régression que dans le sens de
l'équation eqref:eq:statReg. L'objectif est de trouver les coefficients $b_{j}$
qui sont significativement différents de zéro. Dans ce cas on peut dire que
$\Y_{j}$ est potentiellement associée à $\X$. Comme nous l'avons évoqué dans la
partie précédente avec ce genre d'approche il est possible qu'une variable non
observée soit corrélé à la fois à $\Y$ et à $\X$. Dans ce cas, nous détectons
qu'un grand nombre de variable $\Y_{j}$ sont significativement corrélées à $\X$.
Mais cela est du à la variable latentes qui est corrélé a la fois à $\X$ et aux
variables $\Y$ (voir partie [[sec:simu_conf]] pour une simulation qui illustre de
cette situation).
**** Estimation des facteurs latent à priori
Une première approche consiste à trouver les variables latentes en faisant une
analyse factorielle de la matrice $\Y$ et sans prendre en compte la variable
$\X$. Les variables latentes sont ensuite ajoutées au modèle de régression au
coté des autres variables explicatives
\begin{equation}
\Y_{j} = \X b_{j} + \bar{\U} \V_{j}^{T} + \E_{j}
\end{equation}
où $\bare{\U}$ est la matrice des variables latents calculé à priori et $\V_{j}$
la matrice des effets des variables latentes sur $\Y_{j}$. Par exemple, les
méthodes EIGENSTRAT et Refactor calculent les variables latentes à l'aide de
l'analyse en composantes principales (ACP) de $\Y$ cite:Price_2006,Rahmani_2016.
**** Les modèles mixes
Une autre approche de correction pour les facteurs de confusions est le modèle
mixe. Dans un tel modèle on ajoute un effet aléatoire à la régression
\begin{equation}
\Y_{j} = \X \B^{T} + \matr{\Gamma}_{j} + \E_{j}
\end{equation}
où $\matr{\Gamma}_{j}$ est la matrice des effets aléatoires à estimer. Dans les
modèles on s'suppose de plus que la matrice de covariance de l'effet aléatoire
est connue. Dans le cadre des modèle mixe on parle d'effet aléatoire mais il
s'agit en faite du facteur de confusion dont à parlé jusque ici. Ainsi, la
matrice de covariance doit correspondre à la variance du facteur de confusion,
elle est en générale à partir de la matrice $\Y$. Les modèle mixes ont été
largement utilisé pour les GWAS cite:Kang_2008,Zhou_2014. Dans ce cas des GWAS,
l'effet aléatoire permet d'expliquer la variation de $\Y_{j}$ qui est dû à la
structure de population. Dans ce cas la matrice de covariance est estimé à
priori sur les données génétiques.
**** Les modèles mixes à facteurs latents (LFMM, latent factor mixed model en anglais)
Nous introduisons maintenant les modèles mixes à facteurs latents. L'équation de
régression peut s'écrire comme ceci : 
\begin{equation}
\label{eq:glfmm}
\Y = f(\X \B^{T} + \U \V^{T}) + \E.
\end{equation}
Dans cette équation $\U$ est la matrice des variables latentes et $\V$ est la
matrice des axes des facteurs latents. La différence majeur de LFMM avec les
autres modèles est qu'on ne suppose rien a priori sur les facteurs de confusion.
Dans les modèles dont nous avons parlé précédemment on estime à priori soit les
variables latentes directement soir leur matrice de covariance. l'objectif de
LFMM est d'apprendre la variation systématique observées dans les variables $\Y$
grâce aux paramètres $\U$ et $\V$ tout en prenant en compte la variable $\X$. Il
existe différentes méthodes pour estimer les paramètres de LFMM. On distingue
d'abord des approches qui reposent sur des algorithmes de Monte Carlo
cite:frichot13_testin_assoc_between_loci_envir,carvalho08_high_dimen_spars_factor_model.
Ces approches repose sur une modélisation bayésienne de LFMM qui permet
d'échantillonner les lois à posteriori des paramètres. L'avantage de ces
méthodes est qu'elles permettent d'estimer la variance du paramètre $\B$. Cela
permet de faire un test de significativité statistique. Il y a aussi des
approches qui reposent sur des algorithme EM (Expectation Maximixation)
cite:friguet09_factor_model_approac_to_multip,agarwal09_regres,zhou16_spars_multiv_factor_analy_regres.
Ces approches sont plus rapides que les méthodes utilisant des algorithmes de
Monte Carlo. Enfin, il y a les approches qui reposent sur une estimation des
variables latentes à partir d'une transformation de $\Y$
cite:gerard2017unifying,wang2015confounder,article_Leek_Storey_2007. Cette
transformation a pour but de séparer les variations de $\Y$ expliquée par les
variables latentes de celle expliquée par $\X$. Parmi cette dernière catégorie
de méthodes, on distingue des autres les méthodes dites à contrôles négatifs qui
suppose connu un sous ensemble de variable $\Y_{j}$ qui ne sont pas associées
avec $\X$. Ainsi, les méthodes a contrôles négatifs utilisent donc les variables
dites nulles pour estimer les variables latentes. 


*** Source de confusion                                          :noexport:
:LOGBOOK:
- Note taken on [2017-08-04 ven. 11:39] \\
  Je ferrais une expliation de la source de confusion pour chaque dataset !!
:END:
Les sources de confusion peuvent varier selon les différentes catégories
d'études d'association. Dans les GWAS et les GEAS, la confusion englobe des
différences systématiques dans l'ascendance génétique entre les individus
échantillonnés cite:Price_2006. Une autre source de confusion dans ces études
peut également découler d'interactions épistatiques entre les gènes
cite:Vilhj_lmsson_2012. Dans les études de profils d'expression des gènes, les
facteurs latents peuvent être les conditions expérimentales, l'âge et le sexe
des patients, leurs facteurs génétiques et l'hétérogénéité des échantillons de
tissus cite:Lazar_2012. Dans les EWAS, la confusion peut être due à des mélanges
cellulaires lorsque les cellules cibles purifiées ne sont pas disponibles
cite:jaffe14_accoun_cellul_heter_is_critic. Dans chaque catégorie, les facteurs
latents peuvent être confondus avec les variables explicatives en raison de la
nature observatoire de l'étude.

*** Plan du chapitre
Comme nous l'avons vu dans la partie précédente l'estimation des variables
latentes pour corriger les études d'association est un problème très vaste et
aucune méthode ne s'est imposée comme référence. Nous proposons ici, deux
méthodes d'estimation rapides et efficaces des paramètres du modèle LFMM dans le
cas où la fonction de lien $f$ est l'identité. Nos deux méthodes d'estimation
consiste à isolé la variabilité expliquée par les variables latentes de celle
expliquée par les variables explicatives. Les méthodes que nous présentons sont
comparable à SVA cite:article_Leek_Storey_2007 et CATE cite:wang2015confounder
qui procède d'une façon très similaire, nous décrivons plus en détail les
méthodes CATE et SVA dans la partie [[sec:similar_method]]. Chacun des algorithmes
que nous présentons découle de l'optimisation d'une fonction objectif. Nous
montrons montrons que nos algorithmes d'estimation convergent vers le point de
minimum global de leur fonction objectif respective. Enfin, nous comparons nos
méthodes à SVA et CATE sur des simulations numériques ainsi que des exemples de
GWAS, EWAS et GEA.

** Méthodes 
*** Modèle 
<<sec:model>>
Dans cette partie nous introduisons les notations du modèle mixes à facteurs
latents que nous utilisons pour corriger les test d'association : 
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Dans cette équation, $\Y$ est la matrice des variables expliquées de taille
$\Yrow \times \Ycol$, où $\Yrow$ est le nombre d'observations des $\Ycol$ de
variables expliquée. Par exemple, les variables expliquées peuvent être des
SNPs, des niveaux de méthylation ou bien des niveaux d'expression génique. La
matrice $\X$, de taille $\Xrow \times \Xcol$, représente les variables
explicatives. Les variables explicatives peuvent être par exemple un phénotype,
comme une maladie, ou un gradient environnemental, comme la température d'un
habitat. La matrice des effets de taille $\Ycol \times \Xcol$ est notée $\B$. Si
l'on suppose qu'il y a $K$ variable latentes alors la matrice $\U$ est la
matrice des $\K$ variable latentes et $\V$ représente les axes des facteurs
latents. Les matrices $\V$ et $\U$ sont respectivement la matrice des axes
factoriels, de taille $\Ycol\times\Ucol$, et la matrice des coordonnées sur ses
axes, de taille $\Urow \times \K$. Enfin la matrice $\E$ est la matrice d'erreur
résiduelle, de taille $\Yrow\times\Ycol$.

Dans un premier temps, nous remarquons que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. En effet, comme ces deux matrice sont
multiplié entre elle dans l'équation eqref:eq:model, les matrices $\U$ et
$\V$ sont définie a une matrice inversible puisque
\begin{equation}
\U \V = \U \matr{R} \matr{R}^{-1} \V^{T}
\end{equation}
où $\matr{R}$ est une matrice inversible de taille $\K \times \K$. Nous posons alors
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
et nous appelons la matrice $\W$ la matrice latente. Si l'on suppose qu'il y a $\K$
variables latentes linéairement indépendantes cela est équivalent a faire
l'hypothèse que la matrice latente $\W$ est de rang $\K$. Dans la suite nous
considérons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce à
l'analyse en composantes principales de la matrice latente $\W$.

*** Estimation des moindres carrés régularisée en norme $L_{2}$
<<sec:estimator_L2>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres de
défini par l'équation eqref:eq:model basé sur un problème des moindres carrées
régularisé en norme $L_{2}$. Nous montrons que cet algorithme permet de calculer
un minimum global du problème d'optimisation des moindres carrés.

**** Fonction objectif 

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM, nous définissons la
fonction objectif de type ridge suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lambRidge$ le paramètre de régularisation.Le terme premier terme de
$\Lridge$ (terme d'attache aux données) correspond à l'opposé de la log
vraisemblance pour un modèle où la matrice de bruit $\E$ est gaussienne,
isotrope et de moyenne nulle. Le terme deuxième terme de $\Lridge$ (terme de
régularisation) est indispensable pour séparer la variance expliqué par les
variables latentes de celle expliqué des variables explicatives. En effet, si
\begin{equation*}
\lambRidge = 0, 
\end{equation*}
alors pour toute matrice $\matr{P}$, de taille $\Xcol \times \Ycol$, nous avons
\begin{equation*}
\Lridge(\U - \X \matr{P}, \V^{T}, \B + \V \matr{P}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Les points du minimum de la fonction objective ne sont pas définis de
manière univoque pour notre problème quand le paramètre de régularisation est
nulle. 

**** Algorithme de minimisation de la fonction objectif $\Lridge$
Afin d'estimer les paramètres de LFMM minimisant $\Lridge$ nous commençons par
calculer la décomposition en valeurs singulières de la matrice des variables
explicatives
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$ de $\X$. Les estimateurs sont calculés de
la façon suivante
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V}^{T} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T}),
\end{align}
où $\svd_{\K}(\matr{A})$ est la meilleure approximation de rang $\K$ de la matrice
$\matr{A}$, donnée par la décomposition en valeurs singulières (SVD,
singular value décomposition en anglais) et $\Id_{d}$ est la matrice identité de taille $d
\times d$. La matrice $\D$ est la matrice diagonale de taille $\Yrow
\times \Yrow$ qui contient les termes diagonaux suivants
\begin{equation*}
\left\{ \D_{,i,i}\right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latente $\hat{\U} \hat{\V}^{T}$ dans
l'équation eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement
de base $\matr{Q}$. Les $\Xcol$ premiers axes de la base canonique transformée
par $\Q$ forment une base orthonormale de l'espace vectoriel engendré par les
variables explicatives. La matrice diagonale $\D$ a pour effet de réduire
la composante qui appartient à l'espace engendré par $\X$. Si $\lambRidge$ vaut
zéro la multiplication par $\D \matr{Q}^{T}$ revient à prendre le résidu
d'une régression linéaire par $\X$, on enlève alors toute la corrélation
linéaire avec $\X$. Si $\lambRidge$ est très grand alors $\D$ tend vers la
matrice identité. Dans ce cas, le calcul de $\hat{\U} \hat{\V}$ revient à faire
une analyse en composante principale de la matrice $\Y$. Il est donc important
de choisir une valeur de $\lambRidge$ qui enlève la bonne proportion de
corrélation avec les variables explicatives $\X$. Nous expliquons dans la partie
[[sec:hyperparametre]] plus en détail comment choisir l'hyperparamètre
$\lambRidge$.

L'estimation des paramètres régularisé en norme $L_{2}$ est justifié par le
théorème suivant
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambRidge$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, défini un point de
minimum global de la fonction objective $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $ \hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$ qui soit un
minimum global de la fonction $\Lridge$. Commençons par remarquer que la
fonction $\Lridge$ est convexe en la variable $\B$ , on peut donc
trouver le point de minimum global en annulant la dérivée de $\Lridge$ par
rapport à $\B$
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V).
\end{equation}
Il s'agit de l'estimateur ridge du modèle de la régression linéaire de $\Y - \U
\V$ par $\X$.

Il faut maintenant minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeur singulière de $\X$ tel que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T}
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$.L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D^{2} \matr{Q}^{T} (\Y - \U \V^{T})} + 
\frac{1}{2} \lambRidge \norm{\matr{C}_{\lambRidge} \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
où $\matr{C}_{\lambRidge}$ est une matrice de taille $\Xcol \times \Xrow$
remplie de zéro sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambRidge}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\D$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Les matrices $\D$ et $\matr{C}_{\lambRidge}$ étant diagonales, nous pouvons factoriser
$\mathcal{L}^{'}$ de sorte que 
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
Enfin, optimiser la fonction objectif $\mathcal{L}^{'}$ est équivalent au
problème de trouver la meilleur approximation de rang $\K$ de la matrice
\begin{equation*}
\D \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$ valeurs
singulières les plus grandes cite:Eckart_1936. Nous avons bien montré que
\begin{align*}
\hat{\U} \hat{\V} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\hat{\B} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof
*** Estimation des moindres carrées régularisée en norme $L_{1}$  
<<sec:estimator_L1>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle LFMM défini par eqref:eq:model basé sur un problème des moindres carrés
régularisé en norme $L_{1}$. Nous montrons que cet algorithme converge vers
un point de minimum global du problème d'optimisation.

**** Fonction objectif 
Nous proposons la fonction objective suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\W}_{*}$ la norme nucléaire de la matrice
$\W$, définie comme la somme de ses valeurs singulières.

Le choix de la norme $L_{1}$ est motivé par le fait que l'on s'attend à ce que
seulement une certaine proportion de variables expliquées soit associées aux
variables explicatives. C'est à dire que seulement une certaine proportion des
lignes de la matrice des effets $\B$ doivent être non nulles. La régularisation
$L_{1}$ est connue pour produire des estimateurs parcimonieux de $\B$
cite:Tibshirani_1996.

La fonction $\Llasso$ fait aussi intervenir une régularisation sur la matrice
latente $\W$. Ainsi la fonction $\Llasso$ est convexe et nous savons le rang de
$\hat{\W}$, point minimum de $\Llasso$, décroît avec $\gamma$ le paramètre de
régularisation devant la norme nucléaire cite:bach2008consistency.

**** Algorithme de minimisation de la fonction objectif $\Llasso$
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par blocs de coordonnées
qui permet d'estimer les paramètres de LFMM minimisant la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg.

Nous initialisons l'algorithme avec des matrices nulles : 
\begin{align*}
\W_{t = 0} & = 0 \\
\B_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. Calculer $\B_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{lasso}^{2}(\B) =  \frac{1}{2} ||(\Y - \W_{t-1}) - \X \B^T||_{F}^2 + \lambLasso ||\B||_1
   \end{equation}
2. Calculer $\W_{t}$ le point minimum de  
   \begin{equation}
   \label{eq:lasso2}
   \mathcal{L}_{lasso}^{1}(\W) = \frac{1}{2} ||(\Y - \X \B_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répétées jusqu'à ce que l'algorithme est converge ou bien que
$t$ atteint le nombre maximum d'itérations. Nous allons maintenant expliquer
plus en détail les deux étapes de l'algorithme.

La première étape de l'algorithme consiste à faire une régression linéaire
régularisée en norme $L_{1}$ de la matrice résiduelle
\begin{equation}
\matr{E}^{1}_{t} = \Y - \W_{t-1}
\end{equation}
par les variables explicatives $\X$. Il existe plusieurs algorithmes pour
estimer les paramètres de cette régression comme par exemple l'algorithme de
descente par coordonnées cite:Friedman_2007. Dans le cas présent on s'intéresse
plus à l'estimation des variables latentes, qui permettrons ensuite de faire le
test d'association (voir la partie [[sec:hypothese]]). Nous pouvons transformer les
variables explicatives de sorte que
\begin{equation}
\X^{T} \X = Id_{d}.
\end{equation}
On a alors d'après cite:Tibshirani_1996 
\begin{equation}
\B_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambLasso)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s)
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est le paramètre de la
régression linéaire classique données dans ce cas par 
\begin{equation*}
\bar{\B}_{t} = \X^{T} \matr{E}^{1}_{t}.
\end{equation*}

La deuxième étape de l'algorithme est un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \B_{t}^{T}
\end{equation}
Cette approximation est donnée grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
la matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T}
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. On a alors 
\begin{equation}
\W_{t} = \matr{M} \bar{\matr{S}} \matr{N}^{T}
\end{equation}
où $\bar{\matr{S}}$ est la matrice diagonale formé par les les valeur singulière
de $\matr{S}$ seuillées. Ainsi les termes diagonaux de $\bar{\matr{S}}$ sont de
sorte que 
\begin{equation*}
\bar{s}_{j} = (s_{j} - \gamma)_{+}, ~ j = 1,...,\Yrow.
\end{equation*}
Ce seuillage produit des valeurs nulles et ramène vers zéro les valeurs
singulières restantes.

L'algorithme de descente par blocs de coordonnées ne converge pas en général
vers un point minimum quand la fonction n'est pas continûment différentiable,
comme c'est le cas pour $\Llasso$. On peut trouver dans la littérature des
résultats sur les algorithmes par blocs de coordonnées dans des cas ou la
fonction objective n'est pas différentiable cite:Tseng_2001 . Cependant, les
théorèmes démontrer dans cite:Tseng_2001 dépasse largement le cadre de la
convergence de l'algorithme d'estimation $L_{1}$ présenté ici ce qui complique
l'extraction des résultats intéressants. Pour facilité la compréhension, nous
proposons de démontrer un théorème plus faible qui s'applique directement à
notre cas. Pour cela nous introduisons quelques notations. Soit la fonction $f$
définie sur son domaine
\begin{equation}
\label{eq:domf}
A = A_{1} \times A_{2} \times ... \times A_{m}
\end{equation}
un produit cartésien d'ensembles fermés et convexes. L'algorithme de descente par
blocs de coordonnées est défini par la formule de récurrence suivante :
\begin{equation}
\label{eq:blokAlgo}
x_{i}^{k+1} \in \mathrm{arg} \min_{\zeta \in X_{i}} f(x_{1}^{k}, ...,x_{i-1}^{k},\zeta,x_{i+1}^{k},..., x_{m}^{k}), ~
i = 1,...,m.
\end{equation}
En nous inspirant des résultats présenté dans cite:Tseng_2001 et de la
proposition 2.7.1 de cite:Bertsekas_1997 qui montre la convergence de
l'algorithme de descente par bloc de coordonnées dans le cas la fonction
objectif est différentiable, nous démontrons le théorème suivant :
#+BEGIN_theorem 
Si $f$ est continue, convexe et tel que
\begin{equation}
f(x_{1},..., x_{m}) = g(x_{1}, ..., x_{m}) + \sum_{i = 1}^{m} f_{i}(x_{i}) 
\end{equation}
où g est convexe et différentiable et les fonctions $f_{i}$ sont continues et
convexes. Soit $\{x^{k}\}$ la séquence générée par eqref:eq:blokAlgo. Alors tout
point limite de $\{x^{k}\}$ est un point de minimum global de $f$.
#+END_theorem

#+BEGIN_proof 
On note
\begin{equation*}
\bar{x} = (\bar{x}_{1}, ..., \bar{x}_{m})
\end{equation*}
un point limite de $\{x^{k}\}$, $\bar{x}$ est bien dans $A$ le domaine de
définition de $f$ car cet ensemble est fermé. Comme $g$ est convexe et
différentiable on a pour tout $x \in A$
\begin{align}
\label{eq:lassoProof1}
f(x) - f(\bar{x}) & \geq & \nabla g(\bar{x})(x - \bar{x}) + 
\sum_{i = 1}^{N} (f_{i}(x_{i}) - f_{i}(\bar{x}_{i})) \\
 & & = \sum_{i = 1}^{N} ( \nabla_{i} g(\bar{x})(x_{i} - \bar{x}_{i}) + 
 f_{i}(x_{i}) - f_{i}(\bar{x}_{i}))
\end{align}
où $\nabla g(\bar{x})$ et $\nabla_{i} g(\bar{x})$ sont respectivement la dérivée
et la dérivée par rapport à la $i\text{-ième}$ variable de $g$ en $\bar{x}$. Or
nous savons par construction de $\bar{x}$ que
\begin{equation}
\label{eq:lassoProof2}
f(\bar{x}) \leq f(\bar{x}_{1}, ...,x_{i},..., \bar{x}_{m}), ~ \forall x_{i} \in
A_{i}.
\end{equation} 
On a donc pour chaque variable d'indice $i$
\begin{align}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  (\nabla_{i} g(\bar{x}) + r_{i})(x - \bar{x}) \\
\label{eq:lassoProof3}
& \geq 0
\end{align}
où $r_{i}$ est une sous-dérivée de la fonction convexe $f_{i}$. En effet,
l'équation eqref:eq:lassoProof2 nous permet de dire qu'il existe une
sous-dérivée $r_{i}$ tel que
\begin{equation}
\label{eq:3}
(\nabla_{i} g(\bar{x}) + r_{i}) = 0
\end{equation}
d'où l'équation eqref:eq:lassoProof3. Finalement, nous avons en utilisant
eqref:eq:lassoProof3 et eqref:eq:lasso1 
\begin{equation}
f(x) - f(\bar{x}) \geq 0, ~ \forall x \in A.
\end{equation}
#+END_proof
Ce résultat démontre que l'algorithme d'estimation $L_{1}$ des paramètres du
modèle LFMM converge vers un point de minimum global de $\Llasso$.
*** Complexité des algorithmes
Dans cette partie nous abordons la complexité des algorithmes d'estimation des
paramètres présentées dans les parties précédentes. On peut distinguer deux
grandes étapes dans ces algorithmes. La première est le calcul de la
décomposition en valeur singulière tronqué (voir le calcul de la matrice
latente donné par l'équation eqref:eq:RidgeLfmmEstomatorW pour l'estimation
$L_{2}$ et la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{lasso}^{1}$ définie par eqref:eq:lasso2 pour l'estimation
$L_{1}$). La seconde est le calcul de la projection orthogonale sur l'espace
engendré par les variables explicatives (voir le calcul de $\W$ donné par
l'équation eqref:eq:RidgeLfmmEstomatorB pour l'estimation $L_{2}$ et la
résolution du problème d'optimisation de la fonction $\mathcal{L}_{lasso}^{2}$
définie par eqref:eq:lasso1 pour l'estimation $L_{1}$).

D'après cite:Halko_2011, le calcul des $K$ composantes dominantes de la
décomposition en valeurs singulières demande $O(\Yrow \Ycol \K)$ opérations.
Cette complexité temporelle peut même être réduite à $O(\Yrow \Ycol \log(\K))$
si on utilise une méthode avec projections aléatoires, comme celle présenté dans
cite:Halko_2011.

La deuxième étape importante consiste en une projection du résidu de
l'approximation de rang faible sur l'espace engendré par $\X$. Le nombre précis
d'opération dépend des hypothèses qui sont faites sur la matrice $\X$ (dans
l'algorithme d'estimation $L_{1}$ aucune inversion de matrice n'est nécessaire
pour le calcule de $\B_{t}$). Mais dans les deux algorithmes, si on s'intéresse
seulement au comportement asymptotique par rapport à $\Yrow$, $\Ycol$ et $\Ucol$,
alors on peut majorer la complexité temporelle par $O(\Ycol \Yrow + \Ucol
(\Ycol + \Yrow))$.

Finalement, pour les deux algorithmes, le nombre d'opération est majoré par
$O(\Yrow \Ycol \K)$. L'algorithme d'estimation $L_{1}$ est bien entendu plus
long car il réalise plusieurs fois (le nombre d'itérations dépend de la vitesse
à laquelle l'algorithme converge) les opérations de décomposition en valeurs
singulières et de projection alors que l'algorithme d'estimation $L_{2}$ ne les
réalise qu'une seule fois.

Outre la complexité temporelle il est important d'étudier la complexité
spatiale, surtout pour ce genres d'algorithme qui prennent en entrée des données
potentielles trop grandes pour la mémoire vive de l'ordinateur (RAM). Les
algorithmes d'estimation $L_{1}$ et $L_{2}$ ne nécessite pas de dupliquer la
matrice des variables explicatives $\Y$. La matrice $\Y$ est de taille
$\Yrow \times \Ycol$ et donc la dupliquer pourrait poser des problèmes sur des
ordinateurs ne possédant pas assez de RAM. Il est même possible d'envisager de ne
pas charger la matrice $\Y$ en RAM et d'accéder au données seulement quand cela est
nécessaire. 

*** Choix des hyperparamètres 
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

La sélections des hyperparamètres est un problème commun a de nombreuse méthodes
en analyse de données. Nous présentons plusieurs approches pratiques pour
choisir les hyperparamètre qui interviennent dans les algorithmes que nous
présentés ici. Nous commençons par présenter les différentes approches possibles
pour choisir le nombre de variables latentes $K$. Nous présentons ensuite
plusieurs heuristiques qui permettent d'aider le choix des paramètres de
régularisation. Enfin nous présentons un algorithme de validation croisée adapté
aux algorithmes que nous avons présentés.

**** Nombre $\K$ de variables latentes
Nous avons vu dans la section [[sec:estimator_L2]] que la matrice latente $\W$ peut
être estimée grâce à l'analyse en composante principale (ACP) de $\D \Q^{T} \Y$.
Ainsi, afin d'estimer le nombre $\K$ de variable latente pour le modèle LFMM,
nous proposons d'employer les techniques d'estimation du nombre de variables
latentes utilisées pour l'ACP sur la matrice $\D \Q^{T} \Y$ .

Il existe de nombreuses approches pour déterminer le nombre de composantes
principales de l'ACP, celle-ci sont très bien expliquées dans
cite:jolliffe1986principal. On peut grouper ses approches en trois catégories.
Les approches subjectives comme l'utilisation du scree plot, il s'agit du graphe
des valeurs singulières de la matrice des données. Les approches basées sur une
modélisation de la distribution des données observées, comme par exemple la
méthode présentée dans cite:choi2014selecting. Les approches basées sur la
validation croisée, comme celle que nous détaillons plus loin.

Aucune méthode ne s'est imposée comme la référence, et il est préférable d'en
utiliser plusieurs. Pour les expériences que nous avons réalisées sur des vraies
données, le choix du nombre de variables latentes $\K$ du modèle LFMM a été fait à
partir du scree plot de la matrice $\D \Q^{T} \Y$ pour différente valeurs de
$\lambRidge$ et de la validation croisée.

**** TODO Paramètre de régularisation $L_{2}$
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 16:55]
- Note taken on [2017-07-20 Thu 16:54] \\
  j'y verrai plus claire quand j'aurais choisi lambda pour les vrai data set et
  une fois que la cross validation marchera ou pas...
:END:
Le paramètre de régularisation $L_{2}$ intervient dans le calcul de
l'estimation de la matrice latente décrit dans la partie [[sec:estimator_L2]] par le
biais de la matrice diagonal $\D$. Cette matrice permet de réduire la
corrélation entre les variables expliquées $\Y$ et les variables explicatives
$\X$ afin de pouvoir estimer les variables latentes. 

Si le paramètre de régularisation $L_{2}$ tend vers zéro, les variables expliqué
et explicative seront linéairement décorrélé. Cependant on ne pourra plus inverser
la matrice diagonale $\D$. De plus dans le cas ou les variable latentes sont
trop corrélé avec $\X$ alors on risque de mal estimer celles-ci. 

Si le paramètre tend vers l'infini alors la matrice $\D$ tend vers la matrice
identité l'estimation des variables latentes sont données pas l'analyse en
composante principale de $\Y$.

Ainsi le choix de du paramètre de régularisation $L_{2}$ est une affaire de
dosage, il doit être ni trop grand ni trop petit. Nous avons remarqué dans les
expériences que $\lambdaRidge$ petit donne les meilleurs résultats dans de nombreux
cas.

**** Paramètre de régularisation $L_{1}$
Le paramètre de régularisation $L_{1}$ à un impacte sur le nombre de ligne non
nulles dans la matrice des effets $\B$. Nous savons à priori que seulement une
partie des variables expliquées sont corrélé avec les variables explicatives.
Ainsi, il est possible d'interpréter la proportion de lignes non nulles dans
$\B$ comme la proportion des variables qui sont corrélé avec $\X$. Plutôt que de
choisir le paramètre de régularisation, il est plus simple de choisir la
proportion de variable expliquées par $\X$. Pour trouver un paramètre de
régularisation qui correspond à cette proportion nous proposons une heuristique
basée sur un chemin de régularisation inspiré par
cite:friedman10_regul_paths_gener_linear_model.

Nous commençons par la plus petite valeur du paramètre de régularisation
$\lambLasso$ tel que le vecteur
\begin{equation}
\bar{\B}_{t} = (\X^{T} \X + \lambLasso \Id_{d})^{-1} \X^{T} (\matr{E}^{1}_{t = 1})
\end{equation}
vaut zéro. Ceci est le résultat de la première étape de l'algorithme
d'estimation des moindres carrés régularisée en norme $L_{1}$ présenté dans la
partie [[sec:estimator_L1]]. Nous notons cette valeur $\lambLasso^{\mathrm{max}}$.
Ensuite, nous construisons une séquence de $m$ valeurs de $\lambLasso$ décroissant
selon une échelle logarithmique depuis $\lambLasso^{\mathrm{max}}$ jusqu'à
\begin{equation}
\lambLasso^{\mathrm{min}} = \epsilon \lambLasso^{\mathrm{max}}.
\end{equation}
Enfin, nous calculons le nombre de valeurs non nulle dans $\hat{\B}$
l'estimation de la matrice des effets et stoppons si la proportion de valeurs
non nulle souhaitée est dépassée.


**** Paramètre de régularisation de la norme nucléaire
Le paramètre de régularisation de la norme nucléaire dans l'algorithme
d'estimation $L_{1}$ à une influence sur le rang de la matrice latente $\W$. Il
est plus simple de choisir le rang de cette matrice, qui correspond au nombre de
variables latentes $K$, que de choisir le paramètre de régularisation $\gamma$.

Nous proposons l'heuristique suivante pour calculer $\gamma$ à partir de $K$.
Nous commençons par calculer les valeurs singulières de la matrice des variables
expliquées $\Y$, que l'on note $(\sigma_1, ..., \sigma_{\Yrow})$. Ensuite, on calcul 
\begin{equation}
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2}.
\end{equation}

**** Validation croisée
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:00]
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:

La validation croisée est une méthode d'évaluation d'un modèle très utilisé en
apprentissage statistique. Le principe est de séparé les observation en une partie
d'apprentissage et une partie de test. Les observations d'apprentissage sont utilisées
pour estimer les paramètres du modèle. On mesure ensuite l'erreur de prédiction
à l'aide des observations de tests. Pour que la validation croisée fonctionne il est
très important que les observations de test ne soit pas utilisées pour estimer les
paramètres du modèle. Dans le cas des modèles à facteurs latents, les observations
d'apprentissage ne permettent pas de calculer les variables latentes pour les
observation de tests (la matrice $\U$ dans pour LFMM). Le plus simple est de séparer
les variables expliquées des observations de test et d'en utiliser une partie pour estimer
les variables latentes et l'autre partie pour calculer l'erreur de prédiction
cite:Bro_2008. Nous présentons maintenant plus formellement notre procédure de
validation croisée.

Nous commençons par séparer les observations des variables expliquées et
explicative (les lignes des matrices $\Y$ et $\X$) en une partie d'entraînement
et une partie de test. Nous notons $I$ l'ensemble des indices des observations
choisies pour estimer l'erreur de prédiction. On estime à partir des
observations d'apprentissage la matrice des axes factoriels que l'on note
$\hat{\V}_{-I}$ et la matrice des effets que l'on note $\hat{\B}_{-I}$. Ensuite,
nous retirons aux observation de test une partie des variable expliqué (les
colones de la matrice $\Y$) afin d'estimer les variables latentes pour les
observations de test. On notera $J$ l'ensemble des indices de expliquée que l'on 
retire pour l'estimation de la matrice des variable latentes calculé de
la façon suivante
\begin{equation}
\hat{\U}_{-J} = (\Y[I,-J] - \X[I,] (\hat{\B}_{-I}[J,])^{T}) \hat{\V}_{-I}[-J,]^{T}.
\end{equation}
Enfin, on peut calculer l'erreur de prédiction comme ceci
\begin{equation}
\label{eq:2}
\mathrm{err} = \frac{1}{|I| |J|} \norm{\Y[I, J] - \hat{\U}^{-J} \hat{\V}_{-I}[J,]^{T} - \X[I, ] \hat{\B}_{-I}[J,]^{T} }_{F}.
\end{equation}


*** Test d'hypothèse
<<sec:hypothese>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Jusque ici, nous avons seulement abordé l'estimation des paramètres de LFMM.
Cependant, l'objectif initial est de trouver la liste des variables expliquées
associées aux variables explicatives tout en prenant en compte les potentielles
variables latentes. Nous présentons dans cette partie un test d'hypothèse
corrigé pour les variables latentes.

Une approche simple consiste a considérer que l'estimation des variables
latentes $\hat{\U}$ comme les vraies valeurs de $\hat{\U}$ et de les utiliser au
coté des variables explicatives du modèle mis en place pour réaliser le test
d'hypothèse. C'est une méthode très courante dans les études d'associations qui
a montrer de très bon résultats surtout quand il y assez d'observations
cite:gerard2017unifying,Price_2006,Song_2015,article_Leek_Storey_2008,Rahmani_2016.
Nous avons choisi de réaliser un test d'hypothèse qui repose sur le modèle la
régression linéaire car cela correspond au modèle LFMM quand on suppose que $\U$
est connue. Mais les estimations des variables latentes peuvent être traitées comme
variables explicatives dans n'importe quel modèle statistique.

Afin de simplifier les notations et sans perte de généralité, nous supposons
qu'il n'y a qu'une seule variable explicative, c'est à dire que $\Xcol$ vaut $1$.
De plus nous rappelons que l'estimation de la matrice des $\K$ variables
latentes $\hat{\U}$ est définie de façon unique grâce à l'ACP de la matrice
$\hat{\W}$. La matrice $\hat{\W}$ est l'estimation $L_{1}$ ou $L_{2}$ de la
matrice latente du modèle LFMM.

**** Calcul de la statistique de test
Pour chaque variable expliquée $j$ nous avons le modèle de régression linéaire
suivant
\begin{equation}
\Y_{j} =  \hat{\U} \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{\epsilon_{j}}.
\end{equation}
où la matrice $\hat{\U}$ est l'estimation $L_{1}$ ou $L_{2}$ de la matrice des
variables latentes du modèle LFMM. On suppose que l'erreur $\matr{\epsilon_{j}}$
est Gaussienne de moyenne nulle. On veut tester l'hypothèse de nullité du
coefficient de régression $\beta_{j}$. Sous ces hypothèses on peut calculer pour
chaque variable expliquée une statistique $z_{j}$. Le détail des calculs de la
statistique de test est données dans la section 3.2 de cite:Hastie_2009. La
statistique de test suit sous l'hypothèse nulle le loi de Student à $\Yrow -
\K - 1$ degrés de liberté. On peut donc calculer pour chaque variable expliquée
une \pvalue.


**** Calibration du test d'hypothèse
Il arrive parfois que la statistique de suive pas la distribution théorique sous
l'hypothèse nulle. On dit dans ce cas que le test est mal calibré. On peut
trouver dans cite:Efron_2004 des exemples de situations qui peuvent aboutir à
des tests mal calibrés. 

Dans les exemples que nous présentons ici ont s'attend à ce que la majorité des
variables expliqués ne soit pas associé avec la variable explicative, ainsi une
large majorité des statistiques de test sont distribuées selon l'hypothèse nulle.
Nous utilisons l'approche choisi dans cite:Sun_2012, qui consiste à calculer la
médiane et la déviation absolue à la médiane (MAD pour median absolute
déviation) directement sur les $z$ statistiques. En effet, la médiane donne une
estimation robuste de la moyenne et le MAD de l'écart type. On a alors une
nouvelle statistique de test
\begin{equation}
\tilde{z_{j}} = \frac{z_{j} - \med(z_{1}, ..., z_{\Ycol})}{
\mad(z_{1}, ..., z_{\Ycol})}.
\end{equation}
Pour calculer les nouvelles \pvalue, on suppose que $\tilde{z_{j}}$ suit une loi
normal de moyenne nulle et d'écart type 1 sous l'hypothèse nulle.

**** Contrôle du taux de fausse découverte                      :noexport:
:LOGBOOK:
- Note taken on [2017-07-19 Wed 10:44] \\
  non si je fais une partie la dessus il va falloir que je developpe !! alors que
  je veux juste dire que j'ai utilisé qvalue....
:END:
Dans cette dernière partie, nous présentons en quelques mots les outils que nous
avons utiliser pour controler le taux de fausse découvertes dans les
experiences. Dans le cadre des test d'association nous voulons en sortie de la
méthode obtenir une liste de variable expliqué candidat pour l'association avec
la variable explicative. Pour choisir cette liste 
Dans le cadre des test d'association multiple 

** Méthodes comparées
<<sec:similar_method>>
*** lm and lm + pca
We comparared results of our method to two well known method the linear model
and the linear model with PCA scores. 
*** cate

*** sva
*** famt
** Expériences
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:


*** Description des expériences                                  :noexport:
**** TODO Influence de lambda sur les estimations
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 13:53] \\
  ca va faire des sup mat. C'est pour justifier le choix de lambda petit ! deux
  graphe: err X prop outlier et err X angle
- State "TODO"       from              [2017-06-29 jeu. 13:48]
:END:
**** TODO Influence des valeurs manquantes sur l'estimation des variables latentes
:LOGBOOK:
- State "TODO"       from              [2017-06-29 jeu. 13:47]
- State "TODO"       from              [2017-06-29 jeu. 13:45]
:END:
**** TODO Influence des hyper paramètres
:LOGBOOK:
- Note taken on [2017-07-10 lun. 09:12] \\
  Il faut que je montre comment les estimateur évolue en fonction de K, lambda et
  gamma. Montrer que la cross validation marche aussi !
- State "TODO"       from              [2017-07-10 lun. 09:12]
:END:
**** STARTED EAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:
***** TODO Scree plot du 1000 genome pour EAS
:LOGBOOK:
- Note taken on [2017-07-25 mar. 17:52] \\
  faut que je reance avec lambda
- State "TODO"       from "RUNNING"    [2017-07-25 mar. 17:49]
- Note taken on [2017-07-25 mar. 17:46] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_screeplot.y2017_m07_d25_17h_37.log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:46]
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:

#+NAME: code:eas_screeplot
#+CAPTION: Dépend de [[code:eas_prepross]] [[code:eas_climatic_gradient]]
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = NULL, outlier = NULL) * param()

  lambda <- c(1e-5, 1.0, 1e8)

  ## methods
  methods <- method_PCA(scale = FALSE) * param(lambda = lambda)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr)

    pl <- ggplot(expr$df.res, aes(x = index, y = singular.value, color = lambda)) +
      geom_point() + 
      coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "EAS_sree_plot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/EAS_sree_plot.png]]


***** DONE Validation croisée du modèle lfmmRidge sur 1000genome
CLOSED: [2017-07-11 mar. 14:36]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e8) / n
  nb.cluster <- 2
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,4,5,10,15))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "eas_CV_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "eas_CV_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda.png]]
[[./OUTPUT/Rplots/eas_CV_K.png]]

***** STARTED Étude du jeu de données
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 7
  nb.cluster <- 2
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EAS_all.rds")


#+end_src

****** Charger l'experience
#+BEGIN_SRC R
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EAS_all.rds")
#+END_SRC
****** Que donne la calibration ?
#+BEGIN_SRC R
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS:
#+begin_example
  # A tibble: 7 x 3
       method       mad     median
        <chr>     <dbl>      <dbl>
  1      cate 1.1636647 0.02952085
  2      famt 0.7583801 0.54186725
  3 lassoLFMM 0.9976638 0.01602369
  4        lm 2.1461003 0.57581267
  5     PCAlm 0.9873353 0.01161204
  6 ridgeLFMM 1.1645450 0.03903020
  7       sva 0.7385787 0.53293170
#+end_example

****** Les qqplots ?
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
  pll
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots.png]]
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

****** Le top 15
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(15)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_top_inter.png]]

****** Contrôle du FDR à $0.01$
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

****** Venn diagram
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")


  ## see common snps
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- sets[2:5]
  candidates.snps.df <- toplot %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  snps <- unique(candidates.snps.df$colname)
  snps
  ## annotation
  require(biomaRt)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att <- c("p_value", "ensembl_mart_snp")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]

****** TODO Annotation
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:
#+BEGIN_SRC R
  require(biomaRt)

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM")) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att

  toplot <- toplot %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db, att)

  toplot %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()
#+END_SRC

****** TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src

**** STARTED GWAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
***** STARTED SNPs détecté par d'autre analyse
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R :results output :exports both :session *ssh krakenator*
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")


  ## join by marker_ID
  celiac.outlier <- celiac$map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", nrow(celiac.outlier), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac$map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Le chargement a nécessité le package : bigmemory
Le chargement a nécessité le package : bigmemory.sri

Attachement du package : ‘bigmemory.sri’

The following object is masked from ‘package:testthat’:

    describe

Le chargement a nécessité le package : bigstatsr
Joining, by = "marker.ID"
nb of candidates: 60
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

*Candidates for G_clumped and test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  dat <- Article3_Celiac_sampler(clumped = FALSE) %>%
    sampl()

  snps.name <- colnames(dat$G)[dat$outlier]
  snps.name
  length(snps.name)


  ## for clumped dataset
  rm(dat)
  gc()
  G <- readRDS('~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds')
  candidates.clumped <- which(colnames(G) %in% snps.name)
  length(candidates.clumped)
  colnames(G)[candidates.clumped]
  saveRDS(candidates.clumped, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
#+end_src

#+RESULTS:
#+begin_example
  > snps.name
   [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
   [6] "rs859637"   "rs2157453"  "rs2816316"  "rs296547"   "rs13003464"
  [11] "rs10188217" "rs13015714" "rs917997"   "rs13010713" "rs7574865" 
  [16] "rs4675374"  "rs13098911" "rs6441961"  "rs17810546" "rs10936599"
  [21] "rs1464510"  "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
  [26] "rs2474619"  "rs10806425" "rs531930"   "rs802734"   "rs2327832" 
  [31] "rs1738074"  "rs212402"   "rs212388"   "rs6974491"  "rs9792269" 
  [36] "rs975730"   "rs1953126"  "rs1250552"  "rs10876993" "rs653178"  
  [41] "rs2762051"  "rs1958589"  "rs4899260"  "rs12928822" "rs2074404" 
  [46] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428" 
  > length(snps.name)
  [1] 49
  > length(candidates.clumped)
  [1] 10
  > colnames(G)[candidates.clumped]
   [1] "rs10903122" "rs859637"   "rs13010713" "rs1464510"  "rs1020388" 
   [6] "rs1738074"  "rs653178"   "rs1958589"  "rs1893217"  "rs157640" 
#+end_example
***** DONE Scree plot
CLOSED: [2017-07-30 Sun 11:28]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-30 Sun 11:28]
- Note taken on [2017-07-30 Sun 11:27] \\
  c'est fait mais la projection change rien !!
- State "RUNNING"    from "DEBUG"      [2017-07-26 mer. 18:09]
- Note taken on [2017-07-26 mer. 18:09] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:07] \\
  On va relancer sans Rspectra, ca prend trop de temps !!!!
- State "DEBUG"      from "DONE"       [2017-07-26 mer. 18:06]
- State "DONE"       from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "STARTED"    [2017-07-25 mar. 18:21]
- Note taken on [2017-07-25 mar. 18:19] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d25.log
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:

#+NAME: code:gwas_screeplot
#+CAPTION: Dépend de 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds"
  X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"

  lambdas <- c(1e-5, 1.0, 1e10)

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param(lambda = lambdas)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr, "gwas_screeplot_expr.rds")

  toplot <- expr$df.res %>%
    mutate(lambda = as.factor(lambda))
  pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "gwas_screeplot.png")

#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]
[[./OUTPUT/Rplots/gwas_screeplot.png]]

On prend K = 9 variables latentes.

***** DEBUG Validation croisée avec lfmmRidge
:LOGBOOK:
- State "DEBUG"      from "RUNNING"    [2017-08-03 jeu. 14:17]
- Note taken on [2017-08-03 jeu. 14:16] \\
  ca buggé, le processus c'est fait tuer. Il en était a au bout de 5 jours...
  > res.cv <- ExpRmouline(cv, dat)
  === params
    lambda K
  1  1e-05 1
  === params
    lambda K
  2      1 1
  === params
    lambda K
  3  1e+10 1
  === params
    lambda K
  4  1e-05 2
  === params
    lambda K
  5      1 2
  === params
    lambda K
  6  1e+10 2
- State "RUNNING"    from "TODO"       [2017-07-30 Sun 11:31]
- Note taken on [2017-07-30 Sun 11:31] \\
  c'est parti : tail -f /home/cayek/tmp/Logfiles/gwas_CV.y2017_m07_d30.log
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,7,10,15, 30))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K.png")
#+end_src
***** DONE Étude du jeu de données 
CLOSED: [2017-07-28 ven. 09:25]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-28 ven. 09:25]
- Note taken on [2017-07-27 jeu. 13:50] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_run.y2017_m07_d27.log
- State "RUNNING"    from "DEBUG"      [2017-07-27 jeu. 13:50]
- State "DEBUG"      from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "DEBUG"      [2017-07-24 Mon 07:35]
- State "DEBUG"      from "DONE"       [2017-07-24 Mon 06:58]
- State "DONE"       from "RUNNING"    [2017-07-24 Mon 06:58]
- Note taken on [2017-07-23 Sun 16:13] \\
  C'est reparti !! sur krakenator en dehors de annaconda biensur !! pour que
  matter marche (pour avoir R 3.4)
- State "RUNNING"    from "DEBUG"      [2017-07-23 Sun 16:13]
- State "DEBUG"      from "DONE"       [2017-07-17 Lun 08:18]
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:18]
- Note taken on [2017-07-17 Lun 08:18] \\
  lasso c'est planté !! il faudra le relancer mais le reste est OK !!
- Note taken on [2017-07-13 jeu. 08:55] \\
  C'est reparti sur krak !!
- State "RUNNING"    from "STARTED"    [2017-07-13 jeu. 08:55]
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:

#+NAME: code:gwas_expr
#+CAPTION: Etude d'association des données Celiac avec cate ridgeLFMM LassoLFMM LM et LMPCAS. Dépend de 
#+begin_src R
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 9
  lambda <- 1e-5
  nozero.prop <- 0.005

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## methods
  methods <- list()
  methods$m.lm <- method_lm(col.mask = col.mask,
                            inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lm.rds",
                            inter.res.file = "./OUTPUT/Expr/celiac_inter_lm.rds")
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = K.method,
                                  col.mask = col.mask,
                                  inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds",
                                  inter.res.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds")
  methods$m.pca <- method_PCAlm(K = K.method,
                                col.mask = col.mask,
                                inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds",
                                inter.res.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds"
                                )
  methods$m.cate <- method_cate(K = K.method,
                        col.mask = col.mask,
                        inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        inter.res.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        hp = "lm"
                        )
  methods$m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6,
                              col.mask = col.mask,
                              inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds",
                              inter.res.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds"
                              )

  run_celiac <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("celiac_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    if (file.exists(out.file.path)) {
      message("Reading ", out.file.path)
      df <- readRDS(out.file.path)
    } else {
      message("Running method")
      m <- ExpRmouline(m, dat)
      df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
      ## save expr
      message("Saving output in ", out.file)
      save_expr(df, out.file)
    }
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_celiac(m) %>%
      rbind(res.df)
  }
  save_expr(res.df, "celiac_all_df.rds")
#+end_src

#+RESULTS:
#+begin_example
  =============== lassoLFMM
  Running method
  mask data
  Computing latent variables
  It = 1/100, err2 = 0.999934015123588
  It = 2/100, err2 = 0.994766206506411
  === lambda = 0.130189891797758, no zero B proportion = 0.00059261140565309
  It = 1/100, err2 = 0.994766373173339
  === lambda = 0.0976286459727577, no zero B proportion = 0.000878334761950115
  It = 1/100, err2 = 0.994765532716069
  === lambda = 0.0732111562799394, no zero B proportion = 0.00126988158354233
  It = 1/100, err2 = 0.994764638534954
  === lambda = 0.05490062215286, no zero B proportion = 0.00164026371207552
  It = 1/100, err2 = 0.994763845022762
  === lambda = 0.0411696586411789, no zero B proportion = 0.0020106458406087
  It = 1/100, err2 = 0.994763196094342
  === lambda = 0.0308728886152139, no zero B proportion = 0.00292072764214737
  It = 1/100, err2 = 0.994762606837317
  It = 2/100, err2 = 0.99476121574158
  === lambda = 0.0231514003979148, no zero B proportion = 0.0106352582621671
  Saving intermediate res into./OUTPUT/Expr/celiac_inter_lassolfmm.rds
  unmask data
  running hp
       pvalue   colname index outlier    score rep.sampler rep.method    method
  1 0.5255378 rs3934834     1   FALSE 0.634847           1          1 lassoLFMM
    method.K method.lambda
  1        9            NA
  Saving output in celiac_df_lassoLFMM.rds
  Expr save in ./OUTPUT/Expr/celiac_df_lassoLFMM.rds

#+end_example
****** Que donne la calibration

#+NAME: code:gwas_expr_calibration
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  expr %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:gwas_expr_calibration
: # A tibble: 5 x 3
:      method      mad       median
:       <chr>    <dbl>        <dbl>
: 1      cate 1.052221  0.011781682
: 2 lassoLFMM 1.045186  0.012433327
: 3        lm 1.201294 -0.023610211
: 4     PCAlm 1.037876  0.009601749
: 5 ridgeLFMM 1.061488  0.007643094
****** Gwas catalogue et controle du fdr

#+NAME: code:gwas_expr_fdr
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  toplot <- expr %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.05)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "gwas_fdr01_inter.png")

#+end_src

#+RESULTS: code:gwas_expr_fdr
[[./OUTPUT/Rplots/gwas_fdr01_inter.png]]
: # A tibble: 5 x 2
:      method     power
:       <chr>     <dbl>
: 1      cate 0.7755102
: 2 lassoLFMM 0.7959184
: 3        lm 0.5714286
: 4     PCAlm 0.5102041
: 5 ridgeLFMM 0.7346939

**** DONE EWAS
CLOSED: [2017-07-11 mar. 11:45]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-07-11 mar. 11:45]
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
***** Sites candidats detectés dans d'autres études
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+NAME: code:ewas_candidates
#+CAPTION: Dépend de [[code:ewas_G_X]]
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
***** DONE Scree plot 
CLOSED: [2017-07-25 mar. 18:05]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-25 mar. 18:05]
- Note taken on [2017-07-25 mar. 17:56] \\
  tail -f ewas_screeplot.y2017_m07_d25_krakenatorh_juil..log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:51]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:

#+NAME: code:ewas_screeplot
#+CAPTION: Dépend de [[code:ewas_G_X]] 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- "./Data/ThesisDataset/3Article/GSE42861/X.rds"

  lambdas <- c(1e-5, 1.0, 1e10)

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param(lambda = lambdas)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr, "ewas_screeplot_expr.rds")

  toplot <- expr$df.res %>%
    mutate(lambda = as.factor(lambda))
  pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,300))

  save_plot_png(pl, "ewas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-07-27 jeu. 10:49]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 10:49]
- Note taken on [2017-07-26 mer. 19:36]
- Note taken on [2017-07-26 mer. 18:05] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_cv_lambda.y2017_m07_d26.log
  tail -f /home/cayek/tmp/Logfiles/ewas_cv.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 17:56] \\
  On va relancer... il y avait des bug dans la CV...
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 17:56]
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+NAME: code:ewas_CV
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,20, 25,30, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

#+NAME: code:ewas_CV_lambda
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1.0, 1e5, 1e10)
  nb.cluster <- 5
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(10))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lambda_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda.png")

  ## plot smooth
  pl <- ggplot(res.cv$errs, aes(y = err, x = log(lambda))) +
    geom_smooth()
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda_smooth.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda_smooth.png]]
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda.png]]

***** DONE Étude du jeu de données
CLOSED: [2017-07-27 jeu. 11:01]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 11:01]
- Note taken on [2017-07-26 mer. 19:44] \\
  Du coup j'ai relancé avec K = 10 et le bon lasso !!!!!! on va voir
- Note taken on [2017-07-26 mer. 19:43] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 19:43]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:

#+NAME: code:ewas_expr
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")


#+end_src

#+NAME: code:ewas_expr_log
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src shell :session *ssh krakenator* :results output 
  cat /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
#+end_src

#+RESULTS: code:ewas_expr_log
#+begin_example
  R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
  Copyright (C) 2017 The R Foundation for Statistical Computing
  Platform: x86_64-redhat-linux-gnu (64-bit)
  
  R est un logiciel libre livré sans AUCUNE GARANTIE.
  Vous pouvez le redistribuer sous certaines conditions.
  Tapez 'license()' ou 'licence()' pour plus de détails.
  
  R est un projet collaboratif avec de nombreux contributeurs.
  Tapez 'contributors()' pour plus d'information et
  'citation()' pour la façon de le citer dans les publications.
  
  Tapez 'demo()' pour des démonstrations, 'help()' pour l'aide
  en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
  Tapez 'q()' pour quitter R.
  
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  foreach: simple, scalable parallel programming from Revolution Analytics
  Use Revolution R for scalability, fault tolerance and more.
  http://www.revolutionanalytics.com
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
             disease.state
  GSM1051525     0.9720875
  GSM1051526     0.9720875
  GSM1051527     0.9720875
  GSM1051528     0.9720875
  GSM1051529     0.9720875
  GSM1051530     0.9720875
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
  +                             lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
  +   m.lm * param() +
  +   m.pca * param() +
  +   m.cate * param() +
  +   m.famt * param() +
  +   m.sva * param() +
  +   m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9528 on localhost:11939 at 19:35:29.343
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9538 on localhost:11939 at 19:35:33.199
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9548 on localhost:11939 at 19:35:37.112
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9558 on localhost:11939 at 19:35:41.000
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
  +              samplers = samplers,
  +              preprocessors = NULL,
  +              rep.nb.method = 1,
  +              methods = methods,
  +              extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  === Sampling data.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  === Main loop.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  Computing latent variables
  Computing latent variables
  running hp
          pvalue    colname index outlier     score rep.sampler rep.method method
  1 3.208532e-08 cg00000029     1   FALSE -5.593741           1          1     lm
    method.K method.lambda
  1       NA            NA
  Computing latent variables
  Computing latent variables
  Loading required package: impute
  running hp
  `Rows with missing values`
  integer(0)
  `Columns with missing values`
  integer(0)
  
  running hp
       pvalue    colname index outlier      score rep.sampler rep.method
  1 0.6757066 cg00000029     1   FALSE -0.4185102           1          1
       method method.K method.lambda
  1 ridgeLFMM       10         1e-04
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.9531602 cg00000029     1   FALSE 0.05876053           1          1  PCAlm
    method.K method.lambda
  1       10            NA
  Number of significant surrogate variables is:  10 
  Computing latent variables
  It = 1/100, err2 = 0.998548621190457
  It = 2/100, err2 = 0.652592023099809
  It = 3/100, err2 = 0.652018379539831
  [1] "Fitting Factor Analysis Model with 10 factors"
  It = 4/100, err2 = 0.651990819329085
  It = 5/100, err2 = 0.65201511610208
  Iteration (out of 5 ):It = 6/100, err2 = 0.65202139222764
  It = 7/100, err2 = 0.652022747619974
  === lambda = 0.184666840535516, no zero B proportion = 0.00564682358459127
  It = 1/100, err2 = 0.652023080891458
  It = 2/100, err2 = 0.651977189044589
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.6618566 cg00000029     1   FALSE -0.4373513           1          1   cate
    method.K method.lambda
  1       10            NA
  It = 3/100, err2 = 0.651967304634796
  It = 4/100, err2 = 0.651964288072884
  It = 5/100, err2 = 0.65196318471777
  === lambda = 0.138480594373303, no zero B proportion = 0.0549685876152507
  running hp
       pvalue    colname index outlier     score rep.sampler rep.method    method
  1 0.8961906 cg00000029     1   FALSE -0.130524           1          1 lassoLFMM
    method.K method.lambda
  1       10            NA
  1  2  [1] "Fitting Factor Analysis Model with 10 factors"
  3         pvalue    colname index outlier    score rep.sampler rep.method method
  1 1.13824e-05 cg00000029     1   FALSE 19.55117           1          1   famt
    method.K method.lambda
  1       10            NA
  4  5         pvalue    colname index outlier    score rep.sampler rep.method method
  1 3.94329e-12 cg00000029     1   FALSE 49.94426           1          1    sva
    method.K method.lambda
  1       10            NA
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")
  Expr save in ./OUTPUT/Expr/EWAS_all.rds


  >
#+end_example

****** DONE Charger l'expérience et les candidats
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_load_res
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS: code:ewas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:


#+NAME: code:ewas_calibration
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:ewas_calibration
#+begin_example
# A tibble: 7 x 3
     method       mad     median
      <chr>     <dbl>      <dbl>
1      cate  1.287086 0.04677596
2      famt  6.265929 4.33328808
3 lassoLFMM  1.238778 0.02799659
4        lm  4.212716 0.04534315
5     PCAlm  1.226813 0.03996082
6 ridgeLFMM  1.274570 0.04853927
7       sva 10.841806 7.58318108
#+end_example

****** DONE Les qqplots ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_qqplots
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+end_src

#+RESULTS: code:ewas_qqplots
 [[./OUTPUT/Rplots/EWAS_qqplots.png]]
 [[./OUTPUT/Rplots/EWAS_qqplots2.png]]


****** DONE Le top 
CLOSED: [2017-07-27 jeu. 11:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:35]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_top
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")
#+end_src

#+RESULTS: code:ewas_top
#+begin_example
# A tibble: 7 x 2
     method power
      <chr> <dbl>
1      cate   0.8
2      famt   0.0
3 lassoLFMM   1.0
4        lm   0.0
5     PCAlm   1.0
6 ridgeLFMM   1.0
7       sva   0.0
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+end_example

****** DONE Contrôle du FDR à $0.01$
CLOSED: [2017-07-27 jeu. 11:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:37]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_fdr
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+end_src

#+RESULTS: code:ewas_fdr
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 6 x 2
     method power
      <chr> <dbl>
1      cate   1.0
2      famt   1.0
3 lassoLFMM   1.0
4     PCAlm   1.0
5 ridgeLFMM   1.0
6       sva   0.6
#+end_example

****** DONE Venn diagram
CLOSED: [2017-07-27 jeu. 11:39]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS: code:ewas_venn
[[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
Dans cette partie, nous présentons les expériences numériques que nous avons
réalisées pour évaluer la performance de nos algorithmes de correction pour les
facteurs confusions dans les études d'associations qui repose sur une estimation
$\L1$ et $\L2$ des paramètres de LFMM. Ces deux nouveaux algorithmes algorithmes
ont été implémenté dans le langage de programmation R et seront appelé
respectivement ridgeLFMM pour l'estimation $\L2$ et lassoLFMM pour l'estimation
$\L1$. Nous nous sommes comparé aux méthodes que nous avons présenté dans la
partie [[sec:similar_method]]. Les méthodes de régression linéaires avec et sans les
scores de l'ACP ont été implémenté dans le langage R et sont respectivement
appelé lm et PCAlm. Pour les méthodes CATE et sva nous avons respectivement
utilisé les implémentation R de ces méthodes mis à disposition par leurs auteurs.
*** Comparaison des méthodes sur des données simulées
**** Simulation
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 16:10] \\
  [[file:Rpackage/R/ExpRsampler-fromTrueData.R::ExpRmouline.ExpRsampler_fromTrueData%20<-%20function(s)%20{][La fonction sampler]]
:END:
Afin de comparer la performance des méthodes sur une étude d'association pour
laquelle nous connaissons la vérité, nous avons réalisé des simulation à partir
de vrai jeux de données. Pour cela nous réalisons une analyse en composante
principale de la matrice des variables expliquée $\Y$ et ne gardons que les $\K$
composantes choisies en fonction du nombre $\K$ de facteurs de confusion que
l'on souhaites simuler. On a alors 
\begin{equation}
\Y = \U \V^{T} + \E
\end{equation}
où $\V$ est la matrice des $\K$ axes principaux orthonomée et $\U$ la matrice
des variables latentes calculée par l'ACP. La matrice $\E$ est la matrice
residuelle. Nous simulons ensuite une variable explicative et $\K$ variables
latentes de sorte que les nouvelle variables latentes ont la même strucure de
covariance que les variables latentes calculée par l'analyse en composante
principale. Nous choisissont de plus la corrélation entre chaque variables
latentes et la variable expliqué. Ces matrices sont simulé a l'aide d'un
simulateur de variable suivant la loie normale multivariée. Nous notons les
matrices ainsi simulés $\X^{'}$ et $\U^{'}$. Enfin la matrice des effets de la
variable explicative sur la variable expliqué est non nulle pour une certaines
proportion du nombre totale de variable expliqué. Les effets non nulle sont
simulé a l'aide d'une loie normale. Enfin, nous calculons la nouvelle matrice de
variables expliquées tel que
\begin{equation}
\Y^{'} = \U^{'} \V^{T} + \X^{'} \B^{'}^{T} + \E.
\end{equation}
Nous avons ainsi des données pour lesquelle nous connaissont en théorie quelles
variables expliqué associées avec la variable explicative. Nous utilions de plus
la structure lattente d'une matrice de données déjà existante ce qui permet
d'avoir des simulations plus realistes et d'éviter les discution sur le choix de la
structure latente.

Les simulations de comparaison des méthodes 

**** Mesure de comparaison des performances
**** Résultats
**** Scipts                                                     :noexport:
***** RUNNING Comparaisons numériques sur des simulations
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 14:08] \\
  tail -f /home/cayek/tmp/Logfiles/valNum.y2017_m08_d03.log
- State "RUNNING"    from "DEBUG"      [2017-08-03 jeu. 14:07]
- State "DEBUG"      from "RUNNING"    [2017-08-02 mer. 15:53]
- Note taken on [2017-08-02 mer. 15:53] \\
  Ca a bugué :( ca prend une semaine.....
- Note taken on [2017-07-28 ven. 09:38] \\
  tail -f /home/cayek/tmp/Logfiles/valNum.y2017_m07_d28.log
- Note taken on [2017-07-27 jeu. 17:40] \\
  la premiere etape est en train de tourner !!
- State "RUNNING"    from "STARTED"    [2017-07-27 jeu. 17:40]
- State "STARTED"    from "DONE"       [2017-07-27 jeu. 13:43]
- Note taken on [2017-07-17 Lun 08:14] \\
  C'est bon c'est fini ! Il faudra regarder les plots !
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:13]
- Note taken on [2017-07-13 jeu. 12:06] \\
  Je l'ai relancé avec moins de rep pourle sampler ! ca prendra moins de place en
  mémoire !!!
- Note taken on [2017-07-13 jeu. 08:55] \\
  Ca prend 50 % de la mémoire !!!!! C'est par ce qu'il y a beaucoup de données !!
- Note taken on [2017-07-12 mer. 19:39] \\
  je fais tourner la simu final !!!
- State "RUNNING"    from "STARTED"    [2017-07-12 mer. 19:39]
- State "STARTED"    from "RUNNING"    [2017-07-11 mar. 10:26]
- Note taken on [2017-07-06 jeu. 17:52] \\
  sinon les resultats sont top :D
- Note taken on [2017-07-06 jeu. 17:50] \\
  je suis pas sur que c'est le dernier lfmm ridge .... Il faut que je trouve un
  moyen dire quelle version est installé sur krakenator !! avec les commit peut
  être a voir !!!
- State "RUNNING"    from "TODO"       [2017-07-06 jeu. 11:33]
- Note taken on [2017-07-05 mer. 18:11] \\
  j'ai lancé avec le lasso c'est pas mal du tout !! J'ai elevé l'oracle, je sais
  pas pk il merde... le lasso merde quand il y 20% d'outlier mais c'est normal je
  lui ai pas mis le bon nombre de non zero !! :D
- Note taken on [2017-07-03 lun. 16:13] \\
  il faudra le relancer avec un oracle qui marche bien !!
- State "TODO"       from "RUNNING"    [2017-07-03 lun. 16:13]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 18:05]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:

#+NAME: code:num_val_sampler
#+CAPTION: Le sampler pour les comparaisons d'experience et le screeplot de la matrice de génotype. Dépend de [[code:1000g_G_valNum]]
#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  pl <- qplot(seq_along(var), var) +
    coord_cartesian(xlim = c(1,100))
  pl
  save_plot_png(pl, "valNum_screePlot.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/valNum_screePlot.png]]

#+NAME: code:num_val_expr
#+CAPTION: Expérience de comparaison des méthodes sur les simulations. Dépend de [[code:num_val_sampler]]
#+begin_src R 
  library(MaTheseR)

  ## param
  K.method <- 5
  nb.cluster <- 8
  rep.nb.sampler <- 5
  prop.outlier <- c(0.01, 0.05, 0.1, 0.15)
  rho.B <- 3
  rho.c <- c(0.1, 0.3, 0.5, 0.8)

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.K = 100,
                              relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param() +
    m.oracle * param()

  ######################################################################
  ## 1
  ## sampler
  s <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  s$rho.B <- rho.B
  sampler.env <- s$load.env
  samplers <-  s * param(prop.outlier = prop.outlier[1:2], rho.c =rho.c)
  ##run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = rep.nb.sampler,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_fdr,
               sampler.env = sampler.env)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)
  ## checkpoint 
  save_expr(expr, "validation_numerique_1.rds")
  rm(expr)
  gc()
  message("=================== step 1 OK =============================")
  ######################################################################
  ## 2
  ## sampler
  s <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  s$rho.B <- rho.B
  sampler.env <- s$load.env
  samplers <-  s * param(prop.outlier = prop.outlier[3:4], rho.c =rho.c)
  ##run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = rep.nb.sampler,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_fdr,
               sampler.env = sampler.env)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)
  ## checkpoint 
  save_expr(expr, "validation_numerique_2.rds")
  rm(expr)
  gc()
  message("=================== step 2 OK =============================")


  ## retrieve expr
  expr1 <- readRDS("OUTPUT/Expr/validation_numerique_1.rds")
  expr2 <- readRDS("OUTPUT/Expr/validation_numerique_2.rds")
  expr <- list(df.res =
                 rbind(expr1$df.res, expr2$df.res)
    )
  save_expr(expr, "validation_numerique.rds")
  rm(expr1)
  rm(expr2)
  gc()

  ## plot auc
  toplot <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+begin_example
  > save_plot_png(pl, "validation_numerique_auc.png")
  [[./OUTPUT/Rplots/validation_numerique_auc.png]]
  > pll <- plot_gif_boxplot(toplot)
  > save_plot_png(pll, "validation_numerique_gif.png")
  [[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+end_example

***** STARTED Plots
:LOGBOOK:
- State "STARTED"    from "RUNNING"    [2017-07-25 mar. 16:35]
- State "RUNNING"    from "DEBUG"      [2017-07-25 mar. 10:57]
- State "DEBUG"      from "TODO"       [2017-07-24 lun. 17:32]
- Note taken on [2017-07-24 lun. 17:31] \\
  Je sais pas ce j'ai foutu mais c'est super lourd !! ca doit être les test, faut
  que je les enleve du coup ! je vais le faire à part ! Et ca n'a pas exporter les
  bon res. ca plot pas les bonnes choses !
- Note taken on [2017-07-17 Lun 08:15] \\
  L'experience est fini il faut faire le plot et l'anova !!!
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:

#+NAME: code:num_val_auc_gif_df
#+CAPTION: Dépend de [[code:num_val_expr]]
#+begin_src R
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  auc.df <- expr$df.res %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_auc()
  save_expr(auc.df, "auc.df.rds")

  gif.df <- expr$df.res %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_gif()
  save_expr(gif.df, "gif.df.rds")
#+end_src


****** STARTED Plots
:LOGBOOK:
- Note taken on [2017-07-30 Sun 12:28] \\
  on attend que l'expr soit finis !!
- State "STARTED"    from "DONE"       [2017-07-30 Sun 12:28]
- State "DONE"       from "TODO"       [2017-07-30 Sun 12:28]
- Note taken on [2017-07-30 Sun 12:28] \\
  avec les barplot c'est pas mal !!
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_plot
#+CAPTION: Depend de [[code:num_val_auc_gif_df]]
#+begin_src R
  ## Compute plot !
  require(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(gridExtra)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds") 
  auc.df <- auc.df %>%
    dplyr::filter(!(rho.c %in% c(1)),
                                     !(prop.outlier %in% c(0.2)))
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds") 
  gif.df <- gif.df %>%
    dplyr::filter(!(rho.c %in% c(1)),
                  !(prop.outlier %in% c(0.2)))


  #################
  ## by prop outlier

  ## auc
  toplot <- auc.df %>%
    group_by(method, prop.outlier) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge")
  save_plot_png(auc.prop.pl, "num_val_auc_prop.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, prop.outlier) %>%
    summarise(gif.mean = mean(gif), N = length(gif), sd = sd(gif), se = sd / sqrt(N))
  gif.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge")
  save_plot_png(gif.prop.pl, "num_val_gif_prop.png")


  #################
  ## by rho

  ## auc
  toplot <- auc.df %>%
    group_by(method, rho.c) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge")
  save_plot_png(auc.rho.pl, "num_val_auc_rho.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, rho.c) %>%
    summarise(gif.mean = mean(gif), N = length(gif), sd = sd(gif), se = sd / sqrt(N))
  gif.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge")
  save_plot_png(gif.rho.pl, "num_val_gif_rho.png")


  ## plot for pdf
  ## helpers
  ## https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
  ## extract legend
  g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}

  ## C
  C.pl <- gif.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "bottom")
  mylegend <- g_legend(C.pl)
  C.pl <- C.pl +
    theme(legend.position = "none") +
    xlab("Proportion d'outlier") +
    ylab("Gif moyen")

    ## A
    A.pl <- auc.prop.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("Auc moyen")
    ## D
    D.pl <- gif.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("Corrélation") + 
      ylab("") 
    ## B
    B.pl <- auc.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("")

    pl <- cowplot::plot_grid(A.pl,B.pl,C.pl,D.pl,
                             ncol = 2, labels = c("A", "B", "C", "D"))

    ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 mylegend, nrow=2, heights=c(10, 1))
  })

  save_plot_png(pl.leg, filename = "method_comp.png")
  save_plot_MaTheseR(pl.leg, filename = "method_comp.pdf.png", height = 20, width = 14)
#+end_src

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[ht]
\centering
\includegraphics{./OUTPUT/Rplots/method_comp.pdf.png}
\caption{Comparaison des méthodes sur des simulations faites a partir du jeux de
  données 1000Genomes. A-B) Aire sous la source precision-recall en fonction
  respectivement de la proportion d'outlier dans la simulation et la corrélation
  de la varrable explicative et les variables latentes. C-D) Facteur d'inflation
  génomique calculé sur les variable nulles en fonction respectivement de la
  proportion d'outlier et de la corrélation entre les variable explicatives et
  les variables latentes.}
\label{fig:method_comp}
\end{sidewaysfigure}
#+END_EXPORT
****** STARTED Tests d'hypothèse
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-30 Sun 12:28]
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_tests
#+CAPTION: Dépend de [[code:num_auc_gif_df]]
#+begin_src R 
  require(MaTheseR)
  library(broom)
  library(ggplot2)
  library(knitr)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds")
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds")

  auc.lm.res <- auc.df %>%
    mutate(method = as.factor(method)) %>%
    group_by(prop.outlier) %>%
    do(tidy(lm(auc ~ method, data = .))) %>%
    ungroup()
  toplot <- auc.lm.res %>%
    dplyr::filter(term != "(Intercept)")
  ggplot(toplot, aes(x = as.factor(prop.outlier),
                         color = p.value < 1e-5, y = estimate, fill = term)) +
    geom_bar(stat = "identity", position = "dodge")


  lm.res <- lm.res %>%
    dplyr::filter(term != "(Intercept)") %>%
    transmute(method = term, `-log10(p.value)` = -log10(p.value),
                estimate = estimate, prop.outlier = prop.outlier)
  kable(lm.res)

  ggplot(lm.res, ggplot2::aes(x = prop.outlier, y = p.value, color = as.factor(method))) +
    geom_boxplot()
#+end_src


*** Etude d'association entre les données d'expression et la maladie (EWAS)

*** Etude d'association entre des données génétique et un gradient environmental (GEAS)
**** Les données génétiques du project 1000 genomes             :noexport:
:LOGBOOK:
- State "TODO"       from              [2017-07-27 jeu. 17:01]
:END:
***** TODO Scripts                                             :noexport:
:LOGBOOK:
- State "TODO"       from              [2017-08-03 jeu. 17:28]
:END:
---DECRIRE dataset----
****** DONE Téléchargement du jeux de données
CLOSED: [2017-07-26 mer. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-07-26 mer. 18:17]
:END:
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.

#+NAME: code:1000g_ddl
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
****** DONE Contrôle qualité
CLOSED: [2017-07-27 jeu. 14:15]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 14:15]
- Note taken on [2017-07-26 mer. 19:35] \\
  tail -f /home/cayek/tmp/Logfiles/1000g.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:42] \\
  faudra recuperer la sortie dans emacs
- State "RUNNING"    from "TODO"       [2017-07-26 mer. 18:41]
- State "TODO"       from              [2017-07-26 mer. 18:30]
:END:

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+NAME: code:1000g_CQ
#+CAPTION: Dépend de [[code:1000g_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
  do
      echo "===== $file ====="
      plink --vcf $file --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out `basename $file .vcf.gz`_CQ
  done
#+end_src

#+NAME: code:1000g_CQ_log
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_CQ_log
#+begin_example

  > > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:27:19 2017

  Random number seed: 1501090039
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3837178 out of 3992219 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999945.
  806 variants removed due to missing genotype data (--geno).
  --hwe: 75986 variants removed due to Hardy-Weinberg exact test.
  3481563 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  278823 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:31:11 2017
  ============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:31:11 2017

  Random number seed: 1501090271
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3891530 out of 4045628 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  747 variants removed due to missing genotype data (--geno).
  --hwe: 74342 variants removed due to Hardy-Weinberg exact test.
  3548109 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  268332 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:35:22 2017
  ============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:35:22 2017

  Random number seed: 1501090522
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3710299 out of 3868428 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  657 variants removed due to missing genotype data (--geno).
  --hwe: 73200 variants removed due to Hardy-Weinberg exact test.
  3377092 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  259350 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:39:43 2017
  ============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:39:43 2017

  Random number seed: 1501090783
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2737034 out of 2857916 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  497 variants removed due to missing genotype data (--geno).
  --hwe: 52494 variants removed due to Hardy-Weinberg exact test.
  2484161 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  199882 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:42:43 2017
  ============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:42:43 2017

  Random number seed: 1501090963
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2548064 out of 2655067 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999952.
  479 variants removed due to missing genotype data (--geno).
  --hwe: 53291 variants removed due to Hardy-Weinberg exact test.
  2320025 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  174269 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:45:29 2017
  ============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:45:29 2017

  Random number seed: 1501091129
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2328557 out of 2424689 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  434 variants removed due to missing genotype data (--geno).
  --hwe: 51148 variants removed due to Hardy-Weinberg exact test.
  2123668 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  153307 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:47:54 2017
  ============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:47:54 2017

  Random number seed: 1501091274
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2607034 out of 2697949 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  518 variants removed due to missing genotype data (--geno).
  --hwe: 51346 variants removed due to Hardy-Weinberg exact test.
  2387326 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  167844 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:50:35 2017
  ============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:50:35 2017

  Random number seed: 1501091435
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2234710 out of 2329288 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  413 variants removed due to missing genotype data (--geno).
  --hwe: 46649 variants removed due to Hardy-Weinberg exact test.
  2044443 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  143205 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:52:53 2017
  ============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:52:53 2017

  Random number seed: 1501091573
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2178759 out of 2267185 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  392 variants removed due to missing genotype data (--geno).
  --hwe: 39690 variants removed due to Hardy-Weinberg exact test.
  1980142 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  158535 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:55:07 2017
  ============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:55:07 2017

  Random number seed: 1501091707
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1758443 out of 1832506 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999942.
  402 variants removed due to missing genotype data (--geno).
  --hwe: 36837 variants removed due to Hardy-Weinberg exact test.
  1591671 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  129533 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:56:55 2017
  ============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:56:55 2017

  Random number seed: 1501091815
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6216035 out of 6468094 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  1033 variants removed due to missing genotype data (--geno).
  --hwe: 128213 variants removed due to Hardy-Weinberg exact test.
  5676255 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  410534 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:03:16 2017
  ============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:03:16 2017

  Random number seed: 1501092196
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1745171 out of 1812841 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999959.
  278 variants removed due to missing genotype data (--geno).
  --hwe: 35426 variants removed due to Hardy-Weinberg exact test.
  1592817 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  116650 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:05:02 2017
  ============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:05:02 2017

  Random number seed: 1501092302
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1058549 out of 1105538 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999928.
  279 variants removed due to missing genotype data (--geno).
  --hwe: 23191 variants removed due to Hardy-Weinberg exact test.
  956556 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  78523 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:06:06 2017
  ============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:06:06 2017

  Random number seed: 1501092366
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1059735 out of 1103547 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999946.
  222 variants removed due to missing genotype data (--geno).
  --hwe: 25833 variants removed due to Hardy-Weinberg exact test.
  960163 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  73517 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:07:11 2017
  ============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:07:11 2017

  Random number seed: 1501092431
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6808742 out of 7081600 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  1184 variants removed due to missing genotype data (--geno).
  --hwe: 138884 variants removed due to Hardy-Weinberg exact test.
  6233305 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  435369 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:14:09 2017
  ============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:14:09 2017

  Random number seed: 1501092849
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5603261 out of 5832276 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  1069 variants removed due to missing genotype data (--geno).
  --hwe: 111493 variants removed due to Hardy-Weinberg exact test.
  5104864 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  385835 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:19:48 2017
  ============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:19:48 2017

  Random number seed: 1501093188
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5500093 out of 5732585 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  1080 variants removed due to missing genotype data (--geno).
  --hwe: 115329 variants removed due to Hardy-Weinberg exact test.
  4985272 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  398412 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:25:25 2017
  ============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:25:25 2017

  Random number seed: 1501093525
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5055536 out of 5265763 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  909 variants removed due to missing genotype data (--geno).
  --hwe: 91958 variants removed due to Hardy-Weinberg exact test.
  4620648 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  342021 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:30:32 2017
  ============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:30:32 2017

  Random number seed: 1501093832
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4816881 out of 5024119 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999935.
  1292 variants removed due to missing genotype data (--geno).
  --hwe: 101026 variants removed due to Hardy-Weinberg exact test.
  4346787 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  367776 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:35:26 2017
  ============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:35:26 2017

  Random number seed: 1501094126
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4533180 out of 4716715 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.99995.
  842 variants removed due to missing genotype data (--geno).
  --hwe: 87612 variants removed due to Hardy-Weinberg exact test.
  4119828 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  324898 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:40:01 2017
  ============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:40:01 2017

  Random number seed: 1501094401
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4434371 out of 4597105 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999944.
  921 variants removed due to missing genotype data (--geno).
  --hwe: 90154 variants removed due to Hardy-Weinberg exact test.
  4048413 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  294883 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:44:29 2017
  ============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:44:29 2017

  Random number seed: 1501094669
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3427241 out of 3560687 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  689 variants removed due to missing genotype data (--geno).
  --hwe: 68557 variants removed due to Hardy-Weinberg exact test.
  3121045 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  236950 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:47:57 2017
#+end_example

****** DONE Fusion de tous les chromosomes
CLOSED: [2017-07-27 jeu. 14:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 14:43]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

******* Ensuite, nous avons enlever les doublons
#+NAME: code:1000g_rm
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## snp to remove
  echo "rs6658405" > excluded_variant.txt
  echo "." >> excluded_variant.txt
  echo "rs141927528" >> excluded_variant.txt
  echo "rs145926341" >> excluded_variant.txt

  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed
  do
      echo "===== $file ====="
      plink --bfile `basename $file .bed` --exclude excluded_variant.txt --make-bed --out `basename $file .bed`_excluded
  done
#+end_src

#+NAME: code:1000g_rm_log
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_rm_log
#+begin_example

> > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:51 2017

Random number seed: 1501158411
193793 MB RAM detected; reserving 96896 MB for main workspace.
278823 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 278823 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999926.
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
268332 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 268332 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
259350 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 259348 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
259348 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
199882 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 199882 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
174269 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 174269 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
153307 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 153305 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
153305 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
167844 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 167844 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999899.
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
143205 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 143205 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
158535 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 158535 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
129533 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 129533 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
410534 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 410532 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999927.
410532 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
116650 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 116650 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999933.
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
78523 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 78523 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
73517 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 73517 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999913.
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
435369 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 435369 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:57 2017
============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:57 2017

Random number seed: 1501158417
193793 MB RAM detected; reserving 96896 MB for main workspace.
385835 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 385835 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:58 2017
============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:58 2017

Random number seed: 1501158418
193793 MB RAM detected; reserving 96896 MB for main workspace.
398412 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 398412 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
342021 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 342021 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999919.
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
367776 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 367776 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:00 2017
============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:00 2017

Random number seed: 1501158420
193793 MB RAM detected; reserving 96896 MB for main workspace.
324898 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 324898 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
294883 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 294881 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999914.
294881 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
236950 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 236950 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:02 2017
#+end_example

******* On concatène les genomes en 1 seul fichier
#+NAME: code:1000g_concat
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

  ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_CQ")

  system(cmd)
#+end_src

#+RESULTS: code:1000g_concat
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded
    --make-bed
    --merge-list ./file5534632e75c3.txt
    --out 1000GenomePhase3_CQ

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Performing single-pass merge (2504 people, 5398440 variants).
  Merged fileset written to 1000GenomePhase3_CQ-merge.bed +
  1000GenomePhase3_CQ-merge.bim + 1000GenomePhase3_CQ-merge.fam .
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ.bed + 1000GenomePhase3_CQ.bim +
  1000GenomePhase3_CQ.fam ... done.
#+end_example

******* Vérification
#+NAME: code:1000g_test
#+CAPTION: Dépend de [[code:1000g_concat]]
#+begin_src shell :session *ssh krakenator* :results output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS: code:1000g_test
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:5	rs66584056	0	36516119	T	A
****** DONE Élagage (LD pruning)
CLOSED: [2017-07-27 jeu. 15:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 15:01]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

On fait un filtrage des SNPs (voir [[https://www.cog-genomics.org/plink/1.9/ld#indep][doc plink]])

#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_CQ --threads 8
  plink --bfile 1000GenomePhase3_CQ --extract 1000GenomePhase3_CQ.prune.in --make-bed --out 1000GenomePhase3_CQ_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 100 1 0.2
    --out 1000GenomePhase3_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 383854 variants from chromosome 1, leaving 26678.
  Pruned 409475 variants from chromosome 2, leaving 25894.
  Pruned 362867 variants from chromosome 3, leaving 22968.
  Pruned 376230 variants from chromosome 4, leaving 22182.
  Pruned 321811 variants from chromosome 5, leaving 20210.
  Pruned 347157 variants from chromosome 6, leaving 20619.
  Pruned 305597 variants from chromosome 7, leaving 19301.
  Pruned 277562 variants from chromosome 8, leaving 17319.
  Pruned 221173 variants from chromosome 9, leaving 15777.
  Pruned 261581 variants from chromosome 10, leaving 17242.
  Pruned 252405 variants from chromosome 11, leaving 15927.
  Pruned 242512 variants from chromosome 12, leaving 16836.
  Pruned 187679 variants from chromosome 13, leaving 12203.
  Pruned 162767 variants from chromosome 14, leaving 11502.
  Pruned 142011 variants from chromosome 15, leaving 11294.
  Pruned 155528 variants from chromosome 16, leaving 12316.
  Pruned 131567 variants from chromosome 17, leaving 11638.
  Pruned 147436 variants from chromosome 18, leaving 11099.
  Pruned 119524 variants from chromosome 19, leaving 10009.
  Pruned 107571 variants from chromosome 20, leaving 9079.
  Pruned 72922 variants from chromosome 21, leaving 5601.
  Pruned 67200 variants from chromosome 22, leaving 6317.
  Pruning complete.  5056429 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ.prune.in and
  1000GenomePhase3_CQ.prune.out .


  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --extract 1000GenomePhase3_CQ.prune.in
    --make-bed
    --out 1000GenomePhase3_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned.nosex .
  --extract: 342011 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned.bed + 1000GenomePhase3_CQ_prunned.bim
  + 1000GenomePhase3_CQ_prunned.fam ... done.

#+end_example

****** DONE Filtrage des individus trop apparenté
CLOSED: [2017-07-27 jeu. 16:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 16:21]
- Note taken on [2017-07-26 mer. 19:21] \\
  c'est la que ca commence !! il faut que je remplace par les vrais appel de plink !!!
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

On filtre les individus trop apparenté (voir [[https://www.cog-genomics.org/plink/1.9/ibd][doc de plink]]).


******* On commence par calculer la proportion d'IBD.
#+NAME: code:1000g_ibd
#+CAPTION: Dépend de [[code:1000g_concat]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## ibd
  plink -bfile 1000GenomePhase3_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** On visualise la proportion d'IBD
:LOGBOOK:
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:1000g_ibd_visu
#+CAPTION: Dépend de [[code:1000g_ibd_visu]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "1000g_ibd.png")


  ## We filter PI_HAT > 0.125
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.125) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ibd.png]]

On va filter les pour une proportion d'ibd à 0.125 (ca correspond à cousin au 3
ième degré).

******* On filtre les individus trop apparentés

#+NAME: code:1000g_ibd_filter
#+CAPTION: Dépend de [[code:1000g_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ_prunned --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_prunned_norel

  plink --bfile 1000GenomePhase3_CQ --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_norel
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --make-bed
    --out 1000GenomePhase3_CQ_prunned_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.99989.
  342011 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned_norel.bed +
  1000GenomePhase3_CQ_prunned_norel.bim + 1000GenomePhase3_CQ_prunned_norel.fam
  ... done.

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --make-bed
    --out 1000GenomePhase3_CQ_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999904.
  5398440 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_norel.bed + 1000GenomePhase3_CQ_norel.bim +
  1000GenomePhase3_CQ_norel.fam ... done.
#+end_example

****** DONE Conversion dans format utilisable en R
CLOSED: [2017-08-03 jeu. 11:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-03 jeu. 11:37]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R. 

******* DONE Données non prunnées
CLOSED: [2017-08-03 jeu. 11:31]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-08-03 jeu. 11:31]
- State "STARTED"    from "RUNNING"    [2017-07-13 jeu. 12:29]
- Note taken on [2017-07-13 jeu. 11:57] \\
  Après ca on va creer la matrice matter par block !! Et il faudra calculer les
  indice du prinning et aussi les indice sur les individus !!!
- Note taken on [2017-07-13 jeu. 11:57] \\
  Ca tourne sur mon pc fixe :D
- State "RUNNING"    from "TODO"       [2017-07-13 jeu. 11:57]
- State "TODO"       from              [2017-07-13 jeu. 08:59]
:END:

******** TODO Format .rds
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 14:14] \\
  ca a bugger le pense ...a voir.
- State "TODO"       from "RUNNING"    [2017-08-03 jeu. 14:14]
- State "RUNNING"    from "DONE"       [2017-08-03 jeu. 13:26]
- State "DONE"       from "RUNNING"    [2017-08-02 mer. 16:51]
- Note taken on [2017-08-02 mer. 16:11] \\
  il ne veux pas mettre de nom au ligne et colonnes .... je sais pas pk mais c'est
  pas si grave !!
- State "RUNNING"    from              [2017-08-02 mer. 15:59]
:END:
#+NAME: code:1000g_G_bigsnpr
#+CAPTION: Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_norel.bed"

  snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")

  G <- snp_attach("bigsnpr_G/G.rds")
  ## G <- readRDS("bigsnpr_G/G.rds")
  dim(G$genotypes)

  ## G.r <- readRDS("G.rds")
  G.r <- attach.BM(G$genotypes)[,]
  ## rownames(G.r) <- G$fam$sample.ID
  attr(G.r, "rownames") <- G$fam$sample.ID
  ## colnames(G.r) <- G$map$marker.ID
  attr(G.r, "colnames") <- G$map$marker.ID

  saveRDS(G.r, "G.rds")
  #+END_SRC

#+RESULTS:
#+begin_example
  > snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")
  Creating directory "bigsnpr_G" which didn't exist..
  Read 5398440 rows and 6 (of 6) columns from 0.142 GB file in 00:00:22
  [1] "bigsnpr_G/G.rds"
  > 
  > G <- snp_attach("bigsnpr_G/G.rds")
  > dim(G$genotypes)
  [1]    1758 5398440
  > rownames(G.r) <- G$fam$sample.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
  > colnames(G.r) <- G$map$marker.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
#+end_example

******* DONE Données prunnées
CLOSED: [2017-07-27 jeu. 17:17]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 17:17]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

#+NAME: code:1000g_G_prunned_bigsnpr
#+CAPTION: On converti les données prunnées en un format R. Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_prunned_norel.bed"

  snp_readBed(bedfile, "G_prunned", backingpath = "bigsnpr_G_prunned")

  G <- snp_attach("bigsnpr_G_prunned/G_prunned.rds")
  dim(G$genotypes)

  G.r <- attach.BM(G$genotypes)[,]
  typeof(G.r)
  rownames(G.r) <- G$fam$sample.ID
  colnames(G.r) <- G$map$marker.ID
  saveRDS(G.r, "G_prunned.rds")
  rm(G.r)
  gc()


  ## We only keep first chromosomes 1 and 2 for simulation numerique
  in.id <- which(G$map$chromosome %in% c(1,2))
  G.r <- readRDS("G_prunned.rds")
  G.numVal <- G.r[,in.id]
  saveRDS(G.numVal, "G_prunned_chr12.rds")


  ## save indiv data frame
  saveRDS(G$fam, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_indiv_df.rds")
  #+END_SRC

  
****** TODO Scaling des données et valeurs manquantes
:LOGBOOK:
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

******* DONE Données utilisées pour la validation numérique lfmm
CLOSED: [2017-07-27 jeu. 17:26]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 17:26]
:END:
#+NAME: code:1000g_G_valNum
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- readRDS("G_prunned_chr12.rds")
  anyNA(G)
  G.noNa <- preprocessing_filter_na(G)
  anyNA(G.noNa)
  G.scale <- scale(G.noNa)
  saveRDS(G.scale, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds")
#+end_src

#+RESULTS:
#+begin_example
  proportion of removed loci = 0.00686677318724797
#+end_example

******* DONE Données prunnées
CLOSED: [2017-07-28 ven. 11:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-28 ven. 11:01]
- State "TODO"       from              [2017-07-27 jeu. 17:29]
:END:

#+NAME: code:1000g_G_prunned_scaling
#+CAPTION: On scale et enlève les données manquantes. Dépend de [[code:1000g_G_prunned_bigsnpr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  G <- readRDS("./Data/1000Genomes/Phase3/G_prunned.rds")
  anyNA(G)
  G.noNa <- preprocessing_filter_na(G)
  anyNA(G.noNa)
  G.scale <- scale(G.noNa)
  saveRDS(G.scale, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_prunned.rds")
#+end_src

#+RESULTS: code:1000g_G_prunned_scaling
: [1] TRUE
: proportion of removed loci = 0.00785647245264041
: [1] FALSE

******* TODO Données non prunnées 
:LOGBOOK:
- State "TODO"       from              [2017-07-28 ven. 10:34]
:END:

******** TODO Missing data and export to =matter=
:LOGBOOK:
- State "TODO"       from              [2017-08-03 jeu. 11:37]
:END:
#+NAME: code:1000g_G_noNA
#+CAPTION: Dépend de [[code:1000g_G_bigsnpr]]
#+begin_src R 
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- readRDS("G.rds")
  n <- nrow(G)

  ## NA mu sds
  nas <- 1:ncol(G)
  for(j in 1:ncol(G)) {
    nas[j] <- mean(is.na(G[,j]))
  }

  ## export to bin
  con <- file("~/Projects/Thesis/Data/1000Genomes/Phase3/G_noNA.bin", 'wb')
  notNA.ids <- which(nas != 0.0)
  for(j in notNA.ids {
    writeBin(G[,j], con)
  }
  flush(con)
  close(con)

  ## matter matrix
  G.matter <- matter_mat(paths="/home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/G_noNA.bin",
                         ncol = length(notNA.ids),
                         nrow = n, datamode = "double")
  colnames(G.matter) <- attr(G, "colnames")[nas.bool]
  rownames(G.matter) <- attr(G, "rownames")
  ## test
  mean(G[,notNA.ids[length(notNA.ids)]] == G.matter[,length(notNA.ids)])

  saveRDS(G.matter, "G_noNA.matter.rds")

#+end_src

****** TODO Preprocessing des données pour la GEAS
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:28]
- State "DONE"       from "TODO"       [2017-07-28 ven. 14:18]
- State "TODO"       from              [2017-07-28 ven. 11:46]
:END:
Pour cette étude nous avons choisi d'utiliser les données 1000 genome. Après les
étapes de preprocessing présenter dans la section..., les individus metisse ont
été exclu. En effet pour une étude d'association à l'environement il n'est pas
pertinent de travailler avec individu issu du metissage de plusieurs
populations. Pour cette étude nous ne gardons que les individus pour lesquels
qui vivent dans leur un milieu naturel depuis plusieurs générations.

#+NAME: code:eas_prepross
#+CAPTION: Dépend de [[code:1000g_G_prunned_scaling]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)

  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/G_prunned.rds")
  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds") %>% as_tibble()
  indiv.df

  ## keep only indiv in G
  indiv.df <- indiv.df %>%
    dplyr::filter(sample %in% rownames(G))
  indiv.df

  ## retrieve pop

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW", "ACB")))
  indiv.df

  ## remove indiv
  G <- G[indiv.df$sample,]
  dim(G)

  ## filter sd, there are snps without variance !!
  sds <- apply(G, 2, sd)
  quantile(sds, 0.000001)
  G <- preprocessing_filter_sd(G, 0.0)
  dim(G)

  ## scale G
  G <- scale(G)
  anyNA(G)

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds")
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv_df.rds")
#+end_src

#+RESULTS: code:eas_prepross
#+begin_example
# A tibble: 2,504 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00103   GBR       EUR   male
 8 HG00105   GBR       EUR   male
 9 HG00106   GBR       EUR female
10 HG00107   GBR       EUR   male
# ... with 2,494 more rows
# A tibble: 1,758 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,748 more rows
# A tibble: 1,409 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,399 more rows
[1]   1409 339324
0.0001% 
      0
proportion of removed loci = 8.84110761396188e-06
[1]   1409 339321
[1] FALSE
#+end_example


**** Calcule du gradient climatique
***** TODO Scripts                                             :noexport:
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:26]
- State "DONE"       from "TODO"       [2017-07-28 ven. 15:58]
- State "TODO"       from "DONE"       [2017-07-28 ven. 11:46]
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+NAME: code:eas_climatic_gradient
#+CAPTION: Dépend de [[code:eas_prepross]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(tidyverse)
  library(MaTheseR)

  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv_df.rds") %>% as_tibble()
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df


  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "CDX",]$citie = "China"
  indiv.df[indiv.df$pop == "ACB",]$citie = "Barbados"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"
  indiv.df[indiv.df$pop == "ESN",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "FIN",]$citie = "Finland"
  indiv.df[indiv.df$pop == "GBR",]$citie = "England"

  ## cities
  indiv.df %>%
    dplyr::select(pop, `Population Description`, citie) %>%
    group_by(pop, `Population Description`, citie) %>%
    summarise() %>%
    print.data.frame()


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  ## library(leaflet)
  ## m <- leaflet() %>%
  ##   addTiles() %>%  # Add default OpenStreetMap map tiles
  ##   addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  ## ## m  # Print the map
  ## ## to render in rstudio....
  ## save_expr(m, "eas_map.rds")
  ## ## save widget
  ## library(htmlwidgets)
  ## saveWidget(m, "~/Projects/Thesis/MaThese/OUTPUT/Rplots/eas_map.html", selfcontained = FALSE)

  ## plot map
  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  ggplot() + 
  map.world <- get_map(location = "world")
  pl <- ggplot(cities, aes(x = lon, y = lat, color = `Population Description`)) +
    mapWorld + 
    geom_point() +
    theme(legend.position='bottom')
  save_plot_png(pl, "eas_map_ggplot.png", 1000, 600)

  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    mapWorld + 
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_map_ggplot.png]]
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
  >   dim(X.eas)
  [1] 1409   1

#+end_example


** Discussion                                                     :noexport:
** Figures et table
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** STARTED GWAS
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-07-25 mar. 16:37]
- State "DONE"       from "TODO"       [2017-07-25 mar. 16:37]
- State "TODO"       from              [2017-07-17 Lun 08:16]
:END:
#+NAME: code:gwas_qqplot_venn
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(gridExtra)
  MaTheseR.params <- get_MaTheseRparams()

  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")


  ## venn
  toplot <- celiac.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)
  save_plot_png(out, filename = "gwas_venn.png")
  save_plot_MaTheseR(out, filename = "gwas_venn.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  ## qqplot
  toplot <- celiac.df %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lm", "lassoLFMM"))
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    MaTheseR.params$gtheme + 
    theme(legend.position = "bottom") 
  ## pll
  save_plot_png(pll, filename = "gwas_qqplot.png")
  save_plot_MaTheseR(pll, filename = "gwas_qqplot.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


#+END_SRC


#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_venn.pdf.png}
\includegraphics{./OUTPUT/Rplots/gwas_qqplot.pdf.png}
\caption{Diagramme de Venn et qqplot pour la GWAS}
\label{fig:gwas_venn_qqplot}
\end{figure}
#+END_EXPORT

*** DONE EWAS
CLOSED: [2017-07-27 jeu. 13:43]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-07-27 jeu. 13:43]
- State "STARTED"    from "TODO"       [2017-07-27 jeu. 11:40]
- State "TODO"       from              [2017-07-10 lun. 15:49]
:END:

#+NAME: code:ewas_screeplot_
#+CAPTION: Dépend de [[code:ewas_screeplot]] [[code:ewas_CV]] [[code:ewas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/ewas_screeplot_expr.rds")
  toplot <- expr$df.res %>%
      mutate(lambda = as.factor(lambda))
  pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100)) +
    xlab("K") +
    ylab("Proportion de la variance totale") +
    MaTheseR.params$gtheme

  save_plot_MaTheseR(pl, "ewas_screeplot.pdf.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  pl <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab("Nombre de variables latentes (K)") +
    ylab("Erreur de prédiction") +
    MaTheseR.params$gtheme
  pl
  save_plot_MaTheseR(pl, "ewas_CV_K.pdf.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  pl <- ggplot(toplot, aes(x = log(lambda), y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab("Paramètre de regularisation en échelle logarithmique (lambda)") +
    ylab("Erreur de prédiction") +
    MaTheseR.params$gtheme
  pl
  save_plot_MaTheseR(pl, "ewas_CV_lambda.pdf.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_screeplot.pdf.png}
\includegraphics{./OUTPUT/Rplots/ewas_CV_K.pdf.png}
\includegraphics{./OUTPUT/Rplots/ewas_CV_lambda.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre des mesure de
  niveaux de méthylation et la maladie polyarthrite. A) valeurs singulières de
  la matrices des variable expliquées partiellement décorrélé avec les variables
  explicatives. Le resultats est présenté pour plusieurs valeurs du paramètre de
  régularisation de l'estimateur ridge. Ce paramètre rêgle a quelle point les
  variables expliquées sont décorélé avec les variable expliqué (voir ...) B)C)
  Erreur de prédiction calculé grace a la validation croisé présenté de
  l'estimateur $L_{2}$ pour défférente valeurs du paramètre de régularisation
  et du nombre variable lattentes.}
\label{fig:ewas_params}
\end{figure}
#+END_EXPORT

#+NAME: code:ewas_qqplot_venn
#+CAPTION: Dépend de [[code:ewas_run]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(gridExtra)
  MaTheseR.params <- get_MaTheseRparams()

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")


  ## venn
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])
  save_plot_png(out, filename = "ewas_venn.png")
  save_plot_MaTheseR(out, filename = "ewas_venn.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## qqplot
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    MaTheseR.params$gtheme + 
    theme(legend.position = "none") 
  pll
  save_plot_png(pll, filename = "ewas_qqplot.png")
  save_plot_MaTheseR(pll, filename = "ewas_qqplot.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+END_SRC

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_venn.pdf.png}
\includegraphics{./OUTPUT/Rplots/ewas_qqplot.pdf.png}
\caption{A) Diagramme de Venn de la liste de candidats controlé à au taux de
  fausses de découvertes à 1 \%. B) Quantille-quantille plot des \pvaleur
  renvoyé par chaques méthodes.}
\label{fig:ewas_venn_qqplot}
\end{figure}
#+END_EXPORT

*** TODO EAS
:LOGBOOK:
- State "TODO"       from              [2017-07-17 Lun 08:16]
:END:



* perspectives : Vers le big data
:LOGBOOK:
- Note taken on [2017-07-31 lun. 10:20] \\
  on va parler de : 
  - vers le big data ? (valeurs manquantes, données pas loadé en mémoire)
  - est ce que le modèle est polygénique ?
  - théorie stat (cf cate)
  - matrice de dosage
  - lien autre que linéaire ? (lien logistique)
- Note taken on [2017-07-30 Sun 13:56] \\
  matrice de dosage
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:49] \\
  strategie: il faut que je finisse tout le reste avec les versions actuelles
  (tess3r, et ce que j'ai fait pour le moment d'lfmm). Quand tout sera fini ! Je
  repenserai l'archi de tess3r (tout en R et une seul data en mémoire). Je pense
  que je n'arriverais pas faire de l'acces de très grosse données depui un fichier
  et la gestion des NA en même temps. Mais je peux montrer les deux séparément,
  cad on montre que on arrive a faire un algo robuste au NA pour tess3r et lfmm
  mais c'est pas complétement implémenté. ET on montre sur un très gros dataset
  une analyse complete pop et lfmm (le 1001 génome est top pour ca car on a une
  matrice imputé :D)
- Note taken on [2017-07-18 Tue 10:57] \\
  - traitement des données manquantes
  - acess au données (pas dans la ram, je peux parler des infracstructure big data
    classique)
  - si j'ai le temps j'implémente ces 2 feature cad: 
    - NA -> comparaison avec et sans NA et procedure naive
    - matrice en mémoriedans un BED -> on a seulement besoin du produit par X ! 
  
  c'est la suite logique de ma problématique cad : 
  - data de plus en plus grosse donc on veut pas les dupliquer, il y a des données
    manquantes
  - mon taf c'est de fournir des logicielles !
  
  
  Je peux ecrire cette partie comme un mini article ! cad
  intro 
  methode
  resultats
  discution 
  conclusion

- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:

* Conclusion 
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:50]
:END:

bibliographystyle:apalike
bibliography:../biblio.bib

