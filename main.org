# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:6 author:nil email:nil creator:nil timestamp:nil skip:nil toc:t ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(g!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


#+LaTeX_CLASS: these
# #+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \renewcommand{\proofname}{Preuve}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM hyperparamètre

# #+BEGIN_QUOTE
# In Code we trust, all others bring data.
# –William Edwards Deming (1900-1993).
# #+END_QUOTE


* Workenv                                                          :noexport:
** R
#+BEGIN_SRC R
  ## CRAN
  install.packages("tidyverse")
  install.packages("extrafont")
  install.packages("Devtools")
  install.packages("testthat")
  install.packages("foreach")
  install.packages("RSpectra")
  install.packages("doParallel")
  install.packages("DescTools")
  install.packages("roxygen2")
  install.packages("VennDiagram")
    ## bioconductor
  source("https://bioconductor.org/biocLite.R")
  biocLite("matter", ask = FALSE)
  biocLite("qvalue",ask = FALSE)
  biocLite("biomaRt",ask = FALSE)
  biocLite("LEA",ask = FALSE)
  biocLite("impute",ask = FALSE)
  biocLite("sva",ask = FALSE)

  install.packages("cate")
  install.packages("FAMT")
  install.packages("xgboost")
  install.packages("knitr")


  ## github
  devtools::install_github("privefl/bigsnpr")
#+END_SRC
** Ligne de commande
*** ms
*** plink
** python
* Introduction
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-07-20 Thu 17:52]
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:11] \\
  une remarque en passant: l'intro est pour moi la place pour définir le contexte
  général, les mots du titre, la pbq et le plan qui y répond ! 
  Ce n'est pas la que je fait un état de l'art. L'état de l'art est dans les deux
  grosse partis ! C'est deux grosse parties sont indépendantes l'une de l'autre !
  Donc si il y a des répétition, tant pis !!
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
** Contexte
:LOGBOOK:
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:
*** COMMENT 
Cette dernière décennie a été marquée par une accumulation des données dans tous les
domaines de la sciences. Cette accumulation de données est une aubaine pour les
scientifiques. Cependant, que faire d'autant de données et comment en tirer
l'information qui permettrait de mieux comprendre le monde qui nous entoure ? Il
s'agit là d'un défi majeur pour les statistiques cite:slides_sfds2015_saporta. 

Les grandes données posent plusieurs problèmes. En effet, si l'on est capable d'obtenir
des données rapidement, on veut pouvoir les analyser rapidement. Cependant de
nombreux modèle statistiques classiques ne passent pas l'échelle des grands jeux
de données. Il est donc nécessaire de repenser les modèles et algorithmes afin
de les adapter au nous volumes des données. 
... parler de l'inversement du processus d'aquisition des données .. cf
seminaire Bosson



Dans le cadre de cette thèse nous nous sommes intéressé a développer des méthodes
statistiques utiles à deux problématique scientifiques. Le premier est l'estimation
de la structure de population à partir de données génomique. Le deuxièmes est les
problèmes des test d'association multiple. Toutes les méthodes statistiques
developper lors de cette thèse repose sur la factorisation de matrice. Nous
allons maintenant introduire plus en détails les problématiques ainsi que la
factorisation de matrice en statistique.


** La génomique des populations
:LOGBOOK:
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc

 En faite je ne vais def ca ici ! c'est juste le genet des pops ici !!
  - ewas: refactor
  - gwas: gemma etc
  - eas: ...
:END:
** Test d'association
** La factorisation de matrice en statistique
:LOGBOOK:
- Note taken on [2017-07-18 Tue 08:55] \\
  Kenneth lange, factorisation de matrice = avenir des stat ! a retrouver !
:END:
** Problématique et plan
* Données
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
:END:
Nous décrivons dans cette partie les données réelles qui sont analysées dans la
thèse. Afin de rendre les analyses le plus possible reproductibles, nous
décrivons les étapes de pré traitement qui ont été affectées sur ces jeux de
données. Les scripts sont disponible dans la version de la thèse avec le code.
** 1000 genome                                                    :noexport:

---DECRIRE dataset----
*** Téléchargement du jeux de données
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
*** Contrôle qualité

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+begin_src R :results output :exports both
  ## file list
  setwd("./Data/1000Genomes/Phase3/")

  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)

  maf <- 0.05
  mind <- 0.05
  hwe <- 1e-10
  geno <- 0.05
  for (f in files) {
    cmd <- paste("plink",
                 "--vcf", f,
                 "--maf", maf,
                 "--mind", mind,
                 "--geno", geno,
                 "--hwe", hwe,
                 "--snps-only",
                 "--autosome",
                 "--make-bed",
                 "--out", paste0("./plink/", sub(".vcf.gz", "",f)),
                 ">> plink_GC.out")

    system("rm -f plink_QC.out")
    system(cmd)
  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cd ~/Projects/Thesis/Data/1000Genomes/Phase3/plink/
  for f in ALL.chr*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log
  do
      echo "=====FILE:$f====="
      cat "$f"
  done
#+end_src

#+RESULTS:
#+begin_example

> > > > =====FILE:ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:51:39 2017

Random number seed: 1495032699
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3837178 out of 3992219 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999945.
806 variants removed due to missing genotype data (--geno).
--hwe: 75986 variants removed due to Hardy-Weinberg exact test.
3481563 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:55:55 2017
=====FILE:ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:55:55 2017

Random number seed: 1495032955
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3891530 out of 4045628 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
747 variants removed due to missing genotype data (--geno).
--hwe: 74342 variants removed due to Hardy-Weinberg exact test.
3548109 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:00:10 2017
=====FILE:ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:00:10 2017

Random number seed: 1495033210
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3710299 out of 3868428 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
657 variants removed due to missing genotype data (--geno).
--hwe: 73200 variants removed due to Hardy-Weinberg exact test.
3377092 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
259350 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:04:16 2017
=====FILE:ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:04:16 2017

Random number seed: 1495033456
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2737034 out of 2857916 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
497 variants removed due to missing genotype data (--geno).
--hwe: 52494 variants removed due to Hardy-Weinberg exact test.
2484161 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:07:18 2017
=====FILE:ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:07:18 2017

Random number seed: 1495033638
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2548064 out of 2655067 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999952.
479 variants removed due to missing genotype data (--geno).
--hwe: 53291 variants removed due to Hardy-Weinberg exact test.
2320025 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:10:07 2017
=====FILE:ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:10:07 2017

Random number seed: 1495033807
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2328557 out of 2424689 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
434 variants removed due to missing genotype data (--geno).
--hwe: 51148 variants removed due to Hardy-Weinberg exact test.
2123668 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
153307 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:12:41 2017
=====FILE:ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:12:41 2017

Random number seed: 1495033961
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2607034 out of 2697949 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
518 variants removed due to missing genotype data (--geno).
--hwe: 51346 variants removed due to Hardy-Weinberg exact test.
2387326 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:15:30 2017
=====FILE:ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:15:30 2017

Random number seed: 1495034130
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2234710 out of 2329288 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
413 variants removed due to missing genotype data (--geno).
--hwe: 46649 variants removed due to Hardy-Weinberg exact test.
2044443 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:17:58 2017
=====FILE:ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:17:58 2017

Random number seed: 1495034278
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2178759 out of 2267185 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
392 variants removed due to missing genotype data (--geno).
--hwe: 39690 variants removed due to Hardy-Weinberg exact test.
1980142 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:20:20 2017
=====FILE:ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:20:20 2017

Random number seed: 1495034420
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1758443 out of 1832506 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999942.
402 variants removed due to missing genotype data (--geno).
--hwe: 36837 variants removed due to Hardy-Weinberg exact test.
1591671 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:22:17 2017
=====FILE:ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:44:50 2017

Random number seed: 1495032290
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6216035 out of 6468094 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
1033 variants removed due to missing genotype data (--geno).
--hwe: 128213 variants removed due to Hardy-Weinberg exact test.
5676255 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
410534 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:51:39 2017
=====FILE:ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:29:40 2017

Random number seed: 1495034980
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1745171 out of 1812841 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999959.
278 variants removed due to missing genotype data (--geno).
--hwe: 35426 variants removed due to Hardy-Weinberg exact test.
1592817 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:31:43 2017
=====FILE:ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:31:43 2017

Random number seed: 1495035103
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1058549 out of 1105538 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999928.
279 variants removed due to missing genotype data (--geno).
--hwe: 23191 variants removed due to Hardy-Weinberg exact test.
956556 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:32:53 2017
=====FILE:ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:32:53 2017

Random number seed: 1495035173
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1059735 out of 1103547 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999946.
222 variants removed due to missing genotype data (--geno).
--hwe: 25833 variants removed due to Hardy-Weinberg exact test.
960163 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:34:01 2017
=====FILE:ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:22:17 2017

Random number seed: 1495034537
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6808742 out of 7081600 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
1184 variants removed due to missing genotype data (--geno).
--hwe: 138884 variants removed due to Hardy-Weinberg exact test.
6233305 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:29:40 2017
=====FILE:ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:34:01 2017

Random number seed: 1495035241
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5603261 out of 5832276 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
1069 variants removed due to missing genotype data (--geno).
--hwe: 111493 variants removed due to Hardy-Weinberg exact test.
5104864 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:40:14 2017
=====FILE:ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:40:14 2017

Random number seed: 1495035614
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5500093 out of 5732585 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
1080 variants removed due to missing genotype data (--geno).
--hwe: 115329 variants removed due to Hardy-Weinberg exact test.
4985272 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:46:21 2017
=====FILE:ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:46:21 2017

Random number seed: 1495035981
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5055536 out of 5265763 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
909 variants removed due to missing genotype data (--geno).
--hwe: 91958 variants removed due to Hardy-Weinberg exact test.
4620648 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:51:47 2017
=====FILE:ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:51:47 2017

Random number seed: 1495036307
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4816881 out of 5024119 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999935.
1292 variants removed due to missing genotype data (--geno).
--hwe: 101026 variants removed due to Hardy-Weinberg exact test.
4346787 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:57:03 2017
=====FILE:ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:57:03 2017

Random number seed: 1495036623
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4533180 out of 4716715 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99995.
842 variants removed due to missing genotype data (--geno).
--hwe: 87612 variants removed due to Hardy-Weinberg exact test.
4119828 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:01:58 2017
=====FILE:ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:01:58 2017

Random number seed: 1495036918
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4434371 out of 4597105 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999944.
921 variants removed due to missing genotype data (--geno).
--hwe: 90154 variants removed due to Hardy-Weinberg exact test.
4048413 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
294883 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:06:48 2017
=====FILE:ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:06:48 2017

Random number seed: 1495037208
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3427241 out of 3560687 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
689 variants removed due to missing genotype data (--geno).
--hwe: 68557 variants removed due to Hardy-Weinberg exact test.
3121045 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:10:32 2017
#+end_example
*** Fusion de tous les chromosomes
Ensuite, nous avons enlever 
#+begin_src R :results output :exports both
  setwd("./Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)

  ## exclude variant
  write("rs6658405\n.\nrs145926341\nrs141927528" , file = "excluded_variant.txt")

  for (f in prefix) {
    cmd <- paste("plink",
                 "--bfile", f,
                 "--exclude excluded_variant.txt",
                   "--make-bed",
                 "--out", paste0(f, "_excluded"))
    system(cmd)
  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS:
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:5	rs66584056	0	36516119	T	A

#+begin_src R :results output :exports both
  setwd("./Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

    ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_QC")

  system(cmd)
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cat 1000GenomePhase3_QC.log
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded
  --make-bed
  --merge-list ./file290c4546eae6.txt
  --out 1000GenomePhase3_QC

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 09:55:14 2017

Random number seed: 1495094114
193793 MB RAM detected; reserving 96896 MB for main workspace.
Performing single-pass merge (2504 people, 5398440 variants).
Merged fileset written to 1000GenomePhase3_QC-merge.bed +
1000GenomePhase3_QC-merge.bim + 1000GenomePhase3_QC-merge.fam .
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC.bed + 1000GenomePhase3_QC.bim +
1000GenomePhase3_QC.fam ... done.

End time: Thu May 18 09:57:32 2017
#+end_example
*** Filtrage des individus trop apparenté
#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink")
  plink <- "/home/cayek/BiocompSoftware/plink/plink"
  bedfileQC <- "1000GenomePhase3_QC.bed"
  rel <- snp_plinkIBDQC(plink, bedfileQC, ncores = 4,
                        bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC),
                        pruning.args = NULL,
                        do.blind.QC = TRUE)

  bedfileQC2 <- snp_plinkRmSamples(
    plink, 
    bedfile.in = bedfileQC, 
    bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC), 
    df.or.files = subset(rel, PI_HAT > 0.08)
    )
  print(bedfileQC2)
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --genome
    --min 0.08
    --out 1000GenomePhase3_QC
    --threads 4

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
  Using up to 4 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing 1000GenomePhase3_QC.genome .
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --make-bed
    --out 1000GenomePhase3_QC_norel
    --remove /home/cayek/tmp/RtmpVBcWMh/file577662272180

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
  --remove: 919 people remaining.
  Warning: At least 146315 duplicate IDs in --remove file.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 919 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999923.
  5398440 variants and 919 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_QC_norel.bed + 1000GenomePhase3_QC_norel.bim +
  1000GenomePhase3_QC_norel.fam ... done.
#+end_example
*** Élagage 

Il est bien connue qu'il y a une forte corrélation en les SNPs que l'on appel
déséquilibre de liaision CITE. c'est un problème pour l'acp ect... cite 
Pour les analyse factorielle en général il est préférable d'enlever les qui sont
trés corrélé entre elles pour eviter de biaiser l'apprentissage des facteurs.
#+begin_src shell :results output :exports both 
  cd ./Data/1000Genomes/Phase3/plink/
  plink --bfile 1000GenomePhase3_QC_norel --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_QC_norel --threads 8
  plink --bfile 1000GenomePhase3_QC_norel --extract 1000GenomePhase3_QC_norel.prune.in --make-bed --out 1000GenomePhase3_QC_norel_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --indep-pairwise 100 1 0.2
  --out 1000GenomePhase3_QC_norel
  --threads 8

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 10:54:56 2017

Random number seed: 1495097696
193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
5398440 variants and 919 people pass filters and QC.
Note: No phenotypes present.
Pruned 383736 variants from chromosome 1, leaving 26796.
Pruned 409231 variants from chromosome 2, leaving 26138.
Pruned 362671 variants from chromosome 3, leaving 23164.
Pruned 376046 variants from chromosome 4, leaving 22366.
Pruned 321739 variants from chromosome 5, leaving 20282.
Pruned 346793 variants from chromosome 6, leaving 20983.
Pruned 305297 variants from chromosome 7, leaving 19601.
Pruned 277248 variants from chromosome 8, leaving 17633.
Pruned 221055 variants from chromosome 9, leaving 15895.
Pruned 261309 variants from chromosome 10, leaving 17514.
Pruned 252249 variants from chromosome 11, leaving 16083.
Pruned 242441 variants from chromosome 12, leaving 16907.
Pruned 187619 variants from chromosome 13, leaving 12263.
Pruned 162678 variants from chromosome 14, leaving 11591.
Pruned 141956 variants from chromosome 15, leaving 11349.
Pruned 155359 variants from chromosome 16, leaving 12485.
Pruned 131431 variants from chromosome 17, leaving 11774.
Pruned 147368 variants from chromosome 18, leaving 11167.
Pruned 119426 variants from chromosome 19, leaving 10107.
Pruned 107554 variants from chromosome 20, leaving 9096.
Pruned 72900 variants from chromosome 21, leaving 5623.
Pruned 67178 variants from chromosome 22, leaving 6339.
Pruning complete.  5053284 of 5398440 variants removed.
Marker lists written to 1000GenomePhase3_QC_norel.prune.in and
1000GenomePhase3_QC_norel.prune.out .

End time: Thu May 18 10:55:08 2017

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to 1000GenomePhase3_QC_norel_prunned.log.
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --extract 1000GenomePhase3_QC_norel.prune.in
  --make-bed
  --out 1000GenomePhase3_QC_norel_prunned
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel_prunned.nosex .
--extract: 345156 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999904.
345156 variants and 919 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC_norel_prunned.bed +
1000GenomePhase3_QC_norel_prunned.bim + 1000GenomePhase3_QC_norel_prunned.fam
... done.

#+end_example
*** Conversion dans format utilisable en R

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R.

**** STARTED Données non prunnées
:LOGBOOK:
- State "STARTED"    from "RUNNING"    [2017-07-13 jeu. 12:29]
- Note taken on [2017-07-13 jeu. 11:57] \\
  Après ca on va creer la matrice matter par block !! Et il faudra calculer les
  indice du prinning et aussi les indice sur les individus !!!
- Note taken on [2017-07-13 jeu. 11:57] \\
  Ca tourne sur mon pc fixe :D
- State "RUNNING"    from "TODO"       [2017-07-13 jeu. 11:57]
- State "TODO"       from              [2017-07-13 jeu. 08:59]
:END:
Nous allons utiliser =matter=
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("./Data/1000Genomes/Phase3/plink/")
  bedfile <- "1000GenomePhase3_QC_norel.bed"

  snp_readBed(bedfile, "1000GenomePhase3", backingpath = "backingfiles_norel")

  genome1000 <- snp_attach("backingfiles_norel/1000GenomePhase3.rds")
  dim(genome1000$genotypes)

  ## convert in matter format
  library(matter)
  G.matter <- matter_mat(nrow = nrow(genome1000$genotypes),
                         ncol = ncol(genome1000$genotypes))
#+END_SRC

#+RESULTS:
#+begin_example
  > dim(genome1000$genotypes)
  [1]     919 5398440
#+end_example

**** TODO Données prunnées
:LOGBOOK:
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:
#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("./Data/1000Genomes/Phase3/plink")
  bedfile <- "1000GenomePhase3_QC_norel_prunned.bed"

  snp_readBed(bedfile, "1000GenomePhase3")
#+end_src

#+begin_src R :results output :exports both
  library(bigsnpr)
  genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")

  names(genome1000)
  dim(genome1000$genotypes)

  ## G
  G <- attach.BM(genome1000$genotypes)[]
  rownames(G) <- genome1000$fam$sample.ID
  colnames(G) <- genome1000$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)
  saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  dim(G)
#+end_src

#+RESULTS:
#+begin_example
  > library(bigsnpr)
  > genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")
  > 
  > names(genome1000)
  [1] "genotypes" "fam"       "map"       "savedIn"  
  > dim(genome1000$genotypes)
  [1]    919 345156
  > 
  > ## G
  > G <- attach.BM(genome1000$genotypes)[]
  > rownames(G) <- genome1000$fam$sample.ID
  > colnames(G) <- genome1000$map$marker.ID
  > n <- nrow(G)
  > L <- ncol(G)
  > saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  > dim(G)
  [1]    919 345156
#+end_example

On veut récuperer les noms des collones restantes 
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("./Data/1000Genomes/Phase3/plink")
  genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")

#+END_SRC

*** TODO Scaling des données
:LOGBOOK:
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:
Pour certaine analyse il est important de scaler les données. 

#+begin_src R :results output :exports both
  G <- readRDS("./Data/1000Genomes/Phase3/plink/1000GenomePhase3_QC_norel_prunned.rds")
  G <- scale(G)

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
#+end_src
*** TODO Filtrage des données manquantes
:LOGBOOK:
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:
Il reste certain SNPs avec des données manquantes ($0.7 \%$), nous les avons enlevé.
#+begin_src R :results output :exports both
  library(MaTheseR)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
  G <- preprocessing_filter_na(G)
  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
#+end_src

#+RESULTS:
#+begin_example
  TRACE [2017-05-18 16:19:27] proportion of removed loci =  0.00775881050887135
  > dim(G)
  [1]    919 342478
#+end_example
** Arabidopsis Thaliana Regional Mapping Lines                    :noexport:
** 1001 genome                                                    :noexport:
** TODO Celiac GWAS                                               :noexport:
:LOGBOOK:
- Note taken on [2017-07-11 mar. 09:32] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
- State "TODO"       from              [2017-07-11 mar. 09:27]
:END:
*** Téléchargement des données
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=


*** Contrôle qualité
*** Filtrage des individus trop apparenté
*** Imputation des données manquantes
Avec bigsnpr et xgboost
*** Élagage
*** Conversion au format R et scaling
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
**** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
*** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
*** CANCELLED Conversion au format =bigmatrix=
CLOSED: [2017-07-23 Sun 15:46]
:LOGBOOK:
- Note taken on [2017-07-23 Sun 15:46] \\
  MDRRRRR: 
  Error in SetMatrixElements(x@address, as.double(j), as.double(i), as.double(value)) : 
  long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
  In addition: Warning message:
  In filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  No descriptor file given, it will be named G.big.bin.desc
- State "CANCELLED"  from              [2017-07-23 Sun 15:46]
- State "TODO"       from              [2017-07-23 Sun 15:29]
:END:
#+BEGIN_SRC R
  library(bigmemory)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "./Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.big.bin")
  colnames(G.big) <- colnames(G)
  rownames(G.big) <- rownames(G)
  saveRDS(G.big, "./Data/ThesisDataset/3Article/Celiac/G.big.rds")
#+END_SRC
** AT EWAS                                                        :noexport:
*** Téléchargement des données
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC
*** Formatage
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC
*** Preprocessing
Nour avons reproduit le preprocessing expliqué dans cite:Zou_2014.
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC
*** Scaling des données
Pour certaine analyse il est important de scaler les données. 
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

* Inférence rapide des coefficients de métissage à l'aide des données géographique
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:07] \\
  Non je ne vais pas avoir le temps, je vais traduire l'article, étoffer un peu
  et basta. Je mettrais en perspective le traitement des données manquantes pour
  tess3r et sur un très gros dataset si j'ai le temps (1001 genome, avec une
  analyse de la population et une association environmental, pour ilustrer les
  deux feature gros dataset et NA)
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
* Estimation des facteurs latents pour corriger les tests d'association
** Introduction
** Méthodes 
*** Modèle 
<<sec:model>>
Nous introduisons dans cette partie les notations et le modèle. La plupart des
méthodes d'ajustement pour les facteurs de confusions repose sur le modèle
suivant  
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Comme dans cite:frichot13_testin_assoc_between_loci_envir, nous appellerons ce
modèle le modèle mixte à facteurs latents (LFMM pour latent factor mixed model
en anglais). Dans cette équation, $\Y$ est la matrice des variables expliquées
de taille $\Yrow \times \Ycol$, où $\Ycol$ est le nombre de variables et $\Yrow$
le nombre d'observations. Par exemple, les variables expliquées peuvent être des
SNPs, des niveaux de méthylation ou bien des niveaux d'expression génique . La
matrice $\X$ de taille $\Xrow \times \Xcol$ représente les variables
explicatives. Les variables explicatives peuvent être par exemple un phénotype
comme une maladie ou un gradient environnemental comme la température de
l'habitat. La matrice des effets de taille $\Ycol \times \Xcol$ est notée $\B$.
Les matrices $\V$ et $\U$ sont respectivement la matrice des axes factoriels de
taille $\Ycol\times\Ucol$ et la matrice des coordonnées sur ses axes de taille
$\Urow \times \K$. La matrice $\U$ est la matrice des $\K$ variable latentes et
la matrice $\V$ représente les axes des facteurs latents. Enfin la matrice $\E$
est la matrice d'erreur résiduelle de taille $\Yrow\times\Ycol$.

Nous remarquons dans un premier temps que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. Nous posons 
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
et appelons cette matrice, la matrice latente. Si l'on suppose qu'il y à $\K$
variables latentes linéairement indépendants cela est équivalent a faire
l'hypothèse que la matrice latente $\W$ est de rang $\K$. Dans la suite nous
considérons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce à
l'analyse en composante principale de la matrice latente $\W$.

*** Estimation des moindres carrés régularisée en norme $L_{2}$
<<sec:estimator_L2>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres de
LFMM défini par eqref:eq:model basé sur un problème des moindres carrées
régularisé en norme $L_{2}$. Nous montrons que cette algorithme permet de
calculer un point de minimum global du problème d'optimisation de moindres
carrés.

**** Fonction objectif

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM nous définissons la
fonction objectif suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lambRidge$ le paramètre de régularisation. 

Le terme premier terme de $\Lridge$ (terme d'attache aux données) correspond à
l'opposé de la log vraisemblance où la matrice de bruit $\E$ est gaussienne,
isotrope et de moyenne nulle.

Le terme deuxième terme de $\Lridge$ (terme de régularisation) est indispensable
pour distinguer l'effet des variables latentes de celui des variables
explicatives. En effet, si
\begin{equation*}
\lambRidge = 0 
\end{equation*}
alors pour toutes matrices $\matr{T}$ de taille $\Xcol \times \Ycol$ on a 
\begin{equation*}
\Lridge(\U - \X \matr{T}, \V^{T}, \B + \V \matr{T}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Ainsi, les points du minimum d'une telle fonction objective ne sont pas définis
de manière univoque pour notre problème.

**** Algorithme
Afin d'estimer les paramètres de LFMM minimisant $\Lridge$ nous commençons par
calculer la décomposition en valeurs singulières de la matrice des variables
explicatives $\X$
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T}
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$ de $\X$. Les estimateurs sont calculés de
la façon suivante
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V} & =  \matr{Q} \matr{D}^{-1} \svd_{\K}( \matr{D} \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}),
\end{align}
où $\svd_{\K}(\matr{A})$ est la meilleure approximation de rang $\K$ de la matrice
$\matr{A}$ données par la décomposition en valeurs singulières (SVD pour
singular value decomposition) et $\Id_{d}$ est la matrice identité de taille $d
\times d$. La matrice $\matr{D}$ est la matrice diagonale de taille $\Yrow
\times \Yrow$ qui contient les termes diagonaux
\begin{equation*}
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latente $\hat{\U} \hat{\V}$ dans
l'équation eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement
de base $\matr{Q}$. Les $\Xcol$ premiers axes de la base canonique transformée
par $\Q$ forment une base orthonormale de l'espace vectoriel engendré par les
variables explicatives. La matrice diagonale $\matr{D}$ a pour effet de réduire
la composante qui appartient à l'espace engendré par $\X$. Si $\lambRidge$ vaut
zéro la multiplication par $\matr{D} \matr{Q}^{T}$ revient à prendre le résidu
d'une régression linéaire par $\X$, on enlève alors toute la corrélation
linéaire avec $\X$. Si $\lambRidge$ est très grand alors $\D$ tend vers la
matrice identité. Dans ce cas, le calcul de $\hat{\U} \hat{\V}$ revient à faire
une analyse en composante principale de la matrice $\Y$. Il est donc important
de choisir une valeur de $\lambRidge$ qui enlève la bonne proportion de
corrélation avec les variables explicatives $\X$. Nous expliquons dans la partie
[[sec:hyperparametre]] plus en détail comment choisir l'hyperparamètre
$\lambRidge$.

L'estimation des paramètres régularisé en norme $L_{2}$ est justifié par le
théorème suivant
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambRidge$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, défini un point de
minimum global de la fonction objective $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $ \hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$ qui soit un
minimum global de la fonction $\Lridge$. Commençons par remarquer que la
fonction $\Lridge$ est convexe en la variable $\B$ , on peut donc
trouver le point de minimum global en annulant la dérivée de $\Lridge$ par
rapport à $\B$
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V).
\end{equation}
Il s'agit de l'estimateur ridge du modèle de la régression linéaire de $\Y - \U
\V$ par $\X$.

Il faut maintenant minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeur singulière de $\X$ tel que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T}
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$.L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D^{2} \matr{Q}^{T} (\Y - \U \V^{T})} + 
\frac{1}{2} \lambRidge \norm{\matr{C}_{\lambRidge} \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
où $\matr{C}_{\lambRidge}$ est une matrice de taille $\Xcol \times \Xrow$
remplie de zéro sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambRidge}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\D$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Les matrices $\D$ et $\matr{C}_{\lambRidge}$ étant diagonales, nous pouvons factoriser
$\mathcal{L}^{'}$ de sorte que 
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
Enfin, optimiser la fonction objectif $\mathcal{L}^{'}$ est équivalent au
problème de trouver la meilleur approximation de rang $\K$ de la matrice
\begin{equation*}
\matr{D} \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$ valeurs
singulières les plus grandes cite:Eckart_1936. Nous avons bien montré que
\begin{align*}
\hat{\U} \hat{\V} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\hat{\B} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof
*** Estimation des moindres carrées régularisée en norme $L_{1}$  
<<sec:estimator_L1>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle LFMM défini par eqref:eq:model basé sur un problème des moindres carrés
régularisé en norme $L_{1}$. Nous montrons que cet algorithme converge vers
un point de minimum global du problème d'optimisation.

**** Fonction objectif
Nous proposons la fonction objective suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\W}_{*}$ la norme nucléaire de la matrice
$\W$, définie comme la somme de ses valeurs singulières.

Le choix de la norme $L_{1}$ est motivé par le fait que l'on s'attend à ce que
seulement une certaine proportion de variables expliquées soit associées aux
variables explicatives. C'est à dire que seulement une certaine proportion des
lignes de la matrice des effets $\B$ doivent être non nulles. La régularisation
$L_{1}$ est connue pour produire des estimateurs parcimonieux de $\B$
cite:Tibshirani_1996.

La fonction $\Llasso$ fait aussi intervenir une régularisation sur la matrice
latente $\W$. Ainsi la fonction $\Llasso$ est convexe et nous savons le rang de
$\hat{\W}$, point minimum de $\Llasso$, décroît avec $\gamma$ le paramètre de
régularisation devant la norme nucléaire cite:bach2008consistency.

**** Algorithme
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par blocs de coordonnées
qui permet d'estimer les paramètres de LFMM minimisant la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg.

Nous initialisons l'algorithme avec des matrices nulles : 
\begin{align*}
\W_{t = 0} & = 0 \\
\B_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. Calculer $\B_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{lasso}^{2}(\B) =  \frac{1}{2} ||(\Y - \W_{t-1}) - \X \B^T||_{F}^2 + \lambLasso ||\B||_1
   \end{equation}
2. Calculer $\W_{t}$ le point minimum de  
   \begin{equation}
   \label{eq:lasso2}
   \mathcal{L}_{lasso}^{1}(\W) = \frac{1}{2} ||(\Y - \X \B_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répétées jusqu'à ce que l'algorithme est converge ou bien que
$t$ atteint le nombre maximum d'itérations. Nous allons maintenant expliquer
plus en détail les deux étapes de l'algorithme.

La première étape de l'algorithme consiste à faire une régression linéaire
régularisée en norme $L_{1}$ de la matrice résiduelle
\begin{equation}
\matr{E}^{1}_{t} = \Y - \W_{t-1}
\end{equation}
par les variables explicatives $\X$. Il existe plusieurs algorithmes pour
estimer les paramètres de cette régression comme par exemple l'algorithme de
descente par coordonnées cite:Friedman_2007. Dans le cas présent on s'intéresse
plus à l'estimation des variables latentes, qui permettrons ensuite de faire le
test d'association (voir la partie [[sec:hypothese]]). Nous pouvons transformer les
variables explicatives de sorte que
\begin{equation}
\X^{T} \X = Id_{d}.
\end{equation}
On a alors d'après cite:Tibshirani_1996 
\begin{equation}
\B_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambLasso)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s)
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est le paramètre de la
régression linéaire classique données dans ce cas par 
\begin{equation*}
\bar{\B}_{t} = \X^{T} \matr{E}^{1}_{t}.
\end{equation*}

La deuxième étape de l'algorithme est un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \B_{t}^{T}
\end{equation}
Cette approximation est donnée grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
la matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T}
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. On a alors 
\begin{equation}
\W_{t} = \matr{M} \bar{\matr{S}} \matr{N}^{T}
\end{equation}
où $\bar{\matr{S}}$ est la matrice diagonale formé par les les valeur singulière
de $\matr{S}$ seuillées. Ainsi les termes diagonaux de $\bar{\matr{S}}$ sont de
sorte que 
\begin{equation*}
\bar{s}_{j} = (s_{j} - \gamma)_{+}, ~ j = 1,...,\Yrow.
\end{equation*}
Ce seuillage produit des valeurs nulles et ramène vers zéro les valeurs
singulières restantes.

L'algorithme de descente par blocs de coordonnées ne converge pas en général
vers un point minimum quand la fonction n'est pas continûment différentiable,
comme c'est le cas pour $\Llasso$. On peut trouver dans la littérature des
résultats sur les algorithmes par blocs de coordonnées dans des cas ou la
fonction objective n'est pas différentiable cite:Tseng_2001 . Cependant, les
théorèmes démontrer dans cite:Tseng_2001 dépasse largement le cadre de la
convergence de l'algorithme d'estimation $L_{1}$ présenté ici ce qui complique
l'extraction des résultats intéressants. Pour facilité la compréhension, nous
proposons de démontrer un théorème plus faible qui s'applique directement à
notre cas. Pour cela nous introduisons quelques notations. Soit la fonction $f$
définie sur son domaine
\begin{equation}
\label{eq:domf}
A = A_{1} \times A_{2} \times ... \times A_{m}
\end{equation}
un produit cartésien d'ensembles fermés et convexes. L'algorithme de descente par
blocs de coordonnées est défini par la formule de récurrence suivante :
\begin{equation}
\label{eq:blokAlgo}
x_{i}^{k+1} \in \mathrm{arg} \min_{\zeta \in X_{i}} f(x_{1}^{k}, ...,x_{i-1}^{k},\zeta,x_{i+1}^{k},..., x_{m}^{k}), ~
i = 1,...,m.
\end{equation}
En nous inspirant des résultats présenté dans cite:Tseng_2001 et de la
proposition 2.7.1 de cite:Bertsekas_1997 qui montre la convergence de
l'algorithme de descente par bloc de coordonnées dans le cas la fonction
objectif est différentiable, nous démontrons le théorème suivant :
#+BEGIN_theorem 
Si $f$ est continue, convexe et tel que
\begin{equation}
f(x_{1},..., x_{m}) = g(x_{1}, ..., x_{m}) + \sum_{i = 1}^{m} f_{i}(x_{i}) 
\end{equation}
où g est convexe et différentiable et les fonctions $f_{i}$ sont continues et
convexes. Soit $\{x^{k}\}$ la séquence générée par eqref:eq:blokAlgo. Alors tout
point limite de $\{x^{k}\}$ est un point de minimum global de $f$.
#+END_theorem

#+BEGIN_proof 
On note
\begin{equation*}
\bar{x} = (\bar{x}_{1}, ..., \bar{x}_{m})
\end{equation*}
un point limite de $\{x^{k}\}$, $\bar{x}$ est bien dans $A$ le domaine de
définition de $f$ car cet ensemble est fermé. Comme $g$ est convexe et
différentiable on a pour tout $x \in A$
\begin{align}
\label{eq:lassoProof1}
f(x) - f(\bar{x}) & \geq & \nabla g(\bar{x})(x - \bar{x}) + 
\sum_{i = 1}^{N} (f_{i}(x_{i}) - f_{i}(\bar{x}_{i})) \\
 & & = \sum_{i = 1}^{N} ( \nabla_{i} g(\bar{x})(x_{i} - \bar{x}_{i}) + 
 f_{i}(x_{i}) - f_{i}(\bar{x}_{i}))
\end{align}
où $\nabla g(\bar{x})$ et $\nabla_{i} g(\bar{x})$ sont respectivement la dérivée
et la dérivée par rapport à la $i\text{-ième}$ variable de $g$ en $\bar{x}$. Or
nous savons par construction de $\bar{x}$ que
\begin{equation}
\label{eq:lassoProof2}
f(\bar{x}) \leq f(\bar{x}_{1}, ...,x_{i},..., \bar{x}_{m}), ~ \forall x_{i} \in
A_{i}.
\end{equation} 
On a donc pour chaque variable d'indice $i$
\begin{align}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  (\nabla_{i} g(\bar{x}) + r_{i})(x - \bar{x}) \\
\label{eq:lassoProof3}
& \geq 0
\end{align}
où $r_{i}$ est une sous-dérivée de la fonction convexe $f_{i}$. En effet,
l'équation eqref:eq:lassoProof2 nous permet de dire qu'il existe une
sous-dérivée $r_{i}$ tel que
\begin{equation}
\label{eq:3}
(\nabla_{i} g(\bar{x}) + r_{i}) = 0
\end{equation}
d'où l'équation eqref:eq:lassoProof3. Finalement, nous avons en utilisant
eqref:eq:lassoProof3 et eqref:eq:lasso1 
\begin{equation}
f(x) - f(\bar{x}) \geq 0, ~ \forall x \in A.
\end{equation}
#+END_proof
Ce résultat démontre que l'algorithme d'estimation $L_{1}$ des paramètres du
modèle LFMM converge vers un point de minimum global de $\Llasso$.
*** Complexité des algorithmes
Dans cette partie nous abordons la complexité des algorithmes d'estimation des
paramètres présentées dans les parties précédentes. On peut distinguer deux
grandes étapes dans ces algorithmes. La première est le calcul de la
décomposition en valeur singulière tronqué (voir le calcul de la matrice
latente donné par l'équation eqref:eq:RidgeLfmmEstomatorW pour l'estimation
$L_{2}$ et la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{lasso}^{1}$ définie par eqref:eq:lasso2 pour l'estimation
$L_{1}$). La seconde est le calcul de la projection orthogonale sur l'espace
engendré par les variables explicatives (voir le calcul de $\W$ donné par
l'équation eqref:eq:RidgeLfmmEstomatorB pour l'estimation $L_{2}$ et la
résolution du problème d'optimisation de la fonction $\mathcal{L}_{lasso}^{2}$
définie par eqref:eq:lasso1 pour l'estimation $L_{1}$).

D'après cite:Halko_2011, le calcul des $K$ composantes dominantes de la
décomposition en valeurs singulières demande $O(\Yrow \Ycol \K)$ opérations.
Cette complexité temporelle peut même être réduite à $O(\Yrow \Ycol \log(\K))$
si on utilise une méthode avec projections aléatoires, comme celle présenté dans
cite:Halko_2011.

La deuxième étape importante consiste en une projection du résidu de
l'approximation de rang faible sur l'espace engendré par $\X$. Le nombre précis
d'opération dépend des hypothèses qui sont faites sur la matrice $\X$ (dans
l'algorithme d'estimation $L_{1}$ aucune inversion de matrice n'est nécessaire
pour le calcule de $\B_{t}$). Mais dans les deux algorithmes, si on s'intéresse
seulement au comportement asymptotique par rapport à $\Yrow$, $\Ycol$ et $\Ucol$,
alors on peut majorer la complexité temporelle par $O(\Ycol \Yrow + \Ucol
(\Ycol + \Yrow))$.

Finalement, pour les deux algorithmes, le nombre d'opération est majoré par
$O(\Yrow \Ycol \K)$. L'algorithme d'estimation $L_{1}$ est bien entendu plus
long car il réalise plusieurs fois (le nombre d'itérations dépend de la vitesse
à laquelle l'algorithme converge) les opérations de décomposition en valeurs
singulières et de projection alors que l'algorithme d'estimation $L_{2}$ ne les
réalise qu'une seule fois.

Outre la complexité temporelle il est important d'étudier la complexité
spatiale, surtout pour ce genres d'algorithme qui prennent en entrée des données
potentielles trop grandes pour la mémoire vive de l'ordinateur (RAM). Les
algorithmes d'estimation $L_{1}$ et $L_{2}$ ne nécessite pas de dupliquer la
matrice des variables explicatives $\Y$. La matrice $\Y$ est de taille
$\Yrow \times \Ycol$ et donc la dupliquer pourrait poser des problèmes sur des
ordinateurs ne possédant pas assez de RAM. Il est même possible d'envisager de ne
pas charger la matrice $\Y$ en RAM et d'accéder au données seulement quand cela est
nécessaire. 

*** Choix des hyperparamètres 
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

La sélections des hyperparamètres est un problème commun a de nombreuse méthodes
en analyse de données. Nous présentons plusieurs approches pratiques pour
choisir les hyperparamètre qui interviennent dans les algorithmes que nous
présentés ici. Nous commençons par présenter les différentes approches possibles
pour choisir le nombre de variables latentes $K$. Nous présentons ensuite
plusieurs heuristiques qui permettent d'aider le choix des paramètres de
régularisation. Enfin nous présentons un algorithme de validation croisée adapté
aux algorithmes que nous avons présentés.

**** Nombre $\K$ de variables latentes
Nous avons vu dans la section [[sec:estimator_L2]] que la matrice latente $\W$ peut
être estimée grâce à l'analyse en composante principale (ACP) de $\D \Q^{T} \Y$.
Ainsi, afin d'estimer le nombre $\K$ de variable latente pour le modèle LFMM,
nous proposons d'employer les techniques d'estimation du nombre de variables
latentes utilisées pour l'ACP sur la matrice $\D \Q^{T} \Y$ .

Il existe de nombreuses approches pour déterminer le nombre de composantes
principales de l'ACP, celle-ci sont très bien expliquées dans
cite:jolliffe1986principal. On peut grouper ses approches en trois catégories.
Les approches subjectives comme l'utilisation du scree plot, il s'agit du graphe
des valeurs singulières de la matrice des données. Les approches basées sur une
modélisation de la distribution des données observées, comme par exemple la
méthode présentée dans cite:choi2014selecting. Les approches basées sur la
validation croisée, comme celle que nous détaillons plus loin.

Aucune méthode ne s'est imposée comme la référence, et il est préférable d'en
utiliser plusieurs. Pour les expériences que nous avons réalisées sur des vraies
données, le choix du nombre de variables latentes $\K$ du modèle LFMM a été fait à
partir du scree plot de la matrice $\D \Q^{T} \Y$ pour différente valeurs de
$\lambRidge$ et de la validation croisée.

**** TODO Paramètre de régularisation $L_{2}$
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 16:55]
- Note taken on [2017-07-20 Thu 16:54] \\
  j'y verrai plus claire quand j'aurais choisi lambda pour les vrai data set et
  une fois que la cross validation marchera ou pas...
:END:
Le paramètre de régularisation $L_{2}$ intervient dans le calcul de
l'estimation de la matrice latente décrit dans la partie [[sec:estimator_L2]] par le
biais de la matrice diagonal $\D$. Cette matrice permet de réduire la
corrélation entre les variables expliquées $\Y$ et les variables explicatives
$\X$ afin de pouvoir estimer les variables latentes. 

Si le paramètre de régularisation $L_{2}$ tend vers zéro, les variables expliqué
et explicative seront linéairement décorrélé. Cependant on ne pourra plus inverser
la matrice diagonale $\D$. De plus dans le cas ou les variable latentes sont
trop corrélé avec $\X$ alors on risque de mal estimer celles-ci. 

Si le paramètre tend vers l'infini alors la matrice $\D$ tend vers la matrice
identité l'estimation des variables latentes sont données pas l'analyse en
composante principale de $\Y$.

Ainsi le choix de du paramètre de régularisation $L_{2}$ est une affaire de
dosage, il doit être ni trop grand ni trop petit. Nous avons remarqué dans les
expériences que $\lambdaRidge$ petit donne les meilleurs résultats dans de nombreux
cas.

**** Paramètre de régularisation $L_{1}$
Le paramètre de régularisation $L_{1}$ à un impacte sur le nombre de ligne non
nulles dans la matrice des effets $\B$. Nous savons à priori que seulement une
partie des variables expliquées sont corrélé avec les variables explicatives.
Ainsi, il est possible d'interpréter la proportion de lignes non nulles dans
$\B$ comme la proportion des variables qui sont corrélé avec $\X$. Plutôt que de
choisir le paramètre de régularisation, il est plus simple de choisir la
proportion de variable expliquées par $\X$. Pour trouver un paramètre de
régularisation qui correspond à cette proportion nous proposons une heuristique
basée sur un chemin de régularisation inspiré par
cite:friedman10_regul_paths_gener_linear_model.

Nous commençons par la plus petite valeur du paramètre de régularisation
$\lambLasso$ tel que le vecteur
\begin{equation}
\bar{\B}_{t} = (\X^{T} \X + \lambLasso \Id_{d})^{-1} \X^{T} (\matr{E}^{1}_{t = 1})
\end{equation}
vaut zéro. Ceci est le résultat de la première étape de l'algorithme
d'estimation des moindres carrés régularisée en norme $L_{1}$ présenté dans la
partie [[sec:estimator_L1]]. Nous notons cette valeur $\lambLasso^{\mathrm{max}}$.
Ensuite, nous construisons une séquence de $m$ valeurs de $\lambLasso$ décroissant
selon une échelle logarithmique depuis $\lambLasso^{\mathrm{max}}$ jusqu'à
\begin{equation}
\lambLasso^{\mathrm{min}} = \epsilon \lambLasso^{\mathrm{max}}.
\end{equation}
Enfin, nous calculons le nombre de valeurs non nulle dans $\hat{\B}$
l'estimation de la matrice des effets et stoppons si la proportion de valeurs
non nulle souhaitée est dépassée.


**** Paramètre de régularisation de la norme nucléaire
Le paramètre de régularisation de la norme nucléaire dans l'algorithme
d'estimation $L_{1}$ à une influence sur le rang de la matrice latente $\W$. Il
est plus simple de choisir le rang de cette matrice, qui correspond au nombre de
variables latentes $K$, que de choisir le paramètre de régularisation $\gamma$.

Nous proposons l'heuristique suivante pour calculer $\gamma$ à partir de $K$.
Nous commençons par calculer les valeurs singulières de la matrice des variables
expliquées $\Y$, que l'on note $(\sigma_1, ..., \sigma_{\Yrow})$. Ensuite, on calcul 
\begin{equation}
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2}.
\end{equation}

**** TODO Cross validation
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:00]
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:
Cross validation is a classic method to select hyper-parameter in factor
analysis cite:Owen_2009,Bro_2008. The cross validation algorithm we used is
explained in detail in annex. Cross validation procedure can be long to run in
particular on very big data set. Especially since LassoLFMM and RidgeLFMM have
each two hyper-parameters which can be cross-validated. We propose other procedure
to assess hyper-parameters that gave good results in our experiments.

***** COMMENT ANNEX Cross validation algorithm
We present here the cross validation algorithm which can be used to assess
hyper-parameter of LassoLFMM and RidgeLFMM.

We first split the observation output matrix into 
$$
\Y^{(-I)}
$$
and 
$$
\Y^{(I)}
$$ where matrices are respectively compose of 


. We write the training
data matrices $$ \Y^{(-i)}$$ and $$\X^{(-i)}.$$ These matrices are compose of
random lines of the observed output matrix and the primary matrix. Then we
compute (with RidgeLFMM or LassoLFMM) latent factor matrices $$\U^{(-i)}$$ and
$$\V^{(-i)}$$ and the primary effect matrix $$\B^{(-i)}.$$

In a second step we want to compute an estimation of test output matrix
$$\Y^{(i)}$$. However, to predict the output matrix with LFMM model
eqref:eq:model we must estimate the latent score matrix 
$$\U^{(i)}$$ 
for this the test data.
To avoid using test observation for the prediction, we split the test data
by selecting a random set of variables of the observed output matrix which we
note $$\Y^{(i)_{(-j}}$$. 

Then, if we assume that we know the primary effect size
matrix and the latent factor loading matrix for staying variables we write 

\begin{equation}
\label{eq:cvU}
U^{(i)}_{(-j)} = (\Y^{i}_{(-j)} - \X^{(i)}} \B^{(-j)}) \V_{(-j)}^{T}.
\end{equation}

The equation eqref:eq:cvU is given by optimal solution of $L$
ref:eq:optim_no_reg when $V$ and $B$ are fixed.

Finally, we compute the residual error on the test set such as 
\begin{equation}
Err = \norm{ \Y^{i}_{(j)} + \X^{(i)}} \B^{(-i)_{(j)} + \U^{(i)}_{(-j)} \V^{(-i)}
\end{equation}

*** Test d'hypothèse
<<sec:hypothese>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Jusque ici, nous avons seulement abordé l'estimation des paramètres de LFMM.
Cependant, l'objectif initial est de trouver la liste des variables expliquées
associées aux variables explicatives tout en prenant en compte les potentielles
variables latentes. Nous présentons dans cette partie un test d'hypothèse
corrigé pour les variables latentes.

Une approche simple consiste a considérer que l'estimation des variables
latentes $\hat{\U}$ comme les vraies valeurs de $\hat{\U}$ et de les utiliser au
coté des variables explicatives du modèle mis en place pour réaliser le test
d'hypothèse. C'est une méthode très courante dans les études d'associations qui
a montrer de très bon résultats surtout quand il y assez d'observations
cite:gerard2017unifying,Price_2006,Song_2015,article_Leek_Storey_2008,Rahmani_2016.
Nous avons choisi de réaliser un test d'hypothèse qui repose sur le modèle la
régression linéaire car cela correspond au modèle LFMM quand on suppose que $\U$
est connue. Mais les estimations des variables latentes peuvent être traitées comme
variables explicatives dans n'importe quel modèle statistique.

Afin de simplifier les notations et sans perte de généralité, nous supposons
qu'il n'y a qu'une seule variable explicative, c'est à dire que $\Xcol$ vaut $1$.
De plus nous rappelons que l'estimation de la matrice des $\K$ variables
latentes $\hat{\U}$ est définie de façon unique grâce à l'ACP de la matrice
$\hat{\W}$. La matrice $\hat{\W}$ est l'estimation $L_{1}$ ou $L_{2}$ de la
matrice latente du modèle LFMM.

**** Calcul de la statistique de test
Pour chaque variable expliquée $j$ nous avons le modèle de régression linéaire
suivant
\begin{equation}
\Y_{j} =  \hat{\U} \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{\epsilon_{j}}.
\end{equation}
où la matrice $\hat{\U}$ est l'estimation $L_{1}$ ou $L_{2}$ de la matrice des
variables latentes du modèle LFMM. On suppose que l'erreur $\matr{\epsilon_{j}}$
est Gaussienne de moyenne nulle. On veut tester l'hypothèse de nullité du
coefficient de régression $\beta_{j}$. Sous ces hypothèses on peut calculer pour
chaque variable expliquée une statistique $z_{j}$. Le détail des calculs de la
statistique de test est données dans la section 3.2 de cite:Hastie_2009. La
statistique de test suit sous l'hypothèse nulle le loi de Student à $\Yrow -
\K - 1$ degrés de liberté. On peut donc calculer pour chaque variable expliquée
une \pvalue.


**** Calibration du test d'hypothèse
Il arrive parfois que la statistique de suive pas la distribution théorique sous
l'hypothèse nulle. On dit dans ce cas que le test est mal calibré. On peut
trouver dans cite:Efron_2004 des exemples de situations qui peuvent aboutir à
des tests mal calibrés. 

Dans les exemples que nous présentons ici ont s'attend à ce que la majorité des
variables expliqués ne soit pas associé avec la variable explicative, ainsi une
large majorité des statistiques de test sont distribuées selon l'hypothèse nulle.
Nous utilisons l'approche choisi dans cite:Sun_2012, qui consiste à calculer la
médiane et la déviation absolue à la médiane (MAD pour median absolute
déviation) directement sur les $z$ statistiques. En effet, la médiane donne une
estimation robuste de la moyenne et le MAD de l'écart type. On a alors une
nouvelle statistique de test
\begin{equation}
\tilde{z_{j}} = \frac{z_{j} - \med(z_{1}, ..., z_{\Ycol})}{
\mad(z_{1}, ..., z_{\Ycol})}.
\end{equation}
Pour calculer les nouvelles \pvalue, on suppose que $\tilde{z_{j}}$ suit une loi
normal de moyenne nulle et d'écart type 1 sous l'hypothèse nulle.

**** Contrôle du taux de fausse découverte                      :noexport:
:LOGBOOK:
- Note taken on [2017-07-19 Wed 10:44] \\
  non si je fais une partie la dessus il va falloir que je developpe !! alors que
  je veux juste dire que j'ai utilisé qvalue....
:END:
Dans cette dernière partie, nous présentons en quelques mots les outils que nous
avons utiliser pour controler le taux de fausse découvertes dans les
experiences. Dans le cadre des test d'association nous voulons en sortie de la
méthode obtenir une liste de variable expliqué candidat pour l'association avec
la variable explicative. Pour choisir cette liste 
Dans le cadre des test d'association multiple 


** Expériences                                                    :noexport:
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** Méthodes comparées
<<sec:similar_method>>
**** lm and lm + pca
We comparared results of our method to two well known method the linear model
and the linear model with PCA scores. 
**** cate

**** sva
**** famt
*** Simulation et vrai jeux de données

**** Generative model simulation

We used equation to generate generative model dataset. The latent factor
scores and loadings $U$ and $V$ were generated using a multivariate gaussian
distribution with a zero mean and a $K$ identity matrix for the covariance
matrix where is the number of latent factor. The error matrix $E$ was
generated using a multivariate gaussian distribution with a zero mean and a
$L$ identity matrix for the covariance matrix where $L$ is the number of
variables. The co-variable $X$ was generated with a normal distribution with
the mean equal to zero and the standard deviation equal to one such that the
Pearson linear correlation between $X$ and $U_1$ the first latent score
matrix equal to $c$.

**** Real data example
In this section we present the real data we used to compare lasso LFMM, ridge
LFMM with similar methods presented in section [[sec:similar_method]]. To evaluate
the utility of our methods on several situation we select study where correction
for confounding variables is an important step. We realized genome wide
association study (GWAS), an genome-wide association study (EWAS) and an
ecological association study (EAS). Before running algorithm $\G$ and $\X$
matrix was centered and normalized with standard deviation for all the study. We
now describe preprocessing step for each study.

***** Association study of DNA methylation with rheumatoid arthritis (EWAS)
For the EWAS we chose data from a recent association study of DNA methylation with
rheumatoid arthritis (RA) cite:Liu_2013. We retrieve the RA data from Gene
Expression Omnibus (GEO) database (accession number GSE42861). Following
cite:Zou_2014 we filtered out site if its average probe $\beta$ value was above
0.8 are below 0.2. We finally obtain $n = 689$ and $L = 162038$.

#+BEGIN_SRC R :session *ssh krakenator*
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  dim(G)
#+END_SRC

#+RESULTS:
: [1]    689 162038

For this data set confounding variables (batch effect, age, gender, smoking
status, cell-type composition) are known but we did not use them in methods.
Thus, we can compare methods output with output of method considering explicitly
these variables cite:Rahmani_2016,Zou_2014.

***** Association study of genetic variants with Celiac disease (GWAS)
For the GWAS we chose data from an association study of SNPs with Celiac disease
citep:dubois2010multiple. Before running method we apply classic preprossessing
step with the software Plink cite:Purcell_2007. Firstly, we keep only individual
and SNPs with a proportion of missing value inferior to $5\%$. Then, we filter
out variants with minor allele frequency below $0.05$ and Hardy-Weinberg
equilibrium exact test \pvalue below $1e-10$. After that we filter out
individuals which have identity-by-descent proportion (first by pairs) superior
to $0.08$. Finally, we perform an linkage disequilibrium pruning to obtain SNPs
which are not correlated. The final dataset was of size $n = $ and $L = $.

#+BEGIN_SRC R :session *ssh krakenator*
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)
#+END_SRC

#+RESULTS:
#+begin_example
[1] 15155 94497
#+end_example

We also impute missing value with the sowtware 

***** Étude d'association des variants génétique avec un gradient climatique (EAS)
****** Preprocessing des données
Pour cette étude nous avons choisi d'utiliser les données 1000 genome. Après les
étapes de preprocessing présenter dans la section..., les individus metisse ont
été exclu. En effet pour une étude d'association à l'environement il n'est pas
pertinent de travailler avec individu issu du metissage de plusieurs
populations. Pour cette étude nous ne gardons que les individus pour lesquels
qui vivent dans leur un milieu naturel depuis plusieurs générations.

#+begin_src R :results output :exports both
  library(MaTheseR)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds")

  ## keep only indiv in G
  indiv.df <- indiv.df %>%
    dplyr::filter(sample %in% rownames(G))

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW")))
  indiv.df

  ## remove indiv
  G <- G[indiv.df$sample,]
  dim(G)

  ## filter sd, there are snps without variance !!
  sds <- apply(G, 2, sd)
  quantile(sds, 0.000001)
  G <- preprocessing_filter_sd(G, 0.0)
  dim(G)

  ## scale G
  G <- scale(G)
  anyNA(G)

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds")
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
#+end_src

#+RESULTS:
#+begin_example
  > indiv.df
  # A tibble: 670 x 4
      sample   pop super_pop gender
       <chr> <chr>     <chr>  <chr>
   1 HG01527   IBS       EUR   male
   2 HG01531   IBS       EUR female
   3 HG01583   PJL       SAS   male
   4 HG01586   PJL       SAS   male
   5 HG01589   PJL       SAS   male
   6 HG01593   PJL       SAS female
   7 HG01625   IBS       EUR   male
   8 HG01628   IBS       EUR female
   9 HG01630   IBS       EUR   male
  10 HG01679   IBS       EUR female
  # ... with 660 more rows
  > 
  > ## remove indiv
  > G <- G[indiv.df$sample,]
  > dim(G)
  [1]    670 342478
  > 
  > ## filter sd, there are snps without variance !!
  > sds <- apply(G, 2, sd)
  > quantile(sds, 0.000001)
  0.0001% 
        0 
  > G <- preprocessing_filter_sd(G, 0.0)
  proportion of removed loci = 5.83979116906779e-06
  > dim(G)
  [1]    670 342476
  > 
  > ## scale G
  > G <- scale(G)
  > anyNA(G)
  [1] FALSE
  > 
#+end_example

****** DONE Calcul du gradient climatique
CLOSED: [2017-06-27 mar. 17:56]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+begin_src R :results output :exports both
  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df

  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "CDX",]$citie = "China"
  indiv.df[indiv.df$pop == "ACB",]$citie = "Barbados"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  library(leaflet)
  m <- leaflet() %>%
    addTiles() %>%  # Add default OpenStreetMap map tiles
    addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  m  # Print the map


  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save 
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
  >   dim(X.eas)
  [1] 670   1

#+end_example

*** Description des expériences
**** DONE Comparaisons numériques sur des simulations
CLOSED: [2017-07-17 Lun 08:13]
:LOGBOOK:
- Note taken on [2017-07-17 Lun 08:14] \\
  C'est bon c'est fini ! Il faudra regarder les plots !
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:13]
- Note taken on [2017-07-13 jeu. 12:06] \\
  Je l'ai relancé avec moins de rep pourle sampler ! ca prendra moins de place en
  mémoire !!!
- Note taken on [2017-07-13 jeu. 08:55] \\
  Ca prend 50 % de la mémoire !!!!! C'est par ce qu'il y a beaucoup de données !!
- Note taken on [2017-07-12 mer. 19:39] \\
  je fais tourner la simu final !!!
- State "RUNNING"    from "STARTED"    [2017-07-12 mer. 19:39]
- State "STARTED"    from "RUNNING"    [2017-07-11 mar. 10:26]
- Note taken on [2017-07-06 jeu. 17:52] \\
  sinon les resultats sont top :D
- Note taken on [2017-07-06 jeu. 17:50] \\
  je suis pas sur que c'est le dernier lfmm ridge .... Il faut que je trouve un
  moyen dire quelle version est installé sur krakenator !! avec les commit peut
  être a voir !!!
- State "RUNNING"    from "TODO"       [2017-07-06 jeu. 11:33]
- Note taken on [2017-07-05 mer. 18:11] \\
  j'ai lancé avec le lasso c'est pas mal du tout !! J'ai elevé l'oracle, je sais
  pas pk il merde... le lasso merde quand il y 20% d'outlier mais c'est normal je
  lui ai pas mis le bon nombre de non zero !! :D
- Note taken on [2017-07-03 lun. 16:13] \\
  il faudra le relancer avec un oracle qui marche bien !!
- State "TODO"       from "RUNNING"    [2017-07-03 lun. 16:13]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 18:05]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:
Afin de valider la méthodes et son implémentation nous avons comparé ridgeLFMM
et lassoLFMM aux autres méthodes de la littérature sur des simulations
générative. 

#+NAME: code:num_val_sampler
#+CAPTION: Le sampler pour les comparaisons d'experience. Dépend de 
#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/Y_sample_p5e4_n919.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  pl <- qplot(seq_along(var), var)
  pl
  save_plot_png(pl, "file42874c17dae9.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/file42874c17dae9.png]]
#+begin_example
> save_plot_png(pl)
[[./OUTPUT/Rplots/file42874c17dae9.png]]
#+end_example

#+NAME: code:num_val_expr
#+CAPTION: Dépend de [[code:num_val_sampler]]
#+begin_src R 
  library(MaTheseR)

  ## param
  K.method <- 5
  nb.cluster <- 8
  rep.nb.sampler <- 5

  ## sampler
  s <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  s$rho.B <- 3.0
  sampler.env <- s$load.env
  samplers <-  s * param(prop.outlier = c(0.01, 0.05, 0.1, 0.15, 0.2), rho.c = c(0.1, 0.3, 0.5, 0.8, 1.0))

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.K = 100, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param() +
    m.oracle * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = rep.nb.sampler,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_fdr,
               sampler.env = sampler.env)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "validation_numerique.rds")

  ## plot auc
  toplot <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+begin_example
  > save_plot_png(pl, "validation_numerique_auc.png")
  [[./OUTPUT/Rplots/validation_numerique_auc.png]]
  > pll <- plot_gif_boxplot(toplot)
  > save_plot_png(pll, "validation_numerique_gif.png")
  [[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+end_example

**** TODO Influence de lambda sur les estimations
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 13:53] \\
  ca va faire des sup mat. C'est pour justifier le choix de lambda petit ! deux
  graphe: err X prop outlier et err X angle
- State "TODO"       from              [2017-06-29 jeu. 13:48]
:END:
**** TODO Influence des valeurs manquantes sur l'estimation des variables latentes
:LOGBOOK:
- State "TODO"       from              [2017-06-29 jeu. 13:47]
- State "TODO"       from              [2017-06-29 jeu. 13:45]
:END:
**** TODO Influence des hyper paramètres
:LOGBOOK:
- Note taken on [2017-07-10 lun. 09:12] \\
  Il faut que je montre comment les estimateur évolue en fonction de K, lambda et
  gamma. Montrer que la cross validation marche aussi !
- State "TODO"       from              [2017-07-10 lun. 09:12]
:END:
**** STARTED EAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:
***** DONE Scree plot du 1000 genome pour EAS
CLOSED: [2017-07-11 mar. 12:00]
:LOGBOOK:
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:

#+NAME: code:ewas_screeplot
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = NULL, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param()

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr)

  pl <- ExpRplot_sing_values(expr) + 
  coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "EAS_sree_plot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/EAS_sree_plot.png]]


***** DONE Validation croisée du modèle lfmmRidge sur 1000genome
CLOSED: [2017-07-11 mar. 14:36]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e8) / n
  nb.cluster <- 2
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,4,5,10,15))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "eas_CV_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "eas_CV_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda.png]]
[[./OUTPUT/Rplots/eas_CV_K.png]]

***** STARTED Étude du jeu de données
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 7
  nb.cluster <- 2
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EAS_all.rds")


#+end_src

****** Charger l'experience
#+BEGIN_SRC R
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EAS_all.rds")
#+END_SRC
****** Que donne la calibration ?
#+BEGIN_SRC R
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS:
#+begin_example
  # A tibble: 7 x 3
       method       mad     median
        <chr>     <dbl>      <dbl>
  1      cate 1.1636647 0.02952085
  2      famt 0.7583801 0.54186725
  3 lassoLFMM 0.9976638 0.01602369
  4        lm 2.1461003 0.57581267
  5     PCAlm 0.9873353 0.01161204
  6 ridgeLFMM 1.1645450 0.03903020
  7       sva 0.7385787 0.53293170
#+end_example

****** Les qqplots ?
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
  pll
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots.png]]
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

****** Le top 15
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(15)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_top_inter.png]]

****** Contrôle du FDR à $0.01$
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

****** Venn diagram
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")


  ## see common snps
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- sets[2:5]
  candidates.snps.df <- toplot %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  snps <- unique(candidates.snps.df$colname)
  snps
  ## annotation
  require(biomaRt)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att <- c("p_value", "ensembl_mart_snp")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]

****** TODO Annotation
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:
#+BEGIN_SRC R
  require(biomaRt)

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM")) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att

  toplot <- toplot %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db, att)

  toplot %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()
#+END_SRC

****** TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src

**** STARTED GWAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
***** STARTED SNPs détecté par d'autre analyse
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R :results output :exports both :session *ssh krakenator*
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")


  ## join by marker_ID
  celiac.outlier <- celiac$map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", nrow(celiac.outlier), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac$map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Le chargement a nécessité le package : bigmemory
Le chargement a nécessité le package : bigmemory.sri

Attachement du package : ‘bigmemory.sri’

The following object is masked from ‘package:testthat’:

    describe

Le chargement a nécessité le package : bigstatsr
Joining, by = "marker.ID"
nb of candidates: 60
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

*Candidates for G_clumped and test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  dat <- Article3_Celiac_sampler(clumped = FALSE) %>%
    sampl()

  snps.name <- colnames(dat$G)[dat$outlier]
  snps.name
  length(snps.name)


  ## for clumped dataset
  rm(dat)
  gc()
  G <- readRDS('~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds')
  candidates.clumped <- which(colnames(G) %in% snps.name)
  length(candidates.clumped)
  colnames(G)[candidates.clumped]
  saveRDS(candidates.clumped, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
#+end_src

#+RESULTS:
#+begin_example
  > snps.name
   [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
   [6] "rs859637"   "rs2157453"  "rs2816316"  "rs296547"   "rs13003464"
  [11] "rs10188217" "rs13015714" "rs917997"   "rs13010713" "rs7574865" 
  [16] "rs4675374"  "rs13098911" "rs6441961"  "rs17810546" "rs10936599"
  [21] "rs1464510"  "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
  [26] "rs2474619"  "rs10806425" "rs531930"   "rs802734"   "rs2327832" 
  [31] "rs1738074"  "rs212402"   "rs212388"   "rs6974491"  "rs9792269" 
  [36] "rs975730"   "rs1953126"  "rs1250552"  "rs10876993" "rs653178"  
  [41] "rs2762051"  "rs1958589"  "rs4899260"  "rs12928822" "rs2074404" 
  [46] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428" 
  > length(snps.name)
  [1] 49
  > length(candidates.clumped)
  [1] 10
  > colnames(G)[candidates.clumped]
   [1] "rs10903122" "rs859637"   "rs13010713" "rs1464510"  "rs1020388" 
   [6] "rs1738074"  "rs653178"   "rs1958589"  "rs1893217"  "rs157640" 
#+end_example
***** STARTED Scree plot
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:

#+NAME: code:screeplot_expr
#+CAPTION: Dépend de 
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we keep only disease.state
  X <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  head(X)

  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                   X.file = X,
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  expr <- PCAExperiment(s = s,
                        description = "celiac clumped PCA")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

#+NAME: code:screeplot_plot
#+CAPTION: Dépend de [[code:screeplot_expr]]
#+begin_src R :results output graphics :file Rplots/celiac_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(124)
  expr$description
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]

On prend K = 9 variables lattentes.

***** TODO Validation croisée avec lfmmRidge
:LOGBOOK:
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e5) / n
  nb.cluster <- 1
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,7,10,15))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_K.png")
#+end_src
***** RUNNING Étude du jeu de données 
:LOGBOOK:
- State "RUNNING"    from "DEBUG"      [2017-07-24 Mon 07:35]
- State "DEBUG"      from "DONE"       [2017-07-24 Mon 06:58]
- State "DONE"       from "RUNNING"    [2017-07-24 Mon 06:58]
- Note taken on [2017-07-23 Sun 16:13] \\
  C'est reparti !! sur krakenator en dehors de annaconda biensur !! pour que
  matter marche (pour avoir R 3.4)
- State "RUNNING"    from "DEBUG"      [2017-07-23 Sun 16:13]
- State "DEBUG"      from "DONE"       [2017-07-17 Lun 08:18]
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:18]
- Note taken on [2017-07-17 Lun 08:18] \\
  lasso c'est planté !! il faudra le relancer mais le reste est OK !!
- Note taken on [2017-07-13 jeu. 08:55] \\
  C'est reparti sur krak !!
- State "RUNNING"    from "STARTED"    [2017-07-13 jeu. 08:55]
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:

#+NAME: code:gwas_expr
#+CAPTION: Dépend de 
#+begin_src R
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 9
  lambda <- 1e-5
  nozero.prop <- 0.005

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## methods
  methods <- list()
  methods$m.lm <- method_lm(col.mask = col.mask,
                            inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lm.rds",
                            inter.res.file = "./OUTPUT/Expr/celiac_inter_lm.rds")
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = K.method,
                                  col.mask = col.mask,
                                  inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds",
                                  inter.res.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds")
  methods$m.pca <- method_PCAlm(K = K.method,
                                col.mask = col.mask,
                                inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds",
                                inter.res.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds"
                                )
  methods$m.cate <- method_cate(K = K.method,
                        col.mask = col.mask,
                        inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        inter.res.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        hp = "lm"
                        )
  methods$m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6,
                              col.mask = col.mask,
                              inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds",
                              inter.res.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds"
                              )

  run_celiac <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("celiac_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    if (file.exists(out.file.path)) {
      message("Reading ", out.file.path)
      df <- readRDS(out.file.path)
    } else {
      message("Running method")
      m <- ExpRmouline(m, dat)
      df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
      ## save expr
      message("Saving output in ", out.file)
      save_expr(df, out.file)
    }
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_celiac(m) %>%
      rbind(res.df)
  }
  save_expr(res.df, "celiac_all_df.rds")
#+end_src

#+RESULTS:
#+begin_example
  unmask data
  running hp
       pvalue   colname index outlier     score rep.sampler rep.method    method
  1 0.4774726 rs3934834     1   FALSE 0.7103911           1          1 ridgeLFMM
    method.K method.lambda
  1        9         1e-04
  Saving output in celiac_df_ridgeLFMM.rds
  Expr save in ./OUTPUT/Expr/celiac_df_ridgeLFMM.rds
  =============== PCAlm
  Running method
  mask data
  Computing latent variables
  Saving intermediate res into./OUTPUT/Expr/celiac_inter_PCAlm.rds
  unmask data
  running hp
      pvalue   colname index outlier    score rep.sampler rep.method method
  1 0.212448 rs3934834     1   FALSE 1.246915           1          1  PCAlm
    method.K method.lambda
  1        9            NA
  Saving output in celiac_df_PCAlm.rds
  Expr save in ./OUTPUT/Expr/celiac_df_PCAlm.rds
  =============== cate
  Running method
  mask data
  Computing latent variables
  Saving intermediate res into./OUTPUT/Expr/celiac_inter_cate.rds
  unmask data
  running hp
       pvalue   colname index outlier     score rep.sampler rep.method method
  1 0.6707667 rs3934834     1   FALSE 0.4251043           1          1   cate
    method.K method.lambda
  1        9            NA
  Saving output in celiac_df_cate.rds
  Expr save in ./OUTPUT/Expr/celiac_df_cate.rds
  =============== lassoLFMM
  Running method
  mask data
  Computing latent variables
  Error in envRefSetField(x, what, refObjectClass(x), selfEnv, value) :
    ‘missing.ind’ is not a field in class “LfmmMatterDat”
  > save_expr(res.df, "celiac_all_df.rds")
  Expr save in ./OUTPUT/Expr/celiac_all_df.rds
#+end_example

**** DONE EWAS
CLOSED: [2017-07-11 mar. 11:45]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-07-11 mar. 11:45]
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
***** Sites candidats detectés dans d'autres études
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
***** DONE Scree plot 
CLOSED: [2017-06-29 jeu. 09:42]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:
#+begin_src R  
 library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = NULL, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param()

  ## exp r
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr)

  pl <- ExpRplot_sing_values(expr) + 
    coord_cartesian(xlim = c(1,300))

  save_plot_png(pl, "scree_plot_AT.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/scree_plot_AT.png]]
#+begin_example
  > save_plot_png(pl, "scree_plot_AT.png")
  [[./OUTPUT/Rplots/scree_plot_AT.png]]
#+end_example

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-07-03 lun. 16:18]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                                   X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10) / n
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,25, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

***** DONE Étude du jeu de données
CLOSED: [2017-07-11 mar. 11:45]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 25
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")


#+end_src

****** Charger l'expérience et les candidats
#+BEGIN_SRC R
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+END_SRC
****** Que donne la calibration ?
#+BEGIN_SRC R
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS:
#+begin_example
  # A tibble: 7 x 3
       method      mad        median
        <chr>    <dbl>         <dbl>
  1      cate 1.220559  0.0143364030
  2      famt 5.798501  3.9801590213
  3 lassoLFMM 1.138814 -0.0017840118
  4        lm 4.212716  0.0453431462
  5     PCAlm 1.135042  0.0002846393
  6 ridgeLFMM 1.193740  0.0135590474
  7       sva 4.003476  2.8316228410
#+end_example

****** Les qqplots ?
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EWAS_qqplots2.png]]
[[./OUTPUT/Rplots/EWAS_qqplots.png]]

****** Le top 15
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(15)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+begin_example
# A tibble: 7 x 2
     method power
      <chr> <dbl>
1      cate     1
2      famt     0
3 lassoLFMM     1
4        lm     0
5     PCAlm     1
6 ridgeLFMM     1
7       sva     0
#+end_example

****** Contrôle du FDR à $0.01$
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 6 x 2
     method power
      <chr> <dbl>
1      cate     1
2      famt     1
3 lassoLFMM     1
4     PCAlm     1
5 ridgeLFMM     1
6       sva     1
#+end_example

****** Venn diagram
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

** Résultats                                                      :noexport:

** Discussion                                                     :noexport:
** Figures et table
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** STARTED Comparaisons des méthodes
:LOGBOOK:
- State "STARTED"    from "RUNNING"    [2017-07-25 mar. 16:35]
- State "RUNNING"    from "DEBUG"      [2017-07-25 mar. 10:57]
- State "DEBUG"      from "TODO"       [2017-07-24 lun. 17:32]
- Note taken on [2017-07-24 lun. 17:31] \\
  Je sais pas ce j'ai foutu mais c'est super lourd !! ca doit être les test, faut
  que je les enleve du coup ! je vais le faire à part ! Et ca n'a pas exporter les
  bon res. ca plot pas les bonnes choses !
- Note taken on [2017-07-17 Lun 08:15] \\
  L'experience est fini il faut faire le plot et l'anova !!!
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:

#+NAME: code:num_val_plots
#+CAPTION: Depend de 
#+begin_src R
  ## Compute plot !
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  #################
  ## by prop outlier
  toplot.prop <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(x = prop.outlier)

  ## gif
  gif.prop.pl <- plot_gif(toplot.prop, "proportion of H1")
  save_expr(gif.prop.pl, filename = "gif.prop.pl.rds")

  ## auc
  auc.prop.pl <- plot_AUC(toplot.prop, "proportion of H1")
  save_expr(auc.prop.pl, filename = "auc.prop.pl.rds")

  ###########
  ## by rho.c
  toplot.rho <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(x = rho.c)

  ## gif
  gif.rho.pl <- plot_gif(toplot.rho, "rho")
  save_expr(gif.rho.pl, filename = "gif.rho.pl.rds")

  ## auc
  auc.rho.pl <- plot_AUC(toplot.rho, "rho")
  save_expr(auc.rho.pl, filename = "auc.rho.pl.rds")
#+end_src

#+NAME: code:num_val_display
#+CAPTION: Depend de [[code:num_val_plots]]
#+begin_src R 
  ## arrange plots

  require(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(gridExtra)

  gif.prop.pl <- readRDS("./OUTPUT/Expr/gif.prop.pl.rds")
  gif.rho.pl <- readRDS("./OUTPUT/Expr/gif.rho.pl.rds")
  auc.prop.pl <- readRDS("./OUTPUT/Expr/auc.prop.pl.rds")
  auc.rho.pl <- readRDS("./OUTPUT/Expr/auc.rho.pl.rds")

  ## helpers
  #extract legend
  #https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
  g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}

  ## C
  C.pl <- gif.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "bottom")
  mylegend <- g_legend(C.pl)
  C.pl <- C.pl +
    theme(legend.position = "none") +
    xlab("Proportion d'outlier") +
    ylab("Gif moyen")

  ## A
  A.pl <- auc.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    xlab("") +
    ylab("Auc moyen")
  ## D
  D.pl <- gif.rho.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    xlab("Corrélation") + 
    ylab("") 
  ## B
  B.pl <- auc.rho.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    xlab("") +
    ylab("")

  pl <- cowplot::plot_grid(A.pl,B.pl,C.pl,D.pl,
                           ncol = 2, labels = c("A", "B", "C", "D"))

  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 mylegend, nrow=2, heights=c(10, 1))
  })

  save_plot_png(pl.leg, filename = "method_comp.png")
  save_plot_MaTheseR(pl.leg, filename = "method_comp.pdf.png", height = 20, width = 14)
#+end_src


#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics[with=14cm, height=20cm]{./OUTPUT/Rplots/method_comp.pdf.png}
\caption{Comparaison des méthodes sur des simulations numériques.}
\label{fig:method_comp}
\end{figure}
#+END_EXPORT

#+NAME: code:num_val_tests_df
#+CAPTION: Dépend de [[code:num_val_expr]]
#+begin_src R
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  auc.df <- expr$df.res %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_auc()
  save_expr(auc.df, "auc.df.rds")

  gif.df <- expr$df.res %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_gif()
  save_expr(gif.df, "gif.df.rds")
#+end_src

#+NAME: code:num_val_tests
#+CAPTION: Dépend de [[code:num_val_tests_df]]
#+begin_src R 
  require(MaTheseR)
  library(broom)
  library(ggplot2)
  library(knitr)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds")
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds")

  lm.res <- auc.df %>%
    mutate(method = as.factor(method)) %>%
    group_by(prop.outlier) %>%
    do(tidy(lm(auc ~ method, data = .))) %>%
    ungroup()


  lm.res <- lm.res %>%
    dplyr::filter(term != "(Intercept)") %>%
    transmute(method = term, `-log10(p.value)` = -log10(p.value),
                estimate = estimate, prop.outlier = prop.outlier)
  kable(lm.res)

  ggplot(lm.res, ggplot2::aes(x = prop.outlier, y = p.value, color = as.factor(method))) +
    geom_boxplot()
#+end_src

*** STARTED GWAS
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-07-25 mar. 16:37]
- State "DONE"       from "TODO"       [2017-07-25 mar. 16:37]
- State "TODO"       from              [2017-07-17 Lun 08:16]
:END:
#+NAME: code:gwas_qqplot_venn
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(gridExtra)
  MaTheseR.params <- get_MaTheseRparams()

  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")


  ## venn
  toplot <- celiac.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               ## lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[1:4])
  save_plot_png(out, filename = "gwas_venn.png")
  save_plot_MaTheseR(out, filename = "gwas_venn.pdf.png", height = 10, width = 14)

  ## qqplot
  toplot <- celiac.df %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lm"))
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    MaTheseR.params$gtheme + 
    theme(legend.position = "bottom") 
  ## pll
  save_plot_png(pll, filename = "gwas_qqplot.png")
  save_plot_MaTheseR(pll, filename = "gwas_qqplot.pdf.png", height = 10, width = 14)

#+END_SRC


#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics[with=14cm, height=10cm]{./OUTPUT/Rplots/gwas_venn.pdf.png}
\includegraphics[with=14cm, height=10cm]{./OUTPUT/Rplots/gwas_qqplot.pdf.png}
\caption{Diagramme de Venn et qqplot pour la GWAS}
\label{fig:gwas_venn_qqplot}
\end{figure}
#+END_EXPORT

*** TODO EWAS
:LOGBOOK:
- State "TODO"       from              [2017-07-10 lun. 15:49]
:END:

#+NAME: code:ewas_qqplot_venn
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  library(MaTheseR)
  library(gridExtra)
  MaTheseR.params <- get_MaTheseRparams()

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")


  ## venn
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])
  save_plot_png(out, filename = "ewas_venn.png")
  save_plot_MaTheseR(out, filename = "ewas_venn.pdf.png", height = 10, width = 14)

  ## qqplot
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    MaTheseR.params$gtheme + 
    theme(legend.position = "none") 
  pll
  save_plot_png(pll, filename = "ewas_qqplot.png")
  save_plot_MaTheseR(pll, filename = "ewas_qqplot.pdf.png", height = 10, width = 14)

#+END_SRC

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics[with=14cm, height=10cm]{./OUTPUT/Rplots/ewas_venn.pdf.png}
\includegraphics[with=14cm, height=10cm]{./OUTPUT/Rplots/ewas_qqplot.pdf.png}
\caption{Diagramme de Venn et qqplot pour l'EWAS}
\label{fig:ewas_venn_qqplot}
\end{figure}
#+END_EXPORT

*** TODO EAS
:LOGBOOK:
- State "TODO"       from              [2017-07-17 Lun 08:16]
:END:



* perspectives : Vers le big data
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:49] \\
  strategie: il faut que je finisse tout le reste avec les versions actuelles
  (tess3r, et ce que j'ai fait pour le moment d'lfmm). Quand tout sera fini ! Je
  repenserai l'archi de tess3r (tout en R et une seul data en mémoire). Je pense
  que je n'arriverais pas faire de l'acces de très grosse données depui un fichier
  et la gestion des NA en même temps. Mais je peux montrer les deux séparément,
  cad on montre que on arrive a faire un algo robuste au NA pour tess3r et lfmm
  mais c'est pas complétement implémenté. ET on montre sur un très gros dataset
  une analyse complete pop et lfmm (le 1001 génome est top pour ca car on a une
  matrice imputé :D)
- Note taken on [2017-07-18 Tue 10:57] \\
  - traitement des données manquantes
  - acess au données (pas dans la ram, je peux parler des infracstructure big data
    classique)
  - si j'ai le temps j'implémente ces 2 feature cad: 
    - NA -> comparaison avec et sans NA et procedure naive
    - matrice en mémoriedans un BED -> on a seulement besoin du produit par X ! 
  
  c'est la suite logique de ma problématique cad : 
  - data de plus en plus grosse donc on veut pas les dupliquer, il y a des données
    manquantes
  - mon taf c'est de fournir des logicielles !
  
  
  Je peux ecrire cette partie comme un mini article ! cad
  intro 
  methode
  resultats
  discution 
  conclusion

- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:

* Conclusion 
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:50]
:END:

bibliographystyle:unsrt
bibliography:../biblio.bib

