# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:6 author:nil email:nil creator:nil timestamp:nil skip:nil toc:t ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(g!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


#+LaTeX_CLASS: these
# #+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm, bm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \renewcommand{\proofname}{Preuve}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM hyperparamètre LFMM

# #+BEGIN_QUOTE
# In Code we trust, all others bring data.
# –William Edwards Deming (1900-1993).
# #+END_QUOTE

#+BEGIN_EXPORT latex
%% to review
\baselineskip 0.8cm
#+END_EXPORT

* Workenv                                                          :noexport:
** R
#+BEGIN_SRC R
  ## CRAN
  install.packages("tidyverse")
  install.packages("extrafont")
  install.packages("Devtools")
  install.packages("testthat")
  install.packages("foreach")
  install.packages("RSpectra")
  install.packages("doParallel")
  install.packages("DescTools")
  install.packages("roxygen2")
  install.packages("VennDiagram")
  install.packages("ggmap")
  install.packages("rvest")
  install.packages("raster")
  install.packages('printr')
  install.packages("units", configure.args = "--with-udunits2-include=/usr/include/udunits2")
  install.packages("ggforce")
  install.packages("scatterpie")
  install.packages("sp")
  install.packages("raster")
  install.packages("rgeos")
  install.packages("rasterVis")
  install.packages("fields")

  ## output to document
  install.packages("ascii")
  install.packages("xtable")
  install.packages("latex2exp")

  ## bioconductor
  source("https://bioconductor.org/biocLite.R")
  biocLite("matter", ask = FALSE)
  biocLite("qvalue",ask = FALSE)
  biocLite("biomaRt",ask = FALSE)
  biocLite("LEA",ask = FALSE)
  biocLite("impute",ask = FALSE)
  biocLite("sva",ask = FALSE)
  ## biocLite("IlluminaHumanMethylation450kanno.ilmn12.hg19", ask = FALSE)

  install.packages("cate")
  install.packages("FAMT")
  install.packages("xgboost")
  install.packages("knitr")


  ## github
  devtools::install_github("privefl/bigsnpr")
  devtools::install_github("bcm-uga/pcadapt")
  devtools::install_github("perishky/meffil") ## cpG site annotation


  ## my pkgs
  devtools::install_github("cayek/MaTheseR/Rpackage")
  devtools::install_github("cayek/Thesis/ThesisRpackage")
  devtools::install_github("bcm-uga/tess3_encho_sen")
  devtools::install_github("bcm-uga/lfmm")
#+END_SRC
** Ligne de commande
*** ms
*** plink
*** vep
#+NAME: code:install_vep
#+CAPTION: Dépend de 
#+begin_src shell
  cd BiocompSoftware
  git clone https://github.com/Ensembl/ensembl-vep.git
  cd ensembl-vep
  perl INSTALL.pl
#+end_src

*RMK :* J'ai ddl les cache
- =47 : homo_sapiens_vep_89_GRCh38.tar.gz=

** python
* Introduction
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-07-20 Thu 17:52]
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:11] \\
  une remarque en passant: l'intro est pour moi la place pour définir le contexte
  général, les mots du titre, la pbq et le plan qui y répond ! 
  Ce n'est pas la que je fait un état de l'art. L'état de l'art est dans les deux
  grosse partis ! C'est deux grosse parties sont indépendantes l'une de l'autre !
  Donc si il y a des répétition, tant pis !!
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
:LOGBOOK:
- Note taken on [2017-09-13 mer. 10:33] \\
  Biblio: 
  - cite:slides_sfds2015_saporta
  - cite:endOfTheory
  - [[http://callingbullshit.org/syllabus.html#Statistical][Calling Bullshit: Data Reasoning for the Digital Age]]
  - [[http://freakonometrics.hypotheses.org/19023][BIG DATA : PASSER D’UNE ANALYSE DE CORRÉLATION À UNE INTERPRÉTATION
    CAUSALE]] : je suis pas d'accord avec ce qu'il dit (je pense pas qu'il sache
    vraiment de quoi il parle). Il vent l'inférence causale. Faut que je
    comprenne en quoi l'inference causale permet de trouver des lien de
    causalité, c'est juste des modèles avec plus de variable non ?
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:
Cette dernière décennie a été marquée par une accumulation des données dans tous
les domaines de la sciences. Cette accumulation de données est une aubaine pour
les scientifiques. En particulier en biologie l'abondance des données permet de
comprendre toujours mieux le vivant. Cependant, que faire d'autant de données et
comment en tirer l'information qui permettrait de mieux comprendre le monde qui
nous entoure ? Il s'agit là d'un défi majeur pour les statistiques. 

Le premier problème qui se pose avec les grands jeux de données est celui de la
vitesse des algorithmes utilisés pour les traiter. Si nous avons beaucoup de
données rapidement nous voulons aussi des algorithmes rapides pour les traiter
et les visualiser. L'augmentation de la puissance des ordinateurs ne suffis pas
toujours à adapter un modèle à un plus grand jeux de données. Il faut parfois
trouver de nouvelles méthodes pour passer à une échelle de données plus grande.

Par ailleurs, plus nous avons d'observation de deux variables plus il est
possible de détecter une corrélation faible entre celles ci. Ce qui
paradoxalement n'est pas forcément une bonne chose puisque toutes corrélations
aussi faible soit elle est significative quand on à trop de données. De plus,
une corrélation n'est pas un lien de cause à effet. Une corrélation entre deux
variables peut ne plus être observé quand on considère dans l'étude une
troisième variable qui serai corrélé au deux premières (paradoxe de Simpson). Il
faut donc être très prudent dans la recherche de corrélation dans des données,
surtout dans le contexte actuelle où l'accès au données est très facile.

Dans le cadre de cette thèse nous nous sommes intéressé a développer des
méthodes statistiques adapté au traitement de données biologique afin de
répondre à deux problématiques. Le premier est l'estimation de la structure de
population à partir de données génomique et géographique. Le deuxième est
l'estimation de facteurs de confusion pour corriger les tests d'association. Les
méthodes statistiques développer lors de cette thèse repose sur la factorisation
de matrice. Nous allons maintenant introduire plus en détails les contextes
biologiques dans lesquels interviennent les méthodes développé durant cette
thèse.

** La génomique des populations
<<intro_genet>>
:LOGBOOK:
- Note taken on [2017-09-13 mer. 11:00] \\
  Biblio: 
  - [[https://fr.wikipedia.org/wiki/G%25C3%25A9n%25C3%25A9tique_des_populations#D.C3.A9finition_de_la_population][wiki : Génétique des populations]]
  - [[https://en.wikipedia.org/wiki/Evolutionary_pressure][wiki : Evolutionary pressure]]
  - [[https://en.wikipedia.org/wiki/Population_genetics][wiki : Population genetics]]
  - [[http://www.institutlejeune.org/Trisomie-21-et-autres-pathologies-genetiques/les-decouvertes-sur-la-genetique-en-quelques-dates.html][génétique dates]]
  - [[https://fr.wikipedia.org/wiki/S%25C3%25A9quen%25C3%25A7age_de_l%2527ADN#S.C3.A9quen.C3.A7age_haut_d.C3.A9bit_.28HTS.29][wikipedia sequencage de l'adn]]
  - [[https://fr.wikipedia.org/wiki/Polymorphisme_nucl%25C3%25A9otidique][SNP]]
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc

  En faite je ne vais def ca ici ! c'est juste le genet des pops ici !!
  - ewas: refactor
  - gwas: gemma etc
  - eas: ...
:END:
La génétique des populations est l'étude de la distribution et des changement de
la fréquence des versions d'un gêne, que l'on appel allèle, quand des
populations d'être vivant. La génomique des population est un néologisme qui
souligne le fait que l'on n'étudie plus les différences génétiques dans et entre
les populations à l'échelle d'un seul gêne mais à l'échelle du génome complet.
La génomique des populations a des applications en épidémiologie où elle permet
de comprendre la transmission des maladies génétiques. En agronomie, des
programmes de sélection modifient le patrimoine génétique de certains organismes
pour créer des races ou variétés plus performantes, ou plus résistantes à des
maladies. Elle permet également de comprendre les mécanismes de conservation et
de disparition des populations et des espèces.

Les populations étudiée par la génétique des populations est un ensemble
d'individus qui montrent une unité de reproduction : les individus d'une
population peuvent se croiser entre eux, ils se reproduisent moins avec les
individus des populations voisines, desquelles ils sont géographiquement isolés.
On considère 4 pressions évolutives qui permettent d'expliquer des changements
de fréquences d'allèle dans les populations : la mutation, la sélection, la
dérive génétique, et la migration. La mutation créer de nouveau allèle, elle
peut être neutre, c'est a dire sans effet sur l'organisme, ou non et avoir par
exemple un effet sur la capacité de l'organisme à s'adapter à son environement.
La selection est l'hypohtèse central de la théorie de Darwin, ainsi si un allèle
permet à l'organisme d'être mieux adapté à son environement alors cette allèle
aura plus de chance d'être transmis aux générations future car l'organisme
porteur de l'allèle peut se reproduire plus facilement. La dérive génétique
provient du fait qu'il n'existe pas de populations infinis. Ainsi au file des
générations les distributions allélique change à cause de la reproduction au
hasard des individus. Ce processus peut engendrer la disparition ou la fixation
d'un allèle neutre juste par hasard. Enfin la migration est le passage de gène
d'une population à une autre (par des individus qui passent d'une population à
l'autre, par exemple sous forme de graines ou de pollen chez les plantes). Si
cet échange se fait entre des population ayant des fréquences alléliques
différentes, elle va tendre à modifier les fréquences alléliques.

Bien que la génétique des populations trouve ses origines dans les travaux de
Sewall Wright, J. B. S. Haldane et Ronald Fisher qui sont anterieurs à la
découverte de la structure de l'ADN par Watson et Crick en 1953, la génomique
des populations moderne utilise des données d'observation de génome de plusieurs
individus provenant de plusieurs populations. De plus, les récentes
améliorations en séquence de l'ADN on permit le séquence, qui était jusqu'alors
réservé aux espèces modèles, à de nombreuses espèces. Dans le cadre de cette
thèse nous nous somme intéresse seulement au données dite de SNPs
(single-nucleotide polymorphism) qui sont les polymorphismes génétiques simple
d'un seul nucleotide. Un SNP est la variation (polymorphisme) d'une seule paire
de bases du génome, entre individus d'une même espèce. Les SNP représentent 90 \%
de l'ensemble des variations génétiques humaines, et des SNPs avec une fréquence
allélique supérieure à 1 \% sont présents toutes les cent à trois cents paires
de bases en moyenne dans le génome humain. Nous appelons locus une position sur
l'ADN, nous parlons ainsi du locus d'un SNP. Nous représentons les données
génétique comme une matrice avec une ligne par individu et une colonne par
locus.

Une étape très imporante en génétique des populations et particulièrement quand
on étudie des données de SNPs est d'inférer une représentation synthétique qui
de la structure de population à partir des données de SNPs. Dans cette thèse
nous proposons une méthode permettant l'inférence des coefficients de métissage
individuel à partir de données de SNPs et géographique de chaque individu. Nous
expliquons plus en détail ce que sont les coefficients de métissage dans la
partie [[tess3_intro]].
** Test d'association
:LOGBOOK:
- Note taken on [2017-08-22 mar. 09:56] \\
  parler des méthode classsique pour controlé l hétérogénéité en stat (experience
  jardin commum, vidéo les stat expliqué a mon chat :D)
:END:

** La factorisation de matrice en statistique          :noexport:deprecated:
:LOGBOOK:
- Note taken on [2017-07-18 Tue 08:55] \\
  Kenneth lange, factorisation de matrice = avenir des stat ! a retrouver !
:END:
** Problématique et objectifs de la thèse
* Inférence des coefficients de métissage à l'aide de données géographiques
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:07] \\
  Non je ne vais pas avoir le temps, je vais traduire l'article, étoffer un peu
  et basta. Je mettrais en perspective le traitement des données manquantes pour
  tess3r et sur un très gros dataset si j'ai le temps (1001 genome, avec une
  analyse de la population et une association environmental, pour ilustrer les
  deux feature gros dataset et NA)
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
** Introduction
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:
<<tess3_intro>>

Représenter la structure de population est une étape importante dans l'étude de
données génétique. La structure de population permet de visualiser la variation
provoquée par la stratification en sous population des données génétiques qui
sont des données volumineuse et multivariées. La stratification en population
ainsi observée fourni des informations sur l'histoire et l'évolution
démographique de l'espèce étudié cite:Li_2008; il est également indispensable de
l'utiliser comme facteur de correction dans les études d'associations avec un
phénotype, un gradient environnementale ou encore une maladie
cite:marchini2004effects. De même, il existe de nombreuses application en
médecine génétique nécessitant de connaitre la structure de population comme par
exemple le calcule d'un score de risque génétique pour une maladie
cite:Wray_2013. Enfin, l'étude de la répartition en population d'une espèce dans
son habitat est une étape clée en génétique du paysage cite:Fran_ois_2015.

Pour représenter la structure de population nous supposons que le génome de
chaque individu est la combinaison de morceau de génome provenant de $K$ cluster
génétiques. Dans chaque cluster génétique nous devons estimer les fréquences
d'allèle pour chaque SNPs, et pour chaque individu la proportion de son génotype
qui provient de chaque population ancestral appelé coefficient de
métissage individuel. 

DESSIN

Les clusters génétiques se forment par les processus de différenciation des
distributions allélique dont nous avons parlé dans la partie [[intro_genet]]. Pour
illustrer cela nous avons pris un jeux de données de SNPs d'individu humain
provenant de populations européennes, africaines et afro-américaines des États
Unis d'Amérique. La Figure ref:fig:tess3_intro A montre les fréquences des
différentes version du SNP rs499627 dans des populations européennes, africaines
et afro-américaine. Nous constatons une différence de distribution allélique
dans les différentes populations. La Figure ref:fig:tess3_intro B montre les
coefficients de métissage individuel estimé par le logiciel sNMF pour deux
clusters génétiques. Nous constatons que l'algorithme sNMF trouve un cluster
génétique africain et un autre européen, et que les individus afro-américain ont
des génomes provenant des cluster africain et européen. Il s'agit la du résultat
attendu connaissant l'ascendance des individus afro-américain.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_intro.pdf}
\caption{A) Distribution des allèle du SNP rs499627 dans des populations
  européennes, africaine et afro-américaines. B) Estimation par le logiciel sNMF
  de la proportion pour chaque individus de SNPs provenant des cluster
  génétiques africain et européen.}
\label{fig:tess3_intro}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Africain Européen et Afro américain 
CLOSED: [2017-09-14 jeu. 11:38]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-09-14 jeu. 11:38]
- State "STARTED"    from              [2017-09-06 mer. 10:45]
:END:

Tudo pour les piechart : [[https://guangchuangyu.github.io/2016/12/scatterpie-for-plotting-pies-on-ggplot/][here]]
#+NAME: code:tess3_intro
#+CAPTION: Dépend de 
#+begin_src R :results output :exports both
  library("tidyverse")
  library(tess3r)
  library(MaTheseR)

  ## 1000Genome dataset
  dat <- readRDS("./Data/1000Genomes/Phase3/Eu_Af_Afam.chr1.maf.05.rds")
  dim(dat$G)

  expr <- list()
  ## compute Fst
  snmf.res <- sNMFMethod(K = 2) %>% fit(dat)
  expr$G <- snmf.res$G
  expr$Q <- snmf.res$Q
  expr$fst <- ComputeFst(expr$Q, expr$G, 3)

  ## keep info on dataset
  expr$indiv.df <- dat$indiv
  expr$snps.df <- dat$snps.info
  id <- which.max(expr$fst) 
  expr$indiv.df <- expr$indiv.df %>%
    mutate(snps = dat$G[,id])

  save_expr(expr, "tess3_intro.rds")
#+end_src

#+NAME: code:tess3_intro_plot
#+CAPTION: Dépend de [[code:tess3_intro]]
#+begin_src R 
  library("tidyverse")
  library(tess3r)
  library(cowplot)
  library(MaTheseR)
  library(scatterpie)
  MaTheseR.params <- get_MaTheseRparams()
  gtheme <- MaTheseR.params$gtheme


  expr <- readRDS("./OUTPUT/Expr/tess3_intro.rds")

  ## plot freq
  ## get location
  toplot <- expr$indiv.df %>%
    dplyr::distinct(pop) %>%
    mutate(citie = NA)
  toplot[toplot$pop == "LWK",]$citie = "Kenya"
  toplot[toplot$pop == "YRI",]$citie = "Nigeria"
  toplot[toplot$pop == "ASW",]$citie = "New-york"
  toplot[toplot$pop == "TSI",]$citie = "Italia"
  toplot[toplot$pop == "GBR",]$citie = "England"
  toplot <- cbind(toplot, ggmap::geocode(toplot$citie))

  ## frequencie
  id <- which.max(expr$fst)
  expr$snps.df[id,]
  freq.df <- expr$indiv.df %>% group_by(pop) %>%
    dplyr::summarise(freq = mean(snps) / 2)
  toplot <- toplot %>%
    inner_join(freq.df, by = c("pop"))
  toplot <- toplot %>%
    mutate(`allèle T` = freq, `allèle C` = 1 - freq)

  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  map.world <- ggmap::get_map(location = "world")
  pl <- ggplot(toplot, aes(x = lon, y = lat, color = pop)) +
    mapWorld + 
    MaTheseR.params$gtheme +
    scale_size_continuous(guide = FALSE) +
    xlab("Longitude") +
    ylab("Latitude")
  pl.res <- pl + geom_scatterpie(aes(x = lon, y = lat, r = 8), data = toplot, cols = c("allèle T", "allèle C")) +
    guides(fill = guide_legend(title = "SNP rs499627")) +
    scale_fill_manual(values = c("steelblue", "lightgreen")) +
    theme(legend.position="bottom")

  save_plot_png(pl.res, "tess3_intro_freq.png")

  ## barplot
  expr$indiv.df$pop %>% unique()
  ## ordering
  expr$indiv.df$pop %>% unique()
  Q <- expr$Q[expr$indiv.df$pop %in% c("YRI"), ]
  Q <- expr$Q[expr$indiv.df$pop %in% c("GRB","TSI"), ] %>% rbind(Q)
  Q <- expr$Q[expr$indiv.df$pop %in% c("ASW"), ] %>% rbind(Q)
  toplot <- data.frame(Q, index = 1:nrow(Q)) %>% reshape2::melt(id = "index") %>%
    dplyr::mutate(`Cluster génétique` = factor(variable, labels = c("africain",
                                                  "européen")))
  brplot <- ggplot(toplot, aes(x = index, y = value)) +
    geom_bar(stat = "identity", aes(color =`Cluster génétique` , fill = `Cluster génétique`)) +
    xlab("Individus") +
    ylab("Coefficient\nde métissage") +
    scale_y_continuous(breaks = c(0.0,0.5,1.0)) +
    gtheme + 
    theme(legend.position="bottom",
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  save_plot_png(brplot, "tess3_intro_barplot.png")

  ## gather plots
  pl <- plot_grid(pl.res, brplot, ncol = 1, labels = c("A", "B"),
                  rel_heights = c(6,4))
  ThesisRpackage::Plots_export_pdf(pl, "tess3_intro", MaTheseR.params,
                                   height = 0.8 * MaTheseR.params$textheightinch,
                                   width = MaTheseR.params$textwidthinch)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3_intro_freq.png]]
[[./OUTPUT/Rplots/tess3_intro_barplot.png]]

*** Méthodes d'inférence des coefficients de métissage 
:LOGBOOK:
- Note taken on [2017-09-06 mer. 11:57] \\
  Rmk : ici je parle de modèle probabiliste au sens de Kevin p murphy :D
:END:

L'inférence des coefficients de métissage a été largement étudié et il existe de
nombreuse méthodes. On distingue deux types d'approche : les approches reposant
sur un modèle probabiliste et les approches fondées sur l'optimisation une
fonction objective.

Parmi les approches reposant sur un modèle probabiliste on compte le logiciel
=structure= introduit par cite:Pritchard2000 qui à introduit le modèle de
structure de population dont nous avons parlé dans l'introduction. L'acces à des
données génétype de plus en plus grandes on provoquer l'émergence de plusieurs
algorithmes plus rapides que celui de =structure=. En effet l'algorithme du
logiciel =structure= implémente un algorithme d'échantillonnage de monte carlo
pour estimer la distribution à posteriori des coefficients de métissage et les
fréquence de génotype dans les clusters génétiques. Cependant les algorithmes de
monte carlo ne passe à l'échelle sur les grands jeux de données génétiques
utilisé aujourd'hui. Il a été proposé des améliorations du logicielle structure
reposant une fonction de vraisemblance définie pour la matrice des coefficients
de métissage et les fréquence d'allèle dans les clusters. L'estimation est
effectuée en maximisant la fonction log-vraisemblance. La première amélioration
de l'algorithme =structure= est basée sur un algorithme EM (Expectation
Maximisation) maximisant la fonction de vraisemblance cite:Tang_2005. Des
algorithmes de vraisemblance plus récents sont implémentés dans les programmes
=admixture= et =fastStructure= cite:Alexander_2011,Raj_2014.

Dans les approches reposant sur l'optimisation d'un fonction objective, les
coefficients de métissage sont estimés à l'aide de méthodes de moindres carrés
ou d'analyse factorielle. Pour estimer les matrices des coefficients de
métissage et de fréquence d'allèle dans les cluster, cite:Engelhardt_2010
propose d'utiliser l'analyse des facteurs parcimonieuse, cite:Frichot_2014
utilise des algorithmes de factorisation de matrice non négative et
cite:Popescu_2014 utilise l'analyse en composantes principales. Ces méthodes
reposant sur des problèmes d'optimisation permettent de reproduire avec
précision les résultats des approches basé sur une vraisemblance
cite:Frichot_2014. En outre, cette catégorie de méthode fournissent des
algorithme qui sont généralement plus rapides que ceux des méthodes fondé sur un
modèle probabiliste.

*** Méthodes d'inférence des coefficients de métissage à l'aide de données géographique

Dans la natures les individus d'une espèce évolue dans un environnement
géographique et les cluster génétique identifié par les méthodes d'estimations
de la structure de populations sont en faite généré par a des phénomène (les
pressions évolutive) qui ont une réalité dans l'environnement géographique de
l'espèce. Les clusters génétiques peuvent par exemple être causé par une
isolation des populations à cause d'une mer qui sépare des populations ou bien
des différences d'altitude entre celles-ci. L'étude réalisé par
cite:Novembre_2008 a montré qu'il est possible de prédire la position des
individus à partir de l'étude leur structure de population. De nombreuse
méthodes ont permis d'améliorer la prédiction de la position géographique des
individus à partir de leur génome
cite:Baran_2013,Yang_2012,Bhaskar_2016,Ra_ola_2014. Si la structure de
population permet de prédire la position spatiale des individus alors il est
possible d'améliorer l'estimation de la structure de population en utilisant
l'information géographique. Cette idée a été exploité pour améliorer le modèle
bayésien de =structure= en incorporant des données géographiques à travers la
loi de distribution à priori des coefficients de métissage
cite:CHEN_2007,Corander2008. Les algorithmes spatiaux fournissent des
estimations de la structure de population plus robustes que des algorithmes non
spatiaux qui peuvent conduire à des estimations biaisées du nombre de clusters
cite:Durand_2009. Certaines méthodes bayésiennes sont basées sur des algorithmes
de Monte Carlo de chaîne de Markov qui nécessite beaucoup de calcul
cite:FRAN_OIS_2010. Ainsi les méthodes d'estimation de structure de population
continue spatialement ne sont pas adapté au grand jeux de données. Nous
proposons donc une méthode d'estimation de la structure dans des population
continue spatialement reposant l'optimisation d'une fonction objective.

*** Plan du chapitre

Dans ce chapitre, nous présentons une nouvelle méthode pour l'estimation des
coefficients de métissage individuels basées sur des données géographiques et
génétiques. Cette méthode repose un problème de factorisation matrice régularisé
avec des contraintes convexes. Nous proposons deux algorithmes qui résolvent le
problème de factorisation. Le première algorithme repose sur une optimisation
quadratique alterné (AQP pour alternated quadratic programing), l'autre sur un
algorithme des moindres carrés alternés projetés (APLS pour alternated projected
least square). Le terme alterné dans les deux algorithmes fait référence au fait
que l'on alterne une étape d'optimisation selon la matrice de coefficient de
métissage puis la matrice des fréquences de génotypes ancestraux. Alors que les
algorithmes AQP ont un fondement théorique bien établi par cite:Bertsekas_1997,
ce n'est pas le cas des algorithmes APLS. En utilisant des simulations
coalescentes, nous montrons que les estimations calculées par l'algorithme APLS
sont de bonnes approximations des solutions de l'algorithme AQP. En outre, nous
montrons que les performances de l'algorithme APLS s'élève aux dimensions des
ensembles de données modernes. Sur des simulations, nous montrons que l'erreur
statistique des estimateurs des coefficients de métissage et des fréquences
d'allèle dans les clusters génétique fournis par notre méthode est du même que
l'erreur obtenu avec le logicielle =TESS= 2.3, une méthode bayésienne. Toujours
sur des simulations nous montrons que notre méthode spatial estime mieux la
structure de population que la méthode sNMF qui repose aussi sur un problème de
factorisation de matrice mais n'utilise pas l'information spatiale. Enfin, nous
discutons de l'application de nos algorithmes aux données des écotypes européens
de {\ it Arabidopsis thaliana}, pour lesquelles des données géographiques
individuelles et géométriques sont disponibles cite:Horton_2012.

** Nouvelles méthodes
Dans cette section, nous présentons deux nouveaux algorithmes pour estimer les
coefficients de métisse individuel et les fréquences de génotypes dans les
clusters génétiques en supposant $\K$ cluster génétique. En plus des
génotypes, les nouveaux algorithmes présenté ici nécessitent les coordonnées
géographiques de chaque individu.
*** Matrices $\Q$ et $\G$
Nous considérons une matrice de génotype, $\Y$, enregistrant des données de $n$
individus à des locus polymorphes $p$ pour une espèce ayant une ploidy de $d$,
c'est à dire qui possède un génome composé de $d$ exemplaire de chaque
chromosome. Pour les SNPs autosomiques dans un organisme diploïde, le génotype
au locus $\ell$ est un nombre entier, 0, 1 ou 2, correspondant au nombre
d'allèles de référence observé à ce locus. De même que dans cite:Frichot_2014,
dans nos algorithmes nous utilisons des formes disjonctives pour coder les
génotypes. Par exemple pour un organisme diploïde, le nombre d'allèle observé à
chaque locus $,0,1,2$ est encodée comme $100$, $010$ et $001$. Pour les
organismes de ploidy $d$, il existe $(d + 1)$ génotypes possibles à chaque
locus, et chaque valeur est encodée sous une forme disjonctif unique. 

De la même manière que dans cite:Frichot_2014, si l'on suppose qu'il y a $K$
clusters génétiques, nous cherchons à décomposer la matrice $\Y$ en une matrice
de coefficients de métissage $\Q$, de taille $n \times K$ et une matrice de
fréquences de génotypes dans les $K$ clusters génétiques $G$, de taille $p
\times K$. Nous notons $\Q_{i,k}$ le coefficient de métissage de l'individu $i$
pour le cluster $k$. Nous avons de plus
\begin{equation}
\label{eq:QConst}
\Q \geq 0 \, , \quad \sum_{k=1}^K {\bf Q}_{i,k} = 1 .
\end{equation}
Nous notons $\G_{(d + 1)\ell + j, k}$ la fréquence du génotype $j$ au locus $\ell$
dans le cluster $k$ et nous avons
\begin{equation}
\label{eq:GConst}
\G \geq 0 \, , \quad \sum_{j=0}^{d} {\bf G}_{(d+1)\ell + j, k} = 1.
\end{equation}
Enfin, nous voulons estimer les matrices $\Q$ et $\G$ en factorisant la matrice
de génotype de la façon suivante
\begin{equation*}
\Y = \Q \G^{T}.
\end{equation*}
Ainsi le problème d'inférence peut être résolu en utilisant les méthodes de
factorization de matrice non négatives avec en plus les contraintes convexe
décrite par les équations ref:eq:QConst et ref:eq:GConst
cite:lee1999learning,Cichocki2009. Dans la suite, nous utiliserons les notations
$\DQ$ et $\DG$ pour représenter les ensembles formé à partir des contraintes sur
$\Q$ et $\G$.
*** Information géographique
L'information géographique est introduite dans le problème de factorisation de
matrice en utilisant des poids entre les individus. Les poids sont utilisés pour
imposer une contrainte de régularité de l'estimateur des coefficients de
métissage sur l'espace géographique. En effet, nous souhaitons que des individus
proches dans l'espace géographique aient des coefficients de métissage proche.
Les poids sont définis à partir des coordonnées géographiques des individus que
l'on note $x_{i}$ pour chaque individu $i$. Nous attribuons aux individus
proches dans l'espace un poids plus grand que pour des individus éloignés. Les
poids sont calculés en construisant un graphe complet pondéré entre les
individus. Entre chaque individu $i$ et $j$, nous construisons la matrice des
poids du graphe $\W$ de la manière suivante
\begin{equation}
\label{eq:tess3Graph}
\W_{i,j} = \exp( - {\rm dist}( x_i, x_j )^2/ \sigma^2),
\end{equation}
où la fonction ${\rm dist}( x_i, x_j)$ définie n'importe quelle distance entre
les coordonnées géographique $x_{i}$ et $x_{j}$ des individus d'indice $i$ et $j$. 

Ensuite, nous introduisons la matrice laplacienne associée à la matrice des poids
géographique $\W$. La matrice laplacienne est définie de la manière suivante
\begin{equation}
\label{eq:tess3Laplace}
\Laplacienne = \D - \W,
\end{equation}
où $\D$ est la matrice diagonale tel que 
\begin{equation}
\label{eq:tess3Diag}
\left\{ \D_{i,i} \right\}_{i = 1..n}= \left\{\sum_{j = 1}^n \W_{i,j}\right\}_{i = 1..n}.
\end{equation}
Par le calcul, les auteurs de cite:DengCai2011 ont montré que 
\begin{equation}
\label{eq:tess3Reg}
{\rm Tr} (\Q^{T} \Laplacienne \Q)  = \frac{1}{2} \sum_{i,j = 1}^n  \W_{i,j}  \|   \Q_{i,.}  \Q_{j,.} \|^2.
\end{equation}
où $\mathrm{Tr}$ est la fonction qui renvoie la somme des valeurs diagonaux
d'une matrice carrées, la trace. Dans notre approche, nous
supposons que les individus géographiquement proches ont plus de chance d'avoir
des ancêtres communs que des individus éloignés. Ainsi nous utilisons le terme
défini par l'équation ref:eq:tess3Reg pour régulariser l'estimateur de la
matrice des coefficients de métissage $\Q$.

*** Problèmes d'optimisation des moindres carrés
L'estimation des matrices $\Q$ et $\G$ à partir de la matrice de génotype $\Y$
est réalisé en optimisant la fonction suivante
\begin{equation}
\mathcal{L}(\Q, \G) =   \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} +  \alpha {\rm Tr} (\Q^{T} \Laplacienne \Q), 
\label{eq:tess3LS}
\end{equation}
où la matrice $\Q$ appartient à $\DQ$ l'ensemble définie par les contraintes
ref:eq:QConst et la matrice $\G$ appartient à $\DG$ l'ensemble définie par les
contraintes ref:eq:GConst. La notation $\| \matr{M} \|_{\rm F}$ désigne la norme
de Frobenius de la matrice $\matr{M}$. Le paramètre de régularisation $\alpha$
contrôle la régularité des estimations des coefficients de métissage dans
l'espace géographique. Les grandes valeurs de $\alpha$ impliquent que les
coefficients de métissage ont des valeurs proches pour les personnes
géographiquement proches.

*** Algorithme d'optimisation quadratique alterné (AQP)
Parce que les polyèdres $\DQ$ et $\DG$ sont des ensembles convexes et que la
fonction $\LS$ est convexe par rapport à chaque variable $\Q$ ou $\G$ lorsque
l'autre est fixé, nous pouvons appliquer l'algorithme de descente par bloc de
coordonnées au problème pour trouver un minimum local de la fonction $\LS$
définie par l'équation ref:eq:tess3LS cite:Bertsekas_1997. L'algorithme de
descente par bloque de coordonnées consiste à alterner des étapes d'optimisation
selon chacune des coordonnées de la fonction à optimiser. 

DESSIN de https://en.wikipedia.org/wiki/Coordinate_descent ??


Cette algorithme permet de converger vers un minimum local quand la fonction
objectif est convexe et définie sur un ensemble convexe. Le problème
d'optimisation selon $\G$ quand $\Q$ est fixé est un problème d'optimisation
quadratique, il en va de même quand on échange les rôles de $\G$ et $\Q$, c'est
pour cela que l'algorithme est dit d'optimisation quadratique alterné (AQP).


L'algorithme APQ commence à partir de valeurs initiales pour les matrices $\G$
et $\Q$, et alternent deux étapes d'optimisation. La première étape calcule la
matrice $\G$ tandis que $\Q$ est fixé. Nous supposons que $\Q$
est fixé et écrivons $\G$ sous une forme vectorielle comme ceci
\begin{equation*} 
g = {\rm vec}(\G) \in \mathbb{R} ^ {K(d +1)p}.
\end{equation*}
La première étape de l'algorithme résout le problème d'optimisation
quadratique suivant 
\begin{equation}
\begin{aligned}
\underset{g \in \DG}{\min}  ( -2  v^T_Q \, g + g^T \D_Q g ) ,
\end{aligned}
\label{eq:AQPg}
\end{equation}
où $\D_Q = \Id_{(d + 1) p} \otimes \Q^T \Q$ et $v_Q = {\rm vec} (\Q^T \Y)$. Ici,
$\otimes$ désigne le produit Kronecker et $\Id_{d}$ est la matrice identité de
taille $d$. La structure en bloc de la matrice $\D_Q$ nous permet de décomposer
le problème ref:eq:AQPg en $p$ problèmes de programmation quadratiques
indépendants à $K(d + 1)$ variables. 

Nous considérons ensuite que $\G$ est la valeur obtenue après la première étape
de l'algorithme, et écrivons $\Q$ sous une forme vectorielle
\begin{equation}
q = {\rm vec}(\Q) \in \mathbb{R}^{nK} 
\end{equation}
La deuxième étape résout le problème de programmation quadratique suivant
\begin{equation}
\begin{aligned}
\underset{q \in \DQ}{\min} ( -2 v^T_G \, q + q^T \D_G q ) ,
\end{aligned}
\label{eq:AQPq}
\end{equation}
où $\D_G = \Id_{n} \otimes \G^T \G + \alpha \Laplacienne \otimes \Id_K$ et $v_G
= {\rm vec}(\G^T \Y^T)$. Contrairement au problème ref:eq:AQPg de la première
étape, le problème ref:eq:AQPq ne peut pas être séparer en plus petits
problèmes. Ainsi, la deuxième étape de l'algorithme AQP nécessite de résoudre un
problème de programmation quadratique à $nK$ variables, cela peut être très long
pour les jeux de données avec beaucoup d'individus. Nous alternons ces deux
étapes jusque convergence de l'algorithme AQP en un minimum local de $\LS$.
Enfin nous pouvons énoncer le résultat de convergence suivant.
#+BEGIN_theorem
<<AQP_theorem>> L'algorithme AQP qui alterne les étapes d'optimisation définis
par ref:eq:AQPg et ref:eq:AQPq converge vers un minimum local de la fonction
$\LS$ définie par l'équation ref:eq:tess3LS.
#+END_theorem

#+BEGIN_proof
La fonction $\LS$ définie par l'équation ref:eq:tess3LS est convexe par
rapport à $\Q$ quand $\G$ est fixé et inversement. De plus les ensembles de
définition $\DQ$ et $\DG$ sont convexes. Alors d'après le corollaire 2 de
cite:Grippo_2000 tout point limite de l'algorithme AQP converge vers un point de
minimum local de la fonction $\LS$.
#+END_proof

*** Algorithme des moindres carrés alternés projetés (APLS)
Dans cette partie nous présentons l'algorithme APLS de calcul d'un minimum local
de la fonction $\LS$ définie par ref:eq:tess3LS. Contrairement à AQP, il n'y a
pas de résultat qui garentisse la convergence de d'APLS vers un minimum local de
la fonction $\LS$. Cependant l'algorithme APLS a une complexité algorithmique
plus faible que l'algorithme AQP. L'algorithme APLS commence par initialiser au
hasard les matrices $\Q$ et $\G$ puis alterne deux étape. La matrice $\Q$ est
calculé pendant que la matrice $\G$ est fixé et vice versa. La première étape de
calcul de $\G$ de consiste à calculer
\begin{equation}
\label{eq:tess3:apls:g}
{\bf G}^\star = \arg \min  \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} \, .
\end{equation}
Cette étape peut être séparée en $(d+1) p$ (le nombre de colonnes de $\Y$)
problèmes indépendants. Cette opération peut être parallélisé. Ensuite nous
projetons $\G^{\star}$ sur le polyèdre $\DG$. Pour la seconde étape de calcul de
la matrice $\Q$ nous commençons par calculer la matrice des vecteurs propres de
la matrice laplacienne $\laplacienne$ que nous notons $\U$, ainsi que la matrice
diagonale $\LapVp$ formée des valeurs propres de $\Laplacienne$. Comme la
matrice laplacienne est symétrique et positive ses valeurs propres sont des
nombres réels non négatif. D'après le théorème spectral nous avons
\begin{equation}
\Laplacienne = {\U}^T {\LapVp} \U.
\end{equation}
Après cette opération nous projetons la matrice des données $\Y$ sur la base des
vecteurs propres de la façon suivante
\begin{equation}
\label{eq:3}
\mathcal{P}(\Y) = \U \Y,
\end{equation}
et, pour chaque individu, nous calculons 
\begin{equation}
\label{eq:tess3:apls:q}
q_i^\star = \arg \min \| \mathcal{P}(\Y}_i - \G q) \|^{2}_{2} + \alpha \lambda_i \| q \|^{2}_{2}  ,
\end{equation}
où $\mathcal{P}(\Y)_{i}$ est ligne d'indice $i$ de la matrice des données
projetée, et $\lambda_{i}$ désigne la valeur propre d'indice $i$ de
$\Laplacienne$. Les solutions, $q_{i}^{\star}$, sont concaténées en une matrice,
$\hat{\Q}$, puis la matrice $\Q$ est calculé par la projection de $\U \hat{\Q}$
sur le polyèdre $\DQ$. La complexité de la deuxième étape de APLS croit
linéairement avec $\n$, le nombre d'individus. Alors que la propriété théorique
de convergence de algorithme AQP est perdu pour l'algorithme APLS, l'algorithme
APLS devrait être de bonne approximation de l'algorithme AQP. C'est ce que nous
observons dans nos expériences numériques.

*** Choix des hyperparamètres
Le choix des hyperparamètres est un problème qui est commun à toutes les
méthodes d'estimation des coefficients de métissage. La méthode que nous avons
présenté ici nécessite le choix de 3 hyperparamètres : le nombre de
facteurs, $K$, le paramètre de régularisation, $\alpha$ et le paramètre
d'échelle géographique, $\sigma$. Nous présentons ici des méthodes qui permette
d'aider le choix de ces paramètres.

**** Le paramètre d'échelle géographique $\sigma$
:LOGBOOK:
- Note taken on [2017-09-14 jeu. 13:55] \\
  variogramme ou semivariogramme :D ?? https://fr.wikipedia.org/wiki/Variogramme
  je crois que c'est la même chose ...
:END:
Tester la corrélation entre le génotype et les coordonnées géographiques à une
longue tradition en génétique des populations. Des approches populaires sont
basées sur le test de Mantel cite:mantel1967 et la mesure de l'auto-corrélation
spatial cite:HARDY_1999,Epperson_1996. Avant d'utiliser notre méthode spatiale
d'estimation des coefficients de métissage, nous proposons de choisir des
valeurs de l'échelle géographique en visualisant le variogramme spatial
cite:Cressie1993. Le variogramme peut être étendu aux données génétique de la
facons suivante
\begin{equation}
\label{eq:tess3:variogram}
\gamma(h) = \frac{1}{2 |N(h)|} \sum_{i,j \in N(h)} \frac{1}{L} \sum_{l = 1}^{(p+1)L} |\Y_{i,l} - \Y_{j,l}|,
\end{equation}
où $N(h)$ est défini comme l'ensemble des individus à une distance géographique
$h$. Visualisé le variogramme fourni des informations sur le niveau de
l'autocorélation spatial dans les données génétique et donne une estimation
empirique de l'échelle géographique $\sigma$. Une autre approche consiste à
prendre pour paramètre d'echelle géographique la distance géographique moyenne
entre les individus.

**** Le paramètre de régularisation $\alpha$
:LOGBOOK:
- Note taken on [2017-09-09 sam. 17:08] \\
  Je ne sais pas ou est le détail de ce calcule :D
:END:
La valeur par défaut du paramètre de régularisation $\alpha$ a été choisi de
sorte que le terme t'attache aux données et le terme de régularisation de la
fonction $\LS$ soit du même ordre de grandeur. Ainsi, nous proposons de diviser
chaque terme par sa valeur maximale. Cela revient à considérer $\alha$ égal à $p
/ \lambda_{max}$, où $\lambda_{max}$ est la plus grande valeur propre de la
matrice laplacienne.

**** Le nombre de population ancestrale $K$
Le nombre de populations ancestrales, $K$, peut être évalué en utilisant une
technique de validation croisée basée sur l'imputation des génotypes masqués
cite:Wold_1978,Eastment_1982,Alexander_2011,Frichot_2014. La procédure de
validation croisée divise les entrées matricielles génotypiques en un ensemble
d'apprentissage et un ensemble de tests. Les probabilités de génotype pour les
entrées masquées sont prédites à partir des estimations de facteurs obtenues à
partir d'entrées non masquées. Ensuite, l'erreur de prédiction est calculée en
utilisant l'erreur quadratique moyenne (RMSE) entre le génotype prédi et le
génotype réellement observé.

*** Statistique de différentiation des clusters génétiques pour détecter les locus sous adaptation locale

Si les méthodes d'estimation de la structure de population arrive à détecter des
clusters génétiques c'est parce que il existe des pressions évolutives (décrient
dans la partie [[intro_genet]]) qui provoquent la différenciation des distributions
alléliques entre les différent clusters génétiques. À l'origine de cette
différentiation il y a la migration, la dérive génétique et l'adaptation à
l'environnement. Les locus qui ne sont pas impliqués dans un processus
d'adaptation à l'environnement sont dit neutres et nous faisons l'hypothèse
qu'une large majorité des locus sont neutres. La migration et la dérive
génétique influence de la même façon les distribution allélique de tous les
locus neutre induisant une différentiation typique entre les différents cluster
génétiques identifié par les méthode d'estimation de la structure. Les locus
sous adaptation locale peuvent alors être identifier en cherchant les locus où on
observe une différentiation anormal entre les clusters génétiques
cite:Lewontin175. Nous proposons de calculer une statistique de différentiation
entre les distributions génomiques des clusters génétiques identifié par notre
méthode pour détecter les locus sous adaptation à l'environnement.

En supposant qu'il y à $K$ cluster génétiques, les matrices $\Q$ et $\G$
obtenues à partir des algorithmes AQP et APLS sont utilisées pour calculer la
statistique de différentiation entre les clusters génétiques pour chaque locus
de la façon suivante cite:Martins_2016
\begin{equation}
F^{Q}_{\rm ST} = 1 - \sum_{k=1}^K q_k \frac{f_k (1-f_k)}{f(1-f)},
\end{equation}
où $q_{k}$ est la mesure du coefficient de métissage dans le cluster $k$
moyenné sur tous les individus 
\begin{equation}
q_k = \sum_{i =1}^n \Q_{i,k} / n,
\end{equation}
$f_{k}$ est la fréquence d'allèle dans la cluster $k$ au locus considéré 
\begin{equation}
f_k =  \sum_{j = 1}^p  j \G_{(p+1)(\ell) + j, k}/p,
\end{equation}
et 
\begin{equation}
f = \sum_{k = 1}^K q_k f_k.
\end{equation}
A un locus donné, la formule de $F^{Q}_{\mathrm{ST}}$ correspond à la proportion
de la variance génétique qui peut être expliqué par la structure de population
latente 
\begin{equation}
F^Q _{\rm ST}  =  \frac{\sigma^2_T - \sigma^2_S}{\sigma^2_T },
\end{equation}
où $ \sigma^2_T $ est la variance totale et $\sigma^2_S$ est la variance de
l'erreur cite:Weir1996. En suivant la théorie ANOVA nous utilisons les
statistiques $ F^Q_{\rm ST}$ pour effectuer des tests statistiques de neutralité
à chaque locus, en comparant les valeurs observées à la valeur de
différentiation génomique de fond.

Le test porte sur la statistique du $z$-score au carré, $z^2 = (nK) F^{Q}_{\rm
ST} / (1 - F^{Q}_{\rm ST})$, pour lequel une distribution du chi2 à $K-1$ degrés
de liberté est attendue sous l'hypothèse nulle. L'hypothèse nulle est ensuite
calibrée empiriquement en mesurant le niveau différentiation correspondant une
différentiation neutre. Nous utilisons pour cela le facteur d'inflation
génomique cite:Devlin_1999,Fran_ois_2016. . Après un calibration du test, le
contrôle du taux de découverte fausse est effectué en utilisant l'algorithme de
Benjamini-Hochberg cite:benjamini1995controlling.

*** Implémentation en R
Les deux algorithmes APLS et AQP que nous avons présenté dans cette partie ont
été implémenté en langage R dans un package que nous avons appelé =tess3r=. Le
nom du package fait référence au logiciel =TESS= 2.3 qui permet aussi d'estimer
les coefficients de métissage à partir de données génétique et géographique.

** Autres méthodes d'estimation des coefficients de métissage comparées
*** TESS 
*** sNMF
** Données simulées et réelles
*** Données simulées
**** Simulations à partir de données réelle
Des sous-échantillons provenant du jeux de données réelles 
d'/Arabidopsis thaliana/ (données décrites dans la partie [[simu_At]]) ont été utilisés pour
effectuer une analyse de la convergence et du temps de calcule des algorithmes
AQP et APLS . Les temps d'exécution ont été évalués en utilisant un seul
processeur informatique Intel Xeon 2.0 GHz.
**** Simulations coalescentes
Nous avons utilisé le programme informatique =ms= pour effectuer des simulations
coalescentes de SNPs neutres et de SNPs sous adaptation à l'environnement
cite:Hudson_2002. Deux populations sources ont été créées à partir de la
simulation du modèle à deux îles de Wright's. Ensuite nous avons généré des
génotypes en mélangeant les génotype des deux populations simulées avec
=ms= pour $n$ individus pour lesquels les proportions de mélange varient
continuellement selon un gradient longitudinal cite:Durand_2009,FRAN_OIS_2010.
Dans ces scénarios, les individus à chaque extrémité de la zone géographique
sont représentatifs de leur population d'origine, tandis que les individus au
centre de la gamme partagent des niveaux intermédiaires d'ascendance dans les
deux populations ancestrales. Pour ces simulations, la matrice des coefficients
de métissage, noté $\Q_0$, est entièrement décrite par la position des individus
échantillonnés.

DESSIN comme celui que je met dans mes slides

Les segments de chromosome neutre des population source ont été générés en
simulant des séquences d'ADN avec une taille de population efficace de $N_0 =
10^6$ pour chaque cluster. Le taux de mutation par paire de base et génération a
été réglé sur $\mu = 0,25 \times 10^{-7}$, le taux de recombinaison par
génération a été réglé sur $r = 0,25 \times 10^{-8}$, et le paramètre $m$ a été
choisi pour obtenir des niveaux neutres de $F_{\rm ST}$ compris entre des
valeurs de $0.005$ et $0.10$. Le nombre de paires de bases pour chaque séquence
d'ADN variait entre 10k et 300k pour obtenir un nombre de locus polymorphe
compris entre 1k et 200k après avoir filtré les SNPs ayant une fréquence
d'allèle mineure inférieure à 5 $\%$. Pour créer des SNPs avec des valeurs de
$F_{\rm ST}$ atypique par rapport au $F_{\rm ST}$ des locus neutres, des
segments chromosomiques ancestraux supplémentaires ont été générés en simulant
des séquences d'ADN avec un taux de migration $m_s$ inférieur à $m$. Les
simulations ont permis de reproduire pour les SNPs sous adaptation local les
niveaux de diversité attendu lors d'un balayage sélectifs d'un segment
chromosomique particulier cite:Martins_2016. Pour chaque simulation, la taille
de l'échantillon a varié pour un nombre d'individu allant de 50 à 700.

Nous avons comparer les estimateurs des algorithmes APLS et AQP entre eux. De
plus, nous avons comparé les résultats de l'algorithme APLS avec ceux obtenue
par le logiciel =TESS= 2.3. Chaque programme a été exécuté 5 fois sur les mêmes
données simulées en utilisant $K = 2$ clusters génétiques comme hyperparamètres.
Nous avons calculé l'erreur quadratique moyenne (RMSE) entre les valeurs
estimées et connues de la matrice $\Q$, et entre les valeurs estimées et connues
de la matrice $\G$. Ensuite, pour évaluer le bénéfice des algorithmes spatiaux,
nous avons comparé les erreurs statistiques de l'algorithme APLS aux erreurs
obtenues avec la méthode sNMF qui reproduit les résultats du programme
=structure= avec précision cite:Frichot_2014,Frichot_2015. Pour quantifier les
performances des tests de détection de l'adaptation local en fonction de
l'intensité de la sélection environnementale, nous avons utilisé l'aire sous la
courbe précision-rappel du test d'adaptation local (AUC) pour plusieurs valeurs
de l'intensité de la sélection ($m/m_s$).

*** Application à des données humaines                           :noexport:
Pour évaluer la robustesse de notre approche à une situation où le mélange a été
la conséquence d'un grand déplacement plutôt que d'un contact entre des
populations proche géographiquement, nous avons étudié le cas des populations
afro-américaines. Il s'agit d'un cas intéressant pour lequel l'incorporation de
données géographiques pourrait potentiellement nuire à l'estimation des
coefficients de métissage. Les génotypes avec une fréquence d'allèle mineure
supérieure à 5 $\%$ ont été obtenus à partir des données du projet 1000 Genomes
phase 3 pour les Afro-Américains (ASW, 61 individus), des Africains (YRI du
Nigeria et LWK du Kenya, 207 individus) et Européens (GBR du Royaume-Uni et TSI
d'Italie, 198 personnes) cite:1000Genome_2015. Au total, 6 994 677 SNPs ont été
analysés avec des données géographiques correspondant au pays d'origine des
échantillons individuels. Nous avons comparé les estimations de l'algorithme
APLS appliqué avec ces paramètres par défaut aux résultats du programme =snmf=
qui n'utilise pas l'informations géographiques.

*** Application à des écotypes européen d'Arabidopsis thaliana
<<simu_At>>

Nous avons utilisé l'algorithme APLS pour étudier la structure de population
spatiale et pour détecter les locus sous adaptions local en considérant 214k SNP à
partir de 1 095 écotypes européens des espèces végétales /A.thaliana/
cite:Horton_2012. Le critère de validation croisée a été utilisé pour évaluer le
nombre de cluster génétique dans l'échantillon, et nous avons utilisé le
variogramme spatial des données génétique pour évaluer l'échelle de
l'auto-corrélation spatiale. Nous avons utilisé les fonctions du package
=tess3r= pour afficher les coefficients de métissage interpolés sur une carte
géographique d'Europe. Une analyse d'enrichissement de l'ontologie des gènes
utilisant le logiciel =AMIGO= cite:Carbon_2008 a été réalisée afin d'évaluer
quelles fonctions moléculaires et processus biologiques pourraient être
impliqués dans l'adaptation locale de /A.thaliana/ en Europe.

** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:
*** Analyse de la convergence et temps d'exécution

Nous avons utilisé des simulations coalescentes de polymorphismes neutres avec
un modèle spatial de mélange pour comparer les erreurs statistiques des
estimations de $\Q$ et $\G$ obtenu avec AQP et APLS. La référence pour la
matrice $\Q$, noté $\Q_0$, a été calculée à partir des proportions de mélange
utilisées pour générer les génotype à partir des deux populations sources
simulées par =ms=. Pour la matrice $\G$, la matrice de vérité noté ($\G_0$) a
été calculée à partir des fréquences empiriques des génotypes des deux
populations sources. Les erreurs quadratique moyenne (RMSE) pour les estimations
les estimations des matrice $\Q$ et $\G$ diminuent à mesure que la taille de
l'échantillon et le nombre de locus augmentaient (Figure ref:fig:tess3:comp).
Pour tous les algorithmes, les erreurs statistiques sont généralement faibles
lorsque le nombre de locus est supérieur à 10k. Ces résultats permette de
prouver que les deux algorithmes produises des estimations équivalentes des
matrices $\Q_0$ et $\G_0$. Les résultats ont également permis de vérifier que
l'algorithmes APLS converge vers les mêmes estimations que celles obtenues par
l'algorithme AQP, qui est garanti pour converger mathématiquement.

#+NAME: code:tess3:comp
#+CAPTION: Dépend de [[code:tess3:comparison:plot]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_comp_plot.rds")

  ThesisRpackage::Plots_export_tikz_pdf(pl = pl, 
                        basename.output = "tess3_APLS_AQP_rmse_comp", 
                        env = MaTheseR.params,
                        height = 0.5 * MaTheseR.params$textheightinch,
                        width = 1.1 * MaTheseR.params$textwidthinch)
#+end_src
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_APLS_AQP_rmse_comp.pdf}
\caption{{\bf Racine carré de l'erreur quadratique moyenne (RMSE) pour les
    estimations des matrices $\Q$ et $\G$}. Simulations de génotype métissé
  spatialement. A-B) Erreur statistique des estimations de APLS et AQP en
  fonction du nombre d'individu $n$ ($p \sim 10^4$). C-D) Erreur statistique des
  estimations de APLS et AQP en fonction du nombre de locus $p$ ($n = 200$)}
\label{fig:tess3:comp}
\end{figure}
#+END_EXPORT

Nous avons sous-échantillonné un grand jeux de données de SNPs d'écotypes de
/A.thaliana/ pour comparer les propriétés de convergence et les temps
d'exécution des algorithmes AQP et APLS. Dans ces expériences, nous avons
utilisé les méthodes avec $6$ cluster génétiques et avons répliqué 5 fois chaque
simulation. Pour un nombre d'individus allant 500 à 600 et un nombre de 50k
locus, l'algorithme APLS nécessite plus d'itérations (25 itérations) que
l'algorithme AQP (20 itérations) pour converger vers sa solution (Figure
ref:fig:tess3:vitesse). Pour un nombre de locus allant de 10k à 200k et 150
individus, on observe des résultats similaires. Pour 50k SNPs, les temps
d'exécution sont significativement plus bas pour l'algorithme APLS que pour les
algorithmes AQP. Pour 50k SNPs et 600 individus, cela a pris en moyenne 1,0 min
pour l'algorithme APLS et 100 min pour l'algorithme AQP pour calculer leurs
résultats. Pour 100k SNPs et 150 individus, il a fallu en moyenne 0,6 min (9,0
min) pour l'algorithme APLS (AQP) pour calculer leurs résultats. Pour les
valeurs du nombre d'individus et locus considéré ici, l'implémentation de
l'algorithme APLS a été d'environs 2 à 100 fois plus rapide que celle de
l'algorithme AQP.

#+NAME: code:tess3:vitesse
#+CAPTION: Dépend de [[code:tess3:vitesse:plot]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_vitesse_plot.rds")

  ThesisRpackage::Plots_export_tikz_pdf(pl,
                                        basename.output = "tess3_vitesse",
                                        env = MaTheseR.params,
                                        height = 0.5 * MaTheseR.params$textheightinch,
                                        width = MaTheseR.params$textwidthinch)
#+end_src
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_vitesse.pdf}
\caption{{\bf Nombre d'itérations et temps d'exécution pour les algorithmes AQP et
  APLS}. A-B) Nombre total d'itération avant que l'algorithmes ai atteint une
  solution stable. C-D) Temps de calcul d'une seul itération en secondes. Le
  nombre de SNPs a été fixé à $p = 50$k pour A et C. Le nombre d'individus a été
  fixé à $n = 150$ pour B et D.}
\label{fig:tess3:vitesse}
\end{figure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE Expérience comparaison
CLOSED: [2017-09-15 ven. 10:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-15 ven. 10:43]
- State "TODO"       from              [2017-09-15 ven. 10:35]
:END:
#+NAME: code:tess3:comparison:run
#+CAPTION: Dépend de 
#+begin_src R 
  ## setup
  library(ThesisRpackage)
  Article2.env <- get_Article2()
  attach(Article2.env)

  ## Experiment along L
  simu.param <- list(n = 100,
                     nsites.neutral = 1e4,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 10 ^ -8,
                     m.neutral = 0.25 * 10 ^ -6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 10 ^ -7,
                     N0 = 10 ^ 6,
                     k = 0.5,
                     min.maf = 0.05)

  cores = 16
  registerDoParallel(cores = cores)

  simu.param$nsites.neutral <- 1e5

  simu.param$n <- 200
  df.L <- fig1.exp.L(simu.param, Ls = c(1e4, 2.5e4, 5e4, 1e5, 2e5, 3e5), rep = 5)

  saveRDS(df.L, file = "./OUTPUT/Expr/tess3_L.rmse.R")


  ## Experiment along n
  simu.param <- list(n = 100,
                     nsites.neutral = 1e4,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 10 ^ -8,
                     m.neutral = 0.25 * 10 ^ -6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 10 ^ -7,
                     N0 = 10 ^ 6,
                     k = 0.5,
                     min.maf = 0.05)

  cores = 16
  registerDoParallel(cores = cores)

  simu.param$nsites.neutral <- 1e5
  df.n <- fig1.exp.n(simu.param, ns = c(50,100, 200, 500, 700), rep = 5)
  saveRDS(df.n, file = "./OUTPUT/Expr/tess3_n.rmse.R")
#+end_src
***** DONE Plot comparaison
CLOSED: [2017-09-15 ven. 11:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-15 ven. 11:09]
- State "TODO"       from              [2017-09-15 ven. 10:35]
:END:
#+NAME: code:tess3:comparison:plot
#+CAPTION: Dépend de [[code:tess3:comparison:run]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## retrieve results
  df.n <- readRDS("./OUTPUT/Expr/tess3_n.rmse.R") %>%
    dplyr::filter(method != "TESS3")
  df.L <- readRDS("./OUTPUT/Expr/tess3_L.rmse.R") %>%
    dplyr::filter(method != "TESS3")
  ## plot
  toplot <- df.n  %>%
    reshape2::melt(id = c("n", "rep", "L", "method"), value.name = "rmse") %>%
    group_by(n, method, variable) %>%
    mutate(rmse.mean = mean(rmse), N = length(rmse), sd = sd(rmse), se = sd / sqrt(N)) %>%
    mutate(Methods = method)

  pl.n.A <- ggplot(toplot %>% dplyr::filter(variable == "rmseG"),
                   aes(x = n, y = rmse.mean, col = method, linetype = method, shape = method)) +
    geom_line() +
    geom_errorbar(aes(ymin = rmse.mean - se,
                      ymax = rmse.mean + se,
                      width = (max(n) - min(n)) * 0.02 )) +
    geom_point(size = 2) +
    xlab("Nombre d'individus ($n$)") +
    ylab("RMSE") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none",
          plot.title = element_text(size = 16)) +
    Article2.env$scale.linetype +
    Article2.env$scale.color +
    ggtitle("Matrice $G$")

  pl.n.B <- ggplot(toplot %>% dplyr::filter(variable == "rmseQ"),
                   aes(x = n, y = rmse.mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_errorbar(aes(ymin = rmse.mean - se, ymax = rmse.mean + se,
                      width = (max(n) - min(n)) * 0.02 )) +
    geom_line() +
    geom_point(size = 2) +
    xlab("Nombre d'individus ($n$)") +
    ylab("") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none",
          plot.title = element_text(size = 16)) +
    Article2.env$scale.linetype +
    Article2.env$scale.color +
    ggtitle("Matrice $Q$")

  toplot <- df.L  %>%
    reshape2::melt(id = c("nsites.neutral", "rep", "L", "method"), value.name = "rmse") %>%
    group_by(nsites.neutral, method, variable) %>%
    mutate(rmse.mean = mean(rmse), N = length(rmse), sd = sd(rmse), se = sd / sqrt(N), L = mean(L))

  pl.L.C <- ggplot(toplot %>% dplyr::filter(variable == "rmseG"), aes(x = L / 1000, y = rmse.mean, col = method, linetype = method, shape = method)) +
    geom_errorbar(aes(ymin = rmse.mean - se, ymax = rmse.mean + se,
                      width = (max(L) - min(L)) * 0.00002 )) +
    geom_line() +
    geom_point(size = 2) +
    xlab("Nombre de locus $\\times 1000$ ($p$)") +
    ylab("RMSE") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  pl.L.D <- ggplot(toplot %>% dplyr::filter(variable == "rmseQ"), aes(x = L / 1000, y = rmse.mean, col = method, linetype = method, shape = method)) +
    geom_errorbar(aes(ymin = rmse.mean - se, ymax = rmse.mean + se,
                      width = (max(L) - min(L)) * 0.00002 )) +
    geom_line() +
    geom_point(size = 2) +
    xlab("Nombre de locus $\\times 1000$ ($p$)") +
    ylab("") +
    MaTheseR.params$gtheme +
    Article2.env$scale.linetype +
    Article2.env$scale.color +
    theme(legend.position = c(0.75,0.60))


  pl <- cowplot::plot_grid(pl.n.A, pl.n.B, pl.L.C, pl.L.D, ncol = 2, labels = c("A", "B", "C", "D"))

  save_plot_png(pl, "tess3_APLS_AQP_rmse_comp.png")
  save_expr(pl, "tess3_comp_plot.rds")

#+end_src

#+RESULTS: code:tess3:comparison:plot
: [[./OUTPUT/Rplots/tess3_APLS_AQP_rmse_comp.png]]
: Measuring dimensions of:  Nombre de locus $\times 1000$ ($p$)

***** DONE Expérience vitesse
CLOSED: [2017-09-11 lun. 12:21]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 12:21]
:END:
#+NAME: code:tess3:vitesse:run
#+CAPTION: Dépend de [[code:tess3:AhalianaRegMapLines]]
#+begin_src R 
  library(MaTheseR)

  ## loda data
  load("./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR8.RData")

  sample.data.at <- sampler.from.data(call_method_75_TAIR8.europe$X,
    call_method_75_TAIR8.europe$coord)

  data.list <- sample.data.at(50, 5000)

  cores = 16
  registerDoParallel(cores = cores)

  ns = c(1e2, 2e2, 3e2, 4e2, 5e2, 6e2)
  Ls = c(1e3, 5e3, 1e4, 5e4, 1e5, 2e5)
  rep = 5
  L = 50000
  n = 150
  K = 6
  tess3Old.alpha = 0.03

  df.n <- data.frame()
  df.n <- rbind(fig4.exp.n(sample.data = sample.data.at, ns = ns, rep = rep, L = L, K = K, tess3Old.alpha = tess3Old.alpha), df.n)

  df.L <- data.frame()
  df.L <- rbind(fig4.exp.L(sample.data = sample.data.at, Ls = Ls, rep = rep, n = n, K = K, tess3Old.alpha = tess3Old.alpha), df.L)

  expr <- list( df.L = df.L, df.n = df.n)
  save_expr(expr, "tess3_vitesse.rds")
#+end_src
***** DONE Plots vitesse
CLOSED: [2017-09-11 lun. 12:21]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 12:21]
:END:
#+NAME: code:tess3:vitesse:plot
#+CAPTION: Dépend de [[code:tess3:vitesse:run]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(cowplot)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## expr res
  expr <- readRDS("./OUTPUT/Expr/tess3_vitesse.rds")
  expr$df.n <- expr$df.n %>%
    dplyr::filter(method != "TESS3")
  expr$df.L <- expr$df.L %>%
    dplyr::filter(method != "TESS3")


  g_legend <- function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}



  toplot <- expr$df.n  %>% group_by(method, n) %>%
    mutate(mean = mean(it), N = length(it), sd = sd(it), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.it.n <- ggplot(toplot ,aes(x = n, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se,
                      ymax = mean + se,
                      width = (max(n) - min(n)) * 0.02)) +
    theme_bw() +
    xlab("") +
    ylab("Nombre\nd'itérations") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.n  %>% group_by(n, method) %>%
    mutate(mean = mean(time.per.it.mean), N = length(time.per.it.mean), sd = sd(time.per.it.mean), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.time.n <- ggplot(toplot ,aes(x = n, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se,
                      width = (max(n) - min(n)) * 0.02)) +
    theme_bw() +
    scale_y_log10() +
    xlab("Nombre d'individus ($n$)") +
    ylab("Temps par itération \n(seconds)") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.L  %>% group_by(method, L) %>%
    mutate(mean = mean(it), N = length(it), sd = sd(it), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.it.L <- ggplot(toplot ,aes(x = L / 1000, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se,
                      ymax = mean + se,
                      width = (max(L) - min(L)) * 0.02 / 1000)) +
    theme_bw() +
    xlab("") +
    ylab("") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.L  %>% group_by(L, method) %>%
    mutate(mean = mean(time.per.it.mean), N = length(time.per.it.mean), sd = sd(time.per.it.mean), se = sd / sqrt(N)) %>%
    rename(Methods = method)

  pl.time.L <- ggplot(toplot ,aes(x = L / 1000, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se,
                      width = (max(L) - min(L)) * 0.02 / 1000)) +
    theme_bw() +
    scale_y_log10() +
    xlab("Nombre de locus $\\times 1000$ ($p$)") +
    ylab("") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.61,0.22)) +
    Article2.env$scale.linetype +
    Article2.env$scale.color +
    guides(linetype = guide_legend(nrow = 2))

  pl <- cowplot::plot_grid(pl.it.n, pl.it.L, pl.time.n, pl.time.L, ncol = 2, labels = c("A", "B", "C", "D"))
  save_plot_png(pl, "tess3_vitesse.png")
  save_expr(pl, "tess3_vitesse_plot.rds")
#+end_src

#+RESULTS: code:tess3:vitesse:plot
: [[./OUTPUT/Rplots/tess3_vitesse.png]]
*** Comparaison avec une méthode spatial bayésienne : TESS

Nous avons utilisé des simulations coalescentes de polymorphismes neutres avec
un modèle spatial de mélange pour évaluer les capacités de l'algorithme APLS à
reproduire les estimations obtenues avec le logiciel =TESS= 2.3. Nous avons deux
clusters génétiques de 2k de 100 échantillon de 2k locus pour différent de
niveau de différentiation moyen $F_{\rm ST}$ pour créer des jeux de données pour
lesquels il est plus ou moins dure d'estimer la structure de population. Les
erreurs statistiques, mesurées par RMSE, pour l'estimation des matrices $\Q$ et
$\G$ varie entre $0.02$ et $0.15$ (Figure ref:fig:tess3:tess23). Les erreurs
statistiques augmentent à mesure que les niveaux de différenciation entre les
deux populations sources diminue, mais elles reste dans une gamme acceptable
pour les valeurs de $F_{\rm ST}> 0.016$. Dans l'ensemble, les performances
statistiques sont du même ordre pour =TESS= 2.3 et APLS.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\begin{minipage}{0.49\textwidth}
  \includegraphics[width=\textwidth]{./OUTPUT/Rplots/tess3_tess2_3_rmseG.pdf}
\end{minipage}
\begin {minipage}{0.49\textwidth}
  \includegraphics[width=\textwidth]{./OUTPUT/Rplots/tess3_tess2_3_rmseQ.pdf}
\end{minipage}
\caption{{\bf Racine de l'erreur quadratique moyenne (RMSE) pour l'estimation de
    $\Q$ (figure A) et $\G$ (figure B).} Simulations de génotypes métissés
  spatialement pour plusieurs niveaux de différenciation ($\Fst$) entre les
  populations sources. Les populations sources sont simulées par un modèle de
  Wright's à deux iles et la statistique de différenciation est définie comme
  $1/(1+4N_0 m)$ où $m$ est le taux de migration et $N_0$ la taille
  effective de la population. Les erreurs statistique de \textit{TESS} 2.3 et APLS sont
  représentées comme des fonctions de $\Fst$.}
\label{fig:tess3:tess23}
\end{figure}    
#+END_EXPORT

**** Scripts                                                    :noexport:
***** Experience
Code trop vieux...
***** Plots
J'ai mis un petit coup ink scape à des plot qui trainaient :D
*** Comparaison avec une méthode non spatial : sNMF
En utilisant des simulations coalescentes de polymorphismes neutres avec un
modèle spatial de mélange, nous avons comparé les estimations statistiques
obtenues à partir d'un algorithme spatial (APLS) et d'un algorithme non spatial
(sNMF, cite:Frichot_2014). Pour différents niveaux de différenciation de la
population ancestrale, les estimations obtenues à partir de l'algorithme spatial
sont plus précises que celles obtenues en utilisant des approches non spatiales
(Figure ref:fig:tess3:comp:rmse:snmf). Pour les données simulées plus grandes,
la méthode spatiale arrive a détecter une structure de population plus fine que
l'algorithme non spatial (Figure ref:fig:tess3:comp:rmse:snmf).

#+NAME: code:tess3:comp:rmse:snmf
#+CAPTION: Dépend de [[code:tess3:rmse:plot]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_comp_rmse_snmf_plot.rds")

  ThesisRpackage::Plots_export_tikz_pdf(pl,
                                        basename.output = "tess3_comp_rmse_snmf",
                                        env = MaTheseR.params,
                                        height = 0.4 * MaTheseR.params$textheightinch,
                                        width = MaTheseR.params$textwidthinch)

#+end_src
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_comp_rmse_snmf.pdf}
\caption{{\bf Racine de l'erreur quadratique moyenne (RMSE) pour l'estimation de
    $\Q$.} Simulations de génotypes métissés spatialement pour plusieurs niveaux
  de différenciation($F_{\rm ST}$) entre les populations sources. Les
  populations sources sont simulées par un modèle de Wright's à deux iles et la
  statistique de différenciation est définie comme $1 / (1 + 4 N_0 m)$ où $m$
  est le taux de migration et $N_0$ la taille effective de la population. Les
  erreurs statistique de sNMF et APLS sont représentées comme des fonctions de
  $F_{\rm ST}$.}
\label{fig:tess3:comp:rmse:snmf}
\end{figure}
#+END_EXPORT

Sur les simulations avec des locus sous adaptation local, nous avons utilisé
l'aire sous la courbe de précision-rappel (AUC) pour quantifier les performances
des tests de détection des locus sélectionnés reposant sur les estimations des
matrices d'ascendance génétiques, $\Q$ et $\G$. De plus, nous avons calculé les
AUC pour des tests de neutralité basés sur le calcul de la $\Fst$ à partir des
génotypes des populations source simulées par =ms=. Comme ils représentent les
valeurs maximales atteignables, les AUC basés sur les génotypes des populations
sources sont toujours plus élevés que ceux obtenus pour des tests basés sur des
estimations des matrices d'ascendance. Pour toutes les valeurs de l'intensité de
sélection, les AUC étaient plus élevés pour les méthodes spatiales que pour les
méthodes non spatiales (Figure ref:fig:tess3:auc, l'intensité de sélection est
le rapport des taux de migration aux locus neutres et adaptatifs). Pour les
intensités de sélection élevées, les performances des tests basés sur les
estimations des matrices d'ascendance étaient proches des valeurs optimales
atteintes par des tests basés sur les vrais fréquences des populations sources.
Ces résultats ont fourni des preuves que l'inclusion de l'information spatiale
dans les algorithmes d'estimation de l'ascendance améliore la détection des
signatures de balayages sélectifs survenant dans des clusters génétiques
inconnus.

#+NAME: code:tess3:auc
#+CAPTION: Dépend de [[code:tess3:auc:snmf:plots]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/ :results silent
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_comp_auc_snmf_plot.rds")

  ThesisRpackage::Plots_export_tikz_pdf(pl,
                                        "tess3_comp_auc_snmf",
                                        env = MaTheseR.params,
                                        height = 0.4 * MaTheseR.params$textheightinch,
                                        width = MaTheseR.params$textwidthinch)

#+end_src
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_comp_auc_snmf.pdf}
\caption{{\bf Aire sous la courbe de précision-rappel (AUC).} Tests de
  neutralité appliqués aux simulations de populations spatialement métissées.
  Nous avons calculé l'AUC pour les tests basés sur la statistique $F_{\rm ST}$
  calculée à partir des vrais populations sources avant le métissage, à partir
  des estimations d'ascendance spatiale calculées avec l'algorithme APLS,
  l'estimations d'ascendance non spatiales ({\tt structure}) calculées avec
  l'algorithme {\ tt snmf}. L'intensité de la sélection dans les populations
  sources, définies comme le rapport $ m / m_s $, varie dans la fourchette
  de $1-160$.}
\label{fig:tess3:auc}
\end{figure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE RMSE APLS et sNMF
CLOSED: [2017-09-11 lun. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 18:17]
:END:
#+NAME: code:tess3:rmse:snmf
#+CAPTION: 
#+begin_src R 
  ######################################
  ## Setup

  ## Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # sNMF
  if (!require("LEA")) {
    source("https://bioconductor.org/biocLite.R")
    biocLite("LEA")
    if(!require("LEA",character.only = TRUE)) stop("Package not found")
  }

  res.dir <- "./"
  fig.dir <- "./"

                                          # personal packages
                                          #devtools::install_github("cayek/TESS3_encho_sen@experiment")
  require("tess3rExperiment")

                                          #devtools::install_github("cayek/TESS3_encho_sen@master")
  require("tess3r")

  cat(green(paste("DEBUG =", DEBUG,"\n")))
  ######################################
                                          # Functions


  fst.LEA <- function(project,run = 1, K, ploidy = 2){
                                          #require(LEA)
    ll = dim(LEA::G(project, K = K, run = run))[1]
    if (ploidy == 2) {freq = LEA::G(project, K = K, run = run)[seq(2,ll,by = 3),]/2 + LEA::G(project, K = K, run = run)[seq(3,ll,by = 3),] }
    else {freq = LEA::G(project, K = K, run = run)[seq(2,ll,by = 2),]}
    q = apply(LEA::Q(project, K = K, run = run), MARGIN = 2, mean)
    H.s = apply(freq*(1 - freq), MARGIN = 1, FUN = function(x) sum(q*x) )
    P.t = apply(freq, MARGIN = 1, FUN = function(x) sum(q*x) )
    return(1 - H.s/P.t/(1 - P.t))
  }


  tess3.wrapper <- function(data.list, K, method) {
    if (is.null(data.list$admixed.genotype)) {
      capture.output(res <- tess3rExperiment::tess3(X = data.list$X,
                                                    coord = data.list$coord,
                                                    K = K,
                                                    ploidy = data.list$ploidy,
                                                    lambda = 1.0,
                                                    W = data.list$W,
                                                    method = method,
                                                    max.iteration = 200,
                                                    tolerance = 1e-05,
                                                    openMP.core.num = 1,
                                                    Q.init = NULL,
                                                    mask = 0), file = "/dev/null")
    } else {
      capture.output(res <- tess3rExperiment::tess3(X = data.list$admixed.genotype,
                                                    coord = data.list$coord,
                                                    K = K,
                                                    ploidy = data.list$ploidy,
                                                    lambda = 1.0,
                                                    W = data.list$W,
                                                    method = method,
                                                    max.iteration = 200,
                                                    tolerance = 1e-05,
                                                    openMP.core.num = 1,
                                                    Q.init = NULL,
                                                    mask = 0), file = "/dev/null")
    }
    return(res)
  }


  snmf.wrapper <- function(data.list, K, alpha = 10) {
    file.geno <- paste0(tempfile(),".geno")
    if (is.null(data.list$admixed.genotype)) {
      LEA::write.geno(data.list$X, file.geno)
    } else {
      LEA::write.geno(data.list$admixed.genotype, file.geno)
    }
    capture.output(aux <- LEA::snmf(input.file = file.geno,
                                    K = K,
                                    project = "new",
                                    repetitions = 1,
                                    alpha = alpha,
                                    tolerance = 1e-05,
                                    entropy = FALSE,
                                    percentage = 0.05,
                                    I = 0,
                                    iterations = 200,
                                    ploidy = data.list$ploidy,
                                    seed = -1,
                                    CPU = 1,
                                    Q.input.file = ""), file = "/dev/null")
    snmf.run <- list(Q = LEA::Q(aux, K = K, run = 1),
                     G = LEA::G(aux, K = K, run = 1),
                     Fst = fst.LEA(aux, run = 1, K = K, ploidy = 1))
    return(snmf.run)
  }


  fig2.experiment <- function(simu.param, m.neutral, rep) {
    df <- foreach(m = m.neutral, .combine = 'rbind') %:%
      foreach(r = 1:rep, .combine = 'rbind') %dopar% {
        simu.param$m.neutral <- m
        boolFalse <- FALSE
        while (boolFalse == FALSE)
        {
          tryCatch({
            data.list <- sample.data(simu.param)
            boolFalse <- TRUE
          },error = function(e){
          },finally = {})
        }
        tess3.res <- tess3.wrapper(data.list, 2, "MCPA")
        snmf.res <- snmf.wrapper(data.list, 2)
        rbind( data.frame(rmseQ = tess3r::ComputeRmseWithBestPermutation(data.list$Q, tess3.res$Q),
                          rmseG = tess3r::ComputeRmseWithBestPermutation(data.list$Freq, GtoFreq(tess3.res$G, 1)),
                          method = "TESS3-APLS",
                          n = nrow(data.list$admixed.genotype),
                          L = ncol(data.list$admixed.genotype),
                          rep = r,
                          Fst = mean(data.list$Fst),
                          Fst.theorical = data.list$Fst.theorical,
                          m.neutral = m,
                          nsites.neutral = data.list$nsites.neutral,
                          migration.rate = 4 * m * simu.param$N0),
              data.frame(rmseQ = tess3r::ComputeRmseWithBestPermutation(data.list$Q, snmf.res$Q),
                         rmseG = tess3r::ComputeRmseWithBestPermutation(data.list$Freq, GtoFreq(snmf.res$G, 1)),
                         method = "sNMF",
                         n = nrow(data.list$admixed.genotype),
                         L = ncol(data.list$admixed.genotype),
                         rep = r,
                         Fst = mean(data.list$Fst),
                         Fst.theorical = data.list$Fst.theorical,
                         m.neutral = m,
                         nsites.neutral = data.list$nsites.neutral,
                         migration.rate = 4 * m * simu.param$N0))
      }
    return(df)
  }


  sample.data <- function(simu.param) {
    res <- tess3r::SampleGenoOFWithMs(n = simu.param$n,
                                      nsites.neutral = simu.param$nsites.neutral,
                                      nsites.selected = simu.param$nsites.selected,
                                      crossover.proba = simu.param$crossover.proba,
                                      m.neutral = simu.param$m.neutral,
                                      m.selected = simu.param$m.selected,
                                      mutation.rate.per.site = simu.param$mutation.rate.per.site,
                                      N0 = simu.param$N0,
                                      k = simu.param$k,
                                      min.maf = simu.param$min.maf,
                                      plot.debug = FALSE,
                                      tess3.ms = getOption("tess3.ms"))
    res$Fst.theorical <- 1 / (1 + 4 * simu.param$N0 * simu.param$m.neutral)
    return(res)
  }


  ######################################
                                          # Params

  cat(green("== Test params\n"))
  simu.param <- list(n = 500,
                     nsites.neutral = 1.2 * 1e5,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 3 * 1e-6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)
  data.list <- sample.data(simu.param)

  plot(data.list$coord, col = rep(rainbow(2),each = data.list$n / 2))
  mean(data.list$Fst)
  dim(data.list$admixed.genotype)


  barplot(t(data.list$Q), col = rainbow(2))
                                          # data.list$W <- NULL
  tess3.run <- tess3.wrapper(data.list, K = 2, method = "MCPA")
  barplot(t(tess3.run$Q), col = rainbow(2))

  snmf.run <- snmf.wrapper(data.list, K = 2)
  barplot(t(snmf.run$Q), col = rainbow(2))

  ComputeRmseWithBestPermutation(snmf.run$Q, data.list$Q)
  ComputeRmseWithBestPermutation(tess3.run$Q, data.list$Q)

  ComputeRmseWithBestPermutation(GtoFreq(snmf.run$G,1), data.list$Freq)
  ComputeRmseWithBestPermutation(GtoFreq(tess3.run$G,1), data.list$Freq)


  ######################################
                                          # Run experiments


  simu.param <- list(n = 500,
                     nsites.neutral = 1.5 * 1e5,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 3 * 1e-6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)

  cores = 16
  registerDoParallel(cores = cores)

  if (DEBUG) {
    m.neutral =  c(0.25 * 0.05 * 1e-6,
                   0.25 * 0.5 * 1e-6,
                   0.25 * 1 * 1e-6,
                   0.25 * 1.5 * 1e-6,
                   0.25 * 2 * 1e-6,
                   0.25 * 2.5 * 1e-6,
                   0.25 * 3 * 1e-6,
                   0.25 * 5 * 1e-6)
    rep <- 5
  } else {
    m.neutral =  c(0.25 * 0.05 * 1e-6,
                   0.25 * 0.5 * 1e-6,
                   0.25 * 1 * 1e-6,
                   0.25 * 1.5 * 1e-6,
                   0.25 * 2 * 1e-6,
                   0.25 * 2.5 * 1e-6,
                   0.25 * 3 * 1e-6,
                   0.25 * 5 * 1e-6)
    rep <- 5 #  do not work ... why?
  }

  df <- data.frame()

                                          # n = 50
  simu.param$n = 50
  ## L = 10k
  cat(green("== n = 50 & L = 10k \n"))
  simu.param$nsites.neutral = 1.5 * 1e4
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  ## L = 200k
  cat(green("== n = 50 & L = 100k \n"))
  simu.param$nsites.neutral = 1.2 * 1e5
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

                                          # n = 500
  simu.param$n = 500
  ## L = 10k
  cat(green("== n = 500 & L = 10k \n"))
  simu.param$nsites.neutral = 1.5 * 1e4
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  ## L = 100k
  cat(green("== n = 500 & L = 100k \n"))
  simu.param$nsites.neutral = 1.2 * 1e5
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  cat(green("== Save result\n"))
  saveRDS(df, file = "./OUTPUT/Expr/tess3_comp_rmse_sNMF.rds")

#+end_src
***** DONE Plots RMSE APLS et sNMF
CLOSED: [2017-09-11 lun. 18:30]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:30]
- State "TODO"       from "DONE"       [2017-09-11 lun. 18:23]
- State "DONE"       from              [2017-09-11 lun. 18:23]
:END:
#+NAME: code:tess3:rmse:snmf:plot
#+CAPTION: Dépend de [[code:tess3:rmse:snmf]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(cowplot)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## retrieve results
  df <- readRDS("./OUTPUT/Expr/tess3_comp_rmse_sNMF.rds")

  labbeler <- function(variable, value) {
    if (as.character(variable) == "n") {
      paste0("$n = ",value, "$")
    } else if (as.character(variable) == "L") {
      paste0("$L \\approx 10^", floor(log(value,base = 10)), "$")
    }
  }

  toplot <- df %>%
    group_by(nsites.neutral) %>%
    dplyr::mutate(L = round(mean(L))) %>%
    group_by(method, m.neutral, n, L) %>%
    dplyr::mutate(Fst = mean(Fst), rmse.mean = mean(rmseQ), N = length(rmseQ), sd = sd(rmseQ), se = sd / sqrt(N)) %>%
    rename(Methods = method )
  levels(toplot$Methods)[1] <- "APLS"


  pl <- ggplot(toplot ,
               aes(x = Fst.theorical,
                   y = rmse.mean,
                   col = Methods,
                   shape = Methods,
                   linetype = Methods)) +
    geom_errorbar(aes(ymin = rmse.mean - se, ymax = rmse.mean + se,
                      width = (max(Fst.theorical) - min(Fst.theorical)) * 0.02)) +
    geom_line() +
    geom_point(size = 2) +
    facet_grid(L ~ n, labeller = labbeler) +
    theme_bw() +
                                          # xlab("$Fst = 1 / (1 + 4 N_0 m)$") +
    xlab("Fixation index $(F_{\\rm ST})$") +
    ylab("RMSE") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.85,0.3)) +
    Article2.env$scale.color +
    Article2.env$scale.linetype
  save_plot_png(pl, "tess3_comp_rmse_snmf.png")

  save_expr(pl, "tess3_comp_rmse_snmf_plot.rds")

#+end_src

#+RESULTS: code:tess3:rmse:snmf:plot
[[./OUTPUT/Rplots/tess3_comp_rmse_snmf.png]]
***** DONE AUC APLS et sNMF
CLOSED: [2017-09-11 lun. 18:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:41]
- State "TODO"       from              [2017-09-11 lun. 18:35]
:END:
#+NAME: code:tess3:auc:snmf
#+CAPTION: Dépend de 
#+begin_src R 
  library(ThesisRpackage)
  Article2.env <- get_Article2()
  attach(Article2.env)

  simu.param <- list(n = 100,
                     nsites.neutral = 1 * 1e5,
                     nsites.selected = 1 * 1e2,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 10 * 1e-6,
                     m.selected = 0.25 * 0.1 * 1e-6,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)

                                          # Experiment

  cores = 16
  registerDoParallel(cores = cores)

  m.ms <- c(10, 40, 80, 100, 150)

  df <- data.frame()
  df <- rbind(fig3.experiment(simu.param, m.ms = m.ms, rep = 10), df)

  saveRDS(df, "./OUTPUT/Expr/tess3_comp_auc_sNMF.rds")
#+end_src
***** DONE Plots AUC APLS et sNMF
CLOSED: [2017-09-11 lun. 18:57]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:57]
- State "TODO"       from              [2017-09-11 lun. 18:41]
:END:
#+NAME: code:tess3:auc:snmf:plots
#+CAPTION: Dépend de [[code:tess3:auc:snmf]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## retrieve data
  df <- readRDS("./OUTPUT/Expr/tess3_comp_auc_sNMF.rds")

  ## plot
  toplot <- df %>%
    group_by(method, m.ms) %>%
    dplyr::mutate(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  levels(toplot$Methods)[1] <- "APLS"
  levels(toplot$Methods)[3] <- "avant m\\'etissage"

  pl <- ggplot(toplot ,aes(x = m.ms, y = auc.mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se,
                      width = (max(m.ms) - min(m.ms)) * 0.02)) +
    geom_line() +
    geom_point(size = 2) +
    theme_bw() +
    xlab("Intensit\\'e de la s\\'election ($m/m_s$)") +
    ylab("AUC") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.8,0.2)) +
    scale_linetype_manual(values = c("APLS" = Article2.env$linetype$APLS,
                                     "sNMF" = Article2.env$linetype$snmf,
                                     "avant m\\'etissage" = Article2.env$linetype$before.admixure)) + 
    scale_color_manual(values = c("APLS" = Article2.env$color$APLS,
                                  "sNMF" = Article2.env$color$snmf,
                                  "avant m\\'etissage" = Article2.env$color$before.admixure))

  save_plot_png(pl, "tess3_comp_auc_snmf.png")

  save_expr(pl, "tess3_comp_auc_snmf_plot.rds")
#+end_src

#+RESULTS: code:tess3:auc:snmf:plots
[[./OUTPUT/Rplots/tess3_comp_auc_snmf.png]]

*** Sensibilité des estimateurs aux erreurs dans les mesures spatiales
**** Scripts                                                    :noexport:
***** RUNNING Experience
:LOGBOOK:
- State "RUNNING"    from "DONE"       [2017-09-11 lun. 17:44]
- State "DONE"       from "TODO"       [2017-09-11 lun. 17:28]
- State "TODO"       from              [2017-09-11 lun. 15:07]
:END:
#+NAME: code:tess3:noise
#+CAPTION: 
#+begin_src R 
  library(ThesisRpackage)

  expr <- long_tess3_noisyCoord(ns = c(50, 500),
                               nsites.neutral = c(1.5 * 1e4,
                                                  1.2 * 1e5),
                               m.neutral =  c(0.25 * 0.5 * 1e-6,
                                              0.25 * 1 * 1e-6,
                                              0.25 * 1.5 * 1e-6,
                                              0.25 * 2 * 1e-6,
                                              0.25 * 2.5 * 1e-6,
                                              0.25 * 3 * 1e-6,
                                              0.25 * 5 * 1e-6),
                               noise.signal = c(0.0, 0.2, 0.5,0.8, 1.0, 2.0, 3.0),
                               nb.rep = 10,
                               compute.vario = TRUE,
                               cluster.nb = 4,
                               save = FALSE, bypass = TRUE)
  save_expr(expr, "tess3_noise.rds")


  pl.all <- plot_tess3_noisyCoord(expr)
  save_plot_png(pl.all, "tess3_noise_debug.png")
  pl.var <- plot_tess3_noisyCoord_vario(expr)
  save_plot_png(pl.var, "tess3_noise_var_debug.png")
#+end_src

***** TODO Plot
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 15:08]
:END:
#+NAME: code:tess3:noise:plot
#+CAPTION: Dépend de [[code:tess3:noise]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## get data
  expr <- readRDS("./OUTPUT/Expr/tess3_noise.rds")

  ## remove Fst <= 0.5
  expr$df.res <- expr$df.res %>%
    dplyr::filter(Fst.theorical <= 0.5) %>%
    dplyr::filter(noise.signal <= 3.0)

  toplot <- plot_tess3_noisyCoord_toplot(expr) %>%
    dplyr::mutate(Fst.theorical = format(Fst.theorical, digits = 2))


  labbeler <- function(variable, value) {
    if (as.character(variable) == "n") {
      paste0("n = ",value, "")
    } else if (as.character(variable) == "L") {
      paste0("p ~ 10^", ceiling(log(value,base = 10)), "")
    }
  }

  pl <- ggplot(toplot, aes(x = noise.signal, y = rel.diff.rmse.Q.mean,
                           color = as.factor(Fst.theorical),
                           shape = as.factor(Fst.theorical))) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin = rel.diff.rmse.Q.mean - rel.diff.rmse.Q.mean.se, ymax = rel.diff.rmse.Q.mean + rel.diff.rmse.Q.mean.se,
                      width = (max(noise.signal) - min(noise.signal)) * 0.02)) +
    facet_grid(L ~ n, labeller = labbeler) +
    theme_bw() +
                                          # xlab("$Fst = 1 / (1 + 4 N_0 m)$") +
    xlab("Rapport signal sur bruit") +
    ylab("Erreur relative") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.75,0.63)) +
    guides( color = guide_legend(title = "Fst", nrow = 2),
           linetype = guide_legend(title = "Fst", nrow = 3),
           shape = guide_legend(title = "Fst", nrow = 3)) +
    scale_color_manual(values = Article2.env$cbPalette) + 
    geom_hline(yintercept = 0, alpha = 0.8, col = "grey")
  pl

  save_plot_png(pl, "tess3_noise.png")
  save_plot_MaTheseR(pl, "tess3_noise.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:tess3:noise:plot
: Error in plot_tess3_noisyCoord_toplot(expr) : 
:   could not find function "plot_tess3_noisyCoord_toplot"
: Warning message:
: The labeller API has been updated. Labellers taking `variable`and `value` arguments are now deprecated. See labellers documentation.
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found

*** Application à des données humaines                           :noexport:
**** Scripts                                                    :noexport:
***** DONE map des individus et matrice W
CLOSED: [2017-09-14 jeu. 17:24]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-14 jeu. 17:24]
- State "TODO"       from              [2017-09-14 jeu. 17:21]
:END:
#+NAME: code:tess3_1000G_map
#+CAPTION: Dépend de 
#+begin_src R 
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.chr1.maf.05.rds")
  library(maps)
  map()
  points(dat$coord, col = as.factor(dat$indiv$pop))
  image(dat$W)

#+end_src
***** DONE Variogram sur le chromosome 1
CLOSED: [2017-09-14 jeu. 17:28]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-14 jeu. 17:28]
- State "TODO"       from              [2017-09-14 jeu. 17:24]
:END:
#+NAME: code:tess3_1000G_vario
#+CAPTION: Dépend de 
#+begin_src R 
  require(ThesisRpackage)
  require(tess3r)

  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3Chrm22/Eu_Af_Afam.chr1.maf.05.rds")

  exp <- Experiment(name = "1000genome_chrm1_variogram", 
                    description = "1000genome_chrm1_variogram")


  ## subsample G
  prop <- 0.25
  L <- ncol(dat$G)
  ploidy <- max(dat$G)
  loci.index <- sample.int(L, prop * L)
  X <- dat$G[,loci.index]
  XBin <- matrix(as.double(X), nrow(X), ncol(X) * (ploidy + 1))
  X2XBin(X, ploidy, XBin)
  rm(X)
  Dx <- dat$dist.matrix
  rm(dat)
  gc()

  Dz <- stats::dist(XBin, method = "manhattan") / ncol(XBin)
  exp$variogram <- CalculateEmpiricalSemivariogram(Dz = Dz, Dx = Dx)

  dumpExperiment(exp)
#+end_src

#+NAME: code:tess3_1000G_vario_plot
#+CAPTION: Dépend de [[code:tess3r_1000G_vario_res]]
#+begin_src R 
  library(ThesisRpackage)
  library(MaTheseR)

  exp <- retrieveExperiment(61)
  pl <- ggplot(exp$variogram, aes(x = h, y = semi.variance, size = size)) +
    geom_point(shape = 1)
  save_plot_png(pl, "tess3r_1000G_vario.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3r_1000G_vario.png]]

***** DONE Run de tess3r sur les données du 1000Genomes
CLOSED: [2017-09-06 mer. 09:24]
:LOGBOOK:
- State "DONE"       from              [2017-09-06 mer. 09:24]
:END:
#+NAME: code:tess3r_1000G
#+CAPTION: Dépend de 
#+begin_src R 
  ## lib
  require(tess3r)

  dat.file = "./Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds"
  K = 3
  openMP.core.num = 1
  save = TRUE

  dat <- readRDS(dat.file)


  ## compute XBin
  ploidy <- computePloidy(dat$G)
  XBin <- computeXBin(dat$G, ploidy)

  exp <- list()
  ## snmf
  message("Run of snmf")
  exp$snmf.method <- sNMFMethod(K = K,
                                openMP.core.num = ifelse(!is.null(openMP.core.num), openMP.core.num, 1))
  exp$snmf.method <- fit(m = exp$snmf.method, dat)


  ## tess3
  message("Run of tess3")
  exp$tess3r <- tess3r::tess3Main(X = NULL,
                                  XProba = XBin,
                                  coord = dat$coord,
                                  K = K,
                                  ploidy = ploidy,
                                  lambda = 1.0,
                                  W = dat$W,
                                  method = "projected.ls",
                                  max.iteration = 200,
                                  tolerance = 1e-5,
                                  openMP.core.num = openMP.core.num,
                                  Q.init = NULL,
                                  mask = 0.0,
                                  copy = FALSE,
                                  algo.copy = FALSE,
                                  verbose = TRUE,
                                  o wnly.ancestry = TRUE)


  ## save exp
  save_expr(exp, "tess3r_1000G.rds")


#+end_src
***** DONE Résultats
CLOSED: [2017-09-06 mer. 09:24]
:LOGBOOK:
- State "DONE"       from              [2017-09-06 mer. 09:24]
:END:
#+NAME: code:tess3r_1000G_res
#+CAPTION: Dépend de [[code:tess3r_1000G]]
#+begin_src R 
  exp <- readRDS("./OUTPUT/Expr/tess3_1000G.rds")
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.sample.rds")
  indiv <- dat$indiv

  df.res <- tibble()


  pops <- list()
  pops[["EU"]] <- c("TSI", "GBR")
  pops[["AFAM"]] <- c("ASW")
  pops[["AF"]] <- c("YRI", "LWK")
  pops[["AF_East"]] <- c("LWK")
  pops[["AF_West"]] <- c("YRI")

  ## tess3
  cluster.mean <- list()
  Q <- exp$tess3r$Q
  for (n in names(pops)) {
    cluster.mean[[n]] <- apply(Q[indiv$pop %in% pops[[n]],], 2, mean)
  }
  df.res <- as_tibble(cluster.mean) %>%
    mutate(method = "tess3") %>%
    rbind(df.res)

  ## snmf
  cluster.mean <- list()
  Q <- exp$snmf.method$Q
  for (n in names(pops)) {
    cluster.mean[[n]] <- apply(Q[indiv$pop %in% pops[[n]],], 2, mean)
  }
  df.res <- as_tibble(cluster.mean) %>%
    mutate(method = "snmf") %>%
    rbind(df.res)

  df.res
#+end_src

#+RESULTS:
#+begin_example
  # A tibble: 6 x 6
             EU       AFAM          AF     AF_East      AF_West method
          <dbl>      <dbl>       <dbl>       <dbl>        <dbl>  <chr>
  1 0.989908389 0.22213109 0.005763050 0.010570104 1.356584e-03   snmf
  2 0.002622910 0.68385885 0.580945529 0.177235864 9.510127e-01   snmf
  3 0.007468701 0.09401008 0.413291396 0.812194030 4.763065e-02   snmf
  4 0.013114647 0.51804568 0.516530277 0.325146852 6.919651e-01  tess3
  5 0.975247418 0.21433237 0.000639551 0.001319068 1.666043e-05  tess3
  6 0.011637935 0.26762196 0.482830172 0.673534080 3.080183e-01  tess3
#+end_example
*** Application à des données Arabidopsis Thaliana

Nous avons utilisé l'algorithme APLS pour étudier la structure génétique de
population spatiale et effectuer un balayage du génome pour les allèles
adaptatifs dans des écotypes européens de l'espèce végétale /A. thaliana/. Le
critère de validation croisée diminue rapidement pour $K = 1$ à $K = 3$ nombre
de clusters, indiquant qu'il y a trois clusters génétiques principaux en Europe,
correspondant aux régions géographiques d'Europe occidentale, d'Europe centrale
et orientale et de Scandinavie septentrionale. Pour un nombre de cluster $K$
supérieur à quatre, les valeurs du critère de validation croisée diminue de
manière plus lente, ce qui indique qu'une sous-structure subtile résultant de
processus historiques complexes d'isolement par distance pourrait également être
détectée (Figure ref:fig:tess3:at:param). Le variogramme spatial donne une
echelle spatial approximative de $\sigma = 150$ km (Figure
ref:fig:tess3:at:param). La figure ref:fig:tess3:at:map affiche l'estimation de
ma matrice $\Q$ interpolée sur une carte géographique d'Europe pour six cluster
génétique. L'estimation des coefficients de métissage fournit une preuve
claire du regroupement des écotypes dans des groupes génétiques spatialement
homogènes.

#+NAME: code:tess3:at:params
#+CAPTION: Dépend de [[code:tess3_AT_params]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/ :results silent
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_AT_params_plot.rds")

  ThesisRpackage::Plots_export_tikz_pdf(pl,
                                        basename.output = "tess3_AT_params",
                                        env = MaTheseR.params,
                                        height = 0.4 *  MaTheseR.params$textheightinch,
                                        width = MaTheseR.params$textwidthinch)
#+end_src
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_params.pdf}
\caption{{\bf Choix de $\sigma$ et $K$ pour l'algorithme APLS}. A) Variogramme
  empirique pour les données {\it A. thaliana}. La ligne verticale rouge montre
  la valeur de l'échelle géographique choisie, $\sigma = 1.5$. B) Erreur de
  validation croisée en fonction du nombre de clusters génétiques, $K$. La
  ligne verticale rouge montre le nombre de clusters génétiques choisi, $K=6$.}
\label{fig:tess3:at:param}
\end{figure}
#+END_EXPORT

#+NAME: code:tess3:at:map
#+CAPTION: Dépend de [[code:tess3_AT_map]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_AT_map_plor.rds")

  ThesisRpackage::Plots_export_pdf(pl,
                                   basename.output = "tess3_AT_map",
                                   env = MaTheseR.params,
                                   width = MaTheseR.params$textheightinch,
                                   height = MaTheseR.params$textwidthinch)
#+end_src
#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_map.pdf}
\caption{{\bf {\it A. thaliana} coefficients de métissage}. Estimation des
  coefficients de métissage calculée par l'algorithme APLS avec $K = 6$ clusters
  génétiques et $\sigma = 1.5$ pour le paramètre d'échelle géographiques. A)
  Carte géographique des coefficients de métissage. B) Barplot des coefficients
  de métissage.}
\label{fig:tess3:at:map}
\end{sidewaysfigure}
#+END_EXPORT

Les tests basés sur la statistique $\Fst$ ont été appliqués à l'ensemble de 214k
SNP pour détecter les locus sous sélection naturelle dans le génome de l'espèce
/A.thaliana/. /A. thaliana/ se trouve dans une large variété d'habitats, et
l'adaptation locale à l'environnement est reconnue comme étant pression
importante qui façonner la diversité génétique dans l'espace
cite:Hancock2011,Fournier-Level2011. L'algorithme APLS a été exécuté sur les
1095 écotypes européennes de /A. thaliana/ avec 6 de clusters génétique et 1,5
pour le paramètre d'échelle spatiale. En utilisant l'algorithme
Benjamini-Hochberg pour contrôler le FDR à $1 \%$, le programme a produit une
liste de 12 701 SNP candidats. Les 100 meilleurs candidats inclus des SNPs dans
les gènes liés à la floraison SHORT VEGETATIVE PHASE (SVP), COP1-interacting
protein 4.1 (CIP4.1) et FRIGIDA (FRI) ($p\text{-valeur} < 10^{-300}$). Ces gènes
ont été détectés par des analyses antérieures de la sélection sur cet ensemble
de données cite:Horton_2012. Nous avons réalisé une analyse d'enrichissement en
ontologie des gènes en utilisant AmiGO afin d'évaluer quelles fonctions
biologiques pourraient être impliquées dans l'adaptation locale en Europe. Nous
avons trouvé une sur-représentation significative des gènes impliqués dans les
processus cellulaires ($1.06$ fois plus que l'attendu, et une \pvalue égale à
$0.0215$ après correction de Bonferonni).

#+NAME: code:tess3:at:manhattanplot
#+CAPTION: Dépend de [[code:tess3_AT_manhattan]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()

  pl <- readRDS("./OUTPUT/Expr/tess3_AT_manhattan_plot.rds")

  ThesisRpackage::Plots_export_png(pl,
                                   basename.output = "tess3_AT_manhattanplot",
                                   env = MaTheseR.params,
                                   width = MaTheseR.params$textheightinch,
                                   height = MaTheseR.params$textwidthinch,
                                   res = 600)
#+end_src
#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_manhattanplot.png}
\caption{{\bf Détection de locus sous adaptation locale sur des écotypes
    européennes de \bf {\it A. thaliana}}. Manhattan plot de
  $-\log(p\text{-value})$. Les \pvalues int été calculées à partir de la
  structure de la population estimée par l'algorithme APLS avec $K = 6$ clusters
  génétiques et $ \sigma = 1,5 $ pour le paramètre d'échelle géographique.}
\label{fig:tess3:at:manhattanplot}
\end{sidewaysfigure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** TODO Données AthalianaGegMapLines
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
****** TODO Get dataset
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 19:37]
:END:
#+NAME: code:tess3:AthalianaRegMapLines
#+CAPTION: Dépend de 
#+begin_src R 

#+end_src
****** TODO Vep annotation
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 19:37]
:END:
#+NAME: code:
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
                                          # Setup

                                          # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # personal packages
                                          #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")


  library(data.table)

  ################################################################################
  # load data
  at.dir <- "./Data/AthalianaGegMapLines/")

  TAIR9.snps <- t(fread(
    paste0(at.dir,"call_method_75/call_method_75_TAIR9.csv"), sep = ",",
    header=TRUE, skip = 1, data.table = FALSE))
  aux <- apply(TAIR9.snps[-(1:2),], 2, unique)
  # find col0, the reference genome
  call_method_75_info <- fread(
    paste0(at.dir,"call_method_75/call_method_75_info.tsv"))
  col0 <- call_method_75_info[grepl("Col", call_method_75_info$nativename)]
  ancestral.allele <- TAIR9.snps[as.character(col0$ecotype_id),]
  # find variants allele
  variant.allele <- sapply(seq_along(ancestral.allele), function(i) aux[which(!(aux[,i] %in% ancestral.allele[i])),i])
  alleles <- data.frame(variant.allele = variant.allele, ancestral.allele = ancestral.allele, chr = as.numeric(TAIR9.snps[1,]), pos = as.numeric(TAIR9.snps[2,]))
  # load data for colnames
  data.file <-
    paste0(data.dir, "AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData")
  load(data.file)

  ################################################################################
  # vep
  vep.input <- alleles %>% mutate(start = pos, end = pos, allele = paste0(ancestral.allele,"/",variant.allele), strand = NA, identifier = colnames(call_method_75_TAIR9.europe$X)) %>% select(chr, pos, start, end, allele, strand, identifier)

  # check if no error
  head(vep.input)
  tail(vep.input)

  .Options$vep = "variant_effect_predictor.pl"
  runVEP <- function(vep.input, vep = .Options$vep) {
    input <- tempfile()
    write.table(vep.input, file = input, row.names = FALSE, col.names = FALSE, na = "", quote = FALSE)
    output <- tempfile()
    cmd <- paste0("variant_effect_predictor.pl -i ", input, " -o ", output, " --cache --dir ../Data/vep/ --species arabidopsis_thaliana --format ensembl --genomes --cache_version 31")
    system(cmd)
    vep.output <- data.table::fread(output, skip = "#Uploaded_variation", data.table = FALSE, na.strings = "-")
    return(vep.output)
  }

  vep.res <- runVEP(vep.input)

  saveRDS(vep.res, "./OUTPUT/Expr/tess3_snpsTAIR9vepTAIR10.rds")

#+end_src
***** DONE Choix des params
CLOSED: [2017-09-11 lun. 19:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:09]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
****** DONE Variogram
CLOSED: [2017-09-11 lun. 18:58]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:58]
- State "TODO"       from              [2017-09-11 lun. 18:57]
:END:
#+NAME: code:tess3_AT_vario
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
  # Setup

  # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

  # personal packages
  #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")

  # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  # variogram
  vario.gen <- CalculateEmpiricalGenSemivariogram(call_method_75_TAIR9.europe$X, 1,  call_method_75_TAIR9.europe$coord)
  saveRDS(vario.gen, "./OUTPUT/Expr/tess3_AT_vario.rds")
#+end_src
****** DONE K selection
CLOSED: [2017-09-11 lun. 19:04]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:04]
- State "TODO"       from              [2017-09-11 lun. 18:58]
:END:
#+NAME: code:tess3_AT_K
#+CAPTION: Dépend de 
#+begin_src R 
    ################################################################################
    # Setup

    # Install if not function
    pkgTest <- function(x)
    {
      if (!require(x,character.only = TRUE))
      {
        install.packages(x,dep=TRUE)
        if(!require(x,character.only = TRUE)) stop("Package not found")
      }
    }


    pkgTest("raster")
    pkgTest("ggplot2")
    pkgTest("reshape2")
    pkgTest("dplyr")
    pkgTest("gridExtra")
    pkgTest("cowplot")
    pkgTest("DescTools")
    pkgTest("doParallel")
    pkgTest("foreach")
    pkgTest("devtools")
    pkgTest("permute")
    pkgTest("crayon")

    # personal packages
    #devtools::install_github("BioShock38/TESS3_encho_sen@master")
    require("tess3r")

  # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  XBin <- matrix(0.0, nrow(call_method_75_TAIR9.europe$X),
                 ncol(call_method_75_TAIR9.europe$X) * 2)
  X2XBin(call_method_75_TAIR9.europe$X, 1, XBin)
  coord <- call_method_75_TAIR9.europe$coord
  rm(call_method_75_TAIR9.europe) # free memory
  gc()

  # Run tess3
  cat(green(paste("== Runing TESS3 \n")))
  tess3.obj <- tess3(X = NULL,
                           XBin = XBin,
                           coord = coord,
                           K = 1:10,
                           ploidy = 1,
                           lambda = 1.0,
                           rep = 5,
                           W = NULL,
                           method = "MCPA",
                           max.iteration = 200,
                           tolerance = 1e-05,
                           openMP.core.num = 16,
                           Q.init = NULL,
                           mask = 0.05,
                           keep = "best",
                           copy = FALSE,
                           algo.copy = TRUE)


  cat(green(paste("== Save result\n")))
  saveRDS(tess3.obj, "./OUTPUT/Expr/tess3_AT_K110,rep5.rds"))

  # keep only rmse
  err.df <- data.frame()
  for (t in tess3.obj) {
    err.df <- rbind(err.df,
      data.frame(rmse = t$rmse,
                  crossvalid.rmse = t$crossvalid.rmse,
                  crossentropy = t$crossentropy,
                  crossvalid.crossentropy = t$crossvalid.crossentropy,
                  K = t$K,
                  rep = seq_along(t$rmse)))

  }
  saveRDS(err.df, "./OUTPUT/Expr/tess3_AT_K.rds")
#+end_src
****** DONE Plot
CLOSED: [2017-09-11 lun. 19:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:09]
- State "TODO"       from              [2017-09-11 lun. 18:57]
:END:
#+NAME: code:tess3_AT_params
#+CAPTION: Dépend de [[code:tess3_AT_K]] [[code:tess3_AT_vario]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env


  ## get variogram
  vario.gen <- readRDS("./OUTPUT/Expr/tess3_AT_vario.rds")
  err.df <- readRDS( "./OUTPUT/Expr/tess3_AT_K.rds")

  variogram.pl <- ggplot(vario.gen, aes(x = h, y = semi.variance, size = size)) +
    geom_point(shape = 1) +
    geom_vline(xintercept = 1.5, colour = "red") +
    labs(y = "Variogramme",
         x = "\\'Echelle g\\'eographique $\\sigma$ ($100$ km)") +
    theme_gray(base_size = 12) +
    scale_size_continuous(range = c(1,3)) +
    guides(size = guide_legend(title = "Bin size", nrow = 3)) +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.6,0.25)) +
    scale_shape_discrete(solid = FALSE)



  ################################################################################
                                          # K selection
  toplot <- err.df %>% group_by(K) %>%
    summarise(med = median(rmse), min = min(rmse), max = max(rmse),
              mean = mean(rmse), sd = sd(rmse), se = sd/sqrt(length(rmse)))

  selection.pl <- ggplot(toplot) +
    geom_point(aes(x = as.factor(K), y = med)) +
    geom_line(aes(x = K, y = med)) +
                                          #geom_errorbar(aes(x = K, y = med,
                                          #                  ymin=min, ymax=max), width=.1) +
    labs(y = "Erreur de validation crois\\'ee", x = "Nombre de clusters g\\'en\\'etiques $K$") +
    theme_gray() +
    theme(legend.position = "none") +
    MaTheseR.params$gtheme +
    geom_vline(xintercept = 6, colour = "red")



  pl <- cowplot::plot_grid(variogram.pl, selection.pl, nrow = 1, labels = c("A", "B"))

  save_plot_png(pl, "tess3_AT_params.png")

  save_expr(pl, "tess3_AT_params_plot.rds")

#+end_src

#+RESULTS: code:tess3_AT_params
: Warning message:
: Removed 11 rows containing missing values (geom_point).
[[./OUTPUT/Rplots/tess3_AT_params.png]]
: [[./OUTPUT/Rplots/tess3_AT_params.pdf.png]]

***** DONE Run de tess3r avec K = 6 et sigma = 1.5
CLOSED: [2017-09-11 lun. 19:15]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:15]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_run
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
                                          # Setup

                                          # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # personal packages
                                          #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")

                                          # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  # compute W
  W <- ComputeHeatKernelWeight(call_method_75_TAIR9.europe$coord,
                               sigma = 1.5)

  # Run tess3
  cat(green(paste("== Runing TESS3 \n")))
  tess3Main.obj <- tess3Main(X = call_method_75_TAIR9.europe$X,
                           XBin = NULL,
                           coord = call_method_75_TAIR9.europe$coord,
                           K = 6,
                           ploidy = 1,
                           lambda = 1.0,
                           W = W,
                           method = "MCPA",
                           max.iteration = 200,
                           tolerance = 1e-05,
                           openMP.core.num = 16)

  ## saving result
  cat(green(paste("== Save result\n")))
  saveRDS(tess3Main.obj, "./OUTPUT/Expr/tess3_AT_tess3r.rds")

#+end_src
***** DONE Map et barplot
CLOSED: [2017-09-11 lun. 19:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:35]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_map
#+CAPTION: Dépend de [[code:tess3_AT_run]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## result
  tess3Main.obj <- readRDS("./OUTPUT/Expr/tess3_AT_tess3r.rds")

  ################################################################################
  ## load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)
  coord <- call_method_75_TAIR9.europe$coord
  rm(call_method_75_TAIR9.europe)

  ################################################################################
  ## Q
  Q <- tess3Main.obj$Q
  ## northen cluster
  id.northers <- which(apply(Q, 1, which.max) == 2)
  Q.notnorthers <- Q[!(1:nrow(Q) %in% id.northers),]
  coord.notnorthers <- coord[!(1:nrow(Q) %in% id.northers),]
  id <- sort(coord.notnorthers[,1], index.return = TRUE)
  Q.ordered <- rbind(Q[id.northers,], Q.notnorthers[id$ix,])

  ################################################################################
  ## Color palette
  gg_color_hue <- function(n) {
    hues = seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 100)[1:n]
  }
  n = 6
  cols = gg_color_hue(n)

  col.palette = list(
    colorRampPalette(c("white",cols[1]))(9)[5:9],
    colorRampPalette(c("white",cols[2]))(9)[5:9],
    colorRampPalette(c("white",cols[3]))(9)[5:9],
    colorRampPalette(c("white",cols[4]))(9)[5:9],
    colorRampPalette(c("white",cols[5]))(9)[5:9],
    colorRampPalette(c("white",cols[6]))(9)[5:9]
  )
  ## plot(rep(1,5),col = col.palette[[2]],pch=19,cex=3)

  ################################################################################
  ## Interpolation
  require(sp)
  require(raster)
  require(rworldmap)
  require(rgeos)
  require(rasterVis)
  require(fields)

  ## param
  window <- c(-16,42,33,67)
  resolution <- c(300, 300)
  theta <- 10

  ## get europe
  newmap <- getMap(resolution = "low")
  CP <- as(extent(window), "SpatialPolygons")
  europe <- gIntersection(newmap, CP)
  ## Or
  ## europe <- crop(newmap, extent(window))
  plot(europe)

  ## make grid
  raster.grid <- raster(extent(window), ncol = resolution[1], nrow = resolution[2], vals = 1)
  ## plot(grid)

  ## interpolation with krig
  interpol <- stack()
  for (j in seq_along(Q[1,])) {
    model <- Krig(coord, Q[,j], theta = theta)
    interpol <- stack(interpolate(raster.grid, model), interpol)
  }
  interpol <- mask(interpol, europe)
  ## plot(interpol)
  ## levelplot(interpol)
  ## plot with tess3r package

  ## plot(Q = Q,
  ##      coord = coord, plot.type = "max",
  ##      resolution = c(300, 300), window = c(-16,42,33,67), background = TRUE,
  ##      raster.filename = NULL, interpolation.function = kriging(), col = NULL,
  ##      col.palette = col.palette, map = TRUE, palette.step = 9,
  ##      axes = FALSE, xlab = '', ylab = '', cex = 0.25)


  ################################################################################
                                          # Plot map

  toplot <- data.frame(rasterToPoints(interpol))
  ## compute breaks
  col.breaks <- apply(toplot[3:8], 2,
                      function(c) seq(min(c),
                                      max(c),
                                      length.out = length(col.palette[[1]]) + 1))
  ## compute color for each tile
  ##                                         color <- function(coef, col.palette, col.breaks) {
  ##                                           max.i <- which.max(coef)
  ##                                           c <- max(which(col.breaks[,max.i] - as.numeric(coef[max.i]) >= 0)[1] - 1,1)
  ##                                           return(col.palette[[max.i]][c])
  ##                                           # return(c)
  ##                                         }
  ##                                         toplot$color <- apply(toplot[3:8], 1,
  ##                                                               function(r) color(r, col.palette, col.breaks))

  ## ## with removed artefact
  color.rm.art <- function(r, col.palette, col.breaks) {
    coef <- r[3:8]
    pos <- r[1:2]
    if (pos[1] > 28 && pos[2] < 46) {
      max.i <- 5
    } else {
      max.i <- which.max(coef)
    }
    c <- max(which(col.breaks[,max.i] - as.numeric(coef[max.i]) >= 0)[1] - 1,1)
    return(col.palette[[max.i]][c])
                                          # return(c)
  }
  toplot$color <- apply(toplot[1:8], 1,
                        function(r) color.rm.art(r, col.palette, col.breaks))

  mappl <- ggplot() +
    geom_tile(data = toplot, aes(x = x, y = y, fill = color)) +
    scale_fill_identity() +
    geom_path(data = europe, aes(x = long, y = lat, group = group)) +
    coord_equal() +
    geom_point(data = as.data.frame(coord), aes(x = long, y = lat), size = 0.1) +
    MaTheseR.params$gtheme +
    xlab("Longitude (°E)") +
    ylab("Latitude (°N)")

  ################################################################################
  ## barplot
  toplot <- data.frame(Q.ordered, index = seq_along(Q.ordered[,1])) %>% reshape2::melt(id = "index")
  brplot <- ggplot(toplot, aes(x = index, y = value)) +
    geom_bar(stat = "identity", aes(color = variable)) +
    MaTheseR.params$gtheme +
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          panel.background = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
    xlab("Individual") +
    ylab("Admixture\n\ coefficient (Q)") +
    scale_y_continuous(breaks = c(0.0,0.5,1.0)) +
    scale_color_manual(values = cols)

  ################################################################################
  ## Plot


  pl <- cowplot::plot_grid(mappl, brplot, ncol = 1, labels = c("A", "B"), rel_heights = c(3,1), vjust = c(1.5, -0.5))
  save_plot_png(pl, "tess3_AT_map.png")

  save_expr(pl, "tess3_AT_map_plor.rds")


#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3_AT_map.png]]

***** DONE Manhattan plot
CLOSED: [2017-09-11 lun. 19:44]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:44]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_manhattan
#+CAPTION: Dépend de [[code:tess3_AT_run]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## result
  tess3Main.obj <- readRDS("./OUTPUT/Expr/tess3_AT_tess3r.rds")
  vep.res <-readRDS("./OUTPUT/Expr/tess3_snpsTAIR9vepTAIR10.rds")

  ################################################################################
                                          # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)
  coord <- call_method_75_TAIR9.europe$coord

  ################################################################################
  ## flowering genes
  ## search on http://plants.ensembl.org/
  ## SHORT VEGETATIVE PHASE (SVP), a MADS box gene that negatively regulates the transition to flowering (Differentiating Fennoscandia and Eastern Europe/Russia)
  flowering.gene <- vep.res %>% dplyr::filter(Gene == "AT2G22540") %>% dplyr::mutate(label = "SVP")
  ## COP1-interacting protein 4.1 (CIP4.1)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT4G00930") %>% dplyr::mutate(label = "CIP4.1"))
  ## FRIGIDA (FRI)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT4G00650") %>% dplyr::mutate(label = "FRI"))
  ## FLOWERING LOCUS C (FLC),
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT5G10140") %>% dplyr::mutate(label = "FLC"))
  ## DELAY OF GERMINATION 1 (DOG1)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT5G45830") %>% dplyr::mutate(label = "DOG1"))


  ################################################################################
  ## Plot TESS3 manhattanplot
  toplot <- data.frame(fst = tess3Main.obj$Fst,
                       pvalue = tess3Main.obj$pvalue,
                       call_method_75_TAIR9.europe$locus.coord,
                       index = seq_along(tess3Main.obj$Fst)) %>%
    dplyr::mutate(Location = paste0(Chromosome,":",Positions))

  alert <- merge(toplot, flowering.gene, by = c("Location"))
  label <- alert %>% group_by(Gene) %>% filter(row_number(index) == 1)
  label$index[2] = label$index[2] + 8000
  label$index[3] = label$index[3] - 8000
  ## plot with annotation
  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue),
                           color = as.factor(Chromosome), fill = Chromosome)) +
    geom_point() +
    labs(y = "-log(pvalue)", x = "locus index") +
    theme_gray() +
    theme(legend.position = "none") +
    geom_point(data = alert, colour = "red") +
    geom_text(data = label, aes(x = index, y = 0, label = label), vjust = 1.8, check_overlap = FALSE)

  ## plot without annotation
  toplot <- toplot %>% dplyr::filter(pvalue != 0.0)
  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue),
                           color = as.factor(Chromosome), fill = Chromosome)) +
    geom_point(size = 0.25) +
    labs(y = "-log(pvalue)", x = "locus index") +
    scale_y_continuous(limits = c(0,510)) +
    scale_x_continuous(breaks = sapply(1:5, function(i) mean(toplot[toplot$Chromosome == i, ]$index)),
                       labels = 1:5) +
    xlab("Chromosome") +
    ylab("log(p-value)") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    scale_color_manual(values = c(Article2.env$cbPalette[6], Article2.env$cbPalette[2],
                                  Article2.env$cbPalette[6], Article2.env$cbPalette[2],
                                  Article2.env$cbPalette[6]))


  ## rm data
  rm(call_method_75_TAIR9.europe)
  save_plot_png(pl, "tess3_AT_manhattanplot.png")

  save_expr(pl, "tess3_AT_manhattan_plot.rds")
#+end_src

#+RESULTS: code:tess3_AT_manhattan
[[./OUTPUT/Rplots/tess3_AT_manhattanplot.png]]
** Discussion
L'inclusion de l'information géographique dans l'inférence des relations
ancestrales entre les organismes est un objectif majeur des études en génétique
des populations cite:Malecot1948,Epperson_1996,Cavalli-Sforza1994. En supposant
que des individus géographiquement proches sont plus susceptibles de partager
l'ascendance que des individus dans des sites éloignés, nous avons introduit
deux nouveaux algorithmes pour estimer les proportions d'ascendance à l'aide
d'informations géographiques et génétique. Sur la base des problèmes de moindres
carrés, les nouveaux algorithmes combinent des approches de factorisation
matricielle et de statistiques spatiales pour fournir des estimations précises
des coefficients de métissage individuels et des fréquences d'allèle dans les
clusters génétique ainsi estimés. Les deux méthodes partagent de nombreuses
similitudes, mais elles diffèrent dans les approximations qu'elles font pour
diminuer la complexité algorithmique. Plus précisément, l'algorithme AQP est
repose sur un problème d'optimisation quadratique alors que l'algorithme APLS
lève les contrainte des problème d'optimisation pour les transformer en problème
des moindres carrés. La complexité algorithmique de l'algorithme APLS augmente
linéairement avec le nombre d'individus dans l'échantillon en ayant la même
précision statistique que l'algorithme AQP plus lent.

Pour mesurer le bénéfice de l'utilisation d'algorithmes spatiaux, nous avons
comparé les erreurs statistiques observées pour les algorithmes spatiaux avec
celles observées pour les algorithmes non spatiaux. Dans nos expériences
numériques les erreurs des méthodes spatiales sont inférieures à celles
observées avec des méthodes non spatiales, et les algorithmes spatiaux ont
permis de détecter une structure de population plus subtile. En outre, nous
avons mis en place un test de detection de la selection basés sur les
estimations spatiales des matrices $\Q$ et $\G$ cite:Martins_2016, et nous avons
observé que ces tests avaient rejette la neutralité des locus avec plus de
précision que ceux basés sur des approches non spatiales. Ainsi, l'information
spatiale a contribué à améliorer la détection des signatures de balayages
sélectifs survenant dans des populations sources avant les événements de
mélange. Nous avons appliqué les tests de neutralité pour effectuer un balayage
du génome pour la sélection dans les écotypes européens de l'espèce végétale
/A.thaliana/. Le scan du génome a confirmé la preuve de la sélection des gènes
liés à la floraison /CIP4.1/, /FRI/ et /DOG1/ différenciant la Fenno-Scandinavie du
nord-ouest de l'Europe cite:Horton_2012.

L'estimation des coefficients de métissage en utilisant des algorithmes rapides
qui étendent des approches non spatiales telles que, =structure=, a été
intensément discutée au cours des dernières années cite:Wollstein2015. Dans ces
améliorations, les approches spatiales ont reçu moins d'attention que les
approches non spatiales. Dans cette étude, nous avons présenté un cadre
conceptuelle permettant de développer des méthodes rapide d'estimation
d'estimation de l'ascendance spatiale. Ces méthodes rapide sont implémenté en de
la package {\ tt tess3r} qui propose pipeline intégré pour l'estimation et la
visualisation de la structure génétique de la population et pour la recherche de
locus responsable de l'adaptation locale. La complexité algorithmique de nos
algorithmes permet à leurs utilisateurs d'analyser des échantillons comprenant
des centaines à des milliers d'individus. Par exemple, l'analyse de plus d'un
millier de génotypes /A.thaliana/, chacun incluant plus de 210k SNP, n'a pris
que quelques minutes à l'aide d'un seul CPU.

* Algorithmes d'estimation pour les modèles de régression à facteurs latents
** Introduction
Au cours de la dernière décennie, des études d'association à grande échelle ont
été utilisées pour identifier des gènes candidats associés à une maladie
particulière ou un trait phénotypique d'intérêt. Selon le type des marqueurs
moléculaires examinés dans les génomes ou dans les cellules, plusieurs
catégories d'étude d'association ont été menées pour détecter des corrélations
significatives de entre les marqueurs et le phénotype. Par exemple, les études
d'association à l'échelle du génome (GWAS genome-wide association studies) se
concentrent sur des polymorphismes à un seul nucléotide (SNP pour
single-nucleotide polymorphism) en examinant des variants génétiques chez
différents individus cite:Balding_2006. Les GWAS ont été étendus à des études
d'association à l'échelle de l'épigénome (EWAS epigenome-wide association
studies) qui mesurent les niveaux de méthylation de l'ADN chez différents
individus pour des associations entre la variation épigénétique et des
phénotypes cite:Rakyan_2011. Des approches similaires ont été appliquées à la
caractérisation de la variation observée dans l'ARN par rapport à différents
environnements, traitements médicaux, phénotypes ou maladies cite:Slonim_2002.
D'autres exemples d'études d'association incluent des études d'association
génétique-environnement (GEAS) dans lesquelles les locus sont testés
pour leur corrélation avec des gradients écologiques afin de détecter les
signatures de sélection naturelle cite:rellstab15_pract_guide_to_envir_assoc.
En un court laps de temps, les études d'association ont permis des progrès
considérables dans l'identification des variants génétiques qui confèrent une
susceptibilité aux maladies ainsi qu'une compréhension plus approfondie de
l'évolution des génomes en réponse à la sélection naturelle.

*** Les facteurs de confusions
<<sec:fact_conf>>

Basée sur l'analyse de la corrélation, les études d'association sont confrontées
aux problèmes des facteurs de confusion et de la causalité. En effet lorsque
l'on détecte de la corrélation entre deux variables, cela n'implique pas
nécessairement qu'il y a lien de causalité entre celles-ci. Le lien de causalité
entre les deux variables peut être bien plus complexe et notamment impliquer des
liens avec d'autres variables non observées. En particulier, il est possible de
conclure à une association entre deux variables alors qu'elles sont associé à
une autre variable non considérée dans l'étude. On appelle alors la variable non
observée un facteur de confusion. La figure [[graph:conf_factor]] illustre cette
situation. Le problème des facteurs de confusion est connue depuis longtemps. En
effet, on le retrouve déjà dans l'ouvrage /The Design of Experiment/ de Ronald
Fisher qui introduisit entre autre le concept de d'hypothèse nulle en
statistique cite:fisher1937design. Dans cette thèse nous nous intéressons aux
études d'association à très grande échelle. Nous avons d'une part des
observations de $\Ycol$ variables sur $\Yrow$ individus rassemblées dans une
matrice $\Y$ de taille $\Yrow \times \Ycol$, et en général $\Ycol$ est très
grand devant $\Yrow$. Nous avons d'autre part l'observation d'une variable sur
les mêmes $\Xrow$ individus que l'on rassemble dans une matrice $\X$, de taille
$\Xrow \times 1$. L'objectif est alors de trouver parmi les $\Ycol$ variables
$\Y$ celles qui sont associées à $\X$. Nous supposons de plus qu'il existe un
certain nombre de variables non observées qui permettent d'expliquer les
variations de $\Y$. Ces variables non observées, que l'on appellera variables
latentes, sont potentiellement des facteurs de confusion pour l'étude
d'association entre $\Y$ et $\X$. Les variables latentes sont potentiellement
corrélées à $\X$, il faut donc les prendre en compte dans l'étude d'association.

#+NAME: code:conf_factor
#+BEGIN_SRC dot :file Figures/conf_factor.png :exports results :eval no-export
  graph {
    graph [fontname = "serif"];
    node [fontname = "serif"];
    edge [fontname = "serif"];
    U -- Y;
    U -- X;
  }
#+END_SRC

#+NAME: graph:conf_factor
#+CAPTION: Graphe de corrélation entre la variable $\Y$ la variable $\X$ et le facteur de confusion $\U$. Dans cette situation si on ne prend pas en compte $\U$ dans l'étude d'association alors $\X$ et $\Y$ apparaitront comme étant associées.
#+ATTR_LATEX: :width 5cm
#+RESULTS: code:conf_factor
[[file:Figures/conf_factor.png]]

*** Simulation numérique d'une association avec facteurs de confusions
<<sec:simu_ex>>

Dans cette partie nous proposons de montrer l'intérêt de prendre en
considération les facteurs de confusion dans les études d'association par une
simulations numérique. Pour cela nous simulons une variable $\X$ et une variable
latente de sorte que le coefficient de corrélation entre ces deux variables soit
égale à $0.6$. Nous simulons ensuite une matrice de bruit gaussien de moyenne
nulle et variance égale à 1, noté $\E$. La matrice des effets de la variable
latente sur $\Y$ est aussi simulée à l'aide de la loi normale. Nous notons la
matrice des effets latents $\V$. La matrice des effets de $\X$ sur $\Y$, notée
$\B$, est simulée de sorte que $1 \%$ de ses lignes soient non nulles. Enfin, la
matrice $\Y$ est calculée telle que
\begin{equation} 
\Y = \U \V^{T} + \X \B^{T} + \E. 
\end{equation} 
Cette simulation correspond à une situation où $1 \%$ des colonnes de $\Y$ sont
associé avec $\X$ et la variable latente est bien facteur de confusion pour
cette étude d'association car $\U$ est corrélée avec $\X$. 

Afin de détecter les variables expliquées associés à la variable explicative,
nous réalisons une régression linéaire de $\Y$ par $\X$. Nous effectuons une
seconde régression linéaire avec cette fois la variable $\X$ ainsi que la
variable latente $\U$ comme variables explicatives de la régression. Nous
réalisons un test de Student pour tester la nullité des coefficients associés à
la variable $\X$ dans chacune des deux régressions. Quand on ne prend pas en
compte la variable latente plus de $40 \%$ des \pvalues sont inférieures à
$10^{-15}$, alors que quand on prend en compte les facteurs latents la
distribution des \pvalues est bien uniforme comme on s'y attend (Figure
ref:fig:simu_intro). En effet, on s'attend à une distribution uniforme des
\pvaleur car la majorité des colonnes de $\Y$ ne sont pas associées avec la
variable $\X$, seulement 1\% par simulation. Dans le cas de cette simulation il
est impossible de ne pas prendre en compte la variable latente, sans celle-ci on
détecte presque la moitié des colonnes de $\Y$ comme étant associées à $\X$.

#+NAME: code:confusion_plot
#+CAPTION: 
#+begin_src R 
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(scales)

  dat <- ExpRsampler_generativeData(n = 200,
                                    p = 5000,
                                    K = 1,
                                    outlier.prop = 0.01,
                                    cs = c(0.6)) %>%
    ExpRmouline()

  ## lm
  lm.res <- method_lm() %>% ExpRmouline(dat)
  toplot <- data.frame(Régression = "Y ~ X",
                       pvalue = lm.res$pvalue)

  mean(toplot$pvalue < 1e-15)

  ## lm with U
  oracle.res <- method_oracle() %>% ExpRmouline(dat)


  ## qqplot
  toplot <- data.frame(Régression = "Y ~ X + U",
                       pvalue = oracle.res$pvalue) %>%
    rbind(toplot)
  toplot <- as_tibble(toplot)
  pl <- ggplot(toplot, aes(pvalue, fill = Régression)) +
    geom_histogram(position = "dodge", aes(y = (..count..)/sum(..count..))) +
    MaTheseR.params$gtheme +
    xlab("P-valeur") +
    ylab("Pourcentage") +
    scale_y_continuous(labels=percent)

  ThesisRpackage::Plots_export_pdf(pl,
                                   "simu_intro",
                                   MaTheseR.params,
                                   height = 0.3 * MaTheseR.params$textheightinch,
                                   width = MaTheseR.params$textwidthinch)
#+end_src

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/simu_intro.pdf}
\caption{Histogramme des \pvalues du test de nullité des coefficients
  de régression de la régression sans et avec le facteur de
  confusion.}
\label{fig:simu_intro}
\end{figure}
#+END_EXPORT

*** Méthodes de correction pour les facteurs latents
:LOGBOOK:
- Note taken on [2017-08-01 mar. 18:14] \\
  un exemple ici ?? lm, lm + PCA, lm + les facteurs latents comme dans stephens et
  2017 dans son intro,
:END:
Dans cette section, nous nous plaçons dans le cadre méthodologique des modèles
de régression linéaire. Il s'agit d'un cadre très utilisé en étude d'association
que nous pouvons formaliser de la façon suivante
\begin{equation}
\label{eq:statReg}
\Y_{j} = \X b_{j} + \E_{j}
\end{equation}
où $\Y_{j}$ est la matrice des observations de la variable d'indice $j$ pour
$\Yrow$ individus. Le coefficient $b_{j}$ représente l'effet de la variable $\X$
sur $\Y_{j}$. La matrice $\E_{j}$ est la matrice de l'erreur résiduelle. Il
arrive parfois que l'on fasse la régression dans l'autre sens, la régression
s'écrit alors
\begin{equation}
\label{eq:statRegRevers}
\X = \Y_{j} a_{j} + \E^{'}_{j},
\end{equation}
où $\a_{j}$ représente l'effet de $\Y_{j}$ sur $\X$. Dans la suite nous
discutons de régression uniquement dans le sens de l'équation eqref:eq:statReg.
L'objectif est de trouver les coefficients $b_{j}$ qui sont significativement
différents de zéro. Dans ce cas nous disons que $\Y_{j}$ est associée à $\X$.
Comme nous l'avons évoqué dans la partie précédente, avec cette approche il est
possible qu'une ou plusieurs variables latentes soient corrélées à la fois à
$\Y$ et à $\X$. Dans ce cas, si nous ne considérons pas les variables latentes
comme variables explicatives de la régression, nous détectons un grand nombre de
variables $\Y_{j}$ significativement corrélées à $\X$, comme nous l'avons
illustré par une simulation numérique dans la partie précédente. Nous allons
maintenant présenter différentes approches de correction des études
d'association pour les facteurs de confusion.

**** Estimation des facteurs latents a priori
Une première approche consiste à estimer les variables latentes en faisant une
analyse factorielle de $\Y$. On fait l'analyse factorielle a priori et sans
prendre en compte la variable $\X$. Les variables latentes sont ensuite ajoutées
au modèle de régression à coté des autres variables explicatives de sorte que
\begin{equation}
\Y_{j} = \X b_{j} + \bar{\U} \V_{j}^{T} + \E_{j}
\end{equation}
où $\bare{\U}$ est la matrice des variables latents calculée a priori et
$\V_{j}$ la matrice des effets des variables latentes sur $\Y_{j}$. Par exemple,
les méthodes EIGENSTRAT et Refactor calculent les variables latentes à l'aide de
l'analyse en composantes principales (ACP) de la matrice $\Y$
cite:Price_2006,Rahmani_2016.
**** Les modèles mixtes
Une autre approche de correction pour les facteurs de confusion est le modèle
mixte. Dans un tel modèle, on ajoute un effet aléatoire au modèle de la
régression
\begin{equation}
\Y_{j} = \X \B^{T} + \matr{\Gamma}_{j} + \E_{j},
\end{equation}
où $\matr{\Gamma}_{j}$ est la matrice des effets aléatoires à estimer. Dans les
modèles mixtes, on suppose de plus que la matrice de covariance de l'effet
aléatoire est connue. La matrice de covariance doit correspondre à la variance
du facteur de confusion, elle est en général calculée à partir de $\Y$. Les
modèles mixtes ont été largement utilisés pour les GWAS
cite:Kang_2008,Zhou_2014. Dans le cas des GWAS, l'effet aléatoire permet
d'expliquer la variation de $\Y_{j}$ qui est due à la structure de population.
Dans ce cas, la matrice de covariance est estimée a priori sur les données
génétiques.
**** Les modèles mixtes à facteurs latents (LFMM latent factor mixed model)
Nous introduisons maintenant les modèles mixtes à facteurs latents. Pour de tels
modèle, l'équation de régression peut s'écrire comme ceci :
\begin{equation}
\label{eq:glfmm}
\Y = \X \B^{T} + \U \V^{T} + \E,
\end{equation}
Dans cette équation $\U$ est la matrice des variables latentes et $\V$ est la
matrice des effets des facteurs latents. La différence majeure de LFMM avec les
autres modèles est qu'on ne suppose rien a priori sur les facteurs de confusion.
Dans les modèles dont nous avons parlés précédemment, on estime a priori les
variables latentes ou leur matrice de covariance. Dans LFMM l'estimation des
variables latentes $\U$ et des effets de la variable explicative $\B$ ce font en
même temps. Les matrice $\U$ et $\V$ permettent d'apprendre les variations
systématiques observée dans la matrice $\Y$ tandis que la matrice des effets
$\B$ permet d'apprendre l'effet de $\X$ sur certaines colonnes de $\Y$. Il
existe différentes méthodes pour estimer les paramètres de LFMM. On distingue
d'abord des approches qui reposent sur des algorithmes de Monte Carlo
cite:frichot13_testin_assoc_between_loci_envir,carvalho08_high_dimen_spars_factor_model.
Ces approches repose sur une modélisation bayésienne de LFMM qui permet
d'échantillonner les lois à posteriori des paramètres. L'avantage des méthodes
MCMC est qu'elles permettent d'estimer la variance du paramètre $\B$ grâce au
bootstrap bayésien cite:rubin1981bayesian; et de faire un test de
significativité statistique. Certaines approches reposent sur des algorithmes EM
(Expectation Maximisation)
cite:friguet09_factor_model_approac_to_multip,agarwal09_regres,zhou16_spars_multiv_factor_analy_regres.
Ces approches sont souvent plus rapides que les méthodes utilisant des
algorithmes de Monte Carlo. Enfin, d'autres approches reposent sur une
estimation des variables latentes à partir d'une transformation de $\Y$
cite:gerard2017unifying,wang2015confounder,article_Leek_Storey_2007. Cette
transformation a pour but de séparer la variation de $\Y$ expliquée par les
variables latentes de celle expliquée par $\X$. Parmi les méthodes reposant sur
une transformation des données, on distingue des autres les méthodes dites à
contrôles négatifs qui suppose connu un sous ensemble de colonnes de $\Y$ qui ne
sont pas associées avec $\X$. Les méthodes à contrôles négatifs utilisent ces
variables dîtes nulles pour estimer les variables latentes. L'estimation des
variables latentes pour corriger les études d'association est un problème très
vaste et aucune méthode ne s'est imposée comme étant le méthode référence.
*** Source de confusion                                          :noexport:
:LOGBOOK:
- Note taken on [2017-08-04 ven. 11:39] \\
  Je ferrais une expliation de la source de confusion pour chaque dataset !!
:END:
Les sources de confusion peuvent varier selon les différentes catégories
d'études d'association. Dans les GWAS et les GEAS, la confusion englobe des
différences systématiques dans l'ascendance génétique entre les individus
échantillonnés cite:Price_2006. Une autre source de confusion dans ces études
peut également découler d'interactions épistatiques entre les gènes
cite:Vilhj_lmsson_2012. Dans les études de profils d'expression des gènes, les
facteurs latents peuvent être les conditions expérimentales, l'âge et le sexe
des patients, leurs facteurs génétiques et l'hétérogénéité des échantillons de
tissus cite:Lazar_2012. Dans les EWAS, la confusion peut être due à des mélanges
cellulaires lorsque les cellules cibles purifiées ne sont pas disponibles
cite:jaffe14_accoun_cellul_heter_is_critic. Dans chaque catégorie, les facteurs
latents peuvent être confondus avec les variables explicatives en raison de la
nature observatoire de l'étude.

*** Plan du chapitre
Nous proposons dans ce chapitre, deux méthodes d'estimation rapide et efficace
des paramètres du modèle LFMM. Nos deux méthodes d'estimation consistent à
isoler la variation de $\Y$ expliquée par les variables latentes de celle
expliquée par les variables explicatives $\X$. Les méthodes que nous présentons
sont comparable aux méthodes sva cite:article_Leek_Storey_2007; et cate
cite:wang2015confounder; qui procède d'une façon très similaire. Nous décrivons
plus en détail les méthodes cate et sva dans la partie [[sec:similar_method]].
Chacun des algorithmes que nous présentons découle de l'optimisation d'une
fonction objectif. Nous montrons que nos algorithmes d'estimation convergent
vers le point de minimum global de leur fonction objectif respective. Enfin,
nous comparons nos méthodes à sva et cate sur des simulations numériques ainsi
que pour des exemples de GWAS, EWAS et GEAS.

** Nouvelles méthodes 
*** Modèle mixte à facteurs latents
<<sec:model>>
Dans cette partie nous introduisons les notations du modèle mixtes à facteurs
latents que nous utilisons pour corriger les tests d'association : 
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Dans cette équation, $\Y$ est la matrice de taille $\Yrow \times \Ycol$ qui
rassemble les observations de $\Ycol$ variables pour $\Yrow$ individus. Par
exemple, la matrice $\Y$ peut contenir des SNPs, des niveaux de méthylation ou
bien des niveaux d'expression génique. Nous appelons la matrice $\Y$ la matrice
des variable expliquées. La matrice $\X$, de taille $\Xrow \times \Xcol$,
regroupe toutes les variables explicatives. Ainsi les colonnes de $\X$ sont les
variables d'intérêt pour l'association, c'est à dire les variables pour
lesquelles on souhaite trouver les associations avec $\Y$. Les colonnes de $\X$
peuvent être par exemple un phénotype, comme une maladie, ou un gradient
environnemental, comme la température d'un habitat. La matrice des effets de
$\X$ sur $\Y$ de taille $\Ycol \times \Xcol$ est notée $\B$. Si l'on suppose
qu'il y a $K$ variable latentes, la matrice $\U$ est la matrice des $\K$
variable latentes et la matrice $\V$ représente les effets des variables latents
sur $\Y$. Les matrices $\V$ et $\U$ sont respectivement la matrice des effets
latents appelée aussi matrice des axes factorielles, de taille $\Ycol\times\Ucol$,
et la matrice des variables latentes, de taille $\Urow \times \K$. Enfin la
matrice $\E$ est la matrice d'erreur résiduelle, de taille $\Yrow\times\Ycol$.

Dans un premier temps, nous remarquons que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. En effet, comme ces deux matrices sont
multipliées entre elles dans l'équation eqref:eq:model, les matrices $\U$ et
$\V$ sont définies à une matrice inversible près 
\begin{equation}
\U \V^{T} = \U \matr{R} \matr{R}^{-1} \V^{T}
\end{equation}
où $\matr{R}$ est une matrice inversible de taille $\K \times \K$. Nous
considérons donc la matrice
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
et nous appelons la matrice $\W$ la matrice latente. Si l'on suppose qu'il y a $\K$
variables latentes linéairement indépendantes, cela est équivalent à faire
l'hypothèse que la matrice latente $\W$ est de rang $\K$. Dans la suite nous
considérons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce à
l'analyse en composantes principales de la matrice latente $\W$.

*** Estimation des moindres carrés régularisée en norme $L_{2}$
<<sec:estimator_L2>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par l'équation eqref:eq:model. L'algorithme d'estimation est basé
sur un problème des moindres carrées régularisé en norme $L_{2}$. Nous montrons
que cet algorithme calcule un minimum global du problème d'optimisation des
moindres carrés régularisé en norme $L_{2}$.

**** Fonction objectif 

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM, nous définissons la
fonction objectif de type ridge suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lambRidge$ le paramètre de régularisation. Le premier terme de la fonction
$\Lridge$ est le terme d'attache aux données. Si il n'y a pas de variable
explicative $\X$, le terme d'attache aux données correspond à la fonction
objectif de l'analyse en composantes principales. Le deuxième terme de la
fonction $\Lridge$ est le terme de régularisation. Ce terme est indispensable
pour séparer les variations de $\Y$ expliquées par les variables latentes de
celles expliquées par les variables explicatives. En effet, si
\begin{equation*}
\lambRidge = 0, 
\end{equation*}
alors, pour toute matrice $\matr{P}$, de taille $\Xcol \times \Ycol$, nous avons
\begin{equation*}
\Lridge(\U - \X \matr{P}, \V^{T}, \B + \V \matr{P}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Nous voyons que les points du minimum de la fonction objectif ne sont pas définis de
manière univoque pour notre problème quand le paramètre de régularisation est
nul.

**** Algorithme de minimisation de la fonction objectif $\Lridge$
Afin d'estimer les paramètres de LFMM minimisant la fonction $\Lridge$, nous
commençons par calculer la décomposition en valeurs singulières de $\X$
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$ de $\X$. Les estimateurs sont calculés de
la façon suivante
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V}^{T} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B}^{T} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T}),
\end{align}
où $\svd_{\K}(\matr{A})$ est la meilleure approximation de rang $\K$ de la
matrice $\matr{A}$, donnée par la décomposition en valeurs singulières et
$\Id_{d}$ est la matrice identité de taille $d \times d$. La matrice $\D$ est la
matrice diagonale de taille $\Yrow \times \Yrow$ qui contient les termes
diagonaux suivants
\begin{equation*}
\left\{ \D_{,i,i}\right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latente $\hat{\U} \hat{\V}^{T}$ dans
l'équation eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement
de base $\matr{Q}$. Les $\Xcol$ premiers axes de la base canonique transformée
par $\Q$ forment une base orthonormale de l'espace vectoriel engendré par les
variable explicatives $\X$. La matrice diagonale $\D$ a pour effet de ramener
vers zéro la composante qui appartient à l'espace engendré par $\X$. Si
$\lambRidge$ tend vers zéro, multiplier $\Y$ par $\D \matr{Q}^{T}$ revient à
prendre le résidu d'une régression linéaire de $\Y$ par $\X$, on enlève alors
toute la part de variance expliquée par $\X$. À la limite, $\D$ n'est plus
inversible. Si $\lambRidge$ est très grand, $\D$ tend vers la matrice
identité. Dans ce cas, le calcul de $\hat{\U} \hat{\V}$ revient à faire une
analyse en composante principale de la matrice des variable expliquées $\Y$.
Nous expliquons dans la partie [[sec:hyperparametre]] plus en détail comment choisir
l'hyperparamètre $\lambRidge$.

L'estimation des paramètres régularisé en norme $L_{2}$ est justifié par le
théorème suivant.
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambRidge$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, définit un 
minimum global de la fonction objectif $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $\hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$
correspondant à un minimum global de la fonction $\Lridge$. Commençons par
remarquer que la fonction $\Lridge$ est convexe en la variable $\B$ , on peut
donc trouver le point de minimum global en annulant la dérivée de $\Lridge$ par
rapport à $\B$. Cela conduit à l'équation suivante
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V^{T}).
\end{equation}
Il s'agit de l'estimateur ridge du modèle de la régression linéaire de $\Y - \U
\V^{T}$ par $\X$, en supposant que $\U$ et $\V$ sont connues.

Il faut maintenant minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeurs singulières de $\X$ telle que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$. L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D^{2} \matr{Q}^{T} (\Y - \U \V^{T})}^{2}_{F} + 
\frac{1}{2} \lambRidge \norm{\matr{C}_{\lambRidge} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{equation*}
où $\matr{C}_{\lambRidge}$ est une matrice de taille $\Xcol \times \Xrow$
remplie de zéro sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \matr{C}_{\lambRidge, i, i} \right\}_{i = 1..d} = 
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambRidge}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\D$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \matr{D}_{\lambRidge, i, i} \right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Les matrices $\D$ et $\matr{C}_{\lambRidge}$ étant diagonales, il est possible
par le calcule de montrer que
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\sqrt{(\D^{2} + 
\matr{C}_{\lambRidge}^{2})} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2} \\ 
& = \frac{1}{2} \norm{ \D \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{align*}
Enfin, optimiser la fonction objectif $\mathcal{L}^{'}$ est équivalent au
problème de trouver la meilleure approximation de rang $\K$ de la matrice
\begin{equation*}
\D \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$ valeurs
singulières les plus grandes cite:Eckart_1936. Nous avons bien montré que
\begin{align*}
&\hat{\U} \hat{\V}^{T} = \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
&\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof
*** Estimation des moindres carrées régularisée en norme $L_{1}$  
<<sec:estimator_L1>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par eqref:eq:model basé sur un problème des moindres carrés
régularisé en norme $L_{1}$ et en norme nucléaire. Nous montrons que cet
algorithme calcule un minimum global du problème d'optimisation des moindres
carrés régularisé.

**** Fonction objectif 
Afin d’estimer les paramètres $\U$, $\V$ et $\B$ de LFMM, nous définissons la
fonction objectif de type lasso suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso,
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\W}_{*}$ la norme nucléaire de la matrice $\W$, définie
comme la somme de ses valeurs singulières. Le choix de la norme $L_{1}$ est
motivé par le fait que l'on s'attend à ce que seulement une certaine proportion
des colonnes de $\Y$ soit associée à $\X$. Autrement dit seule certaines lignes
de la matrice des effets $\B$ doivent être non nulles. La régularisation $L_{1}$
est connue pour produire des estimateurs parcimonieux de $\B$
cite:Tibshirani_1996. La fonction $\Llasso$ fait aussi intervenir une
régularisation sur la matrice latente $\W$. Nous ajoutons la régularisation
$L_{1}$ afin de lever la contrainte de rang sur $\W$ empechant de définir un
problème d'optimisation convexe. Avec le terme de régularisation sur $\W$, la
fonction $\Llasso$ devient convexe. En outre, les pénalisations sur la norme
nucléaire sont utilisées pour pénaliser le rang
cite:article_Mishra_Meyer_Bach_Sepulchre_2011. Ainsi, la régularisation en norme
nucléaire contraint le rang de $\W$ et donc le nombre de variables latentes.

**** Algorithme de minimisation de la fonction objectif $\Llasso$
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par blocs de coordonnées
qui permet d'estimer les paramètres de LFMM en minimisant la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg. Nous initialisons l'algorithme
avec des matrices nulles :
\begin{align*}
\hat{\W}_{t = 0} & = 0 \\
\hat{\B}_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. Calculer $\hat{\B}_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{\mathrm{lasso}}^{'}(\B) =  \frac{1}{2} ||(\Y - \hat{\W}_{t-1}) - \X \B^T||_{F}^2 + \lambLasso ||\B||_1
   \end{equation}
2. Calculer $\hat{\W}_{t}$ le point minimum de  
   \begin{equation}
   \label{eq:lasso2}
   \mathcal{L}_{\mathrm{lasso}}^{''}(\W) = \frac{1}{2} ||(\Y - \X \hat{\B}_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répétées jusqu'à ce que l'algorithme converge ou bien que
$t$ atteint le nombre maximum d'itérations fixé à l'avance. Nous allons
maintenant expliquer plus en détail les deux étapes de l'algorithme décrit
ci-dessus.

La première étape de l'algorithme consiste à faire une régression linéaire
régularisée en norme $L_{1}$ de la matrice résiduelle
\begin{equation}
\matr{E}^{1}_{t} = \Y - \hat{\W}_{t-1}
\end{equation}
par les variables explicatives $\X$. Il existe plusieurs algorithmes pour
estimer les paramètres de cette régression. Nous utilisons l'algorithme de
descente par coordonnées cite:Friedman_2007. Dans le cas présent, on s'intéresse
plus particulièrement à l'estimation des variables latentes, qui permettront
ensuite de faire le test d'association (voir la partie [[sec:hypothese]]). Nous
supposons donc que les variables explicatives $\X$ ont été transformées de sorte que
\begin{equation}
\X^{T} \X = \Id_{d}.
\end{equation}
On a alors d'après cite:Tibshirani_1996,
\begin{equation}
\hat{\B}_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambLasso)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s),
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est l'estimateur du paramètre
de la régression linéaire classique donné dans ce cas par
\begin{equation*}
\bar{\B}_{t} = \X^{T} \matr{E}^{1}_{t}.
\end{equation*}

La deuxième étape de l'algorithme résout un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \hat{\B}_{t}^{T},
\end{equation}
Cette approximation est donnée grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
la matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T},
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. On a alors 
\begin{equation}
\hat{\W}_{t} = \matr{M} \bar{\matr{S}} \matr{N}^{T}
\end{equation}
où $\bar{\matr{S}}$ est la matrice diagonale formée par les valeurs singulières
de $\matr{S}$ seuillées de sorte que
\begin{equation*}
\bar{s}_{j} = (s_{j} - \gamma)_{+}, ~ j = 1,...,\Yrow.
\end{equation*}
Le seuillage produit des valeurs nulles et ramène vers zéro les valeurs
singulières restantes.

L'algorithme de descente par blocs de coordonnées ne converge pas en général
vers un point minimum quand la fonction objectif n'est pas continûment
différentiable, comme c'est le cas pour la fonction $\Llasso$. On peut trouver
dans la littérature des résultats généraux sur les algorithmes par blocs de
coordonnées dans des cas ou la fonction objective n'est pas différentiable
cite:Tseng_2001. Cependant, les théorèmes démontrés dans cite:Tseng_2001
dépassent largement le cadre de la convergence de l'algorithme d'estimation
$L_{1}$ présenté ici et compliquent l'extraction des résultats intéressants.
Pour faciliter la compréhension, nous proposons de démontrer un théorème plus
faible qui s'applique directement à notre cas. Pour cela nous introduisons
quelques notations. Soit la fonction $f$ définie sur le domaine
\begin{equation}
\label{eq:domf}
A = A_{1} \times A_{2} \times ... \times A_{m},
\end{equation}
un produit cartésien d'ensembles fermés et convexes. L'algorithme de descente
par blocs de coordonnées est défini par la formule de récurrence suivante :
\begin{equation}
\label{eq:blokAlgo}
x_{i}^{k+1} \in \mathrm{arg} \min_{\zeta \in X_{i}} f(x_{1}^{k}, ...,x_{i-1}^{k},\zeta,x_{i+1}^{k},..., x_{m}^{k}), ~
i = 1,...,m.
\end{equation}
En nous inspirant des résultats présentés dans cite:Tseng_2001 et de la
proposition 2.7.1 de cite:Bertsekas_1997 qui démontre la convergence de
l'algorithme de descente par bloc de coordonnées dans le cas où la fonction
objectif est différentiable, nous pouvons énoncer le théorème suivant :
#+BEGIN_theorem 
Si $f$ est une fonction continue de $A$ dans $\RR$, convexe et telle que
\begin{equation}
f(x_{1},..., x_{m}) = g(x_{1}, ..., x_{m}) + \sum_{i = 1}^{m} f_{i}(x_{i}),
\end{equation}
où g est convexe et différentiable et les fonctions $f_{i}$ sont continues et
convexes. Soit $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo. Alors tout
point limite de $\{x^{k}\}$ est un point de minimum global de $f$.
#+END_theorem

#+BEGIN_proof 
On note
\begin{equation*}
\bar{x} = (\bar{x}_{1}, ..., \bar{x}_{m})
\end{equation*}
un point limite de $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo, $\bar{x}$
est bien dans $A$ le domaine de définition de $f$ car cet ensemble est fermé.
Comme $g$ est convexe et différentiable on a pour tout $x \in A$
\begin{align}
\label{eq:lassoProof1}
f(x) - f(\bar{x}) & \geq & \nabla g(\bar{x})(x - \bar{x}) + 
\sum_{i = 1}^{m} (f_{i}(x_{i}) - f_{i}(\bar{x}_{i})) \\
 & & = \sum_{i = 1}^{m} ( \nabla_{i} g(\bar{x})(x_{i} - \bar{x}_{i}) + 
 f_{i}(x_{i}) - f_{i}(\bar{x}_{i}))
\end{align}
où $\nabla g(\bar{x})$ et $\nabla_{i} g(\bar{x})$ sont respectivement la dérivée
et la dérivée par rapport à la $i\text{-ième}$ variable de $g$ en $\bar{x}$.
D'autre part pour chaque variable d'indice $i$
\begin{align}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  (\nabla_{i} g(\bar{x}) + r_{i})(x - \bar{x}) 
\end{align}
où $r_{i}$ est n'importe quelle sous-dérivée de la fonction convexe $f_{i}$ en
$\bar{x}_{i}$. Or nous savons par construction de $\bar{x}$ que
\begin{equation}
\label{eq:lassoProof2}
f(\bar{x}) \leq f(\bar{x}_{1}, ...,x_{i},..., \bar{x}_{m}), ~ \forall x_{i} \in
A_{i}.
\end{equation}
Pour chaque variable $x_{i}$, on peut donc dire que zéro appartient à l'ensemble
des sous-dérivées par rapport la variable $x_{i}$ de $f$ en $\bar{x}_{i}$. On
peut alors dire qu'il existe une sous-dérivé $r_{i}$ telle quelle que 
\begin{equation}
\nabla_{i} g(\bar{x}) + r_{i} = 0.
\end{equation}
Pour chaque variable d'indice $i$ on a finalement 
\begin{equation}
\label{eq:lassoProof3}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  0
\end{equation}
Finalement, en utilisant eqref:eq:lassoProof3 et eqref:eq:lasso1 nous avons
\begin{equation}
f(x) - f(\bar{x}) \geq 0, ~ \forall x \in A.
\end{equation}
#+END_proof
Ce résultat démontre que l'algorithme d'estimation $L_{1}$ des paramètres du
modèle LFMM converge vers un point de minimum global de $\Llasso$.
*** Complexité des algorithmes
Dans cette partie nous abordons la complexité des algorithmes d'estimation des
paramètres présentés dans les sections précédentes. On peut distinguer deux
grandes étapes dans ces algorithmes. La première est le calcul de la
décomposition en valeurs singulières tronquée : calcul de la matrice latente
défini par l'équation eqref:eq:RidgeLfmmEstomatorW pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{'}$ définie par eqref:eq:lasso2 pour l'estimation
$L_{1}$. La seconde est le calcul de la projection orthogonale sur l'espace
engendré par les variables explicatives $\X$ : calcul de la matrice des effets
définie par l'équation eqref:eq:RidgeLfmmEstomatorB pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{''}$ définie par eqref:eq:lasso1 pour
l'estimation $L_{1}$.

D'après cite:Halko_2011, le calcul des $K$ composantes dominantes de la
décomposition en valeurs singulières demande $O(\Yrow \Ycol \K)$ opérations.
Cette complexité peut être réduite à $O(\Yrow \Ycol \log(\K))$ opérations si on
utilise une méthode avec projections aléatoires, comme celle présentée dans
cite:Halko_2011.

La deuxième étape importante consiste en une projection du résidu de
l'approximation de rang faible sur l'espace engendré par $\X$. Le nombre précis
d'opération dépend des hypothèses qui sont faites sur la matrice $\X$. Dans
l'algorithme d'estimation $L_{1}$ aucune inversion de matrice n'est nécessaire
pour le calcul de $\hat{\B}_{t}$. Mais dans les deux algorithmes, si on
s'intéresse seulement au comportement asymptotique par rapport à $\Yrow$,
$\Ycol$ et $\Ucol$, alors on peut majorer la complexité par $O(\Ycol \Yrow +
\Ucol (\Ycol + \Yrow))$.

Finalement, pour les deux algorithmes, le nombre d'opérations est majoré par
$O(\Yrow \Ycol \K)$. L'algorithme d'estimation $L_{1}$ est bien entendu plus
long car il réalise plusieurs fois les opérations de décomposition en valeurs
singulières et de projection. L'algorithme d'estimation $L_{2}$ ne les réalise
qu'une seule fois.

Outre la complexité temporelle il est important de garder à l'esprit la taille
prise en mémoire, surtout pour ce genre d'algorithme qui prend en entrée des
données potentiellement trop grandes pour la mémoire vive de l'ordinateur (RAM).
Les algorithmes d'estimation $L_{1}$ et $L_{2}$ ne nécessitent pas de dupliquer
la matrice des variables expliquées $\Y$. En effet, $\Y$ est de taille $\Yrow
\times \Ycol$ et donc la dupliquer pourrait poser des problèmes sur des
ordinateurs ne possédant pas assez de RAM. Il est possible d'envisager de ne pas
charger $\Y$ en RAM et d'accéder au données seulement quand cela est nécessaire.

*** Choix des hyperparamètres 
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

La sélections des hyperparamètres est un problème commun à de nombreuses
méthodes en analyse de données. Nous présentons plusieurs approches pratiques
pour choisir les hyperparamètres qui interviennent dans les algorithmes que nous
avons présentés ici. Nous commençons par présenter les différentes approches
possibles pour choisir le nombre de variables latentes $K$. Nous présentons
ensuite plusieurs heuristiques qui permettent d'aider le choix des paramètres de
régularisation. Enfin nous présentons un algorithme de validation croisée adapté
aux algorithmes que nous avons présentés.

**** Nombre de variables latentes ($K$)
Pour trouver le nombre de variables latentes $\K$ nous proposons d'isoler les
variations de $\Y$ expliquées par les variables latentes à l'aide de la matrice
$\D$ utilisée dans l'estimation $L_{2}$ (voir la section [[sec:estimator_L2]]). Pour
cela on projette $\Y$ sur l'espace orthogonal à $\X$ en prenant $\lambRidge = 0$.
On a alors
\begin{equation}
 \matr{D}_{0} \Q^{T} \Y = \matr{D}_{0} \Q^{T}\U \V^{T} + \matr{D}_{0} \Q^{T} \E.
\end{equation}
On peut ainsi utiliser les méthodes d'estimation du nombre $\K$ de variables
latentes sur la matrice $\matr{D}_{0} \Q^{T} \Y$. Quand il n'y a plus de
variable explicative $\X$ les fonctions objectifs des deux algorithmes
d'estimations $L_1$ et $L_2$ présentés ici correspondent à la fonction objectif
de l'analyse en composantes principales (ACP). Nous utilisons donc les méthodes
d'estimation du nombre de composantes dans l'ACP pour $\matr{D}_{0} \Q^{T} \Y$.
Il existe de nombreuses approches pour déterminer le nombre de composantes
principales de l'ACP, très bien expliquées dans cite:jolliffe1986principal. On
peut grouper les approches en trois catégories. La première catégorie regroupe
les approches subjectives comme l'utilisation du scree plot (le graphe des
valeurs singulières de la matrice des données). La seconde catégorie comprend
les approches basées sur une modélisation de la distribution des données
observées, comme par exemple la méthode présentée dans cite:choi2014selecting.
La dernière catégorie est formée des approches basées sur la validation croisée,
comme celle que nous détaillons plus loin. Aucune méthode ne s'est imposée comme
la référence, et il est préférable d'en utiliser plusieurs. Pour les expériences
que nous avons réalisées sur des données réelles, le choix du nombre de
variables latentes $\K$ du modèle LFMM a été fait à partir du scree plot de
l'ACP de la matrice $\matr{D}_{0} \Q^{T} \Y$. Nous avons aussi utilisé
l'algorithme de validation croisée que nous présentons dans la section [[sec:CV]].

**** Paramètre de régularisation $L_{2}$
<<sec:paramL2>>
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 16:55]
- Note taken on [2017-07-20 Thu 16:54] \\
  j'y verrai plus claire quand j'aurais choisi lambda pour les vrai data set et
  une fois que la cross validation marchera ou pas...
:END:

Le paramètre de régularisation $L_{2}$ ($\lambRidge$) intervient dans le calcul
de l'estimation de la matrice latente décrit dans la partie [[sec:estimator_L2]]. Ce
paramètre de régularisation intervient dans la matrice diagonale $\D$. Lorsque
le paramètre de régularisation $L_{2}$ tend vers zéro, les variables $\Y$ et
$\X$ sont linéairement décorrélées. Ainsi la matrice $\D$ permet de réduire la
corrélation entre les variables expliquées $\Y$ et les variables explicative
$\X$ afin de pouvoir estimer les variables latentes $\U$. Lorsque le paramètre
$\lambRidge$ tend vers l'infini, la matrice $\D$ tend vers la matrice identité.
L'estimation des variables latentes est alors données par l'ACP de la matrice
$\Y$, sans prendre en compte la variable $\X$. Ainsi lorsque $\lambRidge$ est
trop grand, on risque d'expliquer par les variables latentes une partie de la
variance de $\Y$ qui devrait être expliquée par $\X$ et manquer certaines
associations. Ainsi le choix du paramètre de régularisation $\lambRidge$ est une
affaire de dosage, il doit être ni trop grand ni trop petit. Nous avons remarqué
dans les expériences que de petites valeurs donnes de meilleurs résultats dans
de nombreux cas.

**** Paramètre de régularisation $L_{1}$
Le paramètre de régularisation $L_{1}$ ($\lambLasso$) à un impact sur la le
nombre de lignes nulles dans la matrice des effets $\B$. La proportion de lignes
non nulles dans la matrice $\B$ correspond à la proportion de colonnes de $\Y$
corrélées avec les variables explicatives $\X$. Quand on prend en compte les
variables latentes plutôt que de choisir le paramètre de régularisation
$\lambLasso$, il est équivalent de choisir la proportion de colonnes de $\Y$
corrélées aux variables $\X$. Pour trouver un paramètre de régularisation qui
correspond à la proportion de lignes non nulles, nous proposons une heuristique
basée sur un chemin de régularisation inspirée par
cite:friedman10_regul_paths_gener_linear_model. Nous commençons par la plus
petite valeur du paramètre de régularisation $\lambLasso$ tel que le vecteur
\begin{equation}
\hat{\B}_{t = 1} = \sign(\bar{\B}_{t = 1}) (\bar{\B}_{t = 1} - \lambLasso)_{+}
\end{equation}
vaut zéro. La matrice $\hat{\B}_{t = 1}$ est le résultat de la première étape de
l'algorithme d'estimation des moindres carrés régularisée en norme $L_{1}$
présenté dans la partie [[sec:estimator_L1]]. La valeur de $\lambLasso$
correspondante est notée $\lambLasso^{\mathrm{max}}$. Ensuite, nous construisons
une suite de $m$ valeurs de $\lambLasso$ décroissant selon une échelle
logarithmique depuis $\lambLasso^{\mathrm{max}}$ jusqu'à
\begin{equation}
\lambLasso^{\mathrm{min}} = \epsilon \lambLasso^{\mathrm{max}}.
\end{equation}
Enfin, pour chaque valeur de la suite ainsi croissante, nous calculons le nombre
de lignes non nulles dans $\hat{\B}$ et l'estimation de la matrice des effets.
Nous stoppons l'algorithme si la proportion de lignes non nulles souhaitée est
dépassée.

**** Paramètre de régularisation de la norme nucléaire
Le paramètre de régularisation de la norme nucléaire ($\gamma$) dans
l'algorithme d'estimation $L_{1}$ a une influence sur le rang de la matrice
latente $\W$. Il est préférable de choisir le rang de cette matrice,
correspondant au nombre de variables latentes $K$, que de choisir le paramètre
de régularisation $\gamma$. Nous proposons l'heuristique suivante pour calculer
le paramètre $\gamma$ à partir du nombre de facteurs $K$. Nous commençons par
calculer les valeurs singulières de la matrice des variables explicatives $\Y$,
notées $(\sigma_1, ..., \sigma_{\Yrow})$. Ensuite, nous calculons
\begin{equation}
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2}.
\end{equation}
Nous avons remarqué dans les expériences que ce choix du paramètre de
régularisation $\gamma$ a toujours fait converger l'algorithme d'estimation
$L_{1}$ vers une estimation de la matrice latente $\hat{\W}$ qui est de rang $\K$.

**** Validation croisée
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:00]
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:
<<sec:CV>>

La validation croisée est une méthode d'évaluation d'un modèle très utilisée en
apprentissage statistique. Le principe est de séparer les données en une partie
d'apprentissage et une partie de test. Les données d'apprentissage sont
utilisées pour estimer les paramètres du modèle. On mesure ensuite l'erreur de
prédiction à l'aide des données de tests. Pour que la validation croisée
fonctionne, il est très important que les données de test ne soient pas
utilisées pour estimer les paramètres du modèle. Dans le cas des modèles à
facteurs latents en général, les données d'apprentissage ne permettent toutefois
pas de calculer les variables latentes pour les données de test (la matrice $\U$
pour LFMM). Le plus simple est de séparer les variables des données de test.
Nous utilisons ensuite une partie des variables des données de test pour estimer
les variables latentes et l'autre partie pour calculer l'erreur de prédiction
cite:Bro_2008. Nous présentons maintenant plus formellement notre procédure de
validation croisée.

Nous commençons par séparer les données une partie d'entraînement et une partie
de test, c'est a dire que nous séparons les matrices des variables expliquées
$\Y$ et explicatives $\X$ en deux parties selon leurs lignes. Nous notons $I$
l'ensemble des indices des lignes choisies pour estimer l'erreur de prédiction.
On estime à partir des données d'entraînement la matrice des axes factoriels que
l'on note $\hat{\V}_{-I}$ et la matrice des effets que l'on note
$\hat{\B}_{-I}$. Ensuite, nous séparons les observations des variables
expliquées de test en deux partis afin d'estimer les variables latentes sur les
variables restantes. On notera $J$ l'ensemble des colonnes de la matrice des
variable expliquées $\Y$ sélectionnées pour estimer la matrice des variables
latentes. La matrice des variables latentes est estimée de la manière suivante
\begin{equation}
\hat{\U}_{-J} = (\Y[I,-J] - \X[I,] (\hat{\B}_{-I}[J,])^{T}) \hat{\V}_{-I}[-J,]^{T},
\end{equation}
où l'opérateur crochet représente l'opérateur de sélection de lignes et colonnes
d'une matrice. Enfin, on peut calculer l'erreur de prédiction comme ceci
\begin{equation}
\label{eq:2}
\mathrm{err} = \frac{1}{|I| |J|} \norm{\Y[I, J] - \hat{\U}^{-J} \hat{\V}_{-I}[J,]^{T} - \X[I, ] \hat{\B}_{-I}[J,]^{T} }_{F}.
\end{equation}
Cette procédure permet de mesurer une erreur sur des observations des variables
expliquées qui n'ont pas été utilisées pour estimer les paramètres du modèle.

*** Tests d'hypothèse corrigés pour les facteurs de confusions
<<sec:hypothese>>
:LOGBOOK:
- Note taken on [2017-08-04 ven. 17:14] \\
  Mais il y a aussi
  les autres variables observées qui doivent être prises en compte car elles sont
  potentiellement des facteurs de confusion pour l'association. Les variables
  explicatives qui ne sont pas d'intérêt pour l'association peuvent être par
  exemple l'age des individus, ou bien le sexe
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Jusque ici, nous avons seulement abordé l'estimation des paramètres de LFMM.
Cependant, l'objectif initial est de trouver la liste des colonnes de la matrice
$\Y$ associées aux variables $\X$ tout en prenant en compte les variables
latentes. Nous présentons dans cette partie un test d'hypothèse de nullité de
l'effet de la matrice $\X$ sur la matrice $\Y$ corrigé pour les variables
latentes. Une approche simple consiste à considérer l'estimation des variables
latentes $\hat{\U}$ comme les vraies valeurs de $\U$ et de les utiliser comme
variables explicatives dans le modèle. C'est une méthode très courante dans les
études d'association qui a montré de très bons résultats quand il y suffisamment
d'individus
cite:gerard2017unifying,Price_2006,Song_2015,article_Leek_Storey_2008,Rahmani_2016.
Nous avons choisi de réaliser un test d'hypothèse qui repose sur la régression
linéaire car cela correspond au modèle LFMM quand on suppose que $\U$ est
connue. Les estimations des variables latentes peuvent être traitées comme
variables explicatives dans n'importe quel modèle statistique. On pourrait par
exemple envisager d'utiliser un modèle de régression linéaire généralisée. Afin
de simplifier les notations et sans perte de généralité, nous supposons qu'il
n'y a qu'une seule variable explicative, c'est à dire que la dimension de la
matrice $\B$, égale à $\Xcol$, vaut $1$. De plus, nous signalons qu'il est
possible d'ajouter d'autres variables explicatives à la régression. Cela a un
intérêt si l'on observe des variables qui sont des facteurs de confusion connus
pour notre étude d'association, comme par exemple l'age et le genre des
individus. Nous rappelons que l'estimation de la matrice des $\K$ variables
latentes $\hat{\U}$ est définie de façon unique grâce à l'ACP de la matrice
$\hat{\W}$. La matrice $\hat{\W}$ est estimée grâces aux algorithmes
d'estimation $L_{1}$ ou $L_{2}$ de la matrice latente du modèle LFMM présenté
dans la section [[sec:model]].

**** Calcul de la statistique de test
Pour chaque variable expliquée $\Y_{j}$, nous avons défini le modèle de
régression linéaire suivant
\begin{equation}
\Y_{j} =  \hat{\U} \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{E_{j}},
\end{equation}
où la matrice $\hat{\U}$ est l'estimation de la matrice des variables latentes
du modèle LFMM. On suppose que l'erreur $\matr{E}_{j}$ est gaussienne de moyenne
nulle. On veut tester l'hypothèse de nullité du coefficient de régression
$\beta_{j}$. Sous ces hypothèses on peut calculer pour chaque variable expliquée
$\Y_{j}$ une statistique de test $z_{j}$, assimilable à un \zscore. Sous
l'hypothèse nulle, la statistique de test suit la loi de Student à $\Yrow - \K -
1$ degrés de liberté. On peut donc calculer une \pvalue pour chaque variable
expliquée $\Y_{j}$. Le détail du calcul de la statistique de test est très
classique. Par exemple, il est donné dans la section 3.2 de cite:Hastie_2009.

**** Calibration du test d'hypothèse
<<sec:calibration>> 

Il arrive parfois que la statistique de test ne suive pas la distribution
théorique sous l'hypothèse nulle. On dit dans ce cas que le test est mal
calibré. On peut trouver dans cite:Efron_2004 des exemples de situations qui
peuvent aboutir à des tests mal calibrés. Dans les exemples que nous présentons
ici ont s'attend à ce que la majorité des variables expliquées $\Y_{j}$ ne soit
pas associées avec la variable $\X$. Ainsi une majorité des statistiques de test
sont distribuées selon l'hypothèse nulle. Pour la calibration, nous utilisons
l'approche choisie dans cite:Sun_2012, qui consiste à calculer la médiane et la
déviation absolue à la médiane (MAD pour median absolute déviation) directement
sur les $z$ statistiques. En effet, la médiane donne une estimation robuste de
la moyenne et le MAD de l'écart-type. On a alors une nouvelle statistique de
test
\begin{equation}
\tilde{z_{j}} = \frac{z_{j} - \med(z_{1}, ..., z_{\Ycol})}{
\mad(z_{1}, ..., z_{\Ycol})}.
\end{equation}
Pour calculer les nouvelles \pvalues, on suppose que $\tilde{z_{j}}$ suit une loi
normale de moyenne nulle et d'écart type 1 sous l'hypothèse nulle.

**** Contrôle du taux de fausse découverte                      :noexport:
:LOGBOOK:
- Note taken on [2017-07-19 Wed 10:44] \\
  non si je fais une partie la dessus il va falloir que je developpe !! alors que
  je veux juste dire que j'ai utilisé qvalue....
:END:
Dans cette dernière partie, nous présentons en quelques mots les outils que nous
avons utiliser pour contrôler le taux de fausse découvertes dans les
experiences. Dans le cadre des test d'association nous voulons en sortie de la
méthode obtenir une liste de colonnes de $\Y$ candidates pour l'association avec
la variable explicative. Pour choisir cette liste Dans le cadre des test
d'association multiple....................

*** Implémentation en R
Les deux nouvelles méthodes de test d'association avec correction pour les
facteurs de confusion que nous avons développées dans cette thèse ont été
implémentées dans le langage de programmation R. Nous les avons appelées
respectivement lassoLFMM pour l'implémentation des estimateurs régularisées en
norme $L_{1}$ et ridgeLFMM pour les estimateurs régularisées en norme $L_{2}$.
Les algorithmes lassoLFMM et ridgeLFMM prennent en entrée la matrice $\X$ et la
matrices $\Y$. Ils prennent également en entrée le nombre de variables latentes
$\K$. L'algorithme ridgeLFMM prend une valeur pour $\lambRidge$, le paramètre de
régularisation $L_{2}$. L'algorithme lassoLFMM prend la proportion de lignes non
nulles dans la matrice des effets $\B$. Enfin les deux algorithmes retournent
les estimations pour les paramètres de LFMM ainsi qu'une \pvalue pour le test
d'association de chaque colonne de $\Y$ avec $\X$.
** Autres méthodes existantes
<<sec:similar_method>>

Dans cette section nous présentons d'autres méthodes pour les études
d'association avec et sans correction pour les facteurs de confusion. Les
méthodes que nous présentons dans cette section sont comparées aux méthodes
lassoLFMM et ridgeLFMM dans la section suivante.

*** Régression linéaire simple et avec les scores de l'ACP
Dans lassoLFMM et ridgeLFMM, les tests d'hypothèses utilisés pour détecter les
associations reposent sur un modèle de régression linéaire de $\Y$ par $\X$ et
sur l'estimation des facteurs latents $\bar{\U}$. Il est donc naturel de
comparer nos algorithme à la méthode reposant sur la régression linaire de $\Y$
par $\X$. Dans ce cas, aucun facteur latent n'est pris en compte dans l'étude
d'association. D'autre part, nous comparons nos tests à une méthode qui repose
sur une estimation des variables latentes par l'ACP. Dans ce cas, il s'agit de
faire une régression de $\Y$ par $\X$ et $\bar{\U)}$ définie comme la matrice
des scores sur les $\K$ premières composantes principales. Un principe similaire
est utilisé dans la méthode EIGENSTRAT cite:Price_2006. Les deux méthodes,
reposant sur la régression linéaire avec et sans les score de l'ACP, ont été
implémentées en langage R et nous les appelons respectivement lm et PCAlm.

*** COMMENT emma cite:Kang_2008
:LOGBOOK:
- Note taken on [2017-08-07 lun. 10:23] \\
  Non on va pas ajouter emma aux méthodes ca serais trop compliqué.
:END:
*** Méthode "Surrogate Variable Analysis" (SVA) cite:article_Leek_Storey_2007
:LOGBOOK:
- Note taken on [2017-08-05 Sat 13:57] \\
  sva utilisé:[[file:Rpackage/R/ExpRmethod-sva.R::ExpRmouline.method_sva%20<-%20function(m,%20dat)%20{][sva function]]
:END:

Il existe deux versions de SVA : sva-two-step cite:article_Leek_Storey_2007 et
sva-irw cite:article_Leek_Storey_2008. La méthode sva-two-step se découpe en
deux étapes : une étape d'estimation de la matrice des axes factoriel $\V$ et
une étape d'estimation de la matrice des variables latentes $\U$. Lors de la
premières étape la méthode sva-two-step estime les axes factoriel en faisant une
ACP de la matrice résiduel de la régression linaire de $\Y$ par $\X$. En
utilisant les notations de la section [[sec:estimator_L2]], cela correspond à faire
l'ACP de $\matr{D}_{(\lambRidge = 0)} \Q^{T} \Y$. Ensuite la méthode
sva-two-step détermine un sous-ensemble de colonnes de la matrice $\Y$ qui sont
le moins corrélées avec la variable $\X$. Le sous-ensemble de colonnes est
utilisé pour estimer la matrice des variables latentes $\U$. Cette procédure
peut facilement échouer car une faible corrélation avec la variable $\X$
n'implique pas qu'il n'y a pas d'association celle-ci. En effet une faible
corrélation sans prendre en compte les facteurs latents peut devenir une forte
corrélation quand on les prend en compte.

La deuxième version de SVA est itérative. Plutôt que d'estimer les variables
latentes sur un sous- ensemble de colonnes de la matrice $\Y$, la méthode
sva-irw attribue un poids à chacune d'entre elles. On calcule la probabilité que
l'effet de la variable $\X$ sur chaque colonne de $\Y$ soit nul sachant les
variables latentes calculées à l'itération précédente. Ensuite les probabilités
sont utilisées pour attribuer un poids à chaque colonne de $\Y$ et une nouvelle
estimation des variables latentes est calculée à l'aide d'une ACP qui prend en
compte ces poids. La méthode itère ces deux étapes un nombre de fois choisi par
l'utilisateur. Le désavantage de cette procédure est qu'on ne sais pas vers quoi
elle converge ni si elle converge. Nous avons utilisé le package R sva fourni
par ses auteurs.

*** "High dimensional factor analysis and confounder adjusted testing and estimation" (CATE) cite:wang2015confounder

Nous présentons dans cette partie la méthode cate cite:wang2015confounder. Pour
faciliter les explications, nous considérons le cas où il n'y a qu'une variable
explicative $\X$. Dans la méthode cate, on commence par transformer la matrice
des variables expliquées $\Y$ afin d'isoler les variations expliquées par les
facteurs latents. Pour effectuer la transformation, on applique une matrice de
changement de base aux lignes de $\Y$ de sorte que le premier axe de la nouvelle
base soit colinéaire à $\X$. Cette transformation permet d'avoir sur la première
ligne de la matrice transformée les coefficients de la régression linéaire de
$\Y$ par $\X$ et sur tout les autres lignes le projeté orthogonale de $\Y$ par
rapport à $\X$ correspondant aux résidus de la régression. La méthode cate
utilise le projeté orthogonal de $\Y$ par rapport à $\X$ pour calculer les axes
factoriels. Cette première étape est comparable à l'étape de calcul de la
matrice $\V$ dans notre méthode ridgeLFMM (voir partie [[sec:estimator_L2]]). Dans
ridgeLFMM, plutôt que d'enlever complétement les variations de $\Y$ expliquées
par $\X$ nous la réduisons en fonction du paramètre de régularisation
$\lambRidge$. Comme cela a été montré dans cite:wang2015confounder sva et cate
calcule la même matrice des axes factorielles. Cette matrice correspond à celle
estimée par ridgeLFMM dans le cas où $\lambRidge$ vaut zéro. La méthode cate
diffère de sva dans sa façon de calculer les variables latentes et les effets de
$\X$ sur $\Y$. Les auteurs de cate ont modélisé explicitement la corrélation
entre les variables explicatives $\X$ et les variables latentes $\U$
\begin{equation}
\label{eq:cateU}
\U = \X \bm{\alpha}^{T} + \matr{Z}
\end{equation}
où $\bm{\alpha}$ est la matrice des effets de la variable $\X$ sur les variables
latentes $\U$ et $\matr{Z}$ est une matrice de bruit indépendant de $\X$. La
matrice $\matr{Z}$ est estimée en même temps la matrice des axe factoriel grâce
à l'ACP de la projection de $\Y$ sur l'orthogonale de $\X$. Pour estimer la
matrice $\bm{\alpha}$, la méthode cate fait une régression linaire robuste de la
première ligne de la matrice $\Y$ transformée dans la base où le premier axe est
colinéaire à $\X$ par la matrice des axes factoriels $\V$ déjà estimée. Pour le
comprendre, en injectant eqref:eq:cateU dans l'équation de LFMM eqref:eq:model.
On peut écrire alors la matrice des coefficients de la régression linéaire de
$\Y$ par $\X$, notée $\bm{\tau}$, comme ceci
\begin{equation}
\bm{\tau} = \B + \V \bm{\alpha}^{T},
\end{equation}
où $\B$ est la matrice des effets dans l'équation eqref:eq:model. La méthode
cate estime $\bm{\alpha}$ en faisant une régression linéaire robuste de
$\bm{\tau}$ par l'estimation de la matrice des axe factoriels $\V$. Enfin, la
matrice des effets $\B$ est calculée comme le résidu de cette régression. La
régression robuste permet d'enlever de l'estimation de $\bm{\alpha}$ les effets
atypiques qui correspondent aux colonnes de $\Y$ associés à $\X$ que l'on
cherche. Nous avons utilisé le package R cate fourni par ses auteurs.

** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:

#+NAME: code:krakR
#+begin_src R 
  Sys.info()["nodename"]
  getwd()
#+end_src

#+RESULTS: code:krakR
:             nodename 
: "krakenator.imag.fr"
: [1] "/home/cayek/Projects/Thesis/MaThese"

Dans cette partie, nous présentons les expériences numériques que nous avons
réalisées pour évaluer la performance de nos algorithmes de correction pour les
facteurs confusions dans les études d'associations qui repose sur une estimation
$L_{1}$ et $L_{2}$ des paramètres de LFMM. Ces deux nouveaux algorithmes ont été
implémentés dans le langage de programmation R et seront appelés respectivement
ridgeLFMM pour l'estimation $L_{2}$ et lassoLFMM pour l'estimation $L_{1}$. Nous
nous sommes comparé aux méthodes que nous avons présentées dans la partie
[[sec:similar_method]]. Les méthodes de régression linéaires avec et sans les scores
de l'ACP ont été implémenté dans le langage R et sont respectivement appelées lm
et PCAlm. Pour les méthodes cate, sva-irw et sva-two-step nous avons
respectivement utilisé leurs implémentations R mises à disposition par leurs
auteurs respectifs.
*** Comparaison des méthodes sur des données simulées
**** Simulation à partir de données réelles
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 16:10] \\
  [[file:Rpackage/R/ExpRsampler-fromTrueData.R::ExpRmouline.ExpRsampler_fromTrueData%20<-%20function(s)%20{][La fonction sampler]]
:END:
Afin de comparer la performance des méthodes sur une étude d'association pour
laquelle nous connaissons la vérité, c'est à dire les colonnes de $\Y$ qui sont
associé à $\X$, nous avons réalisé des simulations à partir d'une matrice $\Y$
issue d'un vrai jeu de données. Pour cela nous réalisons une analyse en
composante principale de $\Y$ et ne gardons que les $\K$ premières composantes
en fonction du nombre $\K$ de facteurs de confusion que l'on souhaite simuler.
On a alors
\begin{equation}
\Y = \U \V^{T} + \E
\end{equation}
où $\V$ est la matrice des $\K$ axes principaux orthogonaux et $\U$ la matrice
des variables latentes calculés par l'ACP. La matrice $\E$ est la matrice
residuelle. Nous simulons ensuite la variable d'intérêt pour l'association
$\X^{'}$ et $\K$ variables latentes $\U^{'}$ en choisissant la corrélation entre
chaque variable latente et $\X^{'}$. De plus les variables latentes sont
simulées de sorte quelles aient la même structure de covariance que les
variables latentes calculées par l'ACP. Les matrices $\U^{'}$ et $\X^{'}$ sont
simulées à l'aide de la loi normale multidimensionnelle. Enfin nous calculons
une matrice des effets $\B^{'}$ de sorte qu'une certaines proportion des lignes
de $\B^{'}$ soit non nul et tiré selon à une loi normale. Nous calculons alors
la nouvelle matrice des variables explicatives tel que
\begin{equation}
\Y^{'} = \U^{'} \V^{T} + \X^{'} \B^{'}^{T} + \E.
\end{equation}
Nous avons ainsi des données pour lesquelles nous savons quelles colonnes de
$\Y^{'}$ est associées avec la variable $\X^{'}$, il s'agit des lignes non
nulles de la matrice $\B^{'}$. Nous utilisons de plus la structure lattente
d'une matrice de données déjà existante ce qui permet d'avoir des simulations
plus réalistes.

Le vrai jeu de données que nous avons choisi pour réaliser les simulations est
issu du jeu de données 1000Genome que nous présentons dans la partie [[sec:GEAS]].
Nous avons gardé seulement le chromosome 1 et 2, cela permet de simuler une
matrice de variable expliquées $\Y^{'}$ composée de 52211 variables pour 1758
individus. Nous avons choisi de simuler 5 variables latentes pour plusieurs
valeurs de la corrélation entre $\X^{'}$ et ces 5 variables latentes. Pour
chaque variable latente une valeur entre $-1$ et $1$ de la corrélation avec
$\X^{'}$ est tirée selon une loi uniforme et multipliée par un coefficient que
l'on nome $\rho$ prenant une des valeurs suivantes: $0.1$, $0.3$, $0.5$, $0.8$
ou $1$. Le même coefficient $\rho$ est utilisé pour calculer toutes les
corrélations. Plus le coefficient $\rho$ est proche de 1 plus les variables
latentes seront corrélées à $\X^{'}$ et donc plus la confusion lors du test
d'association de $\X^{'}$ avec $\Y^{'}$ sera importante. Nous avons de plus
choisi une proportion des variables expliquées associées avec la variable
explicative valant $1\%$, $5\%$, $10\%$, $15\%$ ou $20\%$. Pour chaque paramètre
de simulation nous avons simulé $5$ jeux de données ce qui donne un total de 125
jeux de données.

**** Mesure de comparaison des performances
Pour comparer les méthodes entre elles nous avons choisi deux critères. Chaque
méthode renvoie une \pvalue pour chaque colonne de $\Y$. Afin d'évaluer la
capacité des méthodes à détecter le plus possible d'association sans se tromper
nous avons calculer l'aire sous la courbe de précision-rappel, noté AUC, pour
chacune des méthodes. Nous rappelons que pour une liste de candidats données la
précision est le nombre de vraies associations dans la liste divisé par la
taille de la liste et le rappel est le nombre de vraies associations retrouvées
dans la liste divisé par le nombre total des vraies associations. Le rappel est
parfois appelé puissance en statistique. Une méthode qui donne les plus petites
\pvalues permettant de séparer parfaitement les vraies associations du reste
donne une aire sous la courbe de précision-rappel de 1. 

Le deuxième critère de comparaison des méthodes permet d'évaluer la calibration
des \pvalues renvoyées par les méthodes. Pour cela nous calculons le facteur
d'inflation sur les \pvalues attribuées aux variables non associées avec $\X$.
Si les \pvalues sont bien calibrées alors la distribution des \pvalues
attribuées aux colonnes de $\Y$ non associées avec $\X$ suivent une loi uniforme
et donc le facteur d'inflation vaux 1. Une méthode qui renvoie des \pvalues
correctement calibrées permet de calculer une liste de candidats avec un taux de
fausses découvertes moyen contrôlé à une valeur choisie. Pour cela on peut par
exemple utiliser l'algorithme de Benjamini-Hoshberg
cite:benjamini1995controlling ou bien le package qvalue cite:Storey_2011. Une
bonne méthode doit donc à la fois être capable de détecter les vrais
associations sans se tromper mais aussi de fournir des \pvalues correctement
calibrées pour permettre une utilisation des algorithmes de contrôle du taux de
fausse découverte.

**** Résultats
Sur les 125 jeux de données simulés nous avons lancé les méthodes lm, PCAlm,
sva-irw, sva-two-step, cate et les deux méthodes présentées dans cette thèse
lassoLFMM et ridgeLFMM. De plus, nous avons considéré une méthode oracle qui
fait le test d'association entre $\Y$ et $\X$ en connaissant les variables
latentes de la simulation. Les résultats sont résumés dans la Figure
ref:fig:method_comp. Les méthodes cate, lassoLFMM et ridgeLFMM ont les mêmes
performances que l'oracle sur toutes les simulations. Nous constatons toutefois
une exception sur les simulations avec un paramètre $\rho$ de corrélation entre
la variable explicative $\X$ et les variable latentes de $1$ pour cate et
ridgeLFMM qui renvoie des \pvalues avec un taux d'inflation moyen de $3.3$ alors
que celui de lassoLFMM vaux $1.3$ et celui de l'oracle $1.0$ (Figure
ref:fig:method_comp D). Les méthodes cate et ridgeLFMM donnent des résultats
très proches sur toutes les simulations. Les performances de la méthode lm sont
sensible au paramètre de corrélation $\rho$, lorsque celui-ci vaux $0.1$ l'AUC
et le facteur d'inflation de lm est presque égal à ceux de l'oracle mais le
facteur d'inflation croit jusqu'à plus de 30 et l'AUC décroit jusqu'à la moitié
de celui de l'oracle pour $\rho$ valant 1 (Figure ref:fig:method_comp B et D).
Les \pvalues de la méthode PCAlm sont toujours correctement calibrées puisque le
facteur d'inflation est toujours autour de 1 (Figure ref:fig:method_comp C et
D). Cependant l'écart de l'AUC de PCAlm avec l'AUC obtenu par l'oracle croit
avec la proportion de vrais associations et le paramètre de corrélation $\rho$
(Figure ref:fig:method_comp A et B). Enfin sva-two-step et sva-irw renvoient des
\pvalues correctement calibrées sauf quand le paramètre de corrélation $\rho$
vaut 0.8 et 1.0 (Figure ref:fig:method_comp C et D). L'AUC de sva-irw est
toujours en dessous de l'AUC de l'oracle pour toute les proportions de vrais
associations dans les simulations (Figure ref:fig:method_comp A) et la
différence de l'AUC de sva-irw avec de l'AUC de l'oracle croit avec le paramètre
de corrélation $\rho$ (Figure ref:fig:method_comp B). Nous observons également
que l'AUC de sva-two-step est très légèrement en dessous de l'AUC de l'oracle
pour toute les proportions de vrais asociations dans les simulations (Figure
ref:fig:method_comp A) et comme pour sva-irw la différence de l'AUC de
sva-two-step avec de l'AUC de l'oracle croit avec le paramètre de corrélation
$\rho$ mais plus faiblement que pour sva-irw (Figure ref:fig:method_comp B).

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[ht]
\centering
\includegraphics{./OUTPUT/Rplots/method_comp.pdf.png}
\caption{Comparaison des méthodes sur des simulations faites à partir du jeux de
  données 1000Genomes. A-B) Aire sous la courbe précision-rappel en fonction
  respectivement de la proportion de colonnes de $\Y$ associées à $\X$ et la
  corrélation de la variable explicative $\X$ avec les variables latentes. C-D)
  Facteur d'inflation calculé sur les variables nulles en fonction
  respectivement de la proportion de colonnes de $\Y$ associées à $\X$ et la
  corrélation de la variable explicative $\X$ avec les variables latentes.}
\label{fig:method_comp}
\end{sidewaysfigure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Échantillonnage des données
CLOSED: [2017-08-06 Sun 14:42]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_sampler
#+CAPTION: Le sampler qui a été utilisé pour la validation numérique. Dépend de [[code:1000g_G_valNum]]
#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  ## screePlot
  pl <- qplot(seq_along(var), var) +
    coord_cartesian(xlim = c(1,100))
  pl
  save_plot_png(pl, "valNum_screePlot.png")

#+end_src

#+RESULTS: code:num_val_sampler
[[./OUTPUT/Rplots/valNum_screePlot.png]]

#+NAME: code:num_val_dat
#+CAPTION: On sample les données. Dépend de [[code:num_val_sampler]]
#+begin_src R 
  ## sample all data
  library(MaTheseR)
  sampler <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  rep.nb.sampler <- 5
  prop.outlier <- c(0.01, 0.05, 0.1, 0.15, 0.2)
  rho.B <- 3
  rho.c <- c(0.1, 0.3, 0.5, 0.8, 1.0)
  nb.cluster <- 12
  library(foreach)
  library(doParallel)

  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  dat.files <-
    foreach(p = prop.outlier, .combine = 'c') %:%
    foreach(rho = rho.c, .combine = 'c') %:%
    foreach(i = 1:rep.nb.sampler, .combine = 'c') %dopar%
    {
      s <- sampler
      s$prop.outlier = p
      s$rho.B = rho.B
      s$rho.c = rho
      dat <- ExpRmouline(s)
      dat$meta$i <- i
      save_dat(dat, "ValNum", "1000g12", p = p, rho = rho, i = i, rho.B = rho.B)
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)
  save_dat(dat.files, "ValNum", "dat_list")

#+end_src
***** DONE Run des méthodes
CLOSED: [2017-08-14 lun. 11:28]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:28]
- Note taken on [2017-08-10 jeu. 10:24] \\
  ok mes méthodes performe bien :D on peut lancer le reste !!!
- Note taken on [2017-08-06 Sun 14:42] \\
  tail -f ValNum.y2017_m08_d06.log
- State "RUNNING"    from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_expr
#+CAPTION: Expérience de comparaison des méthodes sur les simulations. Dépend de [[code:num_val_dat]]
#+begin_src R 
  library(MaTheseR)
  library(foreach)
  library(doParallel)

  dat.files <- readRDS("./OUTPUT/Dat/ValNum/dat_list_cc6919e751d0b2b138c81d2abc21696a.rds")

  ## param
  K.method <- 5
  nb.cluster <- 4

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.num = 100,
                              relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method, method = "irw")
  m.sva_twostep <- method_sva(K.method, method = "two-step")
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param(force = FALSE, save = TRUE) +
    m.lm * param(force = FALSE, save = TRUE) +
    m.pca * param(force = FALSE, save = TRUE) +
    m.cate * param(force = FALSE, save = TRUE) +
    m.lasso * param(force = FALSE, save = TRUE) +
    m.oracle * param(force = FALSE, save = TRUE) + 
    m.sva_twostep * param(force = FALSE, save = TRUE) +
    m.sva_irw * param(force = FALSE, save = TRUE)
  ##   m.famt * param(force = FALSE, save = TRUE)

  ## main loop
  message("=== Main loop.")
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  df.res <-
    foreach(f = dat.files, .combine = 'rbind') %dopar%
    {
      dat <- readRDS(f)
      res <- data.frame()
      for (m in methods) {
        ## on force
        if (m$force) {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        } else if (exist_res(m , f)) {
          message("Retrieving", m$name)
          m.res <- retrieve_res(m , f)
        } else {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        }
        res <- ExpRextractor_fdr(dat, m.res, rep.sampler = dat$meta$i, rep.method = 1) %>%
          rbind(res)
        rm()
      }
      res
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save
  save_expr(df.res, "validation_numerique.rds")
  gc()

  ## plot auc
  toplot <- df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]

***** DONE Plots
CLOSED: [2017-08-14 lun. 11:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:47]
- State "RUNNING"    from "STARTED"    [2017-08-14 lun. 11:29]
- Note taken on [2017-08-08 mar. 13:48] \\
  j'attend que ca finisse ! et je filtrerais les couleurs et les nom des méthodes
  !
- State "STARTED"    from "RUNNING"    [2017-07-25 mar. 16:35]
- State "RUNNING"    from "DEBUG"      [2017-07-25 mar. 10:57]
- State "DEBUG"      from "TODO"       [2017-07-24 lun. 17:32]
- Note taken on [2017-07-24 lun. 17:31] \\
  Je sais pas ce j'ai foutu mais c'est super lourd !! ca doit être les test, faut
  que je les enleve du coup ! je vais le faire à part ! Et ca n'a pas exporter les
  bon res. ca plot pas les bonnes choses !
- Note taken on [2017-07-17 Lun 08:15] \\
  L'experience est fini il faut faire le plot et l'anova !!!
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:

#+NAME: code:num_val_auc_gif_df
#+CAPTION: Calcul de l'auc et le gif. Dépend de [[code:num_val_expr]]
#+begin_src R
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  auc.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_auc()
  save_expr(auc.df, "auc.df.rds")

  gif.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_gif()
  save_expr(gif.df, "gif.df.rds")
#+end_src

****** DONE Plots
CLOSED: [2017-08-14 lun. 11:46]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-08-14 lun. 11:46]
- Note taken on [2017-07-30 Sun 12:28] \\
  on attend que l'expr soit finis !!
- State "STARTED"    from "DONE"       [2017-07-30 Sun 12:28]
- State "DONE"       from "TODO"       [2017-07-30 Sun 12:28]
- Note taken on [2017-07-30 Sun 12:28] \\
  avec les barplot c'est pas mal !!
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_plot
#+CAPTION: Depend de [[code:num_val_auc_gif_df]]
#+begin_src R
  ## Compute plot !
  require(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(gridExtra)
  library(forcats)
  library(tidyverse)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds") 
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds") 


  ## filter and order method
  auc.df <- auc.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  auc.df$method %>% unique()
  gif.df <- gif.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  gif.df$method %>% unique()

  #################
  ## by prop outlier

  ## auc
  toplot <- auc.df %>%
    group_by(method, prop.outlier) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.prop.pl, "num_val_auc_prop.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, prop.outlier) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.prop.pl, "num_val_gif_prop.png")


  #################
  ## by rho

  ## auc
  toplot <- auc.df %>%
    group_by(method, rho.c) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.rho.pl, "num_val_auc_rho.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, rho.c) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.rho.pl, "num_val_gif_rho.png")


  ## plot for pdf
  ## helpers
  ## https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
  ## extract legend
  g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}

  ## C
  C.pl <- gif.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "bottom")
  mylegend <- g_legend(C.pl)
  C.pl <- C.pl +
    theme(legend.position = "none") +
    xlab("Proportion de vrais associations") +
    ylab("Facteur d'inflaction")

    ## A
    A.pl <- auc.prop.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("AUC")
    ## D
    D.pl <- gif.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab(TeX("Paramètre de corrélation entre et U et X ($\\rho$)")) +
      ylab("") 
    ## B
    B.pl <- auc.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("")

    pl <- cowplot::plot_grid(A.pl,B.pl,C.pl,D.pl,
                             ncol = 2, labels = c("A", "B", "C", "D"))

    ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 mylegend, nrow=2, heights=c(10, 1))
  })

  save_plot_png(pl.leg, filename = "method_comp.png")
  save_plot_MaTheseR(pl.leg, filename = "method_comp.pdf.png", height = 14, width = 20)
#+end_src

#+RESULTS: code:num_val_plot
[[./OUTPUT/Rplots/num_val_auc_prop.png]]
[[./OUTPUT/Rplots/num_val_gif_prop.png]]
[[./OUTPUT/Rplots/num_val_auc_rho.png]]
[[./OUTPUT/Rplots/num_val_gif_rho.png]]
[[./OUTPUT/Rplots/method_comp.png]]

****** CANCELLED Tests d'hypothèse
CLOSED: [2017-08-10 jeu. 11:30]
:LOGBOOK:
- State "CANCELLED"  from "STARTED"    [2017-08-10 jeu. 11:30]
- State "STARTED"    from "TODO"       [2017-07-30 Sun 12:28]
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_tests
#+CAPTION: Dépend de [[code:num_auc_gif_df]]
#+begin_src R 
  require(MaTheseR)
  library(broom)
  library(ggplot2)
  library(knitr)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds")
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds")

  auc.lm.res <- auc.df %>%
    mutate(method = as.factor(method)) %>%
    group_by(prop.outlier) %>%
    do(tidy(lm(auc ~ method, data = .))) %>%
    ungroup()
  toplot <- auc.lm.res %>%
    dplyr::filter(term != "(Intercept)")
  ggplot(toplot, aes(x = as.factor(prop.outlier),
                         color = p.value < 1e-5, y = estimate, fill = term)) +
    geom_bar(stat = "identity", position = "dodge")


  lm.res <- lm.res %>%
    dplyr::filter(term != "(Intercept)") %>%
    transmute(method = term, `-log10(p.value)` = -log10(p.value),
                estimate = estimate, prop.outlier = prop.outlier)
  kable(lm.res)

  ggplot(lm.res, ggplot2::aes(x = prop.outlier, y = p.value, color = as.factor(method))) +
    geom_boxplot()
#+end_src

*** Étude d'association entre des niveaux de méthylation de l'ADN et la polyarthrite rhumatoïde (EWAS)
<<sec:ewas>>

La polyarthrite rhumatoïde est une maladie auto-immune d'origine inconnue. Dans
cette étude nous souhaitons étudier le rôle de la méthylation de l'ADN dans le
développement de la polyarthrite rhumatoïde. La méthylation de l'ADN est un
processus au cours duquel un groupe méthyle est ajouté aux molécules d'ADN. La
méthylation peut changer l'activité de l'ADN et en particulier modifier sa
transcription en protéine. Pour cette étude nous nous intéressons au niveau de
méthylation de $485 577$ sites de l'ADN pour 354 individus atteints de
polyarthrite rhumatoïde et 335 individus sains. Il est connu que la methylation
de l'ADN dépend de l'âge, du sexe et de la consommation de tabac. Nous savons
aussi que le type de la cellule sur laquelle on pratique la mesure influence le
niveau de méthylation. Tous ces facteurs peuvent être des facteurs de confusion
pour l'étude d'association avec la maladie, ils ont d'ailleurs été pris en
compte explicitement dans les études d'association qui ont été faites à partir
des mêmes données que celles étudiées ici cite:Rahmani_2016,Zou_2014,Liu_2013.
Afin d'évaluer la capacité des méthodes à bien corriger pour les facteurs de
confusion, nous ne prenons pas en compte les facteurs de confusion connus et
nous comparons les résultats à ceux obtenus par les études cite:Rahmani_2016 et
cite:Zou_2014 qui prennent en compte explicitement les facteurs de confusion
connus.

De la même façon que dans cite:Zou_2014 nous avons filtré les sites avec un
niveau de methylation moyen constitutif, c'est à dire inférieur à 0.2 ou
supérieur à 0.8. De plus, nous avons centré et divisé par l'écart type les
données de méthylation. Nous avons ensuite lancé les méthodes cate, lm, PCAlm,
sva-irw, sva-two-step, lassoLFMM, ridgeLFMM afin de trouver les sites de
méthylation de l'ADN associés à la polyarthrite. Nous avons choisi $\K = 10$
pour le nombre de variables latentes (voir Figure ref:fig:ewas_params A et B).
Pour $\K = 10$, les valeurs du paramètre de régularisation $L_{2}$ $\lambRidge$
entre $10^{-10}$ et $1$ donnent les mêmes valeurs d'erreur de prédiction moyen
(Figure ref:fig:ewas_params C), nous avons choisi de prendre $\lambRidge =
10^{-5}$ pour ridgeLFMM. Nous avons choisi la proportion de lignes non nulles
pour de la matrice des effets $\B$ valant $1 \%$ pour lassoLFMM.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre des sites
  méthylation de l'ADN et la maladie polyarthrite rhumatoïde. A) Proportion de
  variance expliquées de la projection de $\Y$ sur l'espace orthogonal à $\X$
  (c'est à dire $\matr{D}_{0} \Q^{T} \Y$) par chacune des composantes
  principales. B)C) Erreur de prédiction calculée grâce à la validation croisée
  des estimateurs $L_{2}$ des paramètres de LFMM pour différente valeurs du
  paramètre de régularisation $\lambda$ et du nombre variable latentes $\K$, le
  point représente l'erreur de prédiction moyen et les bar l'erreur standard. La
  ligne pointillée vertical marque sur A et B le nombre de variables latentes
  choisies, c'est à dire 10, et sur C le paramètre de régularisation choisie,
  c'est à dire $10^{-5}$. }
\label{fig:ewas_params}
\end{figure}
#+END_EXPORT

La figure ref:fig:ewas_qqplot_top A montre la distribution observée des \pvalues
pour chaque site de méthylation renvoyées par chaque méthode contre la
distribution théorique hypothèse nulle. On constate une inflation du nombre de
petites \pvalues pour toutes les méthodes. Il y à une forte inflation pour lm et
sva-irw. La figure ref:fig:ewas_qqplot_top B montre la proportion des candidats
identifiés par cite:Zou_2014,Rahmani_2016 qui sont retrouvés dans les top listes
de chaque méthode. Nous rappelons que les candidats identifiés par
cite:Zou_2014,Rahmani_2016 ont été identifiés en prenant en compte les facteurs
de confusion tel que l'age, le sexe et une estimation de la composition
cellulaire. Toutes les méthodes considéré dans notre analyse retrouvent les
candidats de la littérature dans leurs top 40 sauf lm et sva_irw. Pour la
méthode lm il faut prendre le top 11881 pour trouver le premier candidat de
cite:Zou_2014,Rahmani_2016 et le top 138038 pour tous les avoirs, pour la
méthode sva-irw les candidats de cite:Zou_2014,Rahmani_2016 sont tous identifiés
entre le top $5111$ et $87659$.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base 10 des
  \pvaleurs renvoyées par chaque méthode. Les quantiles théoriques suivent la
  loi exponetielle. B) Proportion des candidats proposés par \cite{Rahmani_2016}
  et \cite{Zou_2014} retrouvés dans la top liste revoyée par chaque méthode.}
\label{fig:ewas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste obtenue quand on contrôle
le taux de fausse découverte (FDR) à $1 \%$. Toutefois les algorithmes de
contrôle du FDR nécessitent que les \pvalues soient correctement calibrées. Pour
cela nous avons calibrées les \pvalues grâce à la méthode présentée dans la
partie [[sec:calibration]]. Le contrôle du FDR a été fait à l'aide du package R
qvalue cite:Storey_2011. La figure ref:fig:ewas_venn montre les intersections
entre les méthodes. Nous avons écarté lm et sva-irw car ils renvoyaient des
listes trop différentes des autres. Parmi les 19 sites de méthylation renvoyés
par toutes les méthodes on retrouve les 5 candidats identifiés dans
cite:Zou_2014,Rahmani_2016.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_venn.pdf.png}
\caption{Diagramme de Venn de la liste des candidats controlés à un taux de
  fausses de découvertes de 1 \%.}
\label{fig:ewas_venn}
\end{figure}
#+END_EXPORT

#+NAME: code:ewas_table
#+CAPTION: Dépend de [[ewas_venn]]
#+begin_src R :results output latex :exports results
  library(xtable) ## https://cran.r-project.org/web/packages/xtable/vignettes/xtableGallery.pdf

  inter.cpg.df <- readRDS( "./OUTPUT/Expr/ewas_table.rds")

  ## scientific notation
  inter.cpg.df <- inter.cpg.df %>%
    mutate(cate = format(cate, digits = 2, scientific = TRUE),
           PCAlm = format(PCAlm, digits = 2, scientific = TRUE),
           lassoLFMM = format(lassoLFMM, digits = 2, scientific = TRUE),
           ridgeLFMM = format(ridgeLFMM, digits = 2, scientific = TRUE))

  ## bold candidates
  bold <- function(id) {
    paste0("\\textbf{",id,"}")
  }
  eval(quote(inter.cpg.df$ID[Outlier] <<- sapply(ID, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$cate[Outlier] <<- sapply(cate, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$PCAlm[Outlier] <<- sapply(PCAlm, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$ridgeLFMM[Outlier] <<- sapply(ridgeLFMM, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$lassoLFMM[Outlier] <<- sapply(lassoLFMM, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$Position[Outlier] <<- sapply(Position, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$Chr[Outlier] <<- sapply(Chr, bold)[Outlier]), inter.cpg.df)
  eval(quote(inter.cpg.df$Gene[Outlier] <<- sapply(Gene, bold)[Outlier]), inter.cpg.df)

  ## remove repetition
  inter.cpg.df <- inter.cpg.df %>%
    mutate(Gene = sub(";.*", "", Gene))

  ## print
  inter.cpg.df %>%
    dplyr::select(-Outlier) %>%
    xtable(digits = -2,
           type = "latex",
           caption = "Sites de méthylation trouvées par les méthodes PCAlm, lassoLFMM, ridgeLFMM et cate pour un taux de fausse décourverte controlé à 1$\\%$ pour l'EWAS. Les Sites de méthylation en gras sont les candidats de \\cite{Zou_2014, Rahmani_2016}") %>%
    print(include.rownames=FALSE,
          sanitize.text.function=identity,
          floating.environment = "sidewaystable")
#+end_src

#+RESULTS: code:ewas_table
#+BEGIN_EXPORT latex
% latex table generated in R 3.4.1 by xtable 1.8-2 package
% Sat Sep 16 16:57:05 2017
\begin{sidewaystable}[ht]
\centering
\begin{tabular}{llllllll}
  \hline
ID & Chr & Position & Gene & PCAlm & lassoLFMM & cate & ridgeLFMM \\ 
  \hline
\textbf{cg16411857} & \textbf{16} & \textbf{57023191} & \textbf{NLRC5} & \textbf{9.2e-13} & \textbf{2.4e-12} & \textbf{6.6e-12} & \textbf{5.3e-12} \\ 
  \textbf{cg07839457} & \textbf{16} & \textbf{57023022} & \textbf{NLRC5} & \textbf{1.9e-11} & \textbf{4.5e-11} & \textbf{1.1e-10} & \textbf{9.7e-11} \\ 
  \textbf{cg05428452} & \textbf{6} & \textbf{32712979} & \textbf{HLA-DQA2} & \textbf{5.4e-11} & \textbf{4.6e-11} & \textbf{8.5e-11} & \textbf{8.8e-11} \\ 
  cg02508743 & 8 & 56903623 & LYN & 2.9e-08 & 2.7e-08 & 2.7e-08 & 2.8e-08 \\ 
  \textbf{cg20821042} & \textbf{6} & \textbf{32709158} & \textbf{HLA-DQA2} & \textbf{6.5e-08} & \textbf{6.1e-08} & \textbf{9.6e-08} & \textbf{1.0e-07} \\ 
  cg13081526 & 6 & 32449961 &  & 1.5e-07 & 1.2e-07 & 2.0e-07 & 2.2e-07 \\ 
  cg18052547 & 6 & 32552547 & HLA-DRB1 & 1.8e-07 & 1.8e-07 & 3.0e-07 & 3.1e-07 \\ 
  \textbf{cg25372449} & \textbf{6} & \textbf{32490350} & \textbf{HLA-DRB5} & \textbf{2.5e-07} & \textbf{2.6e-07} & \textbf{4.5e-07} & \textbf{4.6e-07} \\ 
  cg02030958 & 13 & 110386267 &  & 4.0e-07 & 7.8e-08 & 6.0e-08 & 1.1e-07 \\ 
  cg16171858 & 3 & 58472734 &  & 4.6e-07 & 1.6e-07 & 2.7e-08 & 3.8e-08 \\ 
  cg03280622 & 8 & 145023013 & PLEC1 & 4.7e-07 & 5.0e-09 & 5.8e-09 & 3.8e-08 \\ 
  cg24150157 & 19 & 51891210 & LIM2 & 6.2e-07 & 3.1e-07 & 1.6e-07 & 2.1e-07 \\ 
  cg26244575 & 12 & 76354015 &  & 6.9e-07 & 2.7e-09 & 5.0e-10 & 4.2e-09 \\ 
  cg05370853 & 6 & 32606634 & HLA-DQA1 & 7.1e-07 & 3.0e-07 & 3.3e-07 & 4.4e-07 \\ 
  cg14989316 & 10 & 80757927 & LOC283050 & 7.3e-07 & 6.1e-08 & 7.8e-08 & 2.1e-07 \\ 
  cg17360552 & 6 & 32725332 & HLA-DQB2 & 8.1e-07 & 6.1e-07 & 1.1e-06 & 1.2e-06 \\ 
  cg01373248 & 3 & 18480297 & SATB1 & 8.1e-07 & 1.4e-07 & 1.1e-07 & 2.5e-07 \\ 
  cg26164488 & 2 & 64440295 &  & 9.3e-07 & 3.5e-09 & 1.6e-09 & 1.4e-08 \\ 
  cg05874806 & 2 & 102350276 & MAP4K4 & 1.1e-06 & 1.1e-06 & 4.7e-07 & 5.6e-07 \\ 
   \hline
\end{tabular}
\caption{Sites de méthylation trouvées par les méthodes PCAlm, lassoLFMM, ridgeLFMM et cate pour un taux de fausse décourverte controlé à 1$\%$ pour l'EWAS. Les Sites de méthylation en gras sont les candidats de \cite{Zou_2014, Rahmani_2016}} 
\end{sidewaystable}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Télécharger les données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_ddl
#+CAPTION: Téléchargement des données pour l'EWAS.
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC

#+NAME: code:ewas_format
#+CAPTION: Formatage des données pour l'EWAS. Dépend de [[code:ewas_ddl]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC

***** DONE Preprocessing des données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_prepross
#+CAPTION: Preprocessing des données pour l'EWAS. Dépend de [[code:ewas_format]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC

#+NAME: code:ewas_G_X
#+CAPTION: Centrage et normalisation des données pour l'EWAS. Dépend de [[code:ewas_prepross]].
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

***** DONE Sites candidats detectés dans d'autres études
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+NAME: code:ewas_candidates
#+CAPTION: Dépend de [[code:ewas_G_X]]
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
***** DONE Scree plot 
CLOSED: [2017-08-22 mar. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:31]
- State "TODO"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:18]
- State "DONE"       from "RUNNING"    [2017-07-25 mar. 18:05]
- Note taken on [2017-07-25 mar. 17:56] \\
  tail -f ewas_screeplot.y2017_m07_d25_krakenatorh_juil..log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:51]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:

#+NAME: code:ewas_screeplot
#+CAPTION: Dépend de [[code:ewas_G_X]] 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- "./Data/ThesisDataset/3Article/GSE42861/X.rds"

  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "ewas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30))
  pl
  save_plot_png(pl, "ewas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-21 lun. 17:38]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:38]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:05]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 12:57]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 11:07]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 11:00]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 10:21]
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 10:49]
- Note taken on [2017-07-26 mer. 19:36]
- Note taken on [2017-07-26 mer. 18:05] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_cv_lambda.y2017_m07_d26.log
  tail -f /home/cayek/tmp/Logfiles/ewas_cv.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 17:56] \\
  On va relancer... il y avait des bug dans la CV...
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 17:56]
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+NAME: code:ewas_CV
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,20, 25,30, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

#+NAME: code:ewas_CV_encore
#+CAPTION: Dépend de [[ewas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(6,7,8,9))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:ewas_CV_encore_encore
#+CAPTION: Dépend de [[ewas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 11:19)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore_encore.png")
#+end_src


#+NAME: code:ewas_CV_lambda
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1.0, 1e5, 1e10)
  nb.cluster <- 5
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 9:11)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lambda_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda.png")

  ## plot smooth
  pl <- ggplot(res.cv$errs, aes(y = err, x = log(lambda))) +
    geom_smooth()
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda_smooth.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda_smooth.png]]
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda.png]]

***** DONE Étude du jeu de données
CLOSED: [2017-08-07 lun. 18:35]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-07 lun. 18:35]
- State "RUNNING"    from "DONE"       [2017-08-07 lun. 16:39]
- Note taken on [2017-08-07 lun. 16:35] \\
  j'ai rajouté sva two-step a l'arrache
  #+begin_src R :results output :exports both
    expr.all <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  
    expr.all$df.res$method[expr.all$df.res$method == "sva"] = "sva-irw"
  
    expr.all$df.res <- expr.all$df.res %>%
      rbind(expr$df.res)
  
    summarise(expr.all$df.res)
  
  
    save_expr(expr.all, "EWAS_all.rds")
  #+end_src
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 11:01]
- Note taken on [2017-07-26 mer. 19:44] \\
  Du coup j'ai relancé avec K = 10 et le bon lasso !!!!!! on va voir
- Note taken on [2017-07-26 mer. 19:43] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 19:43]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:

#+NAME: code:ewas_expr
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.num = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method)
  m.sva_2step <- method_sva(K.method, method = "two-step")

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva_irw * param() +
    m.sva_2step * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")

#+end_src

#+NAME: code:ewas_expr_log
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src shell :session *ssh krakenator* :results output 
  cat /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
#+end_src

#+RESULTS: code:ewas_expr_log
#+begin_example
  R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
  Copyright (C) 2017 The R Foundation for Statistical Computing
  Platform: x86_64-redhat-linux-gnu (64-bit)
  
  R est un logiciel libre livré sans AUCUNE GARANTIE.
  Vous pouvez le redistribuer sous certaines conditions.
  Tapez 'license()' ou 'licence()' pour plus de détails.
  
  R est un projet collaboratif avec de nombreux contributeurs.
  Tapez 'contributors()' pour plus d'information et
  'citation()' pour la façon de le citer dans les publications.
  
  Tapez 'demo()' pour des démonstrations, 'help()' pour l'aide
  en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
  Tapez 'q()' pour quitter R.
  
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  foreach: simple, scalable parallel programming from Revolution Analytics
  Use Revolution R for scalability, fault tolerance and more.
  http://www.revolutionanalytics.com
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
             disease.state
  GSM1051525     0.9720875
  GSM1051526     0.9720875
  GSM1051527     0.9720875
  GSM1051528     0.9720875
  GSM1051529     0.9720875
  GSM1051530     0.9720875
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
  +                             lambda.num = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
  +   m.lm * param() +
  +   m.pca * param() +
  +   m.cate * param() +
  +   m.famt * param() +
  +   m.sva * param() +
  +   m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9528 on localhost:11939 at 19:35:29.343
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9538 on localhost:11939 at 19:35:33.199
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9548 on localhost:11939 at 19:35:37.112
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9558 on localhost:11939 at 19:35:41.000
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
  +              samplers = samplers,
  +              preprocessors = NULL,
  +              rep.nb.method = 1,
  +              methods = methods,
  +              extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  === Sampling data.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  === Main loop.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  Computing latent variables
  Computing latent variables
  running hp
          pvalue    colname index outlier     score rep.sampler rep.method method
  1 3.208532e-08 cg00000029     1   FALSE -5.593741           1          1     lm
    method.K method.lambda
  1       NA            NA
  Computing latent variables
  Computing latent variables
  Loading required package: impute
  running hp
  `Rows with missing values`
  integer(0)
  `Columns with missing values`
  integer(0)
  
  running hp
       pvalue    colname index outlier      score rep.sampler rep.method
  1 0.6757066 cg00000029     1   FALSE -0.4185102           1          1
       method method.K method.lambda
  1 ridgeLFMM       10         1e-04
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.9531602 cg00000029     1   FALSE 0.05876053           1          1  PCAlm
    method.K method.lambda
  1       10            NA
  Number of significant surrogate variables is:  10 
  Computing latent variables
  It = 1/100, err2 = 0.998548621190457
  It = 2/100, err2 = 0.652592023099809
  It = 3/100, err2 = 0.652018379539831
  [1] "Fitting Factor Analysis Model with 10 factors"
  It = 4/100, err2 = 0.651990819329085
  It = 5/100, err2 = 0.65201511610208
  Iteration (out of 5 ):It = 6/100, err2 = 0.65202139222764
  It = 7/100, err2 = 0.652022747619974
  === lambda = 0.184666840535516, no zero B proportion = 0.00564682358459127
  It = 1/100, err2 = 0.652023080891458
  It = 2/100, err2 = 0.651977189044589
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.6618566 cg00000029     1   FALSE -0.4373513           1          1   cate
    method.K method.lambda
  1       10            NA
  It = 3/100, err2 = 0.651967304634796
  It = 4/100, err2 = 0.651964288072884
  It = 5/100, err2 = 0.65196318471777
  === lambda = 0.138480594373303, no zero B proportion = 0.0549685876152507
  running hp
       pvalue    colname index outlier     score rep.sampler rep.method    method
  1 0.8961906 cg00000029     1   FALSE -0.130524           1          1 lassoLFMM
    method.K method.lambda
  1       10            NA
  1  2  [1] "Fitting Factor Analysis Model with 10 factors"
  3         pvalue    colname index outlier    score rep.sampler rep.method method
  1 1.13824e-05 cg00000029     1   FALSE 19.55117           1          1   famt
    method.K method.lambda
  1       10            NA
  4  5         pvalue    colname index outlier    score rep.sampler rep.method method
  1 3.94329e-12 cg00000029     1   FALSE 49.94426           1          1    sva
    method.K method.lambda
  1       10            NA
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")
  Expr save in ./OUTPUT/Expr/EWAS_all.rds


  >
#+end_example

****** DONE Charger l'expérience et les candidats
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_load_res
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS: code:ewas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:


#+NAME: code:ewas_calibration
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:ewas_calibration
#+begin_example
# A tibble: 8 x 3
        method        mad     median
         <chr>      <dbl>      <dbl>
1         cate  1.2870855 0.04677596
2         famt  6.2659293 4.33328808
3    lassoLFMM  1.2387777 0.02799659
4           lm  4.2127155 0.04534315
5        PCAlm  1.2268129 0.03996082
6    ridgeLFMM  1.2745703 0.04853927
7 sva_two-step  0.9842079 0.71781997
8      sva-irw 10.8418062 7.58318108
#+end_example

Pour sva_irw et sva_two-step les scores sont des Fscrore ! On ne peut pas
calibrer avec le MAD !!! C'est surement idem pour famt

****** DONE Les qqplots ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_qqplots
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+end_src

#+RESULTS: code:ewas_qqplots
[[./OUTPUT/Rplots/EWAS_qqplots.png]]
[[./OUTPUT/Rplots/EWAS_qqplots2.png]]

****** DONE Le top et rank des candidats
CLOSED: [2017-07-27 jeu. 11:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:35]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_top
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")

  ## rang du dernier candidats
  expr$df.res %>%
    mutate(outlier = index %in% candidates) %>%
    group_by(method) %>%
    dplyr::arrange(pvalue, method) %>%
    mutate(rk = seq_along(pvalue)) %>%
    summarise(rk.min = min(rk[outlier]),
              rk.max = max(rk[outlier]))
#+end_src

#+RESULTS: code:ewas_top
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+begin_example
# A tibble: 8 x 2
        method power
         <chr> <dbl>
1         cate   0.8
2         famt   0.0
3    lassoLFMM   1.0
4           lm   0.0
5        PCAlm   1.0
6    ridgeLFMM   1.0
7 sva_two-step   1.0
8      sva-irw   0.0
# A tibble: 8 x 3
        method rk.min rk.max
         <chr>  <int>  <int>
1         cate      1     37
2         famt   9326  27941
3    lassoLFMM      1     24
4           lm  11881 138038
5        PCAlm      1      8
6    ridgeLFMM      1     25
7 sva_two-step      1     18
8      sva-irw   5111  87659
#+end_example

****** DONE Contrôle du FDR à $0.01$
CLOSED: [2017-07-27 jeu. 11:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:37]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_fdr
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+end_src

#+RESULTS: code:ewas_fdr
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 7 x 2
        method power
         <chr> <dbl>
1         cate   1.0
2         famt   1.0
3    lassoLFMM   1.0
4        PCAlm   1.0
5    ridgeLFMM   1.0
6 sva_two-step   1.0
7      sva-irw   0.6
#+end_example

****** DONE Venn diagram fdr 0.01
CLOSED: [2017-07-27 jeu. 11:39]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(sva = toplot$index[toplot$method == "sva_two-step"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS: code:ewas_venn
[[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

****** DONE Venn diagram top 100
CLOSED: [2017-08-07 lun. 18:02]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 18:02]
- State "TODO"       from "DONE"       [2017-08-07 lun. 17:57]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn_top
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  ## 0.05 % de p
  p <- max(expr$df.res$index)
  0.0005 * p

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(100) %>%
    ungroup() 


  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_top100_venn.png")
#+end_src

#+RESULTS: code:ewas_venn_top
[[./OUTPUT/Rplots/ewas_top100_venn.png]]
: [1] 81.019

****** DONE plot top * power
CLOSED: [2017-08-07 lun. 17:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 17:56]
- State "TODO"       from              [2017-08-07 lun. 17:26]
:END:
#+NAME: code:ewas_top_power
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :results output :exports both
  candidates
  m1 <- length(candidates)
  expr$df.res

  df <- expr$df.res %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50))
  pl
  save_plot_png(pl, "ewas_top_power.png")
#+end_src

#+RESULTS: code:ewas_top_power
[[./OUTPUT/Rplots/ewas_top_power.png]]

****** DONE Meta analysis avec la distance de mahalanobis
CLOSED: [2017-09-15 ven. 17:51]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-15 ven. 17:51]
- State "TODO"       from              [2017-09-15 ven. 16:35]
:END:
On va combiner les zscores avec la distance de mahalanobis: 
- https://fr.wikipedia.org/wiki/Distance_de_Mahalanobis : le test d'hypotèse est
  décrit ici.
- https://en.wikipedia.org/wiki/Mahalanobis_distance

Ca fait une union des méthodes, plus une variable sort de l'elispe plus 
sa pvalue sera petite.

On ne garde que cate, lassoLFMM, ridgeLFMM, PCAlm et sva_twostep

On utilise l'implémentation de pcadapt qui estime la matrice de covariance
avec l'estimateur robuste : *Orthogonalized Gnanadesikan-Kettenring pairwise estimator*

#+NAME: code:ewas:mahalanobis
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese
  library(pcadapt)

  ## meta-analisis with mahanalobis
  ## I do not understand why it do not work without ind...
  ## solution found https://stackoverflow.com/questions/43259380/spread-with-duplicate-identifiers-using-tidyverse-and
  Z.df <- expr$df.res %>%
    dplyr::filter(method %in% c("cate", "lassoLFMM", "ridgeLFMM", "PCAlm", "sva_two-step")) %>%
    dplyr::select(method, score, colname, index,outlier) %>%
    group_by(method) %>%
    tidyr::spread(method, calibrated.score)
  Z.df
  Z <- Z.df[,c(-1,-2,-3)] %>% as.matrix()
  dim(Z)
  colnames(Z)
  anyNA(Z)

  mahalanobis.res <- covRob_cpp(Z)

  ## dist
  Z.df <- Z.df %>%
    mutate(mahalanobis.dist = mahalanobis.res$dist%>%as.numeric())
  ggplot(Z.df, aes(mahalanobis.dist)) +
    geom_histogram()
  ggplot(Z.df, aes(y = mahalanobis.dist, x = seq_along(mahalanobis.dist), color = outlier)) +
    geom_point()


  ## compute pvalue
  Z.df <- Z.df %>%
    mutate(pvalue = pchisq(mahalanobis.dist, df = 5, lower.tail = FALSE))
  ggplot(Z.df, aes(pvalue)) +
    geom_histogram() ## :D

  ## recalibration
  gif <- median(Z.df$mahalanobis.dist) / qchisq(0.5, df = 1)
  Z.df <- Z.df %>%
    mutate(recalibrated.pvalue = pchisq(mahalanobis.dist / gif, df = 1, lower.tail = FALSE))
  ggplot(Z.df, aes(recalibrated.pvalue)) +
    geom_histogram()

  ## top by dist
  Z.df %>%
    dplyr::arrange(desc(mahalanobis.dist)) %>%
    dplyr::filter(row_number() < 20) %>%
    print.data.frame()


  ## save res
  save_expr(Z.df, "ewas_mahanalobis.rds")
#+end_src

#+RESULTS: code:
#+begin_example
# A tibble: 162,038 x 8
      colname index outlier       cate   lassoLFMM       PCAlm  ridgeLFMM
 *      <chr> <int>   <lgl>      <dbl>       <dbl>       <dbl>      <dbl>
 1 cg00000029     1   FALSE -0.3761422 -0.12796535  0.01532402 -0.3664368
 2 cg00000165     2   FALSE -0.3660100 -0.26239103 -0.26650002 -0.4112348
 3 cg00000236     3   FALSE -0.1827646 -0.08431626  0.09560440 -0.1333556
 4 cg00000289     4   FALSE  1.2829818  1.12346217  1.06928797  1.3040504
 5 cg00000321     5   FALSE -0.1397402 -0.23408087 -0.26268544 -0.1548929
 6 cg00000363     6   FALSE  0.6435748  0.61728208  0.59508989  0.6252669
 7 cg00000658     7   FALSE -1.3271343 -1.27313197 -1.29301157 -1.3955362
 8 cg00000807     8   FALSE -1.2751202 -1.39045154 -1.48968175 -1.2928754
 9 cg00000924     9   FALSE -1.0563266 -0.77330602 -0.70157261 -1.0659883
10 cg00001099    10   FALSE -0.5107669 -0.42094594 -0.44711010 -0.5382614
# ... with 162,028 more rows, and 1 more variables: `sva_two-step` <dbl>
[1] 162038      5
[1] "cate"         "lassoLFMM"    "PCAlm"        "ridgeLFMM"    "sva_two-step"
[1] FALSE
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
      colname  index outlier      cate lassoLFMM     PCAlm ridgeLFMM
1  cg16411857 101455    TRUE -6.865840 -7.008935 -7.142457 -6.897722
2  cg07839457  51546    TRUE -6.445807 -6.586964 -6.713112 -6.471476
3  cg05428452  36714    TRUE -6.492214 -6.583422 -6.560629 -6.486125
4  cg26244575 153700   FALSE  6.218716  5.950348  4.965036  5.876325
5  cg02508743  17619   FALSE  5.561682  5.557813  5.545263  5.552689
6  cg26164488 153263   FALSE -6.037328 -5.906131 -4.906335 -5.669689
7  cg03280622  22680   FALSE -5.821323 -5.847969 -5.037990 -5.500901
8  cg20821042 125220    TRUE -5.333727 -5.416535 -5.403386 -5.326584
9  cg16171858 100108   FALSE  5.560155  5.240551  5.040972  5.498666
10 cg02030958  14387   FALSE  5.418047  5.370905  5.069725  5.307414
11 cg13081526  81184   FALSE -5.200270 -5.297436 -5.249608 -5.182162
12 cg14989316  93666   FALSE -5.370882 -5.415048 -4.953549 -5.192574
13 cg24150157 142554   FALSE  5.235941  5.119322  4.985110  5.192011
14 cg01373248   9879   FALSE  5.305933  5.270222  4.931840  5.156338
15 cg18052547 110532   FALSE -5.123051 -5.220443 -5.216318 -5.118463
16 cg05874806  39305   FALSE  5.038504  4.864156  4.864469  5.005384
17 cg02435083  17139   FALSE -5.559756 -5.301292 -4.273959 -5.243371
18 cg05370853  36316   FALSE -5.103511 -5.121673 -4.959630 -5.051942
19 cg25372449 149131    TRUE -5.046244 -5.153984 -5.155173 -5.044186
   sva_two-step mahalanobis.dist pvalue recalibrated.pvalue
1      76.85285         8106.560      0       1.284598e-128
2      67.55958         6275.212      0       5.264320e-100
3      66.28534         6046.792      0        1.955346e-96
4      46.22117         3233.695      0        1.960667e-52
5      48.21138         3201.969      0        6.155444e-52
6      45.34648         3197.396      0        7.258918e-52
7      43.77251         2916.795      0        1.803876e-47
8      45.19053         2828.148      0        4.417261e-46
9      43.47836         2626.962      0        6.283704e-43
10     42.79226         2557.593      0        7.685553e-42
11     41.76834         2424.779      0        9.293237e-40
12     40.25901         2344.918      0        1.662163e-38
13     40.94076         2321.189      0        3.916290e-38
14     40.44027         2304.669      0        7.112326e-38
15     40.55306         2284.542      0        1.471451e-37
16     40.08606         2238.044      0        7.892910e-37
17     36.77867         2233.849      0        9.184228e-37
18     39.54110         2185.929      0        5.187371e-36
19     39.42279         2160.502      0        1.300001e-35
#+end_example

Les pvalues sont assez énorme... Il faut 20 site de méthylation pour trouver les
5 ...

****** DONE Gene annotation
CLOSED: [2017-09-16 sam. 15:18]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-16 sam. 15:18]
- State "TODO"       from              [2017-09-15 ven. 17:51]
:END:

Les données on été faite à partir d'une puce Illumina 450K. Du coup : https://www.biostars.org/p/92569/. Finnalement, le pkg de ce post est deprecated. Je vais utiliser ce pkg : https://github.com/perishky/meffil/wiki/CpG-annotations

On annote le top 20 du test de mahalanobis

#+NAME: code:ewas:annotation
#+CAPTION: Dépend de [[code:ewas:mahalanobis]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/ :results output org
  library(MaTheseR)
  library(meffil)
  library(ascii)

  ## get data annotation
  meffil.list.featuresets()
  cpG.df <- meffil.get.features("450k")
  cpG.df %>% head()

  Z.df <- readRDS("./OUTPUT/Expr/ewas_mahanalobis.rds")
  top.cpg.df <- Z.df %>%
    dplyr::arrange(desc(mahalanobis.dist)) %>%
    dplyr::filter(row_number() < 20) %>%
    mutate(name = colname) %>%
    left_join(cpG.df,by = "name")

  ## names(top.cpg.df)

  res <- top.cpg.df %>%
    dplyr::select(recalibrated.pvalue,
                  colname, gene.symbol, outlier, chromosome, position) %>%
    as.data.frame() %>%
    ascii(include.rownames = FALSE)
  print(res, type = "org")
#+end_src

#+RESULTS: code:ewas:annotation

***** DONE Plots
CLOSED: [2017-08-06 Sun 14:25]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:25]
:END:
****** DONE Choix des paramètres
CLOSED: [2017-08-29 mar. 11:46]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-29 mar. 11:46]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "TODO"       [2017-08-08 mar. 15:08]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:
#+NAME: code:ewas_screeplot_CV
#+CAPTION: Dépend de [[code:ewas_screeplot]] [[code:ewas_CV]] [[code:ewas_CV_lambda]] [[code:ewas_CV_encore]] [[code:ewas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  df.res <- readRDS("./OUTPUT/Expr/ewas_screeplot_expr.rds")
  plA <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 10, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "ewas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.4)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 10, linetype = "dashed") +
    coord_cartesian(xlim = c(1,30)) +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "ewas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.5)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    ylab("Erreur de\nprédiction") +
    geom_vline(xintercept = 1e-5, linetype = "dashed") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.15, 0.8))
  save_plot_png(plC, "ewas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "ewas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:ewas_screeplot_CV
: [[./OUTPUT/Rplots/ewas_screeplot.png]]
: [[./OUTPUT/Rplots/ewas_CV_K.png]]
: [[./OUTPUT/Rplots/ewas_CV_lambda.png]]
: [[./OUTPUT/Rplots/ewas_hyperparams.pdf.png]]

****** DONE Résultats des méthodes
CLOSED: [2017-08-09 mer. 13:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-09 mer. 13:56]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:

#+NAME: code:ewas_qqplot_top
#+CAPTION: Dépend de [[code:ewas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  expr$df.res$method %>% unique()
  df.res <- expr$df.res %>%
    dplyr::filter(!(method %in% c("famt"))) %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "ewas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") + 
    xlab("Taille de la top liste") + 
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## pl.top
  save_plot_png(pl.top, filename = "ewas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "ewas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+END_SRC

#+RESULTS: code:ewas_qqplot_top_venn
[[./OUTPUT/Rplots/ewas_qqplot_notcalibrated_all.png]]
[[./OUTPUT/Rplots/ewas_top_power_all.png]]

****** DONE Diagramme de venn et annotation de l'intersection
CLOSED: [2017-09-16 sam. 16:02]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-16 sam. 16:02]
- State "TODO"       from              [2017-09-16 sam. 15:20]
:END:
#+NAME: code:ewas_venn
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  expr$df.res$method %>% unique()
  df.res <- expr$df.res %>%
    dplyr::filter(!(method %in% c("famt"))) %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates,
              name = colname)


  #############################################################################
  ## venn

  ## we calibrate sva-two-step with gif ! 
  calibrate <- function(p) {
    score2 <- qchisq(p, df = 1, lower.tail = FALSE)
    gif <- median(score2) / qchisq(0.5, df = 1)
    score2 <- score2 / gif
    pchisq(score2, lower.tail = FALSE, df = 1)
  }
  p <- df.res$pvalue[df.res$method == "sva-two-step"]
  hist(p)
  p.calibrated <- calibrate(p)
  hist(p.calibrated)
  df.res$calibrated.pvalue[df.res$method == "sva-two-step"] <- p.calibrated

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               `sva-two-step` = toplot$index[toplot$method == "sva-two-step"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                        area1 = inter(1),
                        area2 = inter(2),
                        area3 = inter(3),
                        area4 = inter(4),
                        area5 = inter(5),
                        n12 = inter(1,2),
                        n13 = inter(1,3),
                        n14 = inter(1,4),
                        n15 = inter(1,5),
                        n23 = inter(2,3),
                        n24 = inter(2,4),
                        n25 = inter(2,5),
                        n34 = inter(3,4),
                        n35 = inter(3,5),
                        n45 = inter(4,5),
                        n123 = inter(1,2,3),
                        n124 = inter(1,2,4),
                        n125 = inter(1,2,5),
                        n134 = inter(1,3,4),
                        n135 = inter(1,3,5),
                        n145 = inter(1,4,5),
                        n234 = inter(2,3,4),
                        n235 = inter(2,3,5),
                        n245 = inter(2,4,5),
                        n345 = inter(3,4,5),
                        n1234 = inter(1,2,3,4),
                        n1235 = inter(1,2,3,5),
                        n1245 = inter(1,2,4,5),
                        n1345 = inter(1,3,4,5),
                        n2345 = inter(2,3,4,5),
                        n12345 = inter(1,2,3,4,5),
                        category = names(sets),
                        fill = color.values[names(sets)],
                        cat.col = color.values[names(sets)],
                        cat.cex = 1.2,
                        cat.pos = c(0.0, -30, 180, 180, 30),
                        cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                        margin = 0.07,
                        ind = TRUE
                       )

  save_plot_png(venn, filename = "ewas_venn.png")
  save_plot_MaTheseR(venn, "ewas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    res
  }
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)

  ## annotation of intersection
  library(meffil)
  library(xtable)

  cpG.df <- meffil.get.features("450k")

  inter.cpg.df <- df.res %>%
    dplyr::filter(index %in% l, method %in%
                                c("cate", "lassoLFMM", "ridgeLFMM", "PCAlm", "sva_two-step")) %>%
    left_join(cpG.df, by = "name") %>%
    dplyr::transmute(ID = name,
                     Chr = sub("chr","",chromosome),
                     Position = as.character(position),
                     Gene = gene.symbol,
                     pvalue = calibrated.pvalue,
                     method = method,
                     Outlier = outlier
                     ) %>%
    spread(method, pvalue) %>%
    arrange(PCAlm)
  save_expr(inter.cpg.df, "ewas_table.rds")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_venn.png]]

*** Étude d'association entre des données génétiques et la maladie \celiac (GWAS)
<<sec:gwas>>

La maladie \celiac est une maladie auto-immune ayant une prévalence de près de
$1 \%$ dans la population générale cite:Gujral_2012. Bien que les mécanismes
d'apparition de cette maladie ne soit pas compris des études montres de fortes
associations avec certains gènes cite:dubois2010multiple; lassant envisager des
causes génétiques à la maladie. Comme la maladie \celiac est très étudiée faire
une étude d'association de celle-ci avec des données génomiques constitue un bon
test pour les méthodes de correction pour les variables latentes. Nous pourrons
en effet comparer nos résultats à ceux des nombreuses autres GWAS de la maladie
\celiac. Pour cela nous avons utilisé le GWAS catalog pour récupérer les SNPs
ayant été identifié dans d'autres études comme étant associés avec la maladie
\celiac. Par ailleurs, nous s'avons que la stratification des individus en sous
populations peut être un facteur de confusion dans les GWAS. Il est habituel de
corriger les GWAS en utilisant les scores de l'ACP des données génétiques pour
représenter la structure de population cite:Price_2006. Nous proposons ici de
faire une étude d'association entre la maladie \celiac et des données génétique
présentées dans cite:dubois2010multiple. Ces données comportent 281122 SNPs
(single nucléotyde polimorphism) pour 15155 individus, 10659 individus sains et
4496 atteints de la maladie \celiac. Ce que nous appelons SNP est la mesure pour
une position donnée du génome, que l'on appel locus, du nucleotide présent chez
l'individu observé. On parle de "single nucléotyde polimorphism" car on s'intéresse
seulement aux locus pour lesquels on a observé seulement deux variants dans la
population étudiée. Il faut de plus que le variant le moins fréquent soit au
moins observé chez $5\%$ des individus de la population. Ainsi pour cette GWAS
la matrice des variables expliquées est composée de 0, 1 et 2.

Avant de lancer les méthodes d'étude d'association nous avons filtré les données
génétique afin de garder seulement les SNPs ayant le variant le moins fréquent
présent dans au moins $5\%$ des observations. Nous avons de plus filtré les
individus trop apparentés, pour cela on mesure la probabilité qu'une séquence
consécutive de SNPs prise chez deux individus différents soit identique et si
celle-ci est supérieure à $0.08$ nous ne gardons qu'un des deux individus. Par
ailleurs, il est connu que les SNPs sont corrélés le long du génome, nous avons
donc filtrer les SNPs trop corrélé entre eux. Cette étape est identifié dans la
littérature comme le LD pruning. Pour cela, pour chaque SNP nous ne gardons que
le SNP de variance maximum sur une fenêtre de 100 SNPs et cela sur les SNPs
ayant un coefficient de corrélation linéaire au carré qui est supérieure à
$0.2$, cela nous a permis d'identifier un sous ensemble de 80275 SNPs. Ces
opérations de filtrage ont été effectuées à l'aide du logiciel plink
cite:Purcell_2007. Enfin nous avons utilisé beagle pour imputer les données
manquantes de la matrice de SNPs cite:Browning_2016. Nous obtenons finalement un
jeux de données complet composée 281122 SNPs observés sur 15155 individus.

Afin d'estimer les variables latentes pour corriger le test d'association entre
les SNPs et la maladie \celiac nous avons lancé les méthodes lm, lmPCA, cate,
ridgeLFMM et lassoLFMM sur le sous ensemble de 80275 SNPs identifié par l'étape
de LD pruning. Par la suite, nous avons effectué le test d'hypothèse présenté
dans la partie [[sec:hypothese]] sur les 281122 SNPs mais en utilisant l'estimation
des variables latentes calculées sur le sous ensemble de 80275 SNPs. Nous avons
choisi de lancer les méthodes lmPCA, cate, lassoLFMM et ridgeLFMM avec 9
variables latentes (voir Figure ref:fig:gwas_params A et B). Nous avons choisi
une proportion de lignes non nulles pour la matrice des effets $\B$ valant $1
\%$ pour lassoLFMM. La validation croisée du paramètre $\lambRidge$ tend à faire
choisir une forte valeur pour celui-ci (Figure ref:fig:gwas_params C), nous
avons choisi $1e^{3}$. La validation croisée présentée sur la Figure
ref:fig:gwas_params C tend à faire choisir une valeur plus grande que $1e^{3}$
cependant comme nous l'avons discuté dans la partie [[sec:paramL2]] si
$\lambdaRidge$ est trop grand alors ridgeLFMM renvoie les mêmes résultats que
PCAlm.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre génotype et la
  maladie \celiac. A) Proportion de variance expliquées de la projection de $\Y$
  sur l'espace orthogonal à $\X$ (c'est à dire $\matr{D}_{0} \Q^{T} \Y$) par
  chacune des composantes principales. B)C) Erreur de prédiction calculée grâce à
  la validation croisée des estimateurs $L_{2}$ des paramètres de LFMM pour
  différente valeurs du paramètre de régularisation $\lambda$ et du nombre
  variables latentes $\K$, le point représente l'erreur de prédiction moyenne et
  les bars l'erreur standard de la moyenne. La ligne pointillée vertical marque
  sur A et B le nombre de variables latentes choisies, c'est à dire 9, et sur C
  le paramètre de régularisation choisie, c'est à dire $10^3$.}
\label{fig:gwas_params}
\end{figure}
#+END_EXPORT

La Figure ref:fig:gwas_qqplot_top A montre la distribution observée des \pvalues
renvoyées par chaque méthode contre la distribution théorique sous l'hypothèse
nulle. On constate que les méthodes sont toutes bien calibrées et que la méthode
la plus libérale est lm alors que PCAlm est la méthode la plus conservative. La
Figure ref:fig:gwas_qqplot_top B montre le nombre de SNPs référencés dans le
GWAS catalog comme étant associés avec la maladie \celiac qui sont retrouvés
dans les top listes des différentes méthodes. On observe ainsi sur la Figure
ref:fig:gwas_qqplot_top B que lm sépare le moins facilement les SNPs du GWAS
catalog des autres SNPs, alors que ce sont ridgeLFMM et PCAlm qui séparent le
mieux les SNPs du GWAS catalog du reste. La liste top 1000 de ridgeLFMM et PCAlm
contiennent respectivement $63 \%$ et $57 \%$ des SNPs du GWAS catalog contre
$18 \%$, $14 \%$ et $12 \%$ pour lassoLFMM, cate et lm.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponetielle. B) Proportion des candidats du GWAS catalogue
  retrouvés dans la top liste revoyée par chaques méthodes.}
\label{fig:gwas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste obtenus en contrôlant le
FDR à $1 \%$. Nous avons procédé de la même façon que pour l'EWAS pour calculer
cette liste (voir la section [[sec:ewas]]). La Figure ref:fig:gwas_venn montre
l'intersection des listes contrôlés à un FDR de $1\%$ entre les méthodes. Ce
sont ridgeLFMM et PCAlm qui donnent les plus petites listes contrôlées avec 754
candidats pour ridgeLFMM et 777 candidats pour PCAlm. Les méthodes cate et lm
donne la plus grande liste avec le même nombre de 1319 candidats. Nous
constatons que l'intersection des listes à FDR contrôlé de toutes les méthodes
ne contient que $28\%$ des candidats du GWAS catalog.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_venn.pdf.png}
\caption{Diagramme de Venn des listes controlés à un taux de fausses de
  découvertes de $1 \%$ pour chaque méthode.}
\label{fig:gwas_venn}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
:LOGBOOK:
- Note taken on [2017-08-06 Sun 14:53] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
:END:
***** DONE Téléchargement des données
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=

#+NAME: code:gwas_ddl
#+CAPTION: 
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ls FinnuncorrNLITUK1UK3hap300.*
#+end_src

#+RESULTS: code:gwas_ddl
: 
: FinnuncorrNLITUK1UK3hap300.bed	FinnuncorrNLITUK1UK3hap300.bim	FinnuncorrNLITUK1UK3hap300.fam

***** DONE Contrôle qualité
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_CQ
#+CAPTION: Dépend de [[code:gwas_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300 --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
#+end_src

#+RESULTS: code:gwas_CQ
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
Options in effect:
  --autosome
  --bfile FinnuncorrNLITUK1UK3hap300
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out FinnuncorrNLITUK1UK3hap300_CQ
  --snps-only
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 72672 MB successfully, after larger attempt(s) failed.
287385 out of 295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999579.
67 variants removed due to missing genotype data (--geno).
--hwe: 17 variants removed due to Hardy-Weinberg exact test.
6179 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ.bed +
#+end_example

***** DONE Élagage (LD pruning)
CLOSED: [2017-08-16 mer. 17:49]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:49]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

Pour comprendre le LD pruning: 
- [[https://www.cog-genomics.org/plink/1.9/ld][doc de plink]]
- [[https://privefl.github.io/bigsnpr/reference/pruning-clumping.html][re-implementation du ld pruning de plink]]
- [[https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient][R2 = cor(Y,X)^2]]

****** DONE LD report
CLOSED: [2017-08-17 jeu. 10:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_ld_report
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --r2 --ld-window 10 --ld-window-kb 100 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --ld-window 10
    --ld-window-kb 100
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:gwas_ld_report_R
#+CAPTION: Dépend de [[code:gwas_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "gwas_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "gwas_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_ld_report_bin.png]]
[[./OUTPUT/Rplots/gwas_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:00]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:00]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_prunning
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --indep-pairwise 100 1 0.2 --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
#+end_src

#+RESULTS: code:gwas_prunning
#+begin_example

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --indep-pairwise 100 1 0.2
    --out FinnuncorrNLITUK1UK3hap300_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
  1%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  Pruned 15141 variants from chromosome 1, leaving 6399.
  Pruned 16905 variants from chromosome 2, leaving 6214.
  Pruned 14431 variants from chromosome 3, leaving 5343.
  Pruned 12416 variants from chromosome 4, leaving 4848.
  Pruned 12574 variants from chromosome 5, leaving 4932.
  Pruned 14081 variants from chromosome 6, leaving 4860.
  Pruned 10944 variants from chromosome 7, leaving 4341.
  Pruned 12291 variants from chromosome 8, leaving 4164.
  Pruned 10651 variants from chromosome 9, leaving 3896.
  Pruned 10176 variants from chromosome 10, leaving 4034.
  Pruned 9597 variants from chromosome 11, leaving 3753.
  Pruned 9754 variants from chromosome 12, leaving 3987.
  Pruned 7466 variants from chromosome 13, leaving 3019.
  Pruned 6364 variants from chromosome 14, leaving 2725.
  Pruned 5555 variants from chromosome 15, leaving 2484.
  Pruned 5528 variants from chromosome 16, leaving 2702.
  Pruned 5063 variants from chromosome 17, leaving 2564.
  Pruned 6770 variants from chromosome 18, leaving 2754.
  Pruned 3373 variants from chromosome 19, leaving 2035.
  Pruned 4698 variants from chromosome 20, leaving 2309.
  Pruned 3620 variants from chromosome 21, leaving 1416.
  Pruned 3449 variants from chromosome 22, leaving 1496.
  Pruning complete.  200847 of 281122 variants removed.
  Marker lists written to FinnuncorrNLITUK1UK3hap300_CQ.prune.in and
  FinnuncorrNLITUK1UK3hap300_CQ.prune.out .
  9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in
    --make-bed
    --out FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  --extract: 80275 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned.bed +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.bim +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.fam ... done.
#+end_example
***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-08-16 mer. 18:18]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:18]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 18:10]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:10]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
:END:
#+NAME: code:gwas_ibd
#+CAPTION: Dépend de [[code:gwas_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## ibd
  plink -bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  80275 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-16 mer. 18:12]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:12]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:gwas_ibd_visu
#+CAPTION: Dépend de [[code:gwas_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "celiac_ibd.png")


  ## We filter PI_HAT > 0.08
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.08) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS: code:gwas_ibd_visu
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
[[./OUTPUT/Rplots/celiac_ibd.png]]


On va filter les pour une proportion d'ibd à 0.08 (ca correspond à cousin au 4
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 18:15]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:15]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:gwas_ibd_filter
#+CAPTION: Dépend de [[code:gwas_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel

  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_norel
#+end_src

#+RESULTS: code:gwas_ibd_filter
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
80275 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999592.
80275 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bim +
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999597.
281122 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_norel.bim +
#+end_example

***** STARTED Imputation des données manquantes
:LOGBOOK:
- Note taken on [2017-08-17 jeu. 13:48] \\
  il va falloir le relancer ! ca prend du temps !!! > 1 jour, peut être
  augmenter nb thread et ram
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:48]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 18:53]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_impute
#+CAPTION: Dépend de [[code:gwas_ibd_filter]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## recode to vcf
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel --recode vcf bgz --out FinnuncorrNLITUK1UK3hap300_CQ_norel --threads 8
  ## run beagle
  java -Xmx40g -jar beagle.08Jun17.d8b.jar gt=FinnuncorrNLITUK1UK3hap300_CQ_norel.vcf.gz out=FinnuncorrNLITUK1UK3hap300_CQ_norel_imputed nthreads=8

  ##
#+end_src

***** TODO Conversion au format R et scaling
:LOGBOOK:
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
****** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
***** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
***** CANCELLED Conversion au format =bigmatrix=
CLOSED: [2017-07-23 Sun 15:46]
:LOGBOOK:
- Note taken on [2017-07-23 Sun 15:46] \\
  MDRRRRR: 
  Error in SetMatrixElements(x@address, as.double(j), as.double(i), as.double(value)) : 
  long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
  In addition: Warning message:
  In filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  No descriptor file given, it will be named G.big.bin.desc
- State "CANCELLED"  from              [2017-07-23 Sun 15:46]
- State "TODO"       from              [2017-07-23 Sun 15:29]
:END:
#+BEGIN_SRC R
  library(bigmemory)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "./Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.big.bin")
  colnames(G.big) <- colnames(G)
  rownames(G.big) <- rownames(G)
  saveRDS(G.big, "./Data/ThesisDataset/3Article/Celiac/G.big.rds")
#+END_SRC

***** DONE SNPs détecté par d'autre analyse
CLOSED: [2017-09-12 mar. 14:25]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-09-12 mar. 14:25]
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R 

  ## all the GWAS catalogue
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  ## filter for celiac desease
  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  celiac.map <- readRDS("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")$map

  ## join by marker_ID
  celiac.outlier <- celiac.map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## filter dubois outlier
  celiac.outlier.dubois <- celiac.outlier %>% 
    dplyr::filter(grepl(".*[Dd]ubois.*", `FIRST AUTHOR`))

  celiac.outlier.dubois$`FIRST AUTHOR`

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", length(celiac.outlier$SNPS %>% unique()), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac.map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  ## dubois candidate list
  cat("nb of dubois candidates:", length(celiac.outlier.dubois$SNPS %>% unique()), "\n")
  celiac.outlier.dubois$SNPS
  candidates <- which(celiac.map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Joining, by = "marker.ID"
nb of candidates: 49
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

***** DONE Scree plot
CLOSED: [2017-08-30 mer. 09:31]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 09:31]
- State "RUNNING"    from "DONE"       [2017-08-29 mar. 12:01]
- State "DONE"       from "RUNNING"    [2017-08-29 mar. 11:56]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:59]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-07-30 Sun 11:28]
- Note taken on [2017-07-30 Sun 11:27] \\
  c'est fait mais la projection change rien !!
- State "RUNNING"    from "DEBUG"      [2017-07-26 mer. 18:09]
- Note taken on [2017-07-26 mer. 18:09] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:07] \\
  On va relancer sans Rspectra, ca prend trop de temps !!!!
- State "DEBUG"      from "DONE"       [2017-07-26 mer. 18:06]
- State "DONE"       from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "STARTED"    [2017-07-25 mar. 18:21]
- Note taken on [2017-07-25 mar. 18:19] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d25.log
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:

#+NAME: code:gwas_screeplot
#+CAPTION: Dépend de 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds"
  X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"


  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "gwas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  save_plot_png(pl, "gwas_screeplot.png")

#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]
[[./OUTPUT/Rplots/gwas_screeplot.png]]

On prend K = 9 variables latentes.

***** DONE Validation croisée avec lfmmRidge
CLOSED: [2017-08-31 jeu. 10:03]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 10:03]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 09:37]
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 08:42]
- State "RUNNING"    from "DONE"       [2017-08-28 lun. 15:47]
- State "DONE"       from "RUNNING"    [2017-08-28 lun. 11:53]
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:17]
- Note taken on [2017-08-17 Thu 18:16] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_CV_encore_encore.y2017_m08_d17.log
- Note taken on [2017-08-17 jeu. 13:47] \\
  il va falloir relancer gwas_CV_encore_encore !!!
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:47]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 15:08]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 09:53]
- Note taken on [2017-08-14 lun. 12:07] \\
  Il y a aussi gwas_CV_lambda qui tourne !
- Note taken on [2017-08-14 lun. 12:02] \\
  il y a [[gwas_CV_encore]] qui tourne
- State "RUNNING"    from "DEBUG"      [2017-08-09 mer. 15:26]
- Note taken on [2017-08-09 mer. 15:24] \\
  c'est reparti sur tail -f /home/cayek/tmp/Logfiles/gwas.y2017_m08_d09.log
- State "DEBUG"      from "RUNNING"    [2017-08-03 jeu. 14:17]
- Note taken on [2017-08-03 jeu. 14:16] \\
  ca buggé, le processus c'est fait tuer. Il en était a au bout de 5 jours...
  > res.cv <- ExpRmouline(cv, dat)
  === params
    lambda K
  1  1e-05 1
  === params
    lambda K
  2      1 1
  === params
    lambda K
  3  1e+10 1
  === params
    lambda K
  4  1e-05 2
  === params
    lambda K
  5      1 2
  === params
    lambda K
  6  1e+10 2
- State "RUNNING"    from "TODO"       [2017-07-30 Sun 11:31]
- Note taken on [2017-07-30 Sun 11:31] \\
  c'est parti : tail -f /home/cayek/tmp/Logfiles/gwas_CV.y2017_m07_d30.log
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+NAME: code:gwas_CV
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(1,2,5,9,50))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K.png]]

#+NAME: code:gwas_CV_encore
#+CAPTION: Dépend de [[code:gwas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(10,13,20))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore.png]]

#+NAME: code:gwas_CV_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 6:8)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore.png]]

#+NAME: code:gwas_CV_encore_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 3:4)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore_encore.png]]

#+NAME: code:gwas_CV_lambda
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(9))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda.png]]

#+NAME: code:gwas_CV_lambda_encore
#+CAPTION: Dépend de [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(8,10))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_encore.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_encore.png]]

#+NAME: code:gwas_CV_lambda_round2
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)
  lambdas <- c(1e-5, 1, 10, 1e3, 1e10)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 9)

  ## run
  res.cv <- ExpRmouline(cv, dat)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_round2.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_round2.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_round2.png]]

#+NAME: code:gwas_CV_lambda_round2_encore
#+CAPTION: Dépend de [[code:gwas_CV_lambda_round2]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e5, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 9)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm_round2.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_round2_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_round2_encore.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_round2_encore.png]]

***** DONE Étude du jeu de données 
CLOSED: [2017-09-01 ven. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:31]
- State "TODO"       from "DONE"       [2017-09-01 ven. 09:27]
- State "DONE"       from "RUNNING"    [2017-09-01 ven. 09:27]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 09:28]
- State "DONE"       from "RUNNING"    [2017-07-28 ven. 09:25]
- Note taken on [2017-07-27 jeu. 13:50] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_run.y2017_m07_d27.log
- State "RUNNING"    from "DEBUG"      [2017-07-27 jeu. 13:50]
- State "DEBUG"      from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "DEBUG"      [2017-07-24 Mon 07:35]
- State "DEBUG"      from "DONE"       [2017-07-24 Mon 06:58]
- State "DONE"       from "RUNNING"    [2017-07-24 Mon 06:58]
- Note taken on [2017-07-23 Sun 16:13] \\
  C'est reparti !! sur krakenator en dehors de annaconda biensur !! pour que
  matter marche (pour avoir R 3.4)
- State "RUNNING"    from "DEBUG"      [2017-07-23 Sun 16:13]
- State "DEBUG"      from "DONE"       [2017-07-17 Lun 08:18]
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:18]
- Note taken on [2017-07-17 Lun 08:18] \\
  lasso c'est planté !! il faudra le relancer mais le reste est OK !!
- Note taken on [2017-07-13 jeu. 08:55] \\
  C'est reparti sur krak !!
- State "RUNNING"    from "STARTED"    [2017-07-13 jeu. 08:55]
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:
****** DONE Run des méthodes
CLOSED: [2017-09-01 ven. 09:27]
:LOGBOOK:
- State "DONE"       from              [2017-09-01 ven. 09:27]
:END:
#+NAME: code:gwas_expr
#+CAPTION: Etude d'association des données Celiac avec cate ridgeLFMM LassoLFMM LM et LMPCAS. Dépend de 
#+begin_src R
  library(MaTheseR)
  library(lfmm)
  library(matter)
  library(foreach)
  library(doParallel)


  rerun <- FALSE
  nb.cluster <- 2
  ## param
  param <- list(K.method = 9, lambda = 1e3,
                nozero.prop = 0.01,lambda.num = 25,
                relative.err.epsilon = 1e-6)


  ## methods
  methods <- list()
  methods$m.lm <- method_lm()
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = param$K.method, lambda = param$lambda)
  methods$m.pca <- method_PCAlm(K = param$K.method)
  methods$m.cate <- method_cate(K = param$K.method)
  methods$m.lasso <- method_lassoLFMM(K = param$K.method,
                                      nozero.prop = param$nozero.prop,
                                      lambda.num = param$lambda.num,
                                      relative.err.epsilon = param$relative.err.epsilon)

  run_celiac <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- MaTheseR::LfmmMatterDat(Y, X, outlier)
    col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")
    out.file.res.df <- paste0("./OUTPUT/Expr/Celiac_df","_", m$name)
    out.file.U <- paste0("./OUTPUT/Expr/Celiac_U","_", m$name)

    if (!exist_res(m, out.file.res.df) && !rerun) {
      ## mask data
      message("mask data")
      dat.masked <- lfmm::LfmmDat(Y = NULL, X = dat$X, missing = FALSE)
      dat.masked$Y <- dat$Y[,col.mask]

      ## compute lattente variable
      message("computing U")
      if (!exist_res(m, out.file.U)) {
        m.U <- ExpRmouline(m, dat.masked)
        save_res(m, m.U, out.file.U)
      } else {
        m.U <- retrieve_res(m, out.file.U)
      }

      ## unmask
      message("unmask data")
      rm(dat.masked)
      gc()

      ## run HP
      message("running HP")
      m.res <- m
      X <- cbind(dat$X, m.U$U)
      d <- ncol(dat$X)
      hp <- lfmm::hypothesis_testing_lm(dat, X)
      m.res$score <- hp$score[,1:d, drop = FALSE]
      m.res$pvalue <- hp$pvalue[,1:d, drop = FALSE]
      m.res$B.hp <- hp$B[,1:d, drop = FALSE]
      ## saving res
      message("saving res.df")
      df <- ExpRextractor_pvalue1_calibrated(dat, m.res, 1, 1)
      save_res(m, df, out.file.res.df)
    } else {
      message("res.df exist !! ")
    }
  }


  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  foreach(m = methods) %dopar% {
    run_celiac(m)
  }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## cbind res
  res.df <- tibble()
  for (m in methods) {
    out.file.res.df <- paste0("./OUTPUT/Expr/Celiac_df","_", m$name)
    if (exist_res(m, out.file.res.df)) {
      message("=============== ", m$name)
      res.df <- res.df %>%
        rbind(retrieve_res(m, out.file.res.df))
    }
  }

  save_expr(res.df, "celiac_all_df.rds")
#+end_src

****** DONE Que donne la calibration
CLOSED: [2017-09-01 ven. 09:28]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:28]
- State "TODO"       from              [2017-08-31 jeu. 09:10]
:END:

#+NAME: code:gwas_expr_calibration
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  res.df %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:gwas_expr_calibration
: # A tibble: 5 x 3
:      method      mad       median
:       <chr>    <dbl>        <dbl>
: 1      cate 1.052221  0.011781682
: 2 lassoLFMM 1.045186  0.012433327
: 3        lm 1.201294 -0.023610211
: 4     PCAlm 1.037876  0.009601749
: 5 ridgeLFMM 1.041061  0.009624663

****** DONE Gwas catalogue et controle du fdr
CLOSED: [2017-09-01 ven. 09:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:29]
- State "TODO"       from              [2017-08-31 jeu. 09:10]
:END:

#+NAME: code:gwas_expr_fdr
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  ## fdr 5%
  toplot <- expr %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.05)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "gwas_fdr01_inter.png")

#+end_src

#+RESULTS: code:gwas_expr_fdr
[[./OUTPUT/Rplots/gwas_fdr01_inter.png]]
: # A tibble: 5 x 2
:      method     power
:       <chr>     <dbl>
: 1      cate 0.7755102
: 2 lassoLFMM 0.7959184
: 3        lm 0.5714286
: 4     PCAlm 0.5102041
: 5 ridgeLFMM 0.5306122
****** DONE plot top * power
CLOSED: [2017-09-01 ven. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:31]
- State "TODO"       from "DONE"       [2017-08-31 jeu. 09:10]
- State "DONE"       from              [2017-08-07 lun. 18:12]
:END:
#+NAME: code:gwas_top_power
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  m1 <- length(candidates)
  res.df

  df <- res.df %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,3000))
  pl
  save_plot_png(pl, "gwas_top_power.png")

#+end_src

#+RESULTS: code:gwas_top_power
[[./OUTPUT/Rplots/gwas_top_power.png]]
#+begin_example
# A tibble: 1,405,610 x 14
       pvalue    colname index outlier        score rep.sampler rep.method
        <dbl>      <chr> <int>   <lgl>        <dbl>       <dbl>      <dbl>
 1 0.84762413  rs3934834     1   FALSE -0.192154026           1          1
 2 0.13045046  rs3737728     2   FALSE  1.512409930           1          1
 3 0.09462707  rs6687776     3   FALSE  1.671583791           1          1
 4 0.47099482  rs9651273     4   FALSE  0.720879427           1          1
 5 0.99457651  rs4970405     5   FALSE -0.006797506           1          1
 6 0.82921368 rs12726255     6   FALSE  0.215713881           1          1
 7 0.70303213  rs2298217     7   FALSE -0.381237819           1          1
 8 0.62074572  rs4970362     8   FALSE  0.494803906           1          1
 9 0.76159116  rs9660710     9   FALSE -0.303397447           1          1
10 0.24429269  rs4970420    10   FALSE -1.164369349           1          1
# ... with 1,405,600 more rows, and 7 more variables: method <chr>,
#   method.K <dbl>, method.lambda <dbl>, median <dbl>, mad <dbl>,
#   calibrated.score <dbl>, calibrated.pvalue <dbl>
#+end_example
****** DONE histogrammes
CLOSED: [2017-09-01 ven. 10:20]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 10:20]
- State "TODO"       from              [2017-09-01 ven. 10:13]
:END:

#+NAME: code:gwas_histogram
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  pl <- ggplot(res.df, aes(pvalue, color = method)) +
    geom_histogram() +
    facet_grid(method ~ .)
  save_plot_png(pl, "gwas_hist_pvalue.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_hist_pvalue.png]]
****** DONE Clumping
CLOSED: [2017-09-12 mar. 13:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 13:59]
- State "TODO"       from "DONE"       [2017-09-12 mar. 13:38]
- State "DONE"       from "TODO"       [2017-09-12 mar. 13:12]
- State "TODO"       from              [2017-09-12 mar. 11:22]
:END:

[[http://zzz.bwh.harvard.edu/plink/clump.shtml][doc plink pour le cluming]]

#+NAME: code:gwas_clumping
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")


  ## how much pvalue are less than 0.001
  th <- 0.05
  message("Pvalue less than ", th)
  res.df %>% group_by(method) %>%
    summarise(count = sum(pvalue < th))

  methods <- res.df$method %>% unique()
  methods

  res <- tibble()
  for (m in methods) {
    tmp.file <- tempfile(tmpdir = "~/Projects/Thesis/Data/Celiac/dubois_2010/")
    res.df %>% dplyr::filter(method == m) %>%
      dplyr::transmute(P = pvalue, SNP = colname) %>%
      readr::write_delim(path = tmp.file, delim = "\t")
    plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                       "--bfile ~/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ",
                       "--clump",
                        tmp.file,
                        "--clump-p1 0.05",
                        "--clump-p2 0.1",
                        "--clump-r2 0.20",
                        "--clump-kb 250",
                        "--out plink.clump",
                       "--threads 8")
    system(plink.cmd)

    ## retrieve res
    ## clumping.res <- readr::read_table2(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
    ##                                   col_types = cols(
    ##                                     CHR = col_integer(),
    ##                                     F = col_integer(),
    ##                                     SNP = col_character(),
    ##                                     BP = col_integer(),
    ##                                     P = col_character(),
    ##                                     TOTAL = col_integer(),
    ##                                     NSIG = col_integer(),
    ##                                     S05 = col_integer(),
    ##                                     S01 = col_integer(),
    ##                                     S001 = col_integer(),
    ##                                     S0001 = col_integer(),
    ##                                     SP2 = col_character()))
    clumping.res <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                      data.table = FALSE) %>% as_tibble()

    res <- clumping.res %>%
      mutate(method = m) %>%
      rbind(res)

    file.remove(tmp.file)
  }

  ## saving
  save_expr(res, "celiac_all_clumped.rds")

#+end_src

#+RESULTS: code:gwas_clumping
#+begin_example
Pvalue less than 0.05
# A tibble: 5 x 2
     method count
      <chr> <int>
1      cate 19662
2 lassoLFMM 19261
3        lm 30645
4     PCAlm 18086
5 ridgeLFMM 18345
[1] "lm"        "ridgeLFMM" "PCAlm"     "cate"      "lassoLFMM"
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea243372aa
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 15788 clumps formed from 30645 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea6381dade
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10033 clumps formed from 18345 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea1f19c5ca
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 9905 clumps formed from 18086 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea7bc86cf
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10535 clumps formed from 19662 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea38ddb236
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10381 clumps formed from 19261 top variants.
Results written to plink.clump.clumped .
Warning messages:
1: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '1.25e-320'. It was read using (double)strtold() as numeric value 1.2499860839783538E-320 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
2: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '1.38e-322'. It was read using (double)strtold() as numeric value 1.3833838083554903E-322 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
3: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '4.96e-313'. It was read using (double)strtold() as numeric value 4.9599999999789495E-313 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
Expr save in ./OUTPUT/Expr/celiac_all_clumped.rds
#+end_example

****** DONE plot clumped top * power
CLOSED: [2017-09-12 mar. 14:55]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 14:55]
- State "TODO"       from              [2017-09-12 mar. 13:13]
:END:
#+NAME: code:gwas_top_power_clumped
#+CAPTION: Dépend de [[code:gwas_expr]] [[code:gwas_clumping]]
#+begin_src R 
  library(MaTheseR)
  library(stringr)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  clumped.res.df <- readRDS("./OUTPUT/Expr/celiac_all_clumped.rds")

  candidates.snp <- (res.df %>% dplyr::filter(index %in% candidates))$colname %>% unique()


  ## clump with candidates
  df <- clumped.res.df %>%
    transmute(method = method,
              pvalue = P,
              outlier.SNP = SNP %in% candidates.snp,
              outlier.SP2.count = str_count(SP2, paste(candidates.snp, collapse = "|")),
              outlier = outlier.SNP | (outlier.SP2.count >= 1)) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(candidate = cumsum(outlier), clumped.top = seq_along(pvalue)) %>%
    ungroup()

  sum(df$outlier) / 5 ## the number of method

  df <- df %>%
    add_row(method = unique(df$method), clumped.top = 0, candidate = 0)

  pl <- ggplot(df, aes(x = clumped.top, y = candidate, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,1000))
  pl
  save_plot_png(pl, "gwas_clumped_top_power.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_clumped_top_power.png]]

***** DONE Plots
CLOSED: [2017-09-01 ven. 13:13]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:13]
- State "TODO"       from              [2017-08-06 Sun 15:11]
:END:
****** DONE Choix des paramètres
CLOSED: [2017-09-01 ven. 09:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:35]
- State "TODO"       from              [2017-08-14 lun. 11:40]
:END:
#+NAME: code:gwas_screeplot_CV
#+CAPTION: Dépend de [[code:gwas_screeplot]] [[code:gwas_CV]] [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  df.res <- readRDS("./OUTPUT/Expr/gwas_screeplot_expr.rds")
  plA <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,50)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "gwas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "gwas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm_round2_encore.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() +
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    geom_vline(xintercept = 1e3, linetype = "dashed") +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.2, 0.2))
  save_plot_png(plC, "gwas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "gwas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:gwas_screeplot_CV
[[./OUTPUT/Rplots/gwas_screeplot.png]]
[[./OUTPUT/Rplots/gwas_CV_K.png]]
[[./OUTPUT/Rplots/gwas_CV_lambda.png]]

****** DONE Résultats des méthodes
CLOSED: [2017-09-01 ven. 13:13]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:13]
- State "TODO"       from              [2017-08-14 lun. 11:50]
:END:
#+NAME: code:gwas_qqplot
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme


  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  ## celiac.df$method %>% unique()
  df.res <- celiac.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "gwas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,1500)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") +
    xlab("Taille de la top liste") +
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## When to we have every candidates ?
  message("== Top all ==")
  toplot %>% group_by(method) %>% summarise(top = min(which(power >= 1.0))) %>% knitr::kable()
  message("== Top 3000 ==")
  toplot %>% dplyr::filter(top == 3000) %>% knitr::kable()
  message("== Top 1000 ==")
  toplot %>% dplyr::filter(top == 1000) %>% knitr::kable()

  ## pl.top
  save_plot_png(pl.top, filename = "gwas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "gwas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+END_SRC

#+RESULTS: code:gwas_qqplot_venn
#+begin_example
  [1] lm        ridgeLFMM PCAlm     cate      lassoLFMM
  Levels: lm PCAlm sva-two-step sva-irw lassoLFMM cate ridgeLFMM oracle
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  [[./OUTPUT/Rplots/gwas_qqplot_notcalibrated_all.png]]
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  == Top all ==


  |method    |    top|
  |:---------|------:|
  |lm        | 213444|
  |PCAlm     | 259689|
  |lassoLFMM | 151172|
  |cate      | 156858|
  |ridgeLFMM | 247464|
  == Top 3000 ==


  |method    |  index|    pvalue| calibrated.pvalue|outlier |     power|  top|
  |:---------|------:|---------:|-----------------:|:-------|---------:|----:|
  |lm        | 274194| 0.0005995|         0.0040140|FALSE   | 0.7755102| 3000|
  |PCAlm     |  68895| 0.0047380|         0.0066796|FALSE   | 0.8367347| 3000|
  |lassoLFMM | 148728| 0.0030905|         0.0048138|FALSE   | 0.8775510| 3000|
  |cate      |  86890| 0.0027883|         0.0043251|FALSE   | 0.8775510| 3000|
  |ridgeLFMM |  28408| 0.0045857|         0.0062832|FALSE   | 0.8367347| 3000|
  == Top 1000 ==


  |method    |  index|    pvalue| calibrated.pvalue|outlier |     power|  top|
  |:---------|------:|---------:|-----------------:|:-------|---------:|----:|
  |lm        | 103211| 0.0000000|          0.000000|FALSE   | 0.1224490| 1000|
  |PCAlm     | 103161| 0.0001711|          0.000303|FALSE   | 0.5714286| 1000|
  |lassoLFMM | 102648| 0.0000000|          0.000000|FALSE   | 0.1836735| 1000|
  |cate      | 103120| 0.0000000|          0.000000|FALSE   | 0.1428571| 1000|
  |ridgeLFMM |  28634| 0.0001809|          0.000310|FALSE   | 0.6326531| 1000|
  [[./OUTPUT/Rplots/gwas_top_power_all.png]]
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  [[./OUTPUT/Rplots/gwas_qqplot_top.pdf.png]]
  == List with fdr controle ==
  # A tibble: 5 x 3
       method     n     power
       <fctr> <int>     <dbl>
  1        lm  1319 0.4489796
  2     PCAlm   777 0.3673469
  3 lassoLFMM  1267 0.6122449
  4      cate  1319 0.6734694
  5 ridgeLFMM   754 0.3673469
  [[./OUTPUT/Rplots/gwas_venn.png]]
  [[./OUTPUT/Rplots/gwas_venn.pdf.png]]
  == Prop of candidate in inter all ==
  [1] 0.2857143
  == Prop of candidate in inter cate lfmm pcalm ==
  [1] 0.3673469
#+end_example

****** DONE Diagramme de venn
CLOSED: [2017-09-16 sam. 17:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-16 sam. 17:21]
- State "TODO"       from              [2017-09-16 sam. 17:18]
:END:
#+NAME: code:gwas_qqplot_venn
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme


  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  ## celiac.df$method %>% unique()
  df.res <- celiac.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()
  #############################################################################
  ## venn

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  message("== List with fdr controle ==")
  toplot %>% group_by(method) %>% summarise(n = length(outlier),
                                            power = sum(outlier) / m1)

  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               lm = toplot$index[toplot$method == "lm"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                         area1 = inter(1),
                         area2 = inter(2),
                         area3 = inter(3),
                         area4 = inter(4),
                         area5 = inter(5),
                         n12 = inter(1,2),
                         n13 = inter(1,3),
                         n14 = inter(1,4),
                         n15 = inter(1,5),
                         n23 = inter(2,3),
                         n24 = inter(2,4),
                         n25 = inter(2,5),
                         n34 = inter(3,4),
                         n35 = inter(3,5),
                         n45 = inter(4,5),
                         n123 = inter(1,2,3),
                         n124 = inter(1,2,4),
                         n125 = inter(1,2,5),
                         n134 = inter(1,3,4),
                         n135 = inter(1,3,5),
                         n145 = inter(1,4,5),
                         n234 = inter(2,3,4),
                         n235 = inter(2,3,5),
                         n245 = inter(2,4,5),
                         n345 = inter(3,4,5),
                         n1234 = inter(1,2,3,4),
                         n1235 = inter(1,2,3,5),
                         n1245 = inter(1,2,4,5),
                         n1345 = inter(1,3,4,5),
                         n2345 = inter(2,3,4,5),
                         n12345 = inter(1,2,3,4,5),
                         category = names(sets),
                         fill = color.values[names(sets)],
                         cat.col = color.values[names(sets)],
                         cat.cex = 1.2,
                         cat.pos = c(0.0, -30, 180, 180, 30),
                         cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                         margin = 0.07,
                         ind = TRUE
                       )

  save_plot_png(venn, filename = "gwas_venn.png")
  save_plot_MaTheseR(venn, "gwas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  message("== Prop of candidate in inter all ==")
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)
  message("== Prop of candidate in inter cate lfmm pcalm ==")
  l <- inter.list(1,2,3, 4)
  mean(candidates %in% l)
#+END_SRC

***** CANCELLED Etude de l'intersection des clumps à 1%
CLOSED: [2017-09-16 sam. 18:05]
:LOGBOOK:
- State "CANCELLED"  from "TODO"       [2017-09-16 sam. 18:05]
- State "TODO"       from              [2017-09-16 sam. 17:28]
:END:

#+NAME: code:gwas_inter_clumps
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  library(stringr)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  candidates.rs <- res.df$colname[res.df$index %in% candidates] %>% unique()


  clumps.df <- res.df %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "lassoLFMM", "ridgeLFMM")) %>%
    group_by(method) %>%
    dplyr::mutate(qvalue = qvalue::qvalue(calibrated.pvalue)$qvalues) %>%
    ungroup()


  res <- tibble()
  for (m in methods) {
    tmp.file <- tempfile(tmpdir = "~/Projects/Thesis/Data/Celiac/dubois_2010/")
    clumps.df %>% dplyr::filter(method == m) %>%
      dplyr::transmute(P = qvalue, SNP = colname) %>%
        readr::write_delim(path = tmp.file, delim = "\t")
    plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                       "--bfile ~/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ",
                       "--clump",
                       tmp.file,
                       "--clump-p1 0.01",
                       "--clump-p2 0.1",
                       "--clump-r2 0.20",
                       "--clump-kb 250",
                       "--out plink.clump",
                       "--threads 8")
    system(plink.cmd)
    clumping.res <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                      data.table = FALSE) %>% as_tibble()

    res <- clumping.res %>%
      mutate(method = m) %>%
      rbind(res)

    file.remove(tmp.file)
  }

  res$SNP %>% unique()

  ## explode clumps
  exploded.clumps.df <- tibble()
  for (i in 1:nrow(res)) {
    SNP <- res$SNP[i]
    SP2 <- res$SP2[i] %>% str_split(",", simplify = TRUE) %>%
      str_replace("\\(1\\)", "") %>%
      str_split(";", simplify = TRUE)
    SP2 <- c(SP2, SNP)
    exploded.clumps.df <- exploded.clumps.df %>%
      rbind(tibble(snps = SP2, clump.snps = SNP))
  }

#+end_src

***** TODO Meta analyse
:LOGBOOK:
- State "TODO"       from              [2017-09-16 sam. 18:07]
:END:
****** DONE On utilise mahalanobis
CLOSED: [2017-09-16 sam. 18:32]
:LOGBOOK:
- State "DONE"       from              [2017-09-16 sam. 18:32]
:END:

#+NAME: code:gwas_meta
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)

  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  candidates.rs <- res.df$colname[res.df$index %in% candidates] %>% unique()


  ## arrange score into a matrix
  Z.df <- celiac.df %>%
      dplyr::filter(method %in% c("cate", "lassoLFMM", "ridgeLFMM", "PCAlm")) %>%
      dplyr::select(method, calibrated.score, colname, index,outlier) %>%
      group_by(method) %>%
      tidyr::spread(method, calibrated.score)

  Z.df
  Z <- Z.df[,c(-1,-2,-3)] %>% as.matrix()
  dim(Z)
  colnames(Z)
  anyNA(Z)


  mahalanobis.res <- pcadapt::covRob_cpp(Z)
  Z.df <- Z.df %>%
    mutate(mahalanobis.dist = mahalanobis.res$dist%>%as.numeric())

  ## plot dist
  ggplot(Z.df, aes(mahalanobis.dist)) +
    geom_histogram()
  ggplot(Z.df, aes(y = mahalanobis.dist, x = seq_along(mahalanobis.dist), color = outlier)) +
    geom_point()

  ## compute pvalue
  Z.df <- Z.df %>%
    mutate(pvalue = pchisq(mahalanobis.dist, df = 5, lower.tail = FALSE))
  ggplot(Z.df, aes(pvalue)) +
    geom_histogram()

  ## recalibration
  gif <- median(Z.df$mahalanobis.dist) / qchisq(0.5, df = 1)
  Z.df <- Z.df %>%
    mutate(recalibrated.pvalue = pchisq(mahalanobis.dist / gif, df = 1, lower.tail = FALSE))
  ggplot(Z.df, aes(recalibrated.pvalue)) +
    geom_histogram()

  ## top by dist
  Z.df %>%
    dplyr::arrange(desc(mahalanobis.dist)) %>%
    dplyr::filter(row_number() < 100) %>%
    print.data.frame()

  save_expr(Z.df, "gwas_mahanalobis.rds")
#+end_src
****** TODO On clump
:LOGBOOK:
- State "TODO"       from              [2017-09-16 sam. 18:32]
:END:

#+NAME: code:gwas_meta_clump
#+CAPTION: Dépend de [[code:gwas_meta]]
#+begin_src R 
  library(MaTheseR)

  ## load res
  Z.df <- readRDS("./OUTPUT/Expr/gwas_mahanalobis.rds")
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  candidates.rs <- res.df$colname[res.df$index %in% candidates] %>% unique()


  ## clumping with plink
  tmp.file <- tempfile(tmpdir = "~/Projects/Thesis/Data/Celiac/dubois_2010/")
  Z.df %>% dplyr::transmute(P = recalibrated.pvalue, SNP = colname) %>%
    readr::write_delim(path = tmp.file, delim = "\t")
  plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                     "--bfile ~/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ",
                     "--clump",
                     tmp.file,
                     "--clump-p1 0.01",
                     "--clump-p2 0.1",
                     "--clump-r2 0.20",
                     "--clump-kb 250",
                     "--out plink.clump",
                     "--threads 8")
  system(plink.cmd)
  clumps.df <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                    data.table = FALSE) %>% as_tibble()
  file.remove(tmp.file)

  ## explode clumps
  exploded.clumps.df <- tibble()
  for (i in 1:nrow(res)) {
    SNP <- res$SNP[i]
    SP2 <- res$SP2[i] %>% str_split(",", simplify = TRUE) %>%
        str_replace("\\(1\\)", "") %>%
      str_split(";", simplify = TRUE)
    SP2 <- c(SP2, SNP)
    exploded.clumps.df <- exploded.clumps.df %>%
      rbind(tibble(snps = SP2, clump.snps = SNP))
  }


  ## candidates
  candidates.rs %in% exploded.clumps.df$snps %>% mean()

  ## clump with candidates
  df <- clumps.df %>%
    mutate(pvalue = P,
              outlier.SNP = SNP %in% candidates.rs,
              outlier.SP2.count = str_count(SP2, paste(candidates.rs, collapse = "|")),
              outlier = outlier.SNP | (outlier.SP2.count >= 1)) %>%
    arrange(pvalue)

  df %>%
    dplyr::select(TOTAL, P, outlier) %>%
    print.data.frame()

  ##  annotation
#+end_src
*** Étude d'association entre des données génétiques et un gradient environmental (GEAS)
<<sec:GEAS>>

Depuis Darwin nous s'avons que les organismes vivants s'adaptent à leur
environnement cite:Darwin. Ainsi les organismes les mieux adaptées à leur
habitat ont plus de chance de survivre et de se reproduire. Si l'avantage
adaptatif à des causes génétiques, c'est à dire qu'il existe une combinaison de
gènes qui confère à l'organisme une fonction lui permettant d'être mieux adapté
à son habitat, alors le patrimoine génétique qui confère l'avantage adaptatif
est transmis aux futures générations. On peut donc alors chercher à détecter les
signatures génétiques laissées par l'adaptation à un environnement. C'est
l'objectif des associations génotype-environement. Pour cela nous avons récupéré
les données génétiques du projet 1000Genome phase 3 cite:1000Genome_2015. Ces
données regroupes $84.4$ millions de variants génétiques pour 2506 individus
venant de 26 populations différentes. Par ailleurs nous avons récupéré des
données climatiques à partir de la base de données WorldClim 2.0 cite:Fick_2017.
Nous avons comparé les résultats des méthodes lm, PCAlm, cate, ridgeLFMM et
lassoLFMM lancé sur d'association entre les données du 1000Genome et un gradient
environnemental.

De la même façon que pour la GWAS nous avons filtré les individus trop
apparentés et les variants génétiques pas assez fréquents (voir Partie
[[sec:gwas]]). De plus pour faire une étude d'association entre un génotype et un
environnemental, il faut garder les individus qui vivent dans leurs habitats
depuis plusieurs générations, nous avons donc enlevé les populations
afro-américaine et africaine des caraïbes. Il reste alors 1409 individus et
5397214 locus. Enfin, de la même façon que pour la GWAS nous avons identifié un
sous ensemble de 296948 SNPs grâce au LD pruning des 5397214 locus. Nous avons
utilisé ce sous ensemble de locus pour calculer les variables latentes avec les
méthodes PCAlm, cate, lassoLFMM et ridgeLFMM. Nous avons calculé ensuite des
\pvalues pour chacun des 5397214 locus grâce au test d'hypothèse présenté dans
la partie [[sec:hypothese]].

Afin de calculer le gradient environnemental utilisé pour l'étude d'association
nous avons attribué une position géographique à chaque individu en prenant la
capital de son pays d'origine. Cela nous a parmi de récupérer les données de la
base WorlClim pour les positions géographiques ainsi calculées. Nous ne gardons
que la première composante principale des variables de la base Wordclim. La
Figure ref:fig:eas_gradient représente la valeur du gradient climatique pour
chaque population. On remarque que celui-ci est très corrélé avec la latitude.
En effet, comme les populations sont à différentes latitudes il y a de la
corrélation entre la structure de population et le gradient environnemental.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_climatic_gradient.pdf.png}
\caption{Gradient climatique $\X$ utilisé pour l'association génotype-environement.}
\label{fig:eas_gradient}
\end{figure}
#+END_EXPORT

Nous avons lancer les méthodes cate, ridgeLFMM, lassoLFMM et PCAlm avec 9
variables latentes. Les figures ref:fig:eas_params A et B semble plutôt indiquer
5 variables latentes mais nous avons préféré prendre un nombre légèrement plus
élevé car les individus proviennent de 16 populations différentes. Nous avons
choisi $\lambdaRidge = 10^{-5}$ pour ridgeLFMM et une proportion de lignes non
nulles de $\B$ valant $1 \%$ pour lassoLFMM.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre un génotype et un
  gradient environnemental. A) Proportion de variance expliquées de la
  projection de $\Y$ sur l'espace orthogonal à $\X$ (c'est à dire $\matr{D}_{0}
  \Q^{T} \Y$) par chacune des composantes principales. B)C) Erreur de prédiction
  calculée grâce à la validation croisée des estimateurs $L_{2}$ des paramètres
  de LFMM pour différentes valeurs du paramètre de régularisation $\lambdaRidge$
  et du nombre de variables latentes $\K$, le point représente l'erreur de
  prédiction moyenne et les bars l'erreur standard. Les lignes pointillées
  verticales marquent sur A et B le nombre de variables latentes choisi, c'est à
  dire 9, et sur C le paramètre de régularisation $L_2$ choisi, c'est à dire
  $10^3$.}
\label{fig:eas_params}
\end{figure}
#+END_EXPORT

La figure ref:fig:geas_qqplot montre la distribution observée des \pvalues
renvoyées par chaque méthode contre la distribution théorique sous l'hypothèse
nulle. On constate une forte inflation de la méthode lm, le MAD des \pvalues
renvoyées par lm est de $8.7$. De plus on remarque que le diagramme
quantile-quantile de lm forme une droite. Cela signifie qu'il n'y a de pas de
surplus de \pvalues atypiques alors que c'est dans ce surplus de \pvalues
atypiques que l'on trouve les variables candidates pour l'association avec $\X$.
En d'autre terme lm ne renvoie pas plus de \pvalues outlier que le hasard en
donnerait. Par contre, on observe un surplus \pvalues atypiques dans les
\pvalues renvoyées par les autre méthodes. Pour les méthodes PCAlm, ridgeLFMM,
lassoLFMM et cate nous avons calculé la liste candidats quand on contrôle le FDR
à $1 \%$, nous avons procédé de la même façon que pour l'EWAS et la GWAS pour
calculer cette liste (voir la section [[sec:ewas]]). La méthode lm a été écartée
pour les raisons que nous venons d'évoquer. La Figure ref:fig:gwas_venn montre
l'intersection des listes de candidats contrôlés à un FDR de $1\%$ entre les
méthodes. L'union des candidats retournés par ces quatre méthodes donne 836
SNPs. Le logiciel VEP permet d'annoter l'effet d'une mutation sur l'expression
des gènes cite:McLaren_2016. Les annotations retournés par VEP sont classées en
degré d'importance: LOW, MODERATE et HIGH. Nous avons étudié la
sur-représentation de chacun de des degré d'annotation de vep dans la sous
listes des 836 SNPs par rapport à la liste complète de SNPs. Nous constatons
qu'il y a en proportion 22 fois plus d'annotation HIGH, 8 fois plus de MODERATE
et $1.7$ fois plus de LOW dans la les 836 SNPs que dans les 5397214 SNPs. Nous
avons de plus testé si chaque rapport de proportion est significativement
supérieur à 1 à l'aide d'un test exacte de Fisher et les trois tests renvoie une
\pvalue inférieure à $0.005$.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_qqplot_notcalibrated_all.pdf.png}
\caption{Diagrame quantile-quantile de l'inverse du logarithme en base 10 des
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponentielle.}
\label{fig:geas_qqplot}
\end{figure}
#+END_EXPORT

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_venn.pdf.png}
\caption{Diagramme de Venn des listes controlés à un taux de fausses de
  découvertes de $1 \%$ pour chaque méthode.}
\label{fig:geas_venn}
\end{figure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE Téléchargement du jeux de données
CLOSED: [2017-07-26 mer. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-07-26 mer. 18:17]
:END:
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.

*Remarque* : il faut utiliser GRCh37 !! [[http://www.internationalgenome.org/faq/which-reference-assembly-do-you-use/][here]]

#+NAME: code:1000g_ddl
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
***** DONE Contrôle qualité
CLOSED: [2017-07-27 jeu. 14:15]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 14:15]
- Note taken on [2017-07-26 mer. 19:35] \\
  tail -f /home/cayek/tmp/Logfiles/1000g.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:42] \\
  faudra recuperer la sortie dans emacs
- State "RUNNING"    from "TODO"       [2017-07-26 mer. 18:41]
- State "TODO"       from              [2017-07-26 mer. 18:30]
:END:

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+NAME: code:1000g_CQ
#+CAPTION: Dépend de [[code:1000g_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
  do
      echo "===== $file ====="
      plink --vcf $file --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out `basename $file .vcf.gz`_CQ
  done
#+end_src

#+NAME: code:1000g_CQ_log
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_CQ_log
#+begin_example

  > > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:27:19 2017

  Random number seed: 1501090039
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3837178 out of 3992219 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999945.
  806 variants removed due to missing genotype data (--geno).
  --hwe: 75986 variants removed due to Hardy-Weinberg exact test.
  3481563 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  278823 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:31:11 2017
  ============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:31:11 2017

  Random number seed: 1501090271
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3891530 out of 4045628 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  747 variants removed due to missing genotype data (--geno).
  --hwe: 74342 variants removed due to Hardy-Weinberg exact test.
  3548109 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  268332 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:35:22 2017
  ============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:35:22 2017

  Random number seed: 1501090522
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3710299 out of 3868428 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  657 variants removed due to missing genotype data (--geno).
  --hwe: 73200 variants removed due to Hardy-Weinberg exact test.
  3377092 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  259350 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:39:43 2017
  ============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:39:43 2017

  Random number seed: 1501090783
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2737034 out of 2857916 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  497 variants removed due to missing genotype data (--geno).
  --hwe: 52494 variants removed due to Hardy-Weinberg exact test.
  2484161 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  199882 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:42:43 2017
  ============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:42:43 2017

  Random number seed: 1501090963
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2548064 out of 2655067 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999952.
  479 variants removed due to missing genotype data (--geno).
  --hwe: 53291 variants removed due to Hardy-Weinberg exact test.
  2320025 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  174269 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:45:29 2017
  ============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:45:29 2017

  Random number seed: 1501091129
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2328557 out of 2424689 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  434 variants removed due to missing genotype data (--geno).
  --hwe: 51148 variants removed due to Hardy-Weinberg exact test.
  2123668 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  153307 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:47:54 2017
  ============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:47:54 2017

  Random number seed: 1501091274
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2607034 out of 2697949 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  518 variants removed due to missing genotype data (--geno).
  --hwe: 51346 variants removed due to Hardy-Weinberg exact test.
  2387326 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  167844 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:50:35 2017
  ============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:50:35 2017

  Random number seed: 1501091435
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2234710 out of 2329288 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  413 variants removed due to missing genotype data (--geno).
  --hwe: 46649 variants removed due to Hardy-Weinberg exact test.
  2044443 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  143205 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:52:53 2017
  ============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:52:53 2017

  Random number seed: 1501091573
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2178759 out of 2267185 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  392 variants removed due to missing genotype data (--geno).
  --hwe: 39690 variants removed due to Hardy-Weinberg exact test.
  1980142 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  158535 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:55:07 2017
  ============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:55:07 2017

  Random number seed: 1501091707
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1758443 out of 1832506 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999942.
  402 variants removed due to missing genotype data (--geno).
  --hwe: 36837 variants removed due to Hardy-Weinberg exact test.
  1591671 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  129533 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:56:55 2017
  ============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:56:55 2017

  Random number seed: 1501091815
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6216035 out of 6468094 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  1033 variants removed due to missing genotype data (--geno).
  --hwe: 128213 variants removed due to Hardy-Weinberg exact test.
  5676255 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  410534 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:03:16 2017
  ============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:03:16 2017

  Random number seed: 1501092196
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1745171 out of 1812841 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999959.
  278 variants removed due to missing genotype data (--geno).
  --hwe: 35426 variants removed due to Hardy-Weinberg exact test.
  1592817 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  116650 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:05:02 2017
  ============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:05:02 2017

  Random number seed: 1501092302
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1058549 out of 1105538 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999928.
  279 variants removed due to missing genotype data (--geno).
  --hwe: 23191 variants removed due to Hardy-Weinberg exact test.
  956556 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  78523 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:06:06 2017
  ============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:06:06 2017

  Random number seed: 1501092366
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1059735 out of 1103547 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999946.
  222 variants removed due to missing genotype data (--geno).
  --hwe: 25833 variants removed due to Hardy-Weinberg exact test.
  960163 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  73517 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:07:11 2017
  ============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:07:11 2017

  Random number seed: 1501092431
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6808742 out of 7081600 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  1184 variants removed due to missing genotype data (--geno).
  --hwe: 138884 variants removed due to Hardy-Weinberg exact test.
  6233305 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  435369 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:14:09 2017
  ============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:14:09 2017

  Random number seed: 1501092849
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5603261 out of 5832276 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  1069 variants removed due to missing genotype data (--geno).
  --hwe: 111493 variants removed due to Hardy-Weinberg exact test.
  5104864 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  385835 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:19:48 2017
  ============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:19:48 2017

  Random number seed: 1501093188
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5500093 out of 5732585 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  1080 variants removed due to missing genotype data (--geno).
  --hwe: 115329 variants removed due to Hardy-Weinberg exact test.
  4985272 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  398412 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:25:25 2017
  ============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:25:25 2017

  Random number seed: 1501093525
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5055536 out of 5265763 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  909 variants removed due to missing genotype data (--geno).
  --hwe: 91958 variants removed due to Hardy-Weinberg exact test.
  4620648 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  342021 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:30:32 2017
  ============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:30:32 2017

  Random number seed: 1501093832
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4816881 out of 5024119 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999935.
  1292 variants removed due to missing genotype data (--geno).
  --hwe: 101026 variants removed due to Hardy-Weinberg exact test.
  4346787 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  367776 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:35:26 2017
  ============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:35:26 2017

  Random number seed: 1501094126
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4533180 out of 4716715 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.99995.
  842 variants removed due to missing genotype data (--geno).
  --hwe: 87612 variants removed due to Hardy-Weinberg exact test.
  4119828 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  324898 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:40:01 2017
  ============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:40:01 2017

  Random number seed: 1501094401
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4434371 out of 4597105 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999944.
  921 variants removed due to missing genotype data (--geno).
  --hwe: 90154 variants removed due to Hardy-Weinberg exact test.
  4048413 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  294883 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:44:29 2017
  ============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:44:29 2017

  Random number seed: 1501094669
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3427241 out of 3560687 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  689 variants removed due to missing genotype data (--geno).
  --hwe: 68557 variants removed due to Hardy-Weinberg exact test.
  3121045 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  236950 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:47:57 2017
#+end_example

***** DONE Fusion de tous les chromosomes
CLOSED: [2017-07-27 jeu. 14:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 14:43]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** Ensuite, nous avons enlever les doublons
#+NAME: code:1000g_rm
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## snp to remove
  echo "rs6658405" > excluded_variant.txt
  echo "." >> excluded_variant.txt
  echo "rs141927528" >> excluded_variant.txt
  echo "rs145926341" >> excluded_variant.txt

  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed
  do
      echo "===== $file ====="
      plink --bfile `basename $file .bed` --exclude excluded_variant.txt --make-bed --out `basename $file .bed`_excluded
  done
#+end_src

#+NAME: code:1000g_rm_log
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_rm_log
#+begin_example

> > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:51 2017

Random number seed: 1501158411
193793 MB RAM detected; reserving 96896 MB for main workspace.
278823 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 278823 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999926.
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
268332 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 268332 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
259350 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 259348 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
259348 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
199882 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 199882 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
174269 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 174269 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
153307 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 153305 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
153305 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
167844 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 167844 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999899.
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
143205 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 143205 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
158535 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 158535 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
129533 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 129533 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
410534 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 410532 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999927.
410532 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
116650 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 116650 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999933.
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
78523 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 78523 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
73517 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 73517 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999913.
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
435369 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 435369 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:57 2017
============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:57 2017

Random number seed: 1501158417
193793 MB RAM detected; reserving 96896 MB for main workspace.
385835 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 385835 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:58 2017
============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:58 2017

Random number seed: 1501158418
193793 MB RAM detected; reserving 96896 MB for main workspace.
398412 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 398412 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
342021 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 342021 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999919.
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
367776 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 367776 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:00 2017
============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:00 2017

Random number seed: 1501158420
193793 MB RAM detected; reserving 96896 MB for main workspace.
324898 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 324898 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
294883 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 294881 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999914.
294881 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
236950 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 236950 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:02 2017
#+end_example

****** On concatène les genomes en 1 seul fichier
#+NAME: code:1000g_concat
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

  ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_CQ")

  system(cmd)
#+end_src

#+RESULTS: code:1000g_concat
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded
    --make-bed
    --merge-list ./file5534632e75c3.txt
    --out 1000GenomePhase3_CQ

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Performing single-pass merge (2504 people, 5398440 variants).
  Merged fileset written to 1000GenomePhase3_CQ-merge.bed +
  1000GenomePhase3_CQ-merge.bim + 1000GenomePhase3_CQ-merge.fam .
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ.bed + 1000GenomePhase3_CQ.bim +
  1000GenomePhase3_CQ.fam ... done.
#+end_example

****** Vérification
#+NAME: code:1000g_test
#+CAPTION: Dépend de [[code:1000g_concat]]
#+begin_src shell :session *ssh krakenator* :results output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS: code:1000g_test
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:5	rs66584056	0	36516119	T	A
***** DONE Élagage (LD pruning)
CLOSED: [2017-07-27 jeu. 15:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 15:01]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** DONE LD report
CLOSED: [2017-08-17 jeu. 11:23]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:23]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:01]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:1000g_ld_report
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --r2 --ld-window 10 --ld-window-kb 10 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --ld-window 10
    --ld-window-kb 10
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:1000g_ld_report_R
#+CAPTION: Dépend de [[code:1000g_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "1000g_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "1000g_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ld_report_bin.png]]
[[./OUTPUT/Rplots/1000g_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:01]
:LOGBOOK:
- State "DONE"       from              [2017-08-17 jeu. 11:01]
:END:

On fait un filtrage des SNPs (voir [[https://www.cog-genomics.org/plink/1.9/ld#indep][doc plink]])
#+NAME: code:1000g_prunning
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_CQ --threads 8
  plink --bfile 1000GenomePhase3_CQ --extract 1000GenomePhase3_CQ.prune.in --make-bed --out 1000GenomePhase3_CQ_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 100 1 0.2
    --out 1000GenomePhase3_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 383854 variants from chromosome 1, leaving 26678.
  Pruned 409475 variants from chromosome 2, leaving 25894.
  Pruned 362867 variants from chromosome 3, leaving 22968.
  Pruned 376230 variants from chromosome 4, leaving 22182.
  Pruned 321811 variants from chromosome 5, leaving 20210.
  Pruned 347157 variants from chromosome 6, leaving 20619.
  Pruned 305597 variants from chromosome 7, leaving 19301.
  Pruned 277562 variants from chromosome 8, leaving 17319.
  Pruned 221173 variants from chromosome 9, leaving 15777.
  Pruned 261581 variants from chromosome 10, leaving 17242.
  Pruned 252405 variants from chromosome 11, leaving 15927.
  Pruned 242512 variants from chromosome 12, leaving 16836.
  Pruned 187679 variants from chromosome 13, leaving 12203.
  Pruned 162767 variants from chromosome 14, leaving 11502.
  Pruned 142011 variants from chromosome 15, leaving 11294.
  Pruned 155528 variants from chromosome 16, leaving 12316.
  Pruned 131567 variants from chromosome 17, leaving 11638.
  Pruned 147436 variants from chromosome 18, leaving 11099.
  Pruned 119524 variants from chromosome 19, leaving 10009.
  Pruned 107571 variants from chromosome 20, leaving 9079.
  Pruned 72922 variants from chromosome 21, leaving 5601.
  Pruned 67200 variants from chromosome 22, leaving 6317.
  Pruning complete.  5056429 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ.prune.in and
  1000GenomePhase3_CQ.prune.out .


  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --extract 1000GenomePhase3_CQ.prune.in
    --make-bed
    --out 1000GenomePhase3_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned.nosex .
  --extract: 342011 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned.bed + 1000GenomePhase3_CQ_prunned.bim
  + 1000GenomePhase3_CQ_prunned.fam ... done.

#+end_example

***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-07-27 jeu. 16:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 16:21]
- Note taken on [2017-07-26 mer. 19:21] \\
  c'est la que ca commence !! il faut que je remplace par les vrais appel de plink !!!
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

On filtre les individus trop apparenté (voir [[https://www.cog-genomics.org/plink/1.9/ibd][doc de plink]]).


****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:
#+NAME: code:1000g_ibd
#+CAPTION: Dépend de [[code:1000g_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## ibd
  plink -bfile 1000GenomePhase3_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-14 lun. 13:55]
:LOGBOOK:
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:1000g_ibd_visu
#+CAPTION: Dépend de [[code:1000g_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "1000g_ibd.png")


  ## We filter PI_HAT > 0.125
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.125) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ibd.png]]

On va filter les pour une proportion d'ibd à 0.125 (ca correspond à cousin au 3
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:1000g_ibd_filter
#+CAPTION: Dépend de [[code:1000g_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ_prunned --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_prunned_norel

  plink --bfile 1000GenomePhase3_CQ --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_norel
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --make-bed
    --out 1000GenomePhase3_CQ_prunned_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.99989.
  342011 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned_norel.bed +
  1000GenomePhase3_CQ_prunned_norel.bim + 1000GenomePhase3_CQ_prunned_norel.fam
  ... done.

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --make-bed
    --out 1000GenomePhase3_CQ_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999904.
  5398440 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_norel.bed + 1000GenomePhase3_CQ_norel.bim +
  1000GenomePhase3_CQ_norel.fam ... done.
#+end_example

***** DONE Conversion dans format utilisable en R
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-08-03 jeu. 11:37]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R. 

****** DONE Données non prunnées
CLOSED: [2017-08-14 lun. 14:14]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:11]
- Note taken on [2017-08-03 jeu. 14:14] \\
  ca a bugger le pense ...a voir.
- State "TODO"       from "RUNNING"    [2017-08-03 jeu. 14:14]
- State "RUNNING"    from "DONE"       [2017-08-03 jeu. 13:26]
- State "DONE"       from "RUNNING"    [2017-08-02 mer. 16:51]
- Note taken on [2017-08-02 mer. 16:11] \\
  il ne veux pas mettre de nom au ligne et colonnes .... je sais pas pk mais c'est
  pas si grave !!
- State "RUNNING"    from              [2017-08-02 mer. 15:59]
:END:

#+NAME: code:1000g_G_bigsnpr
#+CAPTION: Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_norel.bed"

  snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")

  G <- snp_attach("bigsnpr_G/G.rds")
  ## G <- readRDS("bigsnpr_G/G.rds")
  dim(G$genotypes)

  ## G.r <- readRDS("G.rds")
  G.r <- attach.BM(G$genotypes)[,]
  ## rownames(G.r) <- G$fam$sample.ID
  ## attr(G.r, "rownames") <- G$fam$sample.ID
  ## colnames(G.r) <- G$map$marker.ID
  ## attr(G.r, "colnames") <- G$map$marker.ID

  saveRDS(G.r, "G.rds")
  #+END_SRC

#+RESULTS:
#+begin_example
  > snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")
  Creating directory "bigsnpr_G" which didn't exist..
  Read 5398440 rows and 6 (of 6) columns from 0.142 GB file in 00:00:22
  [1] "bigsnpr_G/G.rds"
  > 
  > G <- snp_attach("bigsnpr_G/G.rds")
  > dim(G$genotypes)
  [1]    1758 5398440
  > rownames(G.r) <- G$fam$sample.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
  > colnames(G.r) <- G$map$marker.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
#+end_example

****** DONE Données prunnées
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 17:17]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

#+NAME: code:1000g_G_prunned_bigsnpr
#+CAPTION: On converti les données prunnées en un format R. Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_prunned_norel.bed"

  snp_readBed(bedfile, "G_prunned", backingpath = "bigsnpr_G_prunned")

  G <- snp_attach("bigsnpr_G_prunned/G_prunned.rds")
  dim(G$genotypes)

  G.r <- attach.BM(G$genotypes)[,]
  typeof(G.r)
  rownames(G.r) <- G$fam$sample.ID
  colnames(G.r) <- G$map$marker.ID
  saveRDS(G.r, "G_prunned.rds")
  rm(G.r)
  gc()


  ## We only keep first chromosomes 1 and 2 for simulation numerique
  in.id <- which(G$map$chromosome %in% c(1,2))
  G.r <- readRDS("G_prunned.rds")
  G.numVal <- G.r[,in.id]
  saveRDS(G.numVal, "G_prunned_chr12.rds")


  ## save indiv data frame
  saveRDS(G$fam, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/indiv_df.rds")
  #+END_SRC

***** DONE Données utilisées pour la validation numérique lfmm
CLOSED: [2017-07-27 jeu. 17:26]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 17:26]
:END:
#+NAME: code:1000g_G_valNum
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- readRDS("G_prunned_chr12.rds")
  anyNA(G)
  G.noNa <- preprocessing_filter_na(G)
  anyNA(G.noNa)
  G.scale <- scale(G.noNa)
  saveRDS(G.scale, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds")
#+end_src

#+RESULTS:
#+begin_example
  proportion of removed loci = 0.00686677318724797
#+end_example

***** DONE Filtrage des individus pour la GEAS
CLOSED: [2017-08-14 lun. 15:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 15:37]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:28]
- State "DONE"       from "TODO"       [2017-07-28 ven. 14:18]
- State "TODO"       from              [2017-07-28 ven. 11:46]
:END:

Nous ne gardons que les individus non métisses.

#+NAME: code:eas_indiv_df
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]] [[code:1000g_ibd_visu]]
#+begin_src R
  library(MaTheseR)

  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds") %>% as_tibble()
  indiv.df

  ## keep only indiv with no rel
  out.indif <- read_delim(file = "./Data/1000Genomes/Phase3/out.indif.txt", delim = " ",
                          col_names = FALSE, col_types = cols(.default = col_character()))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(sample %in% out.indif$X1))
  indiv.df

  ## retrieve pop

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW", "ACB")))
  indiv.df

  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
#+end_src

#+RESULTS: code:eas_indiv_df
#+begin_example
# A tibble: 2,504 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00103   GBR       EUR   male
 8 HG00105   GBR       EUR   male
 9 HG00106   GBR       EUR female
10 HG00107   GBR       EUR   male
# ... with 2,494 more rows
# A tibble: 1,758 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,748 more rows
# A tibble: 1,409 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,399 more rows
#+end_example

***** DONE Scaling des données et valeurs manquantes pour GEAS

CLOSED: [2017-08-16 mer. 15:44]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:44]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

****** DONE Données non prunnées 
CLOSED: [2017-08-16 mer. 15:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:29]
- State "TODO"       from              [2017-07-28 ven. 10:34]
:END:

#+NAME: code:1000g_G_noNA_scaled
#+CAPTION: Dépend de [[code:1000g_G_bigsnpr]] [[code:eas_indiv_df]]
#+begin_src R 
  library(bigsnpr)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- snp_attach("bigsnpr_G/G.rds")
  G.r <- attach.BM(G$genotypes)
  dim(G.r) ## [1]    1758 5398440

  ## indiv to keep
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
  kept.indiv.id <- G$fam$sample %in% eas.indiv.df$sample

  ## NA mu sds
  nas <- 1:ncol(G.r)
  mus <- 1:ncol(G.r)
  sds <- 1:ncol(G.r)
  pb <- txtProgressBar(min = 1, max = ncol(G.r))
  for(j in 1:ncol(G.r)) {
    aux <- as.double(G.r[kept.indiv.id,j])
    nas[j] <- mean(is.na(aux))
    mus[j] <- mean(aux, na.rm = TRUE)
    sds[j] <- sd(aux, na.rm = TRUE)
    setTxtProgressBar(pb, j)
  }
  close(pb)

  ## test
  quantile(nas)
  quantile(mus)
  quantile(sds)
  sum(nas > 0.0)
  sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)

  ## filter
  col.ids <- which(sds > 0.095) 

  ## size matrix file 1409x5397214
  ## save col and row name
  saveRDS(G$fam$sample.ID[kept.indiv.id], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  saveRDS(G$map$marker.ID[col.ids], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")

  ## export to bin
  con <- file("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin", 'wb')
  for(j in col.ids) {
    aux <- as.double(G.r[kept.indiv.id,j])
    writeBin((aux - mus[j]) / sds[j], con)
  }
  flush(con)
  close(con)

  ############################################################################################
  ## matter matrix
  library(matter)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G.big <- readRDS("bigsnpr_G/G.rds")
  row.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  col.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")

  G.matter <- matter_mat(paths="~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin",
                         nrow = length(row.names),
                         ncol = length(col.names),
                         datamode = "double")
  rownames(G.matter) <- row.names
  colnames(G.matter) <- col.names

  ## test
  dim(G.matter)
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  G.matter[1409,5397214]

  saveRDS(G.matter, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

#+end_src

#+RESULTS:
#+begin_example
  > quantile(nas)
    0%  25%  50%  75% 100% 
     0    0    0    0    0 
  > quantile(mus)
         0%       25%       50%       75%      100% 
  0.9254791 1.3584102 1.6217175 1.7934705 2.0539390 
  > quantile(sds)
         0%       25%       50%       75%      100% 
  0.0000000 0.4419241 0.5679660 0.6762505 0.8825680 
  > sum(nas > 0.0)
  [1] 0
  > sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)
  [1] 1226

#+end_example
****** DONE Données prunnées
CLOSED: [2017-08-16 mer. 15:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:40]
- State "TODO"       from "DONE"       [2017-08-14 lun. 14:19]
- State "DONE"       from "TODO"       [2017-07-28 ven. 11:01]
- State "TODO"       from              [2017-07-27 jeu. 17:29]
:END:

On fait un pruning plus fort que celui de [[code:1000g_prunning]]

#+NAME: code:1000g_prunning_more
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 5000 1 0.2 --out 1000GenomePhase3_CQ_more --threads 8
#+end_src


#+RESULTS:
#+begin_example
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_more.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 5000 1 0.2
    --out 1000GenomePhase3_CQ_more
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_more.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 387086 variants from chromosome 1, leaving 23446.
  Pruned 413054 variants from chromosome 2, leaving 22315.
  Pruned 366259 variants from chromosome 3, leaving 19576.
  Pruned 379840 variants from chromosome 4, leaving 18572.
  Pruned 324752 variants from chromosome 5, leaving 17269.
  Pruned 350848 variants from chromosome 6, leaving 16928.
  Pruned 308455 variants from chromosome 7, leaving 16443.
  Pruned 280143 variants from chromosome 8, leaving 14738.
  Pruned 223125 variants from chromosome 9, leaving 13825.
  Pruned 263958 variants from chromosome 10, leaving 14865.
  Pruned 254728 variants from chromosome 11, leaving 13604.
  Pruned 244633 variants from chromosome 12, leaving 14715.
  Pruned 189373 variants from chromosome 13, leaving 10509.
  Pruned 164213 variants from chromosome 14, leaving 10056.
  Pruned 143194 variants from chromosome 15, leaving 10111.
  Pruned 156696 variants from chromosome 16, leaving 11148.
  Pruned 132527 variants from chromosome 17, leaving 10678.
  Pruned 148556 variants from chromosome 18, leaving 9979.
  Pruned 120363 variants from chromosome 19, leaving 9170.
  Pruned 108299 variants from chromosome 20, leaving 8351.
  Pruned 73482 variants from chromosome 21, leaving 5041.
  Pruned 67649 variants from chromosome 22, leaving 5868.
  Pruning complete.  5101233 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ_more.prune.in and
  1000GenomePhase3_CQ_more.prune.out .
#+end_example

#+NAME: code:1000g_G_noNA_scaled_prunned
#+CAPTION: On scale et enlève les données manquantes. Dépend de [[code:1000g_G_noNA_scaled]] [[code:1000g_prunning_more]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  prune.in <- read_delim(file = "~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/1000GenomePhase3_CQ_more.prune.in", delim = " ", col_names = FALSE, col_types = cols(col_character()))

  library(matter)
  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

  ## test
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  dim(G.matter)

  ## prunning
  keep.id <- colnames(G.matter) %in% prune.in$X1
  saveRDS(which(keep.id), "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")
  G.prunned <- G.matter[,keep.id]

  ## test
  length(colnames(G.prunned))
  dim(G.prunned)

  saveRDS(G.prunned, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds")
#+end_src

#+RESULTS:
#+begin_example
> dim(G.prunned)
[1]   1409 296948
#+end_example

***** DONE Annotation VEP
CLOSED: [2017-08-31 jeu. 13:30]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 13:30]
- State "RUNNING"    from "DONE"       [2017-08-31 jeu. 11:09]
- State "DONE"       from "RUNNING"    [2017-08-29 mar. 14:51]
- State "RUNNING"    from "DONE"       [2017-08-29 mar. 08:35]
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 15:31]
- State "RUNNING"    from "TODO"       [2017-08-22 mar. 12:41]
- State "TODO"       from              [2017-08-22 mar. 11:53]
:END:

vep cache : [[https://www.ensembl.org/info/docs/tools/vep/script/vep_cache.html#cache][here]]

#+NAME: code:1000g_vep_cache
#+CAPTION: Dépend de 
#+begin_src R 
  cd $HOME/.vep
  curl -O ftp://ftp.ensembl.org/pub/release-89/variation/VEP/homo_sapiens_vep_89_GRCh37.tar.gz
  tar -xvf homo_sapiens_vep_89_GRCh37.tar.gz
#+end_src

vep input format : [[http://www.ensembl.org/info/docs/tools/vep/vep_formats.html#input][here]]

#+NAME: code:1000g_vep_input
#+CAPTION: On creer un fichier input pour vep. Dépend de [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(matter)
  library(tidyverse)

  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")
  snps.info <- readRDS("./Data/1000Genomes/Phase3/bigsnpr_G/G.rds")$map
  snps.info <- snps.info %>%
    dplyr::filter(marker.ID %in% colnames(G.matter))

  vep.input <- snps.info %>%
    transmute(chromosome = chromosome,
              start = physical.pos,
              end = physical.pos,
              allele = paste0(allele1,"/", allele2),
              strand = NA,
              identifier = marker.ID)

  write.table(vep.input, file = "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.input.txt",
              row.names = FALSE, col.names = FALSE, na = "", quote = FALSE)

#+end_src

run vep option : [[http://www.ensembl.org/info/docs/tools/vep/script/vep_options.html][here]]

#+NAME: code:1000g_vep_run
#+CAPTION: Dépend de [[code:1000g_vep_input]]
#+begin_src shell
  cd ~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/
  vep --cache --species homo_sapiens --assembly GRCh37 --offline -i vep.input.txt -o vep.output.txt --force --variant_class --sift b
#+end_src

#+NAME: code:1000g_vep_output
#+CAPTION: Dépend de [[code:1000g_vep_run]]
#+begin_src R 
  vep.output <- data.table::fread("./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.txt", skip = "#Uploaded_variation", data.table = FALSE, na.strings = "-")

  vep.output <- vep.output %>% as_tibble()

  ## add column
  library(stringr)

  IMPACT <- vep.output$Extra %>%
    str_match(pattern = "IMPACT=([:alnum:]*);?")
  unique(IMPACT[,2])
  anyNA(IMPACT[,2])

  SIFT <- vep.output$Extra %>%
    str_match(pattern = "SIFT=([:alpha:]*)\\((.*)\\)[;]?")

  vep.output <- vep.output %>%
    mutate(IMPACT = as.factor(IMPACT[,2])) %>%
    mutate(SIFT.score = as.numeric(SIFT[,3]),
           SIFT.prediction = as.factor(SIFT[,2]))

  pl <- ggplot(vep.output, aes(SIFT.score)) +
    geom_histogram()


  ## add snps name
  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")
  snps.info <- readRDS("./Data/1000Genomes/Phase3/bigsnpr_G/G.rds")$map %>% as_tibble()
  snps.info <- snps.info %>%
    dplyr::filter(marker.ID %in% colnames(G.matter))
  snps.info <- snps.info %>%
    transmute(Location = paste0(chromosome,":",physical.pos),
              snps = marker.ID)

  vep.output <- left_join(vep.output, snps.info, by = c('Location'))

  saveRDS(vep.output, "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  summary(vep.output)
#+end_src

#+RESULTS: code:1000g_vep_output
#+begin_example
[1] "MODIFIER" "HIGH"     "LOW"      "MODERATE"
[1] FALSE
 #Uploaded_variation   Location            Allele              Gene          
 Length:17113181     Length:17113181    Length:17113181    Length:17113181   
 Class :character    Class :character   Class :character   Class :character  
 Mode  :character    Mode  :character   Mode  :character   Mode  :character  
                                                                             
                                                                             
                                                                             
                                                                             
   Feature          Feature_type       Consequence        cDNA_position     
 Length:17113181    Length:17113181    Length:17113181    Min.   :     1    
 Class :character   Class :character   Class :character   1st Qu.:   333    
 Mode  :character   Mode  :character   Mode  :character   Median :   917    
                                                          Mean   :  1685    
                                                          3rd Qu.:  2171    
                                                          Max.   :107492    
                                                          NA's   :16762390  
  CDS_position      Protein_position   Amino_acids           Codons         
 Min.   :     1     Min.   :    1      Length:17113181    Length:17113181   
 1st Qu.:   288     1st Qu.:   96      Class :character   Class :character  
 Median :   741     Median :  247      Mode  :character   Mode  :character  
 Mean   :  1544     Mean   :  515                                           
 3rd Qu.:  1602     3rd Qu.:  534                                           
 Max.   :107267     Max.   :35756                                           
 NA's   :17017945   NA's   :17017945                                        
 Existing_variation    Extra                IMPACT           SIFT.score      
 Mode:logical       Length:17113181    HIGH    :    1535   Min.   :0         
 NA's:17113181      Class :character   LOW     :   68224   1st Qu.:0         
                    Mode  :character   MODERATE:   42072   Median :1         
                                       MODIFIER:17001350   Mean   :1         
                                                           3rd Qu.:1         
                                                           Max.   :1         
                                                           NA's   :17106978  
    SIFT.prediction         snps          
 deleterious:     538   Length:17113181   
 tolerated  :    5665   Class :character  
 NA's       :17106978   Mode  :character
#+end_example


Understanding variant consequence: 
- [[https://www.ensembl.org/info/genome/variation/predicted_data.html#consequences][Ensembl Variation - Predicted data]]
- [[http://gemini.readthedocs.io/en/latest/content/functional_annotation.html#columns-populated-by-snpeff-vep-tools][Annotation with snpEff or VEP]]

***** DONE Calcule du gradient climatique
CLOSED: [2017-08-17 jeu. 11:52]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:52]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:57]
- State "TODO"       from              [2017-08-06 Sun 14:47]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:26]
- State "DONE"       from "TODO"       [2017-07-28 ven. 15:58]
- State "TODO"       from "DONE"       [2017-07-28 ven. 11:46]
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+NAME: code:eas_climatic_gradient
#+CAPTION: Dépend de [[code:eas_indiv_df]]
#+begin_src R 
  library(tidyverse)
  library(MaTheseR)

  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds") %>% as_tibble()
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df


  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"
  indiv.df[indiv.df$pop == "ESN",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "FIN",]$citie = "Finland"
  indiv.df[indiv.df$pop == "GBR",]$citie = "England"

  ## cities
  indiv.df %>%
    dplyr::select(pop, `Population Description`, citie) %>%
    group_by(pop, `Population Description`, citie) %>%
    summarise() %>%
    print.data.frame()


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  ## library(leaflet)
  ## m <- leaflet() %>%
  ##   addTiles() %>%  # Add default OpenStreetMap map tiles
  ##   addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  ## ## m  # Print the map
  ## ## to render in rstudio....
  ## save_expr(m, "eas_map.rds")
  ## ## save widget
  ## library(htmlwidgets)
  ## saveWidget(m, "~/Projects/Thesis/MaThese/OUTPUT/Rplots/eas_map.html", selfcontained = FALSE)

  ## plot map
  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  map.world <- get_map(location = "world")
  pl <- ggplot(cities, aes(x = lon, y = lat, color = `Population Description`)) +
    mapWorld +
    geom_point() +
    theme(legend.position='bottom')
  pl
  save_plot_png(pl, "eas_map_ggplot.png", 1000, 600)

  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  plot(pc.bio$sdev)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    mapWorld + 
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS: code:eas_climatic_gradient
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
Le chargement a nécessité le package : xml2

Attachement du package : ‘rvest’

The following object is masked from ‘package:readr’:

    guess_encoding
  Population Code
1             CHB
2             JPT
3             CHS
4             CDX
5             KHV
6             CEU
                                             Population Description
1                                      Han Chinese in Bejing, China
2                                          Japanese in Tokyo, Japan
3                                              Southern Han Chinese
4                               Chinese Dai in Xishuangbanna, China
5                                 Kinh in Ho Chi Minh City, Vietnam
6 Utah Residents (CEPH) with Northern and Western European Ancestry
  Super Population Code Sequence Data Available Alignment Data Available
1                   EAS                       1                        1
2                   EAS                       1                        1
3                   EAS                       1                        1
4                   EAS                       1                        1
5                   EAS                       1                        1
6                   EUR                       1                        1
  Variant Data Available
1                      1
2                      1
3                      1
4                      1
5                      1
6                      1
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation('ggmap') for details.

Attachement du package : ‘ggmap’

The following object is masked from ‘package:magrittr’:

    inset
Joining, by = "pop"
# A tibble: 1,409 x 9
    sample   pop super_pop gender        `Population Description`
     <chr> <chr>     <chr>  <chr>                           <chr>
 1 HG00096   GBR       EUR   male British in England and Scotland
 2 HG00097   GBR       EUR female British in England and Scotland
 3 HG00099   GBR       EUR female British in England and Scotland
 4 HG00100   GBR       EUR female British in England and Scotland
 5 HG00101   GBR       EUR   male British in England and Scotland
 6 HG00102   GBR       EUR female British in England and Scotland
 7 HG00105   GBR       EUR   male British in England and Scotland
 8 HG00106   GBR       EUR female British in England and Scotland
 9 HG00107   GBR       EUR   male British in England and Scotland
10 HG00108   GBR       EUR   male British in England and Scotland
# ... with 1,399 more rows, and 4 more variables: `Super Population
#   Code` <chr>, `Sequence Data Available` <int>, `Alignment Data
#   Available` <int>, `Variant Data Available` <int>
   pop                                            Population Description
1  BEB                                           Bengali from Bangladesh
2  CEU Utah Residents (CEPH) with Northern and Western European Ancestry
3  ESN                                                   Esan in Nigeria
4  FIN                                                Finnish in Finland
5  GBR                                   British in England and Scotland
6  GIH                               Gujarati Indian from Houston, Texas
7  GWD                        Gambian in Western Divisions in the Gambia
8  IBS                                       Iberian Population in Spain
9  ITU                                         Indian Telugu from the UK
10 JPT                                          Japanese in Tokyo, Japan
11 LWK                                            Luhya in Webuye, Kenya
12 MSL                                             Mende in Sierra Leone
13 PJL                                     Punjabi from Lahore, Pakistan
14 STU                                      Sri Lankan Tamil from the UK
15 TSI                                                 Toscani in Italia
16 YRI                                         Yoruba in Ibadan, Nigeria
            citie
1      Bangladesh
2  United Kingdom
3         Nigeria
4         Finland
5         England
6         Gujarat
7          Gambia
8           Spain
9       Telangana
10          Japan
11          Kenya
12   Sierra Leone
13       Pakistan
14      Sri Lanka
15         Italia
16        Nigeria
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=England&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Finland&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Spain&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Pakistan&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gambia&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Bangladesh&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sierra%20Leone&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sri%20Lanka&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Telangana&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=United%20Kingdom&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Kenya&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Japan&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Italia&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gujarat&sensor=false

Attaching package: ‘maps’

The following object is masked from ‘package:purrr’:

    map
Map from URL : http://maps.googleapis.com/maps/api/staticmap?center=world&zoom=10&size=640x640&scale=2&maptype=terrain&language=en-EN&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=world&sensor=false
[[./OUTPUT/Rplots/eas_map_ggplot.png]]
Le chargement a nécessité le package : sp

Attachement du package : ‘raster’

The following object is masked from ‘package:magrittr’:

    extract

The following object is masked from ‘package:dplyr’:

    select

The following object is masked from ‘package:tidyr’:

    extract
Joining, by = c("pop", "Population Description", "citie")
[1] 1409    1

Attachement du package : ‘plotly’

The following object is masked from ‘package:raster’:

    select

The following object is masked from ‘package:ggmap’:

    wind

The following object is masked from ‘package:stats’:

    filter

The following object is masked from ‘package:graphics’:

    layout

The following object is masked from ‘package:ggplot2’:

    last_plot
We recommend that you use the dev version of ggplot2 with `ggplotly()`
Install it with: `devtools::install_github('hadley/ggplot2')`
#+end_example

***** DONE Scree plot
CLOSED: [2017-08-28 lun. 15:48]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-28 lun. 15:48]
- State "RUNNING"    from "DONE"       [2017-08-28 lun. 15:23]
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 13:25]
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 12:11]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 17:24]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 16:03]
- Note taken on [2017-07-25 mar. 17:52] \\
  faut que je reance avec lambda
- State "TODO"       from "RUNNING"    [2017-07-25 mar. 17:49]
- Note taken on [2017-07-25 mar. 17:46] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_screeplot.y2017_m07_d25_17h_37.log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:46]
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:

#+NAME: code:eas_screeplot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "geas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  save_plot_png(pl, "geas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-17 Thu 18:09]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-17 Thu 18:09]
- State "RUNNING"    from "DONE"       [2017-08-17 jeu. 16:49]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 16:47]
- Note taken on [2017-08-17 jeu. 13:58] \\
  Faut que je relance eas_CV_lambda pour etre sur
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 13:26]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "STARTED"    [2017-08-17 jeu. 08:52]
- State "STARTED"    from "RUNNING"    [2017-08-16 mer. 18:55]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 17:23]
- State "TODO"       from "DONE"       [2017-08-06 Sun 14:48]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:

#+NAME: code:eas_CV
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "geas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "geas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_CV_lfmm_K.png]]

#+NAME: code:eas_CV_encore
#+CAPTION: Dépend de [[eas_CV]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                                X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                                outlier = NULL) %>%
      ExpRmouline()

  lambdas <- c(1e10)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)


  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/geas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "geas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:eas_CV_lambda
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(4,5,6))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "eas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda_lfmm_lambda.png]]

***** TODO Étude du jeu de données
:LOGBOOK:
- State "TODO"       from "RUNNING"    [2017-08-21 lun. 16:48]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 16:48]
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 16:41]
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:13]
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 12:11]
- State "RUNNING"    from "STARTED"    [2017-08-17 jeu. 09:11]
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
****** DONE Run all methods
CLOSED: [2017-08-31 jeu. 08:34]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 08:34]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 12:06]
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:28]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 16:49]
- State "TODO"       from              [2017-08-21 lun. 16:48]
:END:

#+NAME: code:eas_expr
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]] [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(MaTheseR)
  library(lfmm)
  library(matter)
  library(foreach)
  library(doParallel)

  rerun <- FALSE
  nb.cluster <- 1
  ## param
  param <- list(K.method = 9,
                lambda = 1e-5,
                nozero.prop = 0.01,
                lambda.num = 25,
                relative.err.epsilon = 1e-6)


  ## methods
  methods <- list()
  methods$m.lm <- method_lm()
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = param$K.method, lambda = param$lambda)
  methods$m.pca <- method_PCAlm(K = param$K.method)
  methods$m.cate <- method_cate(K = param$K.method)
  methods$m.lasso <- method_lassoLFMM(K = param$K.method,
                                      nozero.prop = param$nozero.prop,
                                      lambda.num = param$lambda.num,
                                      relative.err.epsilon = param$relative.err.epsilon)

  run_eas <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds"
    X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
    outlier <- c()
    dat <- MaTheseR::LfmmMatterDat(Y, X, outlier)
    col.mask <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")
    out.file.res.df <- paste0("./OUTPUT/Expr/Eas_df","_", m$name)
    out.file.U <- paste0("./OUTPUT/Expr/Eas_U","_", m$name)

    if (!exist_res(m, out.file.res.df) && !rerun) {
      ## mask data
      message("mask data")
      dat.masked <- lfmm::LfmmDat(Y = NULL, X = dat$X, missing = FALSE)
      dat.masked$Y <- dat$Y[,col.mask]

      ## compute lattente variable
      message("computing U")
      if (!exist_res(m, out.file.U)) {
        m.U <- ExpRmouline(m, dat.masked)
        save_res(m, m.U, out.file.U)
      } else {
        m.U <- retrieve_res(m, out.file.U)
      }

      ## unmask
      message("unmask data")
      rm(dat.masked)
      gc()

      ## run HP
      message("running HP")
      m.res <- m
      X <- cbind(dat$X, m.U$U)
      d <- ncol(dat$X)
      hp <- lfmm::hypothesis_testing_lm(dat, X)
      m.res$score <- hp$score[,1:d, drop = FALSE]
      m.res$pvalue <- hp$pvalue[,1:d, drop = FALSE]
      m.res$B.hp <- hp$B[,1:d, drop = FALSE]
      ## saving res
      message("saving res.df")
      df <- ExpRextractor_pvalue1_calibrated(dat, m.res, 1, 1)
      save_res(m, df, out.file.res.df)
    } else {
      message("res.df exist !! ")
    }
  }


  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  foreach(m = methods) %dopar% {
    run_eas(m)
  }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)


  ## cbind res
  res.df <- tibble()
  for (m in methods) {
    out.file.res.df <- paste0("./OUTPUT/Expr/Eas_df","_", m$name)
    if (exist_res(m, out.file.res.df)) {
      message("=============== ", m$name)
      res.df <- res.df %>%
        rbind(retrieve_res(m, out.file.res.df))
    }
  }

  save_expr(res.df, "eas_all_df.rds")

#+end_src

****** DONE compute qvalue
CLOSED: [2017-08-21 lun. 17:57]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from              [2017-08-21 lun. 16:42]
:END:
#+NAME: code:eas_qvalue
#+CAPTION: Dépend de [[code:eas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/eas_all_df.rds")

  qval.df <- res.df %>%
    group_by(method) %>%
    dplyr::mutate(qvalue = qvalue::qvalue(calibrated.pvalue)$qvalues) %>%
    ungroup()

  save_expr(qval.df, "eas_all_qvalue_df.rds")
#+END_SRC

****** load expr res
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_load_res
#+CAPTION: Dépend de [[code:eas_qvalue]]
#+BEGIN_SRC R
  library(MaTheseR)
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
#+END_SRC


#+RESULTS: code:eas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-08-22 mar. 09:36]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:36]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_calibration
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  qval.df %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS: code:eas_calibration
: # A tibble: 5 x 3
:      method      mad     median
:       <chr>    <dbl>      <dbl>
: 1      cate 1.580635 0.11340787
: 2 lassoLFMM 1.224637 0.08467967
: 3        lm 8.760657 0.38152482
: 4     PCAlm 1.046560 0.01363840
: 5 ridgeLFMM 1.587502 0.11969276

****** TODO Les qqplots ?
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_qqplot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- qval.df %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))

  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

****** TODO Comparaison des top listes
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-31 jeu. 08:53]
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:41]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_top
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- res.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS: code:eas_top
[[./OUTPUT/Rplots/eas_top_inter.png]]

****** DONE Comparaison des listes avec contrôle du FDR à $0.01$ and venn diag
CLOSED: [2017-08-31 jeu. 10:14]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-31 jeu. 10:14]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_fdr
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- qval.df %>%
    dplyr::filter(qvalue <= 0.01)

  ## matrix
  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")

  ## venn diagram
  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")

#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

****** TODO Annotation Biomart
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-08-30 mer. 10:22]
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:

#+NAME: code:eas_annotation
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation union ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()


  message("== annotation lfmmRidge ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("ridgeLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation cate ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("cate")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation lasso ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("lassoLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation PCAlm ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("PCAlm")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

#+END_SRC

#+NAME: code:eas_annotation_inter
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation inter ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- list(lm = aux$index[aux$method == "lm"],
               cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  sets <- sets[2:5]
  candidates.snps.df <- aux %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  length(unique(candidates.snps.df$colname))
  aux2 <- candidates.snps.df %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux2 %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()


#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_inter_manhattan.png]]

****** TODO Annotation Vep
:LOGBOOK:
- State "TODO"       from              [2017-08-22 mar. 11:46]
:END:

#+NAME: code:eas_annotation_vep
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  vep.output$Consequence %>% table()
  vep.output$IMPACT %>% table() / nrow(vep.output)

  message("== vep annotation union ==")
  res.df.union <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))


  res.df.union$IMPACT %>% table() / nrow(res.df.union)
  res.df.union$Consequence %>% table()

  message("== annotation lfmmRidge ==")
  res.df.union <- res.df %>%
    dplyr::filter(method %in% c("ridgeLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))

  res.df.union$IMPACT %>% table() / nrow(res.df.union)

  message("== annotation cate ==")
  res.df.union <- res.df %>%
    dplyr::filter(method %in% c("cate")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))

  res.df.union$IMPACT %>% table() / nrow(res.df.union)
#+end_src

****** TODO Annotation de l'intersection
:LOGBOOK:
- State "TODO"       from              [2017-08-30 mer. 10:15]
:END:

#+NAME: code:eas_inter_annotation
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)
  library(stringr)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  ## filter FDR 1%
  aux <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  ## intersection
  inter.list <- function(...) {
    id <- list(...)
      res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- list(cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  inter.candidates.df <- aux %>%
    dplyr::filter(index %in% inter.list(1,2,3,4),
                  method == "cate") 
  ## 14 candidates
  length(inter.candidates.df$colname)

  ## vep annotation
  inter.candidates.df.vep <- inter.candidates.df %>%
    dplyr::left_join(vep.output, by = c('snps')) %>%
    mutate(chrm = str_replace(Location, ":[:digit:]*",""),
           pos = str_replace(Location, "[:digit:]*:",""))


  inter.candidates.df.vep$chrm
  inter.candidates.df.vep$pos
  inter.candidates.df.vep$IMPACT %>% table()
  inter.candidates.df.vep$Gene %>% table()
  inter.candidates.df.vep$Consequence %>% table()

  inter.candidates.df.vep %>% dplyr::filter(IMPACT == "MODERATE") %>%
    dplyr::select(IMPACT, Consequence)

  ## plot
  pl <- ggplot(inter.candidates.df.vep, aes(x = pos, y = -log10(pvalue))) +
    geom_point() +
    facet_grid(~ chrm, scales = "free")
  save_plot_png(pl, "eas_inter_manhattan.png")

  ## biomart
  require(biomaRt)
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")

  inter.candidates.df.biomart <- inter.candidates.df %>%
    mutate_annotation(snp.db)

  inter.candidates.df.vep$phenotype_name

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_inter_manhattan.png]]

****** DONE Annotation de l'union
CLOSED: [2017-09-01 ven. 13:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:11]
- State "TODO"       from              [2017-08-31 jeu. 13:56]
:END:
#+NAME: code:eas_inter_annotation
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)
  library(stringr)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  ## contingency IMPACT
  impact.all <- vep.output %>%
    distinct(snsp, keep_all = TRUE) %>%
    dplyr::select(IMPACT)
  cont.impact.all <- impact.all$IMPACT %>% table()

  ## filter FDR 1%
  aux <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  ## union
  union.list <- function(...) {
    id <- list(...)
      res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::union(res, sets[[i]])
    }
    res
  }
  sets <- list(cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  union.candidates.df <- aux %>%
    dplyr::filter(index %in% union.list(1,2,3,4))
  message("== number of SNPS detected ==")
  length(unique(union.candidates.df$colname))

  ## vep annotation
  union.candidates.df.vep <- union.candidates.df %>%
    dplyr::left_join(vep.output, by = c('snps')) %>%
    mutate(chrm = str_replace(Location, ":[:digit:]*",""),
           pos = str_replace(Location, "[:digit:]*:",""))

  ## over representation of HIGH
  library(broom)
  cont <- rbind(union = union.candidates.df.vep$IMPACT %>% table(), cont.impact.all)
  over.test.res <- tibble()
  f.aux <- function(lvl) {
    cont.lvl <- cbind(lvl = cont[,lvl], other = rowSums(cont[,!(colnames(cont) %in% lvl)]))
    over.test.res <<- fisher.test(cont.lvl, alternative="greater") %>% tidy() %>%
      mutate(lvl = lvl) %>%
      rbind(over.test.res)
  }
  message("== over representation tests ==")
  f.aux(lvl = "HIGH")
  f.aux(lvl = "LOW")
  f.aux(lvl = "MODERATE")
  over.test.res %>%
    transmute(odds.ratio = estimate,
                pvalue = p.value,
                lvl = lvl) %>%
    knitr::kable()

  ## biomart
  require(biomaRt)
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  ## listFilters(snp.db)
  ## listAttributes(snp.db)

  union.candidates.df.biomart <- union.candidates.df %>%
    mutate_annotation(snp.db)

  ## tab
  message("== phenotype description in union union ==")
  union.candidates.df.biomart %>%
    dplyr::filter(phenotype_description != "") %>%
    group_by(phenotype_description) %>%
    dplyr::summarise(methods = paste0(unique(method), collapse=", "),
                     spns = paste0(unique(snps), collapse=", ")) %>%
    knitr::kable()

  ## amiGo2
  message("== panther input ==")
  (union.candidates.df.vep %>%
    distinct(Gene))$Gene %>%
    paste0(collapse=" ")
#+end_src

#+RESULTS: code:eas_inter_annotation
#+begin_example
== number of SNPS detected ==
[1] 836
== over representation tests ==


| odds.ratio|    pvalue|lvl      |
|----------:|---------:|:--------|
|   7.922087| 0.0000000|MODERATE |
|   1.706059| 0.0026103|LOW      |
|  22.281430| 0.0000000|HIGH     |
               biomart               version
1 ENSEMBL_MART_ENSEMBL      Ensembl Genes 90
2   ENSEMBL_MART_MOUSE      Mouse strains 90
3     ENSEMBL_MART_SNP  Ensembl Variation 90
4 ENSEMBL_MART_FUNCGEN Ensembl Regulation 90
== phenotype description in union union ==


|phenotype_description                                                                                     |methods                    |spns                                                  |
|:---------------------------------------------------------------------------------------------------------|:--------------------------|:-----------------------------------------------------|
|Alcoholism (heaviness of drinking)                                                                        |ridgeLFMM, cate            |rs10908907                                            |
|Body Height                                                                                               |lassoLFMM                  |rs10496731                                            |
|Caffeine metabolism (plasma 13-dimethylxanthine (theophylline) level)                                     |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Caffeine metabolism (plasma 137-trimethylxanthine (caffeine) level)                                       |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Caffeine metabolism (plasma 17-dimethylxanthine (paraxanthine) to 137-trimethylxanthine (caffeine) ratio) |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Cholesterol total                                                                                         |ridgeLFMM, cate, lassoLFMM |rs2256175                                             |
|Coffee consumption (cups per day)                                                                         |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Congenital lactase deficiency                                                                             |lassoLFMM                  |rs2278544, rs2322659                                  |
|Corneal structure                                                                                         |ridgeLFMM, cate, lassoLFMM |rs4954218                                             |
|Electrocardiographic traits                                                                               |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Electrocardiography                                                                                       |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Giant cell arteritis                                                                                      |ridgeLFMM, cate, lassoLFMM |rs2256175                                             |
|Height                                                                                                    |ridgeLFMM, cate, lassoLFMM |rs2256175, rs6085576, rs2104012, rs1983716, rs2853977 |
|Hematocrit                                                                                                |ridgeLFMM, cate, lassoLFMM |rs6430549                                             |
|Lactose intolerance                                                                                       |lassoLFMM                  |rs2278544, rs2322659                                  |
|Multiple sclerosis                                                                                        |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Neuroblastoma                                                                                             |ridgeLFMM, cate, lassoLFMM |rs1123848                                             |
|Obesity-related traits                                                                                    |lassoLFMM                  |rs17158483                                            |
== panther input ==
[1] "ENSG00000171735 ENSG00000270171 ENSG00000270035 ENSG00000269978 NA ENSG00000138071 ENSG00000152127 ENSG00000152128 ENSG00000224043 ENSG00000153086 ENSG00000263783 ENSG00000082258 ENSG00000176601 ENSG00000115850 ENSG00000226806 ENSG00000076003 ENSG00000115866 ENSG00000231890 ENSG00000227347 ENSG00000216081 ENSG00000229568 ENSG00000221762 ENSG00000144229 ENSG00000228043 ENSG00000144227 ENSG00000231567 ENSG00000223921 ENSG00000168702 ENSG00000128645 ENSG00000224189 ENSG00000155657 ENSG00000144749 ENSG00000172340 ENSG00000075651 ENSG00000249782 ENSG00000230873 ENSG00000204536 ENSG00000238211 ENSG00000206337 ENSG00000204520 ENSG00000184465 ENSG00000048052 ENSG00000234336 ENSG00000127957 ENSG00000200874 ENSG00000008277 ENSG00000253350 ENSG00000148429 ENSG00000183621 ENSG00000183801 ENSG00000251364 ENSG00000255191 ENSG00000150676 ENSG00000149972 ENSG00000182667 ENSG00000181234 ENSG00000256630 ENSG00000151952 ENSG00000177596 ENSG00000226240 ENSG00000102466 ENSG00000232662 ENSG00000206190 ENSG00000261401 ENSG00000248334 ENSG00000156642 ENSG00000167508 ENSG00000260630 ENSG00000176890 ENSG00000176912 ENSG00000263727 ENSG00000142544 ENSG00000229876 ENSG00000157933 ENSG00000175130 ENSG00000116478 ENSG00000004455 ENSG00000236065 ENSG00000233047 ENSG00000121957 ENSG00000162641 ENSG00000143442 ENSG00000143627 ENSG00000117523 ENSG00000162779 ENSG00000143839 ENSG00000152104 ENSG00000134121 ENSG00000234661 ENSG00000144645 ENSG00000154175 ENSG00000181804 ENSG00000163347 ENSG00000197283 ENSG00000264085 ENSG00000146416 ENSG00000217648 ENSG00000131018 ENSG00000170632 ENSG00000233025 ENSG00000105939 ENSG00000173068 ENSG00000106804 ENSG00000130713 ENSG00000165695 ENSG00000065665 ENSG00000165609 ENSG00000122958 ENSG00000233163 ENSG00000205339 ENSG00000110318 ENSG00000187151 ENSG00000139151 ENSG00000255993 ENSG00000065150 ENSG00000150403 ENSG00000238737 ENSG00000242502 ENSG00000261739 ENSG00000103742 ENSG00000140443 ENSG00000048471 ENSG00000126856 ENSG00000072849 ENSG00000167842 ENSG00000263433 ENSG00000264734 ENSG00000136450 ENSG00000266086 ENSG00000186111 ENSG00000105072 ENSG00000269058 ENSG00000141979 ENSG00000131943 ENSG00000099904 ENSG00000188424 ENSG00000235578 ENSG00000198089 ENSG00000236052 ENSG00000116288 ENSG00000233008 ENSG00000135845 ENSG00000180999 ENSG00000228098 ENSG00000144224 ENSG00000131389 ENSG00000204681 ENSG00000223702 ENSG00000225851 ENSG00000230994 ENSG00000265294 ENSG00000185920 ENSG00000171811 ENSG00000134873 ENSG00000246877 ENSG00000260288 ENSG00000256530 ENSG00000152217 ENSG00000101384 ENSG00000117154 ENSG00000173406 ENSG00000237262 ENSG00000227149 ENSG00000135931 ENSG00000206527 ENSG00000239523 ENSG00000114544 ENSG00000251297 ENSG00000249462 ENSG00000271307 ENSG00000234745 ENSG00000271581 ENSG00000269964 ENSG00000106069 ENSG00000237065 ENSG00000235669 ENSG00000136193 ENSG00000253260 ENSG00000165185 ENSG00000252730 ENSG00000110057 ENSG00000110721 ENSG00000236267 ENSG00000258118 ENSG00000153575 ENSG00000104044 ENSG00000141429 ENSG00000266312 ENSG00000268184 ENSG00000241604"
#+end_example

****** CANCELLED Meta analysis
CLOSED: [2017-09-12 mar. 19:57]
:LOGBOOK:
- State "CANCELLED"  from "DEFERRED"   [2017-09-12 mar. 19:57]
- State "DEFERRED"   from "TODO"       [2017-09-12 mar. 19:57]
- State "TODO"       from              [2017-09-12 mar. 15:22]
:END:
#+NAME: code:eas_meta_analysis
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  require(MaTheseR)


  ## we want to have independant statistic
  method <- c("ridgeLFMM", "lassoLFMM", "cate")
  calibrated.score.mat <- NULL
  for (m in method) {
    message(m)
    calibrated.score.mat <- calibrated.score.mat %>%
      cbind(qval.df[qval.df$method == m,]$calibrated.score)
  }

  pca.res <- prcomp(calibrated.score.mat, center = FALSE, scale. = FALSE)
  pca.res$sdev

  ## combination
  pca.res$x[,1] %>% hist() ## il sont pas normal
  pca.res$x[,2] %>% hist()
  pca.res$x[,3] %>% hist()
#+end_src

****** DONE Clumping list with fdr controled to 1%
CLOSED: [2017-09-12 mar. 17:04]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 17:04]
- State "TODO"       from              [2017-09-12 mar. 15:56]
:END:
#+NAME: code:eas_clumping
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  library(MaTheseR)

  methods <- (qval.df$method %>% unique())
  methods

  ## clumping with plink
  res <- tibble()
  for (m in methods) {
    tmp.file <- tempfile()
    qval.df %>% dplyr::filter(method == m) %>%
      dplyr::transmute(P = qvalue, SNP = colname) %>%
        readr::write_delim(path = tmp.file, delim = "\t")
    plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                       "--bfile ~/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ",
                       "--clump",
                       tmp.file,
                       "--clump-p1 0.01", ## FDR control to 1%
                       "--clump-p2 1.0",
                       "--clump-r2 0.50",
                       "--clump-kb 250",
                       "--out plink.clump",
                       "--threads 8")
    system(plink.cmd)

    clumping.res <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                      data.table = FALSE) %>% as_tibble()

    res <- clumping.res %>%
      mutate(method = m) %>%
      rbind(res)

    file.remove(tmp.file)
  }

  save_expr(res, "eas_all_clumps.rds")
#+end_src

#+RESULTS: code:eas_clumping
#+begin_example
[1] "lm"        "ridgeLFMM" "PCAlm"     "cate"      "lassoLFMM"
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea27d82590
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
Warning: No significant --clump results.  Skipping.
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69eae397bd3
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 88 clumps formed from 482 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea58a6d150
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 57 clumps formed from 90 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea185529f6
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 111 clumps formed from 538 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea410344c5
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 103 clumps formed from 606 top variants.
Results written to plink.clump.clumped .
Expr save in ./OUTPUT/Expr/eas_all_clumps.rds
#+end_example

****** DONE Annotation de l'union des clumps
CLOSED: [2017-09-12 mar. 19:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 19:11]
- State "TODO"       from "CANCELLED"  [2017-09-12 mar. 18:39]
- Note taken on [2017-09-12 mar. 18:38] \\
  c'est bizare en gros je trouve les mêmes chose de toute facon !!
- State "CANCELLED"  from "TODO"       [2017-09-12 mar. 18:38]
- State "TODO"       from              [2017-09-12 mar. 17:05]
:END:
#+NAME: code:eas_clumps_annotation
#+CAPTION: Dépend de [[code:eas_clumping]]
#+begin_src R 
  library(MaTheseR)
  library(stringr)
  clumps.df <- readRDS("./OUTPUT/Expr/eas_all_clumps.rds")
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")

  ## fdr control
  controled.qval.df <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  message("unique clumps")
  clumps.df$SNP %>% unique() %>% length()

  ## explode clumps
  exploded.clumps.df <- tibble()
  for (i in 1:nrow(clumps.df)) {
    SNP <- clumps.df$SNP[i]
    SP2 <- clumps.df$SP2[i] %>% str_split(",", simplify = TRUE) %>%
      str_replace("\\(1\\)", "") %>%
      str_split(";", simplify = TRUE)
    SP2 <- c(SP2, SNP)
    exploded.clumps.df <- exploded.clumps.df %>%
      rbind(tibble(snps = SP2, clump.snps = SNP))
  }

  ## biomart annotation
  require(biomaRt)
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  attributes = c("refsnp_id",
                 "refsnp_source",
                 "chr_name",
                 "chrom_start",
                 'phenotype_name',
                 "phenotype_description",
                 "ensembl_gene_stable_id")

  the.snps <- unique(exploded.clumps.df$snps)
  nt.biomart <- biomaRt::getBM(attributes = attributes,
                               filters = "snp_filter",
                               values = the.snps,
                               mart = snp.db)
  nt.biomart <- nt.biomart %>%
    dplyr::mutate(snps = refsnp_id)
  nt.biomart <- left_join(exploded.clumps.df,nt.biomart, by = "snps")

  ## lil test
  nt.biomart$clump.snps %in% controled.qval.df$snps %>% mean()

  save_expr(nt.biomart, "eas_annotation_clumps.rds")
#+end_src

****** DONE Tableau de l'annotation des clumps
CLOSED: [2017-09-12 mar. 20:22]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 20:22]
- State "TODO"       from              [2017-09-12 mar. 19:12]
:END:
#+NAME: code:eas_clumps_tab
#+CAPTION: Dépend de [[code:eas_clumps_annotation]]
#+begin_src R 
  library(MaTheseR)

  clumps.df <- readRDS("./OUTPUT/Expr/eas_all_clumps.rds")
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
  nt.biomart <- readRDS("./OUTPUT/Expr/eas_annotation_clumps.rds")

  clumps.df$SNP %in% controled.qval.df$snps %>% mean()

  ## On regroupe le tout
  aux <- qval.df %>%
    transmute(clump.snps = colname,
              pvalue = calibrated.pvalue,
              method = method)
  aux <- left_join(nt.biomart, aux, by = "clump.snps")
  aux <- aux %>%
    transmute(snps = snps,
              clump.snps = clump.snps,
              pvalue = pvalue,
              method = method,
              gene = ensembl_gene_stable_id,
              phenotype_name= phenotype_name,
              phenotype_description = phenotype_description)

  res.df <- aux %>%
    dplyr::filter(phenotype_description != "") %>%
    group_by(clump.snps, method, pvalue) %>%
    summarise(genes = paste0(unique(gene), collapse = ", "),
              phenotype_names = paste0(unique(phenotype_name), collapse = ", "),
              phenotype_descriptions = paste0(unique(phenotype_description), collapse = ", "),
              snp.in.clump = paste0(unique(snps), collapse = ", ")) %>%
    tidyr::spread(key = method, value = pvalue) %>%
    ungroup()

  ## tabble
  res.df %>%
    dplyr::select(cate, lassoLFMM, lm, PCAlm, clump.snps, phenotype_descriptions) %>%
    knitr::kable()

#+end_src

#+RESULTS: code:eas_clumps_tab
#+begin_example
[1] 1


|      cate| lassoLFMM|        lm|     PCAlm|clump.snps |phenotype_descriptions                                                                                                                                                                                                                                                                   |
|---------:|---------:|---------:|---------:|:----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 0.0000003| 0.0039447| 0.0151267| 0.6393762|rs10908907 |Alcoholism (heaviness of drinking)                                                                                                                                                                                                                                                       |
| 0.0000000| 0.0000000| 0.0614097| 0.0001885|rs12691876 |Electrocardiography, Multiple sclerosis, Electrocardiographic traits                                                                                                                                                                                                                     |
| 0.0000000| 0.0000000| 0.0830381| 0.0000022|rs1470457  |Congenital lactase deficiency, Lactose intolerance                                                                                                                                                                                                                                       |
| 0.0000000| 0.0000000| 0.0566630| 0.0000000|rs1530559  |Hematocrit                                                                                                                                                                                                                                                                               |
| 0.0000822| 0.0000000| 0.2876809| 0.0000003|rs17158483 |Obesity-related traits                                                                                                                                                                                                                                                                   |
| 0.0000654| 0.0000005| 0.1190359| 0.0000228|rs17228197 |Cholesterol HDL, Exercise Test                                                                                                                                                                                                                                                           |
| 0.0000002| 0.0000250| 0.1364597| 0.1167581|rs1983716  |Height                                                                                                                                                                                                                                                                                   |
| 0.0000028| 0.0000003| 0.1936770| 0.0001651|rs2256174  |Height, Behcet Syndrome, Lupus Erythematosus Systemic, Cholesterol total, Cervical Cancer                                                                                                                                                                                                |
| 0.0000002| 0.0000003| 0.2245867| 0.0001560|rs2256175  |Cholesterol total, Height, Behcet Syndrome, Giant cell arteritis                                                                                                                                                                                                                         |
| 0.0000003| 0.0000007| 0.0204494| 0.0027263|rs2472297  |Coffee consumption (cups per day), Caffeine metabolism (plasma 17-dimethylxanthine (paraxanthine) to 137-trimethylxanthine (caffeine) ratio), Caffeine metabolism (plasma 13-dimethylxanthine (theophylline) level), Caffeine metabolism (plasma 137-trimethylxanthine (caffeine) level) |
| 0.0002303| 0.0000011| 0.0054879| 0.0000242|rs2727791  |High-density lipoprotein cholesterol, Apolipoprotein A-IV levels                                                                                                                                                                                                                         |
| 0.0000000| 0.0093811| 0.1221122| 0.8835068|rs3101270  |Response to antipsychotic treatment                                                                                                                                                                                                                                                      |
| 0.0000009| 0.0012005| 0.0406157| 0.1291847|rs35731977 |CELIAC DISEASE                                                                                                                                                                                                                                                                           |
| 0.0000392| 0.0000007| 0.0137603| 0.0000908|rs4466389  |Multiple myeloma (IgH translocation)                                                                                                                                                                                                                                                     |
| 0.0000004| 0.0000000| 0.0484197| 0.0000494|rs4954218  |Corneal structure                                                                                                                                                                                                                                                                        |
| 0.0000000| 0.0000000| 0.2562551| 0.0000113|rs4954567  |Neuroblastoma                                                                                                                                                                                                                                                                            |
| 0.0338803| 0.0000083| 0.4738190| 0.0000000|rs62056344 |Vitamin K                                                                                                                                                                                                                                                                                |
| 0.0000001| 0.0000001| 0.0085463| 0.0001146|rs66733621 |Cardiovascular phenotype, Hypertrophic cardiomyopathy, Dilated Cardiomyopathy Dominant, Hereditary Myopathy with Early Respiratory Failure, Limb-Girdle Muscular Dystrophy Recessive, Myopathy early-onset with fatal cardiomyopathy, Distal myopathy Markesbery-Griggs type             |
| 0.0000000| 0.0000000| 0.1304925| 0.0000049|rs6716987  |Neuroblastoma, Electrocardiography, Multiple sclerosis, Electrocardiographic traits                                                                                                                                                                                                      |
| 0.0000000| 0.0000000| 0.0119291| 0.0000002|rs6730196  |Congenital lactase deficiency, Lactose intolerance                                                                                                                                                                                                                                       |
| 0.0005657| 0.0000008| 0.5858195| 0.0000005|rs7259739  |Capecitabine sensitivity                                                                                                                                                                                                                                                                 |
| 0.0000001| 0.0000000| 0.1888716| 0.0000588|rs766271   |Body Height, Blood metabolite levels                                                                                                                                                                                                                                                     |
| 0.0000004| 0.0000473| 0.0195241| 0.0615935|rs9267897  |Prostate Cancer                                                                                                                                                                                                                                                                          |
| 0.0000004| 0.0000498| 0.0187989| 0.0626544|rs9267907  |Prostate Cancer                                                                                                                                                                                                                                                                          |
| 0.9524410| 0.0046970| 0.1427599| 0.0000001|rs9927276  |Subjective well-being                                                                                                                                                                                                                                                                    |
#+end_example

Mouais c'est pas forcément très fair de faire remonter le phénotype de la touffe avec la pvaleur max de celle ci ....
a mediter

****** TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:

#+NAME: code:eas_manhattan_plot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src
***** DONE Plot
CLOSED: [2017-09-01 ven. 13:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:11]
- State "TODO"       from              [2017-08-17 jeu. 14:32]
:END:

****** DONE Gradient climatique
CLOSED: [2017-08-29 mar. 11:46]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-29 mar. 11:46]
- State "TODO"       from              [2017-08-21 lun. 14:48]
:END:
#+NAME: code:eas_climatic_gradient_plot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  library(ggmap)
  MaTheseR.params <- get_MaTheseRparams()


  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, text = `Population Description`)) +
    mapWorld + 
    geom_point() +
    MaTheseR.params$gtheme +
    scale_size_continuous(guide = FALSE) +
    xlab("Longitude") +
    ylab("Latitude")
  pl
  save_plot_MaTheseR(pl, "eas_climatic_gradient.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)



#+end_src

#+RESULTS: code:eas_climatic_gradient_plot
#+begin_example
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation('ggmap') for details.

Attaching package: ‘ggmap’

The following object is masked from ‘package:cowplot’:

    theme_nothing

The following object is masked from ‘package:magrittr’:

    inset

Attaching package: ‘maps’

The following object is masked from ‘package:purrr’:

    map
[[./OUTPUT/Rplots/eas_climatic_gradient.pdf.png]]
#+end_example

****** DONE Choix des paramètres
CLOSED: [2017-08-28 lun. 16:07]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-28 lun. 16:07]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 16:47]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 16:46]
- State "TODO"       from              [2017-08-17 jeu. 14:33]
:END:

#+NAME: code:eas_screeplot_CV
#+CAPTION: Dépend de [[code:eas_screeplot]] [[code:eas_CV]] [[code:eas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/geas_screeplot_expr.rds")
  plA <- ggplot(expr, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,15)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "eas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/geas_CV_lfmm_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.5)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.8))
  save_plot_png(plB, "eas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/eas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    geom_vline(xintercept = 1e-5, linetype = "dashed") +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.8, 0.2))
  save_plot_png(plC, "eas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "eas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:eas_screeplot_CV
: [[./OUTPUT/Rplots/eas_screeplot.png]]
: [[./OUTPUT/Rplots/eas_CV_K.png]]
: [[./OUTPUT/Rplots/eas_CV_lambda.png]]
****** DONE qqplot and venn diagram
CLOSED: [2017-08-31 jeu. 12:12]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 12:12]
- State "RUNNING"    from "DONE"       [2017-08-31 jeu. 08:57]
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 08:42]
- State "RUNNING"    from "TODO"       [2017-08-29 mar. 16:24]
- State "TODO"       from              [2017-08-21 lun. 16:50]
:END:

#+NAME: code:eas_ggplot_venn
#+CAPTION: Dépend de [[code:eas_qvalue]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  res.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
  ## filter and order method
  res.df <- res.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              qvalue = qvalue)
  res.df$method %>% unique()

  #############################################################################
  ## qqplot

  pl.qq <- ggplot(res.df, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom") +
    xlab("Quantiles théoriques") +
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "eas_qqplot_notcalibrated_all.png")
  save_plot_MaTheseR(pl.qq, "eas_qqplot_notcalibrated_all.pdf.png",
                       height = 0.5 * MaTheseR.params$textheightcm,
                       width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  toplot <- res.df %>%
    dplyr::filter(qvalue <= 0.01)
  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"])

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quad.venn(
                         area1 = inter(1),
                         area2 = inter(2),
                         area3 = inter(3),
                         area4 = inter(4),
                         n12 = inter(1,2),
                         n13 = inter(1,3),
                         n14 = inter(1,4),
                         n23 = inter(2,3),
                         n24 = inter(2,4),
                         n25 = inter(2,5),
                         n34 = inter(3,4),
                         n123 = inter(1,2,3),
                         n124 = inter(1,2,4),
                         n134 = inter(1,3,4),
                         n234 = inter(2,3,4),
                         n245 = inter(2,4,5),
                         n1234 = inter(1,2,3,4),
                         category = names(sets),
                         fill = color.values[names(sets)],
                         cat.col = color.values[names(sets)],
                         cat.cex = 1.2,
                         margin = 0.07,
                         ind = TRUE
                       )

  save_plot_png(venn, filename = "eas_venn.png")
  save_plot_MaTheseR(venn, "eas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_venn.png]]
[[./OUTPUT/Rplots/eas_qqplot_notcalibrated_all.png]]

** Discussion
Les études d'association sont largement utilisées en biologie pour trouver des
liens de corrélation entre des variables. Cependant une corrélation n'est pas
une lien de causalité. Nous nous sommes intéressé dans ce chapitre à la
situation où des variables non observées explique une partie de variations de
$\Y$ et sont corrélé à la variable explicative $\X$. Dans nos résultats la
méthodes lm ne prend pas en compte les facteurs latents. Nous avons observé une
forte inflation des \pvalues retrouné par lm sur les données simulées (Figure
ref:fig:method_comp C et D) ainsi que dans l'EWAS (Figure
ref:fig:ewas_qqplot_top A) et la GEAS (Figure ref:fig:geas_qqplot A) que nous
avons présentés dans ce chapitre. En plus de la forte inflation des \pvalues on
observe également que lm ne permet pas de trouver les bonnes associations, on
observe ainsi dans les données simulées que l'AUC obtenu par lm est largement
inférieur à celui de la méthode oracle qui connait les vrais facteur latents
(Figure ref:fig:method_comp A et B). Enfin pour les études d'associations à
partir de données réelle lm donne les moins bon résultat quand il s'agit de
retrouver les candidats pour l'association trouvés par ailleurs dans la
littérature (Figure ref:fig:ewas_qqplot_top B et Figure ref:fig:gwas_qqplot_top
B).

Une méthode de correction pour les facteurs de confusion consiste à utiliser les
scores de l'ACP pour apprendre les facteurs de confusions; nous l'avons nommée
dans ce chapitre PCAlm. Sur les simulations numériques PCAlm renvoie des
\pvalues bien calibrées (Figure ref:fig:method_comp C et D) mais l'AUC de PCAlm
décroit avec le nombre de variables associées et la corrélation entre les
variables latentes et la variable explicative (Figure ref:fig:method_comp A et
B). On retrouve le fait que les \pvalues sont bien calibrées dans les études
d'association sur des vrais données (Figure ref:fig:ewas_qqplot_top A, Figure
ref:fig:gwas_qqplot_top A et ref:fig:geas_qqplot). Les candidats trouvé par
d'autre méthodes sont bien retrouvés par PCAlm (Figure ref:fig:ewas_qqplot_top B
et Figure ref:fig:gwas_qqplot_top B). On peut supposer que PCAlm donne de bonne
performance sur la GWAS et l'EWAS car il y à peu de variables à détecter. De
plus certain candidats trouvés dans d'autre étude ont trouvé avec des méthodes
similaires à PCAlm comme Refactor de cite:Rahmani_2016 ou EIGENSTRAT de
cite:Price_2006.

Les deux méthodes SVA comparées dans ce chapitre donnent des résultats
similaires à PCAlm sur les simualtions numériques (Figure ref:fig:method_comp).
La méthode sva-two-step donne des résultats très similaires à PCAlm sur l'EWAS
alors que sva-two-step donne des résultats très atypique comparées aux autres
méthodes considérées pour l'EWAS. Avec les bons hyper paramètres, il est
possible que sva-irw donne des résultats comparables aux autres méthodes.
Cependant il n'y a aucun garantit sur la convergence de sva-irw ce qui rend
compliqué l'exploration pour trouver les bons hyper paramètres.

Nous avons proposé dans ce chapitre deux méthodes, ridgeLFMM et lassoLFMM, de
correction des études d'association pour les facteurs latents qui reposent sur
les solutions optimales de problèmes de moindres carré régularisés. Sur les jeux
de données simulées ces méthodes ont les mêmes performances que la méthode
oracle qui connait les facteurs de confusions (Figure ref:fig:method_comp),
elles sont bien calibré sur les vrais jeux de données (Figure
ref:fig:ewas_qqplot_top A, Figure ref:fig:gwas_qqplot_top A et
ref:fig:geas_qqplot) et on retrouve les candidats validés par la littératures
(Figure ref:fig:ewas_qqplot_top B et ref:fig:gwas_qqplot_top B). Les
performances globales de ces méthodes sont très comparable à la méthode cate.
Bien que cate, ridgeLFMM et lassoLFMM ont des performances très similaires pour
nos critères d'évaluation il existe tout de même des différences entre les
listes de candidats renvoyés pas ces trois méthodes (Figure ref:fig:ewas_venn,
Figure ref:fig:gwas_venn et Figure ref:fig:geas_venn). Il serait intéressant de
mettre en évidence des situations mettant en défaut une méthode par rapport à
une autre. Par ailleurs, il existe des techniques permettant de combiner les
résultats venant de plusieurs méthodes pour tester l'association, cela permet de
d'augmenter la confiance que l'on a en les résultats d'une étude d'association.
Nous avons utilisé l'union dans l'étude entre génome et environnement pour
combiner les résultats mais il existe des techniques plus sophistiquées pour
combiner des \pvalues venant de plusieurs test d'hypothèse comme par exemple
celle utilisée dans cette étude cite:sniekers2017genome.

Dans les études d'association considérées ici il n'y pas de vérité terrain et
une méthode peut toujours donner de meilleurs résultats qu'une autre sur des
simulations bien choisis cite:Wolpert_1997. Ces deux nouvelles méthodes
s'ajoutent à l'arsenal des méthodes permettant de corriger pour les facteurs de
confusion les test d'association statistique pour les facteurs de confusion.

** SANDBOX                                                        :noexport:
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** CANCELLED ridgeLFMM et cate quand B et V sont corrélé :D
CLOSED: [2017-08-07 lun. 14:32]
:LOGBOOK:
- Note taken on [2017-08-07 lun. 16:22] \\
  cate marche bien, la regression robuste va eviter ce cas la !!!
- State "CANCELLED"  from              [2017-08-07 lun. 14:32]
:END:

Que se passe-t-il quand B et V sont corrélé :D

#+begin_src R :results output :exports both
  sampler
#+end_src

Voir cahier le 7/08/2017

* Perspectives et conclusion 
:LOGBOOK:
- Note taken on [2017-09-14 jeu. 13:25] \\
  L'ancestry local ? utiliser l'information spatial pour l'ancestry locale ???
- Note taken on [2017-08-30 mer. 11:58] \\
  Le choix de K dans les étude d'association c'est ca le vrai pb !! une petite
  experience qui montre que ca fait n'imp ?? genre sur la GEAS on augment K et on
  compare les liste controlé à 1% ?
- Note taken on [2017-08-10 jeu. 12:05] \\
  Les données manquante :D il y en a beaucoups dans les gandes données ! tess3r
  devrais être quand il y a des données manquante. Enfin si il prennait en compre
  correctement les NA. Faire une petite simu d'un tess qui prend en compre bien
  les missing data :D !!!!
- Note taken on [2017-07-31 lun. 10:20] \\
  on va parler de : 
  - vers le big data ? (valeurs manquantes, données pas loadé en mémoire)
  - est ce que le modèle est polygénique ?
  - théorie stat (cf cate)
  - matrice de dosage
  - lien autre que linéaire ? (lien logistique)
- Note taken on [2017-07-30 Sun 13:56] \\
  matrice de dosage
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:49] \\
  strategie: il faut que je finisse tout le reste avec les versions actuelles
  (tess3r, et ce que j'ai fait pour le moment d'lfmm). Quand tout sera fini ! Je
  repenserai l'archi de tess3r (tout en R et une seul data en mémoire). Je pense
  que je n'arriverais pas faire de l'acces de très grosse données depui un fichier
  et la gestion des NA en même temps. Mais je peux montrer les deux séparément,
  cad on montre que on arrive a faire un algo robuste au NA pour tess3r et lfmm
  mais c'est pas complétement implémenté. ET on montre sur un très gros dataset
  une analyse complete pop et lfmm (le 1001 génome est top pour ca car on a une
  matrice imputé :D)
- Note taken on [2017-07-18 Tue 10:57] \\
  - traitement des données manquantes
  - acess au données (pas dans la ram, je peux parler des infracstructure big data
    classique)
  - si j'ai le temps j'implémente ces 2 feature cad: 
    - NA -> comparaison avec et sans NA et procedure naive
    - matrice en mémoriedans un BED -> on a seulement besoin du produit par X ! 
  
  c'est la suite logique de ma problématique cad : 
  - data de plus en plus grosse donc on veut pas les dupliquer, il y a des données
    manquantes
  - mon taf c'est de fournir des logicielles !
  
  
  Je peux ecrire cette partie comme un mini article ! cad
  intro 
  methode
  resultats
  discution 
  conclusion

- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:

bibliographystyle:apalike
bibliography:../biblio.bib
* Soutenance                                                       :noexport:
:LOGBOOK:
- Note taken on [2017-09-05 mar. 10:31] \\
  Je vais suivre le plan de la thèse: 
  - une intro pour le context, très générals, présentation de quelque
    problématique importante en génétique de populations en association.
  - Problématique
  - Plan
    celui de la thèse
  - developpement des deux axes
  - Conclusion et résumé de la thèse
:END:
** FAQ                                                            :noexport:
*** tess3
**** Pourquoi cette fonction de poid pour le graphe ? Tester d'autre ?
**** Quelle est l'influence de $\sigma$ sur les estimations ?
**** Quelle est l'influence de $\alpha$ sur les estimations ?
**** Pourquoi une matrice laplacienne apparait ici ?
C'est purement numérique... j'ai pas d'intuition.
**** Est ce que tess3 est sensible au LD ?
**** Est ce que tess3 est sensible à la taille des pops ?
Est ce que c'est pas les zone ou il y a le plus d'individu que je clustrise ??
*** lfmm
#  LocalWords:  GWAS EWAS GEAS hyperparamètres décorrélé décorrélées ridgeLFMM
#  LocalWords:  lassoLFMM Thaliana Arabidopsis thaliana variogramme
