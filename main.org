# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:6 author:nil email:nil creator:nil timestamp:nil skip:nil toc:t ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(g!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


#+LaTeX_CLASS: these
# #+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm, bm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \renewcommand{\proofname}{Preuve}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM hyperparamètre

# #+BEGIN_QUOTE
# In Code we trust, all others bring data.
# –William Edwards Deming (1900-1993).
# #+END_QUOTE

#+BEGIN_EXPORT latex
%% to review
\baselineskip 0.8cm
#+END_EXPORT

* Workenv                                                          :noexport:
** R
#+BEGIN_SRC R
  ## CRAN
  install.packages("tidyverse")
  install.packages("extrafont")
  install.packages("Devtools")
  install.packages("testthat")
  install.packages("foreach")
  install.packages("RSpectra")
  install.packages("doParallel")
  install.packages("DescTools")
  install.packages("roxygen2")
  install.packages("VennDiagram")
  install.packages("ggmap")
  install.packages("rvest")
  install.packages("raster")
  install.packages("latex2exp")

    ## bioconductor
  source("https://bioconductor.org/biocLite.R")
  biocLite("matter", ask = FALSE)
  biocLite("qvalue",ask = FALSE)
  biocLite("biomaRt",ask = FALSE)
  biocLite("LEA",ask = FALSE)
  biocLite("impute",ask = FALSE)
  biocLite("sva",ask = FALSE)

  install.packages("cate")
  install.packages("FAMT")
  install.packages("xgboost")
  install.packages("knitr")


  ## github
  devtools::install_github("privefl/bigsnpr")
#+END_SRC
** Ligne de commande
*** ms
*** plink
*** vep
#+NAME: code:install_vep
#+CAPTION: Dépend de 
#+begin_src shell
  cd BiocompSoftware
  git clone https://github.com/Ensembl/ensembl-vep.git
  cd ensembl-vep
  perl INSTALL.pl
#+end_src

*RMK :* J'ai ddl les cache
- =47 : homo_sapiens_vep_89_GRCh38.tar.gz=

** python
* Introduction
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-07-20 Thu 17:52]
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:11] \\
  une remarque en passant: l'intro est pour moi la place pour définir le contexte
  général, les mots du titre, la pbq et le plan qui y répond ! 
  Ce n'est pas la que je fait un état de l'art. L'état de l'art est dans les deux
  grosse partis ! C'est deux grosse parties sont indépendantes l'une de l'autre !
  Donc si il y a des répétition, tant pis !!
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
** Contexte
:LOGBOOK:
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:
*** COMMENT 
Cette dernière décennie a été marquée par une accumulation des données dans tous les
domaines de la sciences. Cette accumulation de données est une aubaine pour les
scientifiques. Cependant, que faire d'autant de données et comment en tirer
l'information qui permettrait de mieux comprendre le monde qui nous entoure ? Il
s'agit là d'un défi majeur pour les statistiques cite:slides_sfds2015_saporta. 

Les grandes données posent plusieurs problèmes. En effet, si l'on est capable d'obtenir
des données rapidement, on veut pouvoir les analyser rapidement. Cependant de
nombreux modèle statistiques classiques ne passent pas l'échelle des grands jeux
de données. Il est donc nécessaire de repenser les modèles et algorithmes afin
de les adapter au nous volumes des données. 
... parler de l'inversement du processus d'aquisition des données .. cf
seminaire Bosson



Dans le cadre de cette thèse nous nous sommes intéressé a développer des méthodes
statistiques utiles à deux problématique scientifiques. Le premier est l'estimation
de la structure de population à partir de données génomique. Le deuxièmes est les
problèmes des test d'association multiple. Toutes les méthodes statistiques
developper lors de cette thèse repose sur la factorisation de matrice. Nous
allons maintenant introduire plus en détails les problématiques ainsi que la
factorisation de matrice en statistique.


** La génomique des populations
:LOGBOOK:
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc

 En faite je ne vais def ca ici ! c'est juste le genet des pops ici !!
  - ewas: refactor
  - gwas: gemma etc
  - eas: ...
:END:
** Test d'association
:LOGBOOK:
- Note taken on [2017-08-22 mar. 09:56] \\
  parler des méthode classsique pour controlé l hétérogénéité en stat (experience
  jardin commum, vidéo les stat expliqué a mon chat :D)
:END:
** La factorisation de matrice en statistique
:LOGBOOK:
- Note taken on [2017-07-18 Tue 08:55] \\
  Kenneth lange, factorisation de matrice = avenir des stat ! a retrouver !
:END:
** Problématique et objectifs de la thèse
* Inférence des coefficients de métissage à l'aide de données géographiques
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:07] \\
  Non je ne vais pas avoir le temps, je vais traduire l'article, étoffer un peu
  et basta. Je mettrais en perspective le traitement des données manquantes pour
  tess3r et sur un très gros dataset si j'ai le temps (1001 genome, avec une
  analyse de la population et une association environmental, pour ilustrer les
  deux feature gros dataset et NA)
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
* Estimation de facteurs latents pour corriger les tests d'association
** Introduction
*** Les études d'association
Au cours de la dernière décennie, les études d'association à grande échelle ont
été largement utilisées pour identifier les gènes candidats associés à une
maladie particulière ou un trait phénotypique d'intérêt. Selon le type de
marqueurs moléculaires examinés dans les génomes ou dans les cellules, plusieurs
catégories d'études d'association ont été menées pour détecter des corrélations
significatives de ses marqueurs avec le phénotype. Par exemple, les études
d'association à l'échelle du génome (GWAS genome-wide association studies) se
concentrent sur les polymorphismes à un seul nucléotide (SNP pour
single-nucleotide polymorphisms) en examinant des variants génétiques chez
différents individus cite:Balding_2006. Les GWAS ont été étendus à des études
d'association à l'échelle de l'épigenome (EWAS epigenome-wide association
studies) qui mesurent les niveaux de méthylation de l'ADN chez différents
individus pour des associations entre la variation épigénétique et les
phénotypes cite:Rakyan_2011. Des approches similaires ont été appliquées à la
caractérisation de la variation observée dans l'ARN par rapport à différents
environnements, traitements, phénotypes ou maladies cite:Slonim_2002. D'autres
exemples d'études d'association incluent des études d'association
génétique-environnement (GEAS) dans lesquelles les sites génétiques sont testés
pour leur corrélation avec des gradients écologiques afin de détecter les
signatures de sélection naturelle cite:rellstab15_pract_guide_to_envir_assoc.
Dans un court laps de temps, les études d'association ont permis des progrès
considérables dans l'identification des variants de gènes qui confèrent une
susceptibilité aux maladies ainsi qu'une compréhension plus approfondie de
l'évolution des génomes en réponse à la sélection naturelle.

*** Les facteurs confusions
<<sec:fact_conf>>

Basée sur l'analyse de la corrélation, les études d'association sont confrontées
aux problèmes des facteurs de confusion et de causalité. En effet lorsque l'on
détecte de la corrélation entre deux variables cela n'implique pas qu'il y a
lien de causalité entre celle-ci. Le lien de causalité entre ces deux variables
peut être bien plus complexe et notamment impliquer des lien avec d'autres
variables non observées. En particulier, il est possible de conclure une
association entre deux variables alors qu'elles sont en faite chacune associé à
une autre variable non considéré dans l'étude. On appelle alors cette variable
non observé un facteur de confusion. La figure [[graph:conf_factor]] illustre cette
situation. Le problème des facteurs de confusion est connue depuis longtemps. En
effet, on le retrouve déjà dans l'ouvrage /The Design of Experiement/ de Ronald
Fisher qui introduisit entre autre le concept de d'hypothèse nulle en
statistique cite:fisher1937design. Dans cette thèse nous nous intéressons aux
études d'association à très grande échelle. C'est a dire que nous avons d'une
part les observations de $\Ycol$ variables sur $\Yrow$ individus qui sont
rassemblées dans une matrice $\Y$ de taille $\Yrow \times \Ycol$, en général
$\Ycol$ est très grand devant $\Yrow$. Nous avons d'autre part l'observation
d'une variable sur les mêmes $\Xrow$ individus que l'on rassemble dans la
matrice $\X$ de taille $\Xrow \times 1$. L'objectif est alors de trouver parmi
les $\Ycol$ variables $\Y$ celles qui sont associées à $\X$. Nous supposons de
plus qu'il existe un certain nombre de variables non observées qui permettent
d'expliquer les variations de $\Y$. Ces variables non observées, que l'on
appellera variables latentes, sont potentiellement des facteurs de confusion
pour l'étude d'association entre $\Y$ et $\X$. C'est a dire que les variables
latentes sont potentiellement corrélées à $\X$, il faut donc les prendre en compte
dans l'étude d'association.

#+NAME: code:conf_factor
#+BEGIN_SRC dot :file Figures/conf_factor.png :exports results :eval no-export
  graph {
    graph [fontname = "serif"];
    node [fontname = "serif"];
    edge [fontname = "serif"];
    U -- Y;
    U -- X;
  }
#+END_SRC

#+NAME: graph:conf_factor
#+CAPTION: Graphe de corrélation entre la variable $y$ la variable $x$ et le facteur de confusion $u$. Dans cette situation si on ne prend pas en compte $u$ dans l'étude d'association alors $x$ et $y$ apparaitrons comme étant associées.
#+ATTR_LATEX: :width 5cm
#+RESULTS: code:conf_factor
[[file:Figures/conf_factor.png]]

*** Simulation numérique d'une association avec facteurs de confusions
<<sec:simu_ex>>

Dans cette partie nous proposons de montrer l'intérêt de prendre en
considération les facteurs de confusion dans les études d'association. Pour cela
nous simulation une variable $\X$ et une variable latente de sorte que leur
corrélation vaille $0.6$. Nous simulons ensuite une matrice de bruit gaussien
$\E$. La matrice des effets de la variable latente sur $\Y$ est aussi calculé a
l'aide de la loi normale, nous notons cette matrice $\V$. La matrice des effets
de $\X$ sur $\Y$, noté $\B$, est simulée de sorte que $1 \%$ de ses lignes soit
non nulle. Enfin, la matrice $\Y$ est calculée telles que 
\begin{equation} 
\Y = \U \V^{T} + \X \B^{T} + \E. 
\end{equation} 
Cette simulation correspond à une situation où 1 \% des colonnes de $\Y$ sont
associé avec $\X$ et la variable latente est bien facteur de confusion pour
cette étude d'association car $\U$ est corrélé avec $\X$. Afin de détecter les
variables expliquées associés à la variables explicative, nous avons réalisé une
régression linéaire avec seulement la variable $\X$ en variable explicative de
la régression. Nous effectuons une autre régression linéaire avec cette fois la
variable $\X$ ainsi que la variable latente $\U$ comme variable explicatives de
la régression. Nous avons ensuite réalisé un test de Student pour tester la
nullité des coefficient associé à la variable $\X$ dans chacune des deux
régressions. La figure ref:fig:simu_intro montre que quand on ne prend pas en
compte la variable latente plus de 40 \% des \pvalues sont proches de zéro, on
détecte alors beaucoup de candidats pour l'association avec la variable $\X$.
Alors que quand on prend en compte les facteurs latents la distribution des
\pvalues est bien uniforme comme on s'y attend. On s'attend a une distribution
uniforme des \pvaleur car la majorité des colonnes de $\Y$ ne sont pas associées
avec la variable $\X$, seulement 1\% par simulation. Dans le cas de cette
simulation il est impossible de ne pas prendre en compte la variable latente,
sans celle-ci on détecte presque la moitié des colonnes de $\Y comme étant
associées à $\X$.

#+NAME: code:confusion_plot
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(scales)

  dat <- ExpRsampler_generativeData(n = 200,
                                    p = 5000,
                                    K = 1,
                                    outlier.prop = 0.01,
                                    cs = c(0.6)) %>%
    ExpRmouline()

  ## lm
  lm.res <- method_lm() %>% ExpRmouline(dat)
  toplot <- data.frame(Régression = "Y ~ X",
                   pvalue = lm.res$pvalue)

  ## lm with U
  oracle.res <- method_oracle() %>% ExpRmouline(dat)


  ## qqplot
  toplot <- data.frame(Régression = "Y ~ X + U",
                       pvalue = oracle.res$pvalue) %>%
    rbind(toplot)
  toplot <- as_tibble(toplot)
  pl <- ggplot(toplot, aes(pvalue, fill = Régression)) +
    geom_histogram(position = "dodge", aes(y = (..count..)/sum(..count..))) +
    MaTheseR.params$gtheme +
    xlab("P-valeur") +
    ylab("Pourcentage") +
    scale_y_continuous(labels=percent)
  save_plot_MaTheseR(pl, "simu_intro.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/simu_intro.png}
\caption{Histogramme des \pvalues du test de nullité des coefficients
  de régression de la régression sans et avec le facteur de
  confusion.}
\label{fig:simu_intro}
\end{figure}
#+END_EXPORT

*** Méthodes de correction pour les facteurs latents
:LOGBOOK:
- Note taken on [2017-08-01 mar. 18:14] \\
  un exemple ici ?? lm, lm + PCA, lm + les facteurs latents comme dans stephens et
  2017 dans son intro,
:END:
Nous nous plaçons dans le cadre méthodologique des modèles de régression
linéaire. Il s'agit d'un cadre très utilisé en étude d'association que nous
pouvons formaliser de la façon suivante
\begin{equation}
\label{eq:statReg}
\Y_{j} = \X b_{j} + \E_{j}
\end{equation}
où $\Y_{j}$ est la matrice des observations de la variable d'indice $j$ sur
$\Yrow$ individus. Le coefficient $b_{j}$ représente l'effet de $\X$ sur
$\Y_{j}$. La matrice $\E_{j}$ est la matrice de l'erreur résiduelle. Il arrive
parfois que l'on fasse la régression dans l'autre sens, la régression s'écrit
alors
\begin{equation}
\label{eq:statRegRevers}
\X = \Y_{j} a_{j} + \E^{'}_{j},
\end{equation}
où $\a_{j}$ représente l'effet de $\Y_{j}$ sur $\X$. Dans la suite nous ne
parlerons de régression que dans le sens de l'équation eqref:eq:statReg. Aussi
$\X$ peut contenir plusieurs variable d'intérêt pour l'étude d'association. De
plus, sxi nous avons observé des variables supplémentaires qui sont des facteurs
de confusion pour notre étude, celle si sont être ajouté au coté des variables
explicatives du modèle de régression. Dans cette partie on considère le cas
simple d'une association avec une seul variable et autres observation de
variables de confusions. L'objectif est de trouver les coefficients $b_{j}$ qui
sont significativement différents de zéro. Dans ce cas on peut dire que $\Y_{j}$
est associée à $\X$. Comme nous l'avons évoqué dans la partie précédente avec
cette approche il est possible qu'une ou plusieurs variables latentes soit
corrélée à la fois à $\Y$ et à $\X$. Dans ce cas, si l'on ne considère les
variables latentes comme variables explicatives de la régression nous détectons
qu'un grand nombre de variables $\Y_{j}$ sont significativement corrélées à
$\X$, comme nous l'avons illustré par une simulation numérique dans la partie
précédente. Nous allons maintenant présenter les différentes approches possible
pour corriger les études d'association pour les facteurs de confusion.

**** Estimation des facteurs latent à priori
Une première approche consiste à trouver les variables latentes en faisant une
analyse factorielle de $\Y$. On fait l'analyse factorielle à priori et sans
prendre en compte la variable $\X$. Les variables latentes sont ensuite ajoutées
au modèle de régression au coté des autres variables explicatives de sorte que
\begin{equation}
\Y_{j} = \X b_{j} + \bar{\U} \V_{j}^{T} + \E_{j}
\end{equation}
où $\bare{\U}$ est la matrice des variables latents calculé à priori et $\V_{j}$
la matrice des effets des variables latentes sur $\Y_{j}$. Par exemple, les
méthodes EIGENSTRAT et Refactor calculent les variables latentes à l'aide de
l'analyse en composantes principales (ACP) de $\Y$ cite:Price_2006,Rahmani_2016.
**** Les modèles mixes
Une autre approche de correction pour les facteurs de confusions est le modèle
mixe. Dans un tel modèle on ajoute un effet aléatoire à la régression
\begin{equation}
\Y_{j} = \X \B^{T} + \matr{\Gamma}_{j} + \E_{j}
\end{equation}
où $\matr{\Gamma}_{j}$ est la matrice des effets aléatoires à estimer. Dans les
modèles mixes on suppose de plus que la matrice de covariance de l'effet
aléatoire est connue. On parle d'effet aléatoire mais il s'agit en faite du
facteur de confusion dont à parlé jusque ici. Ainsi, la matrice de covariance
doit correspondre à la variance du facteur de confusion, elle est en générale
calculé à partir de $\Y$. Les modèles mixes ont été largement utilisés pour les
GWAS cite:Kang_2008,Zhou_2014. Dans le cas des GWAS, l'effet aléatoire permet
d'expliquer la variation de $\Y_{j}$ qui est dû à la structure de population.
Dans ce cas la matrice de covariance est estimé à priori sur les données
génétiques.
**** Les modèles mixes à facteurs latents (LFMM latent factor mixed model)
Nous introduisons maintenant les modèles mixes à facteurs latents. L'équation de
régression peut s'écrire comme ceci : 
\begin{equation}
\label{eq:glfmm}
\Y = \X \B^{T} + \U \V^{T} + \E.
\end{equation}
Dans cette équation $\U$ est la matrice des variables latentes et $\V$ est la
matrice des axes des facteurs latents. La différence majeur de LFMM avec les
autres modèles est qu'on ne suppose rien a priori sur les facteurs de confusion.
Dans les modèles dont nous avons parlés précédemment on estime à priori soit les
variables latentes directement soir leurs matrice de covariance. l'objectif de
LFMM est d'apprendre la variation systématique observées dans $\Y$ grâce aux
paramètres $\U$ et $\V$ tout en prenant en compte la variable $\X$. Il existe
différentes méthodes pour estimer les paramètres de LFMM. On distingue d'abord
des approches qui reposent sur des algorithmes de Monte Carlo
cite:frichot13_testin_assoc_between_loci_envir,carvalho08_high_dimen_spars_factor_model.
Ces approches repose sur une modélisation bayésienne de LFMM qui permet
d'échantillonner les lois à posteriori des paramètres. L'avantage de ces
méthodes est qu'elles permettent d'estimer la variance du paramètre $\B$. Cela
permet de faire un test de significativité statistique. Il y a aussi des
approches qui reposent sur des algorithmes EM (Expectation Maximisation)
cite:friguet09_factor_model_approac_to_multip,agarwal09_regres,zhou16_spars_multiv_factor_analy_regres.
Ces approches sont plus rapides que les méthodes utilisant des algorithmes de
Monte Carlo. Enfin, il y a les approches qui reposent sur une estimation des
variables latentes à partir d'une transformation de $\Y$
cite:gerard2017unifying,wang2015confounder,article_Leek_Storey_2007. Cette
transformation a pour but de séparer la variation de $\Y$ expliquée par les
variables latentes de celle expliquée par $\X$. Parmi cette dernière catégorie
de méthodes, on distingue des autres les méthodes dites à contrôles négatifs qui
suppose connu un sous ensemble de colonnes de $\Y$ qui ne sont pas associées
avec $\X$. Les méthodes à contrôles négatifs utilisent ces variables dîtes
nulles pour estimer les variables latentes.


*** Source de confusion                                          :noexport:
:LOGBOOK:
- Note taken on [2017-08-04 ven. 11:39] \\
  Je ferrais une expliation de la source de confusion pour chaque dataset !!
:END:
Les sources de confusion peuvent varier selon les différentes catégories
d'études d'association. Dans les GWAS et les GEAS, la confusion englobe des
différences systématiques dans l'ascendance génétique entre les individus
échantillonnés cite:Price_2006. Une autre source de confusion dans ces études
peut également découler d'interactions épistatiques entre les gènes
cite:Vilhj_lmsson_2012. Dans les études de profils d'expression des gènes, les
facteurs latents peuvent être les conditions expérimentales, l'âge et le sexe
des patients, leurs facteurs génétiques et l'hétérogénéité des échantillons de
tissus cite:Lazar_2012. Dans les EWAS, la confusion peut être due à des mélanges
cellulaires lorsque les cellules cibles purifiées ne sont pas disponibles
cite:jaffe14_accoun_cellul_heter_is_critic. Dans chaque catégorie, les facteurs
latents peuvent être confondus avec les variables explicatives en raison de la
nature observatoire de l'étude.

*** Plan du chapitre
Comme nous l'avons vu dans la partie précédente l'estimation des variables
latentes pour corriger les études d'association est un problème très vaste et
aucune méthode ne s'est imposée comme référence. Nous proposons ici, deux
méthodes d'estimation rapides et efficaces des paramètres du modèle LFMM. Nos
deux méthodes d'estimation consiste à isolé la variation de $\Y$ expliquée par
les variables latentes de celle expliquée par les variables explicatives. Les
méthodes que nous présentons sont comparable à SVA cite:article_Leek_Storey_2007;
et CATE cite:wang2015confounder; qui procède d'une façon très similaire, nous
décrivons plus en détail les méthodes CATE et SVA dans la partie
[[sec:similar_method]]. Chacun des algorithmes que nous présentons découle de
l'optimisation d'une fonction objectif. Nous montrons que nos algorithmes
d'estimation convergent vers le point de minimum global de leur fonction
objectif respective. Enfin, nous comparons nos méthodes à SVA et CATE sur des
simulations numériques ainsi que des exemples de GWAS, EWAS et GEA.

** Nouvelles méthodes 
*** Modèle 
<<sec:model>>
Dans cette partie nous introduisons les notations du modèle mixes à facteurs
latents que nous utilisons pour corriger les tests d'association : 
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Dans cette équation, $\Y$ est la matrice, de taille $\Yrow \times \Ycol$, qui
rassemble les observations de $\Ycol$ variables sur $\Yrow$ individus. Par
exemple, la matrice $\Y$ peut contenir des SNPs, des niveaux de méthylation ou
bien des niveaux d'expression génique. Nous appellerons la matrice $\Y$ la
matrice des variable expliquées. La matrice $\X$, de taille $\Xrow \times \Xcol$,
regroupe toutes les variables explicatives. Ainsi les colonnes de $\X$ sont les
variables d'intérêt pour l'association, c'est à dire les variables pour
lesquelles on souhaite trouver les associations avec $\Y$. Les colonnes de $\X$
peuvent être par exemple un phénotype, comme une maladie, ou un gradient
environnemental, comme la température d'un habitat. La matrice des effets de
$\X$ sur $\Y$ de taille $\Ycol \times \Xcol$ est notée $\B$. Si l'on suppose
qu'il y a $K$ variable latentes alors la matrice $\U$ est la matrice des $\K$
variable latentes et $\V$ représente les axes des facteurs latents. Les matrices
$\V$ et $\U$ sont respectivement la matrice des axes factoriels, de taille
$\Ycol\times\Ucol$, et la matrice des coordonnées sur ses axes, de taille $\Urow
\times \K$. Enfin la matrice $\E$ est la matrice d'erreur résiduelle, de taille
$\Yrow\times\Ycol$.

Dans un premier temps, nous remarquons que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. En effet, comme ces deux matrices sont
multipliées entre elle dans l'équation eqref:eq:model, les matrices $\U$ et
$\V$ sont définies à une matrice inversible prêt puisque
\begin{equation}
\U \V^{T} = \U \matr{R} \matr{R}^{-1} \V^{T}
\end{equation}
où $\matr{R}$ est une matrice inversible de taille $\K \times \K$. Nous posons alors
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
et nous appelons la matrice $\W$ la matrice latente. Si l'on suppose qu'il y a $\K$
variables latentes linéairement indépendantes cela est équivalent à faire
l'hypothèse que la matrice latente $\W$ est de rang $\K$. Dans la suite nous
considérons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce à
l'analyse en composantes principales de la matrice latente $\W$.

*** Estimation des moindres carrés régularisée en norme $L_{2}$
<<sec:estimator_L2>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par l'équation eqref:eq:model. L'algorithme d'estimation est basé
sur un problème des moindres carrées régularisé en norme $L_{2}$. Nous montrons
que cet algorithme calcule un minimum global du problème d'optimisation des
moindres carrés régularisé en norme $\L2$.

**** Fonction objectif 

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM, nous définissons la
fonction objectif de type ridge suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lambRidge$ le paramètre de régularisation. Le premier terme de $\Lridge$,
le terme d'attache aux données, correspond à l'opposé de la log vraisemblance si
l'on suppose que la matrice de bruit $\E$ est gaussienne, isotrope et de moyenne
nulle. Le deuxième terme de $\Lridge$, le terme de régularisation, est
indispensable pour séparer les variations de $\Y$ expliquées par les variables
latentes de celles expliquées des variables explicatives. En effet, si
\begin{equation*}
\lambRidge = 0, 
\end{equation*}
alors pour toute matrice $\matr{P}$, de taille $\Xcol \times \Ycol$, nous avons
\begin{equation*}
\Lridge(\U - \X \matr{P}, \V^{T}, \B + \V \matr{P}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Les points du minimum de la fonction objective ne sont pas définis de
manière univoque pour notre problème quand le paramètre de régularisation est
nulle.

**** Algorithme de minimisation de la fonction objectif $\Lridge$
Afin d'estimer les paramètres de LFMM minimisant $\Lridge$ nous commençons par
calculer la décomposition en valeurs singulières de $\X$
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$ de $\X$. Les estimateurs sont calculés de
la façon suivante
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V}^{T} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B}^{T} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T}),
\end{align}
où $\svd_{\K}(\matr{A})$ est la meilleure approximation de rang $\K$ de la
matrice $\matr{A}$, donnée par la décomposition en valeurs singulières et
$\Id_{d}$ est la matrice identité de taille $d \times d$. La matrice $\D$ est la
matrice diagonale de taille $\Yrow \times \Yrow$ qui contient les termes
diagonaux suivants
\begin{equation*}
\left\{ \D_{,i,i}\right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latente $\hat{\U} \hat{\V}^{T}$ dans
l'équation eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement
de base $\matr{Q}$. Les $\Xcol$ premiers axes de la base canonique transformée
par $\Q$ forment une base orthonormale de l'espace vectoriel engendré par les
variable explicatives $\X$. La matrice diagonale $\D$ a pour effet de ramener
vers zéro la composante qui appartient à l'espace engendré par $\X$. Si
$\lambRidge$ tend vers zéro multiplier $\Y$ par $\D \matr{Q}^{T}$ revient à
prendre le résidu d'une régression linéaire de $\Y$ par $\X$, on enlève alors
toute la part de variance expliquée par $\X$. Mais $\D$ n'est plus inversible.
Si $\lambRidge$ est très grand alors $\D$ tend vers la matrice identité. Dans ce
cas, le calcul de $\hat{\U} \hat{\V}$ revient à faire une analyse en composante
principale de la matrice des variable expliquées $\Y$. Nous expliquons dans la
partie [[sec:hyperparametre]] plus en détail comment choisir l'hyperparamètre
$\lambRidge$.

L'estimation des paramètres régularisé en norme $L_{2}$ est justifier par le
théorème suivant
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambRidge$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, défini un 
minimum global de la fonction objective $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $\hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$
correspondant à un minimum global de la fonction $\Lridge$. Commençons par
remarquer que la fonction $\Lridge$ est convexe en la variable $\B$ , on peut
donc trouver le point de minimum global en annulant la dérivée de $\Lridge$ par
rapport à $\B$. Cela conduit a l'équation suivante
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V^{T}).
\end{equation}
Il s'agit de l'estimateur ridge du modèle de la régression linéaire de $\Y - \U
\V^{T}$ par $\X$, en supposant que $\U$ et $\V$ sont connues.

Il faut maintenant minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeurs singulières de $\X$ telle que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$. L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D^{2} \matr{Q}^{T} (\Y - \U \V^{T})}^{2}_{F} + 
\frac{1}{2} \lambRidge \norm{\matr{C}_{\lambRidge} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{equation*}
où $\matr{C}_{\lambRidge}$ est une matrice de taille $\Xcol \times \Xrow$
remplie de zéro sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \matr{C}_{\lambRidge, i, i} \right\}_{i = 1..d} = 
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambRidge}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\D$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \matr{D}_{\lambRidge, i, i} \right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Les matrices $\D$ et $\matr{C}_{\lambRidge}$ étant diagonales, par le calcule il
est possible de montrer que
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\sqrt{(\D^{2} + 
\matr{C}_{\lambRidge}^{2})} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2} \\ 
& = \frac{1}{2} \norm{ \D \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{align*}
Enfin, optimiser la fonction objectif $\mathcal{L}^{'}$ est équivalent au
problème de trouver la meilleure approximation de rang $\K$ de la matrice
\begin{equation*}
\D \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$ valeurs
singulières les plus grandes cite:Eckart_1936. Nous avons bien montré que
\begin{align*}
&\hat{\U} \hat{\V}^{T} = \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
&\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof
*** Estimation des moindres carrées régularisée en norme $L_{1}$  
<<sec:estimator_L1>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par eqref:eq:model basé sur un problème des moindres carrés
régularisé en norme $L_{1}$ et en norme nucléaire. Nous montrons que cet
algorithme calcule un minimum global du problème d'optimisation des moindres
carrés régularisé.

**** Fonction objectif 
Afin d’estimer les paramètres U, V et B de LFMM, nous définissons la fonction
objectif de type lasso suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso,
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\W}_{*}$ la norme nucléaire de la matrice $\W$, définie
comme la somme de ses valeurs singulières. Le choix de la norme $L_{1}$ est
motivé par le fait que l'on s'attend à ce que seulement une certaine proportion
des colonnes de $\Y$ soit associée à $\X$. C'est à dire que seulement une certaine
des lignes de la matrice des effets $\B$ doivent être non nulles. La
régularisation $L_{1}$ est connue pour produire des estimateurs parcimonieux de
$\B$ cite:Tibshirani_1996. La fonction $\Llasso$ fait aussi intervenir une
régularisation sur la matrice latente $\W$. Nous ajoutons cette régularisation
afin de lever la contrainte sur le rang de $\W$ qui ne permet pas de définir un
problème d'optimisation convexe. Avec le terme de régularisation de $\W$, la
fonction $\Llasso$ est convexe. De plus il a été montré que le rang d'un point
de minimum de $\Llasso$ décroît avec $\gamma$ le paramètre de régularisation de
$\W$ cite:bach2008consistency. La régularisation en norme nucléaire contraint le
rang de $\W$ et donc le nombre de variables latentes.

**** Algorithme de minimisation de la fonction objectif $\Llasso$
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par blocs de coordonnées
qui permet d'estimer les paramètres de LFMM en minimisant la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg. Nous initialisons l'algorithme
avec des matrices nulles :
\begin{align*}
\hat{\W}_{t = 0} & = 0 \\
\hat{\B}_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. Calculer $\hat{\B}_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{\mathrm{lasso}}^{'}(\B) =  \frac{1}{2} ||(\Y - \hat{\W}_{t-1}) - \X \B^T||_{F}^2 + \lambLasso ||\B||_1
   \end{equation}
2. Calculer $\hat{\W}_{t}$ le point minimum de  
   \begin{equation}
   \label{eq:lasso2}
   \mathcal{L}_{\mathrm{lasso}}^{''}(\W) = \frac{1}{2} ||(\Y - \X \hat{\B}_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répétées jusqu'à ce que l'algorithme converge ou bien que
$t$ atteint le nombre maximum d'itérations. Nous allons maintenant expliquer
plus en détail les deux étapes de l'algorithme. 

La première étape de l'algorithme consiste à faire une régression linéaire
régularisée en norme $L_{1}$ de la matrice résiduelle
\begin{equation}
\matr{E}^{1}_{t} = \Y - \hat{\W}_{t-1}
\end{equation}
par les variables explicatives $\X$. Il existe plusieurs algorithmes pour
estimer les paramètres de cette régression comme par exemple l'algorithme de
descente par coordonnées cite:Friedman_2007. Dans le cas présent on s'intéresse
plus à l'estimation des variables latentes, qui permettrons ensuite de faire le
test d'association (voir la partie [[sec:hypothese]]). Nous supposons que les
variables explicatives $\X$ ont été transformées de sorte que
\begin{equation}
\X^{T} \X = \Id_{d}.
\end{equation}
On a alors d'après cite:Tibshirani_1996,
\begin{equation}
\hat{\B}_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambLasso)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s),
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est l'estimateur du paramètre
de la régression linéaire classique donné dans ce cas par
\begin{equation*}
\bar{\B}_{t} = \X^{T} \matr{E}^{1}_{t}.
\end{equation*}

La deuxième étape de l'algorithme est un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \hat{\B}_{t}^{T},
\end{equation}
Cette approximation est donnée grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
la matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T},
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. On a alors 
\begin{equation}
\hat{\W}_{t} = \matr{M} \bar{\matr{S}} \matr{N}^{T}
\end{equation}
où $\bar{\matr{S}}$ est la matrice diagonale formée par les valeurs singulières
de $\matr{S}$ seuillées de sorte que
\begin{equation*}
\bar{s}_{j} = (s_{j} - \gamma)_{+}, ~ j = 1,...,\Yrow.
\end{equation*}
Le seuillage produit des valeurs nulles et ramène vers zéro les valeurs
singulières restantes.

L'algorithme de descente par blocs de coordonnées ne converge pas en général
vers un point minimum quand la fonction objectif n'est pas continûment
différentiable, comme c'est le cas pour $\Llasso$. On peut trouver dans la
littérature des résultats généraux sur les algorithmes par blocs de coordonnées
dans des cas ou la fonction objective n'est pas différentiable cite:Tseng_2001 .
Cependant, les théorèmes démontrés dans cite:Tseng_2001 dépassent largement le
cadre de la convergence de l'algorithme d'estimation $L_{1}$ présenté ici et
complique l'extraction des résultats intéressants. Pour faciliter la
compréhension, nous proposons de démontrer un théorème plus faible qui
s'applique directement à notre cas. Pour cela nous introduisons quelques
notations. Soit la fonction $f$ définie sur son domaine
\begin{equation}
\label{eq:domf}
A = A_{1} \times A_{2} \times ... \times A_{m}
\end{equation}
un produit cartésien d'ensembles fermés et convexes. L'algorithme de descente
par blocs de coordonnées est défini par la formule de récurrence suivante :
\begin{equation}
\label{eq:blokAlgo}
x_{i}^{k+1} \in \mathrm{arg} \min_{\zeta \in X_{i}} f(x_{1}^{k}, ...,x_{i-1}^{k},\zeta,x_{i+1}^{k},..., x_{m}^{k}), ~
i = 1,...,m.
\end{equation}
En nous inspirant des résultats présentés dans cite:Tseng_2001 et de la
proposition 2.7.1 de cite:Bertsekas_1997 qui démontre la convergence de
l'algorithme de descente par bloc de coordonnées dans le cas où la fonction
objectif est différentiable, nous pouvons énoncer le théorème suivant :
#+BEGIN_theorem 
Si $f$ est une fonction continue de $A$ dans $\RR$, convexe et telle que
\begin{equation}
f(x_{1},..., x_{m}) = g(x_{1}, ..., x_{m}) + \sum_{i = 1}^{m} f_{i}(x_{i}),
\end{equation}
où g est convexe et différentiable et les fonctions $f_{i}$ sont continues et
convexes. Soit $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo. Alors tout
point limite de $\{x^{k}\}$ est un point de minimum global de $f$.
#+END_theorem

#+BEGIN_proof 
On note
\begin{equation*}
\bar{x} = (\bar{x}_{1}, ..., \bar{x}_{m})
\end{equation*}
un point limite de $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo, $\bar{x}$
est bien dans $A$ le domaine de définition de $f$ car cet ensemble est fermé.
Comme $g$ est convexe et différentiable on a pour tout $x \in A$
\begin{align}
\label{eq:lassoProof1}
f(x) - f(\bar{x}) & \geq & \nabla g(\bar{x})(x - \bar{x}) + 
\sum_{i = 1}^{m} (f_{i}(x_{i}) - f_{i}(\bar{x}_{i})) \\
 & & = \sum_{i = 1}^{m} ( \nabla_{i} g(\bar{x})(x_{i} - \bar{x}_{i}) + 
 f_{i}(x_{i}) - f_{i}(\bar{x}_{i}))
\end{align}
où $\nabla g(\bar{x})$ et $\nabla_{i} g(\bar{x})$ sont respectivement la dérivée
et la dérivée par rapport à la $i\text{-ième}$ variable de $g$ en $\bar{x}$.
D'autre part pour chaque variable d'indice $i$
\begin{align}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  (\nabla_{i} g(\bar{x}) + r_{i})(x - \bar{x}) 
\end{align}
où $r_{i}$ est n'importe quelle sous-dérivée de la fonction convexe $f_{i}$ en
$\bar{x}_{i}$. Or nous savons par construction de $\bar{x}$ que
\begin{equation}
\label{eq:lassoProof2}
f(\bar{x}) \leq f(\bar{x}_{1}, ...,x_{i},..., \bar{x}_{m}), ~ \forall x_{i} \in
A_{i}.
\end{equation}
Pour chaque variable $x_{i}$, on peut donc dire que zéro appartient à l'ensemble
des sous dérivées par rapport la variable $x_{i}$ de $f$ en $\bar{x}_{i}$. On
peut alors dire qu'il existe une sous dérivé $r_{i}$ telle quelle que 
\begin{equation}
\nabla_{i} g(\bar{x}) + r_{i} = 0.
\end{equation}
On a finalement pour chaque variable d'indice $i$
\begin{equation}
\label{eq:lassoProof3}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  0
\end{equation}
Finalement, nous avons en utilisant
eqref:eq:lassoProof3 et eqref:eq:lasso1 que
\begin{equation}
f(x) - f(\bar{x}) \geq 0, ~ \forall x \in A.
\end{equation}
#+END_proof
Ce résultat démontre que l'algorithme d'estimation $L_{1}$ des paramètres du
modèle LFMM converge vers un point de minimum global de $\Llasso$.
*** Complexité des algorithmes
Dans cette partie nous abordons la complexité des algorithmes d'estimation des
paramètres présentés dans les sections précédentes. On peut distinguer deux
grandes étapes dans ces algorithmes. La première est le calcul de la
décomposition en valeurs singulières tronquée : calcul de la matrice latente
défini par l'équation eqref:eq:RidgeLfmmEstomatorW pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{'}$ définie par eqref:eq:lasso2 pour l'estimation
$L_{1}$. La seconde est le calcul de la projection orthogonale sur l'espace
engendré par les variables explicatives $\X$ : calcul de la matrice des effets
définie par l'équation eqref:eq:RidgeLfmmEstomatorB pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{''}$ définie par eqref:eq:lasso1 pour
l'estimation $L_{1}$.

D'après cite:Halko_2011, le calcul des $K$ composantes dominantes de la
décomposition en valeurs singulières demande $O(\Yrow \Ycol \K)$ opérations.
Cette complexité peut être réduite à $O(\Yrow \Ycol \log(\K))$ opérations si on
utilise une méthode avec projections aléatoires, comme celle présentée dans
cite:Halko_2011.

La deuxième étape importante consiste en une projection du résidu de
l' approximation de rang faible sur l'espace engendré par $\X$. Le nombre précis
d'opération dépend des hypothèses qui sont faites sur la matrice $\X$. Dans
l'algorithme d'estimation $L_{1}$ aucune inversion de matrice n'est nécessaire
pour le calcul de $\hat{\B}_{t}$. Mais dans les deux algorithmes, si on s'intéresse
seulement au comportement asymptotique par rapport à $\Yrow$, $\Ycol$ et
$\Ucol$, alors on peut majorer la complexité par $O(\Ycol \Yrow +
\Ucol (\Ycol + \Yrow))$.

Finalement, pour les deux algorithmes, le nombre d'opération est majoré par
$O(\Yrow \Ycol \K)$. L'algorithme d'estimation $L_{1}$ est bien entendu plus
long car il réalise plusieurs fois les opérations de décomposition en valeurs
singulières et de projection. L'algorithme d'estimation $L_{2}$ ne les réalise
qu'une seule fois.

Outre la complexité temporelle il est important d'étudier la complexité de la
taille prise en mémoire, surtout pour ce genre d'algorithme qui prennent en
entrée des données potentiellement trop grandes pour la mémoire vive de
l'ordinateur (RAM). Les algorithmes d'estimation $L_{1}$ et $L_{2}$ ne
nécessitent pas de dupliquer la matrice des variables expliquées $\Y$. En effet,
$\Y$ est de taille $\Yrow \times \Ycol$ et donc la dupliquer pourrait poser des
problèmes sur des ordinateurs ne possédant pas assez de RAM. Il est possible
d'envisager de ne pas charger $\Y$ en RAM et d'accéder au données seulement
quand cela est nécessaire.

*** Choix des hyperparamètres 
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

La sélections des hyperparamètres est un problème commun a de nombreuses
méthodes en analyse de données. Nous présentons plusieurs approches pratiques
pour choisir les hyperparamètres qui interviennent dans les algorithmes que nous
avons présentés ici. Nous commençons par présenter les différentes approches
possibles pour choisir le nombre de variables latentes $K$. Nous présentons
ensuite plusieurs heuristiques qui permettent d'aider le choix des paramètres de
régularisation. Enfin nous présentons un algorithme de validation croisée adapté
aux algorithmes que nous avons présentés.

**** Nombre de variables latentes ($K$)
Nous avons vu dans la section [[sec:estimator_L2]] que la matrice latente $\W$ peut
être estimée grâce à l'analyse en composantes principales (ACP) de $\D \Q^{T}
\Y$. Ainsi, afin d'estimer le nombre $\K$ de variables latentes pour le modèle
LFMM, nous proposons d'employer les techniques d'estimation du nombre de
variables latentes utilisées pour l'ACP sur la matrice $\D \Q^{T} \Y$ . Il
existe de nombreuses approches pour déterminer le nombre de composantes
principales de l'ACP, celle-ci sont très bien expliquées dans
cite:jolliffe1986principal. On peut grouper ses approches en trois catégories.
Les approches subjectives comme l'utilisation du scree plot, il s'agit du graphe
des valeurs singulières de la matrice des données. Les approches basées sur une
modélisation de la distribution des données observées, comme par exemple la
méthode présentée dans cite:choi2014selecting. Les approches basées sur la
validation croisée, comme celle que nous détaillons plus loin. Aucune méthode ne
s'est imposée comme la référence, et il est préférable d'en utiliser plusieurs.
Pour les expériences que nous avons réalisées sur des vraies données, le choix
du nombre de variables latentes $\K$ du modèle LFMM a été fait à partir du scree
plot de la matrice $\D \Q^{T} \Y$ pour différente valeurs de $\lambRidge$. Nous
avons aussi utilisé l'algorithme de validation croisée que nous présentons dans
la section [[sec:CV]].

**** Paramètre de régularisation $L_{2}$
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 16:55]
- Note taken on [2017-07-20 Thu 16:54] \\
  j'y verrai plus claire quand j'aurais choisi lambda pour les vrai data set et
  une fois que la cross validation marchera ou pas...
:END:
Le paramètre de régularisation $L_{2}$ intervient dans le calcul de l'estimation
de la matrice latente décrit dans la partie [[sec:estimator_L2]] par le biais de la
matrice diagonale $\D$. Cette matrice permet de réduire la corrélation entre les
variables expliquées $\Y$ et les variables explicative $\X$ afin de pouvoir
estimer les variables latentes $\U$. Lorsque le paramètre de régularisation
$L_{2}$ tend vers zéro, les variables $\Y$ et $\X$ sont linéairement
décorrélées. Cependant on ne pourra plus inverser la matrice diagonale $\D$. De
plus dans le cas ou les variables latentes sont trop corrélées avec $\X$ alors
on risque de mal estimer celles-ci. Lorsque le paramètre tend vers l'infini
alors la matrice $\D$ tend vers la matrice identité l'estimation des variables
latentes sont données pas l'analyse en composantes principales de $\Y$, sans
prendre en compte $\X$. Le risque est alors d'expliquer par les variables
latentes une partie de la variance de $\Y$ qui devrait être expliquée par $\X$,
et dont passer à coté de certaine associations. Ainsi le choix du paramètre de
régularisation $L_{2}$ est une affaire de dosage, il doit être ni trop grand ni
trop petit. Nous avons remarqué dans les expériences que $\lambdaRidge$ petit
donne les meilleurs résultats dans de nombreux cas.

**** Paramètre de régularisation $L_{1}$
Le paramètre de régularisation $L_{1}$ à un impact sur le nombre de lignes non
nulles dans la matrice des effets $\B$. Seulement une partie des colonnes de
$\Y$ est corrélée avec les variables explicatives $\X$. Ainsi, il est possible
d'interpréter la proportion de lignes non nulles dans $\B$ comme la proportion
des variables qui sont corrélées avec $\X$. Plutôt que de choisir le paramètre
de régularisation, il est plus simple de choisir la proportion de variable
expliquées par $\X$ quand on prend en compte les variables latentes. Pour
trouver un paramètre de régularisation qui correspond à cette proportion nous
proposons une heuristique basée sur un chemin de régularisation inspirée par
cite:friedman10_regul_paths_gener_linear_model. Nous commençons par la plus
petite valeur du paramètre de régularisation $\lambLasso$ tel que le vecteur
\begin{equation}
\hat{\B}_{t = 1} = \sign(\bar{\B}_{t = 1}) (\bar{\B}_{t = 1} - \lambLasso)_{+}
\end{equation}
vaut zéro. Ceci est le résultat de la première étape de l'algorithme
d'estimation des moindres carrés régularisée en norme $L_{1}$ présenté dans la
partie [[sec:estimator_L1]]. Nous notons cette valeur $\lambLasso^{\mathrm{max}}$.
Ensuite, nous construisons une séquence de $m$ valeurs de $\lambLasso$ décroissant
selon une échelle logarithmique depuis $\lambLasso^{\mathrm{max}}$ jusqu'à
\begin{equation}
\lambLasso^{\mathrm{min}} = \epsilon \lambLasso^{\mathrm{max}}.
\end{equation}
Enfin, pour chaque valeur du paramètre de régularisation $\lambLasso$ nous
calculons le nombre de valeurs non nulle dans $\hat{\B}$, l'estimation de la
matrice des effets calculé par l'algorithme d'estimation $L_{1}$, et stoppons si
la proportion de valeurs non nulle souhaitée est dépassée.

**** Paramètre de régularisation de la norme nucléaire
Le paramètre de régularisation de la norme nucléaire dans l'algorithme
d'estimation $L_{1}$ à une influence sur le rang de la matrice latente $\W$. Il
est plus simple de choisir le rang de cette matrice, correspondant au nombre de
variables latentes $K$, que de choisir le paramètre de régularisation $\gamma$.
Nous proposons l'heuristique suivante pour calculer $\gamma$ à partir de $K$.
Nous commençons par calculer les valeurs singulières de la matrice des variable
explicative $\Y$, que l'on note $(\sigma_1, ..., \sigma_{\Yrow})$. Ensuite, nous
calculons
\begin{equation}
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2}.
\end{equation}
Nous avons remarqué dans les expériences que ce choix de paramètre de
régularisation $\gamma$ a toujours fait converger l'algorithme d'estimation
$L_{1}$ vers une estimation de la matrice latente $\hat{\W}$ qui est de rang $\K$.

**** Validation croisée
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:00]
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:
<<sec:CV>>

La validation croisée est une méthode d'évaluation d'un modèle très utilisée en
apprentissage statistique. Le principe est de séparer les individus en une
partie d'apprentissage et une partie de test. Les individus d'apprentissage sont
utilisées pour estimer les paramètres du modèle. On mesure ensuite l'erreur de
prédiction à l'aide des individus de tests. Pour que la validation croisée
fonctionne il est très important que les individus de test ne soit pas utilisées
pour estimer les paramètres du modèle. Dans le cas des modèles à facteurs
latents en général, les individus d'apprentissage ne permettent pas de calculer
les variables latentes pour les individus de tests (la matrice $\U$ dans pour
LFMM). Le plus simple est de séparer les variables des individus de test et d'en
utiliser une partie pour estimer les variables latentes et l'autre partie pour
calculer l'erreur de prédiction cite:Bro_2008. Nous présentons maintenant plus
formellement notre procédure de validation croisée.

Nous commençons par séparer les individus en une partie d'entraînement et une
partie de test, c'est a dire que nous séparons les matrices $\Y$ et $\X$ en deux
parties selon leurs lignes. Nous notons $I$ l'ensemble des indices des individus
choisies pour estimer l'erreur de prédiction. On estime à partir des individus
d'apprentissage la matrice des axes factoriels que l'on note $\hat{\V}_{-I}$ et
la matrice des effets que l'on note $\hat{\B}_{-I}$. Ensuite, nous la matrice de
test $\Y[I,]$ en deux partie selon ses colonnes afin d'estimer les variables
latentes sur les variables restantes. On notera $J$ l'ensemble des colonnes de
$\Y$ sélectionnées pour estimer de la matrice des variables latentes de la façon
suivante
\begin{equation}
\hat{\U}_{-J} = (\Y[I,-J] - \X[I,] (\hat{\B}_{-I}[J,])^{T}) \hat{\V}_{-I}[-J,]^{T}.
\end{equation}
Enfin, on peut calculer l'erreur de prédiction comme ceci
\begin{equation}
\label{eq:2}
\mathrm{err} = \frac{1}{|I| |J|} \norm{\Y[I, J] - \hat{\U}^{-J} \hat{\V}_{-I}[J,]^{T} - \X[I, ] \hat{\B}_{-I}[J,]^{T} }_{F}.
\end{equation}
Cette procédure permet bien de mesurer une erreur sur des observations des
variables expliquées qui n'ont pas été utilisées pour estimer les paramètres du
modèle.

*** Tests d'hypothèse corrigés pour les facteurs de confusions
<<sec:hypothese>>
:LOGBOOK:
- Note taken on [2017-08-04 ven. 17:14] \\
  Mais il y a aussi
  les autres variables observées qui doivent être prises en compte car elles sont
  potentiellement des facteurs de confusion pour l'association. Les variables
  explicatives qui ne sont pas d'intérêt pour l'association peuvent être par
  exemple l'age des individus, ou bien le sexe
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Jusque ici, nous avons seulement abordé l'estimation des paramètres de LFMM.
Cependant, l'objectif initial est de trouver la liste des colonnes de $\Y$
associées aux variables $\X$ tout en prenant en compte les variables latentes.
Nous présentons dans cette partie un test d'hypothèse de nullité de l'effet de
$\X$ sur $\Y$ corrigé pour les variables latentes. Une approche simple consiste
à considérer l'estimation des variables latentes $\hat{\U}$ comme les vraies
valeurs de $\U$ et de les utiliser au coté des variables $\X$ du modèle mis en
place pour réaliser le test d'hypothèse. C'est une méthode très courante dans
les études d'associations qui a montré de très bons résultats quand il y suffisamment
d'individus
cite:gerard2017unifying,Price_2006,Song_2015,article_Leek_Storey_2008,Rahmani_2016.
Nous avons choisi de réaliser un test d'hypothèse qui repose sur la
régression linéaire car cela correspond au modèle LFMM quand on suppose que $\U$
est connue. Les estimations des variables latentes peuvent être traitées
comme variables explicatives dans n'importe quel modèle statistique. On pourrait
par exemple envisager d'utiliser une régression linéaire
généralisée. Afin de simplifier les notations et sans perte de généralité, nous
supposons qu'il n'y a qu'une seule variable explicative, c'est à dire que
$\Xcol$ vaut $1$. De plus, nous signalons qu'il est possible d'ajouter d'autres
variables à la régression, cela à un intérêt si l'on connait des variables qui
sont des facteurs de confusion pour notre étude d'association, comme par exemple
le l'age et le sexe des individus. Nous rappelons que l'estimation de la matrice
des $\K$ variables latentes $\hat{\U}$ est définie de façon unique grâce à l'ACP
de la matrice $\hat{\W}$. La matrice $\hat{\W}$ est estimé grâces aux
algorithmes d'estimation $L_{1}$ ou $L_{2}$ de la matrice latente du modèle
LFMM.

**** Calcul de la statistique de test
Pour chaque variable expliquée $\Y_{j}$ nous avons la régression linéaire
suivante
\begin{equation}
\Y_{j} =  \hat{\U} \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{E_{j}},
\end{equation}
où la matrice $\hat{\U}$ est l'estimation de la matrice des variables latentes
du modèle LFMM. On suppose que l'erreur $E_{j}}$ est Gaussienne de moyenne
nulle. On veut tester l'hypothèse de nullité du coefficient de régression
$\beta_{j}$. Sous ces hypothèses on peut calculer pour chaque variable expliquée
$\Y_{j}$ une statistique de test $z_{j}$, assimilable à un z-score. La
statistique de test suit sous l'hypothèse nulle le loi de Student à $\Yrow -
\K - 1$ degrés de liberté. On peut donc calculer une \pvalue pour chaque
variable expliquées $\Y_{j}$. Le détail du calcul de la statistique de test est
donnée dans la section 3.2 de cite:Hastie_2009.


**** Calibration du test d'hypothèse
<<sec:calibration>> Il arrive parfois que la statistique de suive pas la
distribution théorique sous l'hypothèse nulle. On dit dans ce cas que le test
est mal calibré. On peut trouver dans cite:Efron_2004 des exemples de situations
qui peuvent aboutir à des tests mal calibrés. Dans les exemples que nous
présentons ici ont s'attend à ce que la majorité des variables expliquées
$\Y_{j}$ ne soit pas associé avec $\X$, ainsi une large majorité des
statistiques de test sont distribuées selon l'hypothèse nulle. Nous utilisons
l'approche choisie dans cite:Sun_2012, qui consiste à calculer la médiane et la
déviation absolue à la médiane (MAD pour median absolute déviation) directement
sur les $z$ statistiques. En effet, la médiane donne une estimation robuste de
la moyenne et le MAD de l'écart type. On a alors une nouvelle statistique de
test
\begin{equation}
\tilde{z_{j}} = \frac{z_{j} - \med(z_{1}, ..., z_{\Ycol})}{
\mad(z_{1}, ..., z_{\Ycol})}.
\end{equation}
Pour calculer les nouvelles \pvalues, on suppose que $\tilde{z_{j}}$ suit une loi
normal de moyenne nulle et d'écart type 1 sous l'hypothèse nulle.

**** Contrôle du taux de fausse découverte                      :noexport:
:LOGBOOK:
- Note taken on [2017-07-19 Wed 10:44] \\
  non si je fais une partie la dessus il va falloir que je developpe !! alors que
  je veux juste dire que j'ai utilisé qvalue....
:END:
Dans cette dernière partie, nous présentons en quelques mots les outils que nous
avons utiliser pour contrôler le taux de fausse découvertes dans les
experiences. Dans le cadre des test d'association nous voulons en sortie de la
méthode obtenir une liste de colonnes de $\Y$ candidates pour l'association avec
la variable explicative. Pour choisir cette liste Dans le cadre des test
d'association multiple....................

*** Implémentation en R
Les deux nouvelles méthodes de test d'association avec correction pour les
facteurs de confusion que nous avons développées dans cette thèse ont été
implémentées en R. Nous les avons appelées respectivement lassoLFMM pour
l'implémentation des estimateurs régularisées en norme $L_{1}$ et ridgeLFMM pour
les estimateurs régularisées en norme $L_{2}$. Les algorithmes lassoLFMM et
ridgeLFMM prennent en entrée la matrice $/X$ et la matrices $/Y$ à associer avec
$/X$. Ils prennent également le nombre de variables latentes $\K$. L'algorithme
ridgeLFMM prend une valeur pour $\lambLFMM$, le paramètre de régularisation
$\L_{2}$. L'algorithme lassoLFMM prend la proportion de lignes non nulles dans
la matrice $\B$, la matrice des effets de $\X$ sur $\Y$. Enfin les deux
algorithmes retournent les estimations pour les paramètres de LFMM ainsi qu'une
\pvaleur pour le test d'association de chaque colonne de $\Y$ avec $\X$.
** Autres méthodes existantes comparées
<<sec:similar_method>>

Dans cette section nous présentons des méthodes pour l'étude d'association avec
et sans correction pour les facteurs de confusions. Les méthodes que nous
présentons ici sont comparées aux méthodes lassoLFMM et ridgeLFMM présentées
dans la section précédente.

*** Régression linéaire simple et avec les scores de l'ACP
Dans lassoLFMM et ridgeLFMM, les tests d'hypothèses utilisés pour détecter les
associations reposent sur une régression linéaire de $\Y$ par $\X$ et
l'estimation des facteurs latents $\bar{\U)}$. Il est donc naturel de se
comparer à la méthode de test d'hypothèse nullité de l'effet dans la régression
linaire de $\Y$ par $\X$. Dans ce cas aucun facteur latent n'est pris en compte
dans l'étude d'association. De plus, nous nous comparons à une méthode qui
repose sur une estimation des variables latents par l'ACP. Dans ce cas, il
s'agit alors de faire une régression de $\Y$ par $\X$ et $\bar{\U)}$ la matrice
des scores sur les $\K$ premières composantes principales. Ces deux méthodes ont
été implémentées en R et nous les appellerons respectivement lm et PCAlm.

*** COMMENT emma cite:Kang_2008
:LOGBOOK:
- Note taken on [2017-08-07 lun. 10:23] \\
  Non on va pas ajouter emma aux méthodes ca serais trop compliqué.
:END:
*** sva cite:article_Leek_Storey_2007
:LOGBOOK:
- Note taken on [2017-08-05 Sat 13:57] \\
  sva utilisé:[[file:Rpackage/R/ExpRmethod-sva.R::ExpRmouline.method_sva%20<-%20function(m,%20dat)%20{][sva function]]
:END:

Il existe deux versions de SVA : subset-SVA cite:article_Leek_Storey_2007 et
IRW-SVA cite:article_Leek_Storey_2008. La méthode subset-SVA se découpe en deux
étapes : une étape d'estimation de la matrice des axes factorielles $\V$ et une
étape d'estimation de la matrice des variables latentes $\U$. Lors de la
premières étape la méthode subset-SVA estime les axes factorielles en faisant
une ACP de la matrice résiduelles de la régression linaire de $\Y$ par $\X$.
Cela correspond à aire l'ACP de $\matr{D}_{(\lambRidge = 0)} \Q \Y$, en utilisant
les notations de la section [[sec:estimator_L2]]. Ensuite la méthode subset-SVA
calcule un sous-ensemble de colonnes de $\Y$ qui sont le moins corrélées avec
$\X$. Ce sous ensemble de variables est utilisées pour estimer la matrice des
variables latentes. Cette procédure peut facilement échouer car une faible
corrélation avec $\X$ n'implique pas qu'il n'y a pas d'association avec $\X$. En
effet une faible corrélation sans prendre en compte les facteurs latents peut
devenir une forte corrélation quand on les prend en compte.

La deuxième version de SVA est itérative. Plutôt que d'estimer les variables
latentes sur un sous ensemble de colonne de $\Y$ la méthode IRW-SVA attribue un
poids à chacune d'entre elles en fonction de la probabilité que la matrice des
effet $\B$ de LFMM soit nul sachant les variables latentes calculées à
l'itération précédente. Ensuite les probabilités sont utilisées pour attribuer
un poids à chaque colonne de $\Y$ et une nouvelle estimation des variables
latentes est calculée à l'aide d'une ACP qui prend en compte les poids. La
méthode itère ces deux étapes un nombre de fois choisie par l'utilisateur. Le
désavantage de cette procédure est qu'on ne sais pas vers quoi elle converge ni
si elle converge. Nous avons utilisé le package R sva fourni par ces auteurs.

*** cate cite:wang2015confounder

Nous présentons dans cette partie la méthodes cate, nous considérons le cas où
il n'y à qu'une variable explicative $\X$ pour faciliter les explications. Dans
la méthode cate on commence par transformer la matrice des variables expliquées
$\Y$ afin d'isoler les variations expliquées par les facteurs latents. Pour cela
on applique une matrice de changement de base aux lignes de $\Y$ de sorte que le
premier axe de la nouvelle base soit colinéaire à $\X$. Cette transformation
permet d'avoir sur le premier axe les coefficients de la régression linéaire de
$\Y$ par $\X$ et sur tout les autres axes le projeté orthogonale de $\Y$ par
rapport à $\X$ correspondant aux résidus de cette régression. La méthode cate
utilise alors les $\Yrow - 1$ autres lignes pour calculer les axes factorielles
notés $\V$ dans nos notations. Cette première étape est comparable à l'étape de
calcul de $\V$ dans notre méthode ridgeLFMM (voir partie [[sec:estimator_L2]]). Dans
ridgeLFMM, plutôt que d'enlever complétement les variations de $\Y$ expliquées
par $\X$ nous la réduisons en fonction de régularisation $\lambRidge$. Comme
cela a été montré dans cite:wang2015confounder sva et cate estime la même
matrice des axes factorielles qui correspond en faite à celle estimée par
ridgeLFMM dans le cas ou $\lambRidge$ vaux zéro. La méthode cate diffère de sva
dans sa façon de calculer les variables latents et les effets de $\X$ sur $\Y$.
Pour cela les auteurs de cate ont modélisé explicitement la corrélation entre
les variables explicatives $\X$ et les variables latentes $\U$ tel que
\begin{equation}
\label{eq:cateU}
\U = \X \bm{\alpha}^{T} + \matr{Z}.
\end{equation}
Comme la matrice $\Z$ est orthogonal à $\X$ elle déjà été estimée en même temps
que la matrice des axes factorielles $\V$. Pour estimer la matrice
$\matr{\alpha}$ la méthode cate utilise la première ligne de la matrice $\Y$
transformées dans la base où le premier axe est colinéaire à $\X$. En effet en
injectant eqref:eq:cateU dans l'équation du modèle LFMM eqref:eq:model on peut
écrire la matrice des coefficients de régression de $\Y$ par $\X$, notée
$\bm{\tau}$, comme ceci
\begin{equation}
\bm{\tau} = \B + \V \bm{\alpha}^{T},
\end{equation}
où $\B$ est la matrice des effets dans l'équation eqref:eq:model. La méthode
cate estime ensuite $\matr{\alpha}$ en faisant une régression linéaire robuste
de $\bm{\tau}$ par son estimation de la matrice des axe factorielles $\V$ et
$\B$ est calculé comme le résidu de cette régression. La régression robuste
permet d'enlever de l'estimation de $\bm{\alpha}$ les effets atypiques qui
correspondent aux colonnes de $\Y$ associés à $\X$ que l'on cherche.

** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:

#+NAME: code:krakR
#+begin_src R 
  Sys.info()["nodename"]
  getwd()
#+end_src

#+RESULTS: code:krakR
:             nodename 
: "krakenator.imag.fr"
: [1] "/home/cayek/Projects/Thesis/MaThese"

Dans cette partie, nous présentons les expériences numériques que nous avons
réalisées pour évaluer la performance de nos algorithmes de correction pour les
facteurs confusions dans les études d'associations qui repose sur une estimation
$\L1$ et $\L2$ des paramètres de LFMM. Ces deux nouveaux algorithmes ont été
implémenté dans le langage de programmation R et seront appelés respectivement
ridgeLFMM pour l'estimation $\L2$ et lassoLFMM pour l'estimation $\L1$. Nous
nous sommes comparé aux méthodes que nous avons présenté dans la partie
[[sec:similar_method]]. Les méthodes de régression linéaires avec et sans les scores
de l'ACP ont été implémenté dans le langage R et sont respectivement appelé lm
et PCAlm. Pour les méthodes CATE et sva nous avons respectivement utilisé les
implémentations R de ces méthodes mises à disposition par leurs auteurs.
*** Comparaison des méthodes sur des données simulées
**** Simulation à partir de données réelles
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 16:10] \\
  [[file:Rpackage/R/ExpRsampler-fromTrueData.R::ExpRmouline.ExpRsampler_fromTrueData%20<-%20function(s)%20{][La fonction sampler]]
:END:
Afin de comparer la performance des méthodes sur une étude d'association pour
laquelle nous connaissons la vérité, nous avons réalisé des simulations à partir
de vrai jeux de données. Pour cela nous réalisons une analyse en composante
principale de $\Y$ et ne gardons que les $\K$ premières composantes en fonction
du nombre $\K$ de facteurs de confusion que l'on souhaite simuler. On a alors
\begin{equation}
\Y = \U \V^{T} + \E
\end{equation}
où $\V$ est la matrice des $\K$ axes principaux orthogonaux et $\U$ la matrice
des variables latentes calculés par l'ACP. La matrice $\E$ est la matrice
residuelle. Nous simulons ensuite la variable d'intérêt pour l'association
$\X^{'}$ et $\K$ variables latentes $\U^{'}$ de sorte qu'elles aient la même
structure de covariance que les variables latentes calculée par l'ACP. Nous
choisissons de plus la corrélation entre chaque colonne de $\U^{'}$ et $\X$. Ces
matrices sont simulé à l'aide de la loi normale multidimensionnelle. Enfin nous
calculons une matrice des effets $\B^{'}$ de sorte qu'une certaines proportion
des lignes de $\B^{'}$ soit non nul et simulés grâce à une loi normale. Nous
calculons alors la nouvelle matrice des variables à tester tel que
\begin{equation}
\Y^{'} = \U^{'} \V^{T} + \X^{'} \B^{'}^{T} + \E.
\end{equation}
Nous avons ainsi des données pour lesquelles nous savons quelles colonnes de
$\Y^{'}$ est associées avec la variable $\X$, il s'agit des lignes non nulles de
la matrice $\B^{'}$. Nous utilisons de plus la structure lattente d'une matrice
de données déjà existante ce qui permet d'avoir des simulations plus réalistes
et d'éviter les discussions sur le choix des variables latentes.

Les vrais jeu de données que nous avons choisi pour réaliser les simulations
sont issu du jeux de données 1000 génome que nous présentons dans la partie
[[sec:GEAS]]. Nous avons garder seulement le chromosome 1 et 2, cela permet de
simuler une matrice de variable expliquées $\Y^{'}$ composée de 52211 variables
pour 1758 individus. Nous avons choisi de simuler 5 variables latentes pour
plusieurs valeurs de la corrélation entre $\X^{'}$ et ces 5 variables latentes.
Pour chaque variable latente une valeur entre $-1$ et $1$ de la corrélation avec
$\X^{'}$ est tirée selon une loi uniforme et multipliée par un coefficient que
l'on nome $\rho$ prenant une des valeurs suivantes: $0.1$, $0.3$, $0.5$, $0.8$
ou $1$. Le même coefficient $\rho$ est utilisé pour calculer toutes les
corrélations. Plus le coefficient $\rho$ est proche de 1 plus les variables
latentes seront corrélées à $\X^{'}$ et donc plus la confusion lors du test
d'association de $\X^{'}$ avec la matrice $\Y^{'}$ sera importante. Nous avons
de plus choisi la proportion proportions des variables expliquées associées avec
la variable explicative valant $1\%$, $5\%$, $10\%$, $15\%$ ou $20\%$. Pour
chaque paramètre de simulation nous avons simulé $5$ jeux de données ce
qui donne un total de 125 jeux de données.

**** Mesure de comparaison des performances
Pour comparer les méthodes entre elles nous avons choisi deux critères. Chaque
méthode renvoie une \pvalue pour chaque colonne de $\Y$. Afin d'évaluer la
capacité des méthodes à détecter le plus possible d'association sans se tromper
nous avons calculer l'aire sous la courbe de précision-rappel, noté AUC, pour
chacune des méthodes. Nous rappelons que pour une liste de candidats données la
précision est le nombre de vraies associations dans la liste divisé par la
taille de la liste et le rappel est le nombre de vraies associations retrouvées
dans la liste divisé par le nombre total des vraies associations. Le rappel est
parfois appelé puissance en statistique. Une méthode qui donne les plus petites
\pvalues d'abord à toutes les vraies associations donne une aire sous la courbe
de précision-rappel de 1. Le deuxième critère de comparaison des méthodes permet
d'évaluer la calibration des \pvalues renvoyées par les méthodes. Pour cela nous
calculons le facteur d'inflation sur les \pvalues attribuées aux variables non
associées avec $\X$. Si les \pvalues sont bien calibrées alors la distribution
des \pvalues attribuées aux colonne de $\Y$ non associées avec $\X$ suivent une
loi uniforme et donc le facteur d'inflation vaux 1. Une méthode qui renvoie des
\pvalues correctement calibrées permet de calculé une liste de candidats avec un
taux de fausses découvertes moyen contrôlé à une valeur choisie en utilisant par
exemple l'algorithme de Benjamini-Hoshberg cite:benjamini1995controlling. Une
bonne méthode doit donc à la fois être capable de detecter les vrais
associations sans se tromper mais aussi fournir des \pvalues correctement
calibrées.

**** Résultats
Sur les 125 jeux de données simulés nous avons lancé les méthodes lm, PCAlm,
sva-irw, sva-two-step, cate et les deux méthodes présentées dans cette thèse
lassoLFMM et ridgeLFMM. De plus, nous avons considéré une méthode oracle qui
fait le test d'association entre $\Y$ et $\X$ en connaissant les variables
latentes de la simulation. Les résultats sont résumés dans la Figure
ref:fig:method_comp. Les méthodes cate, lassoLFMM et ridgeLFMM ont les mêmes
performance que l'oracle sur toutes les simulations. Nous constatons toutefois
une exception sur les simulations avec un paramètre $\rho$ de corélation entre
la variable explicative $\X$ et les variable latentes de $1$ pour cate et
ridgeLFMM qui renvoie des \pvalues avec un taux d'inflation moyen de $3.3$ alors
que celui de lassoLFMM vaux $1.3$ et celui de l'oracle $1.0$ (Figure
ref:fig:method_comp D). Les performance de la méthode lm sont sensible au
paramètre de corélation $\rho$, lorsque celui-ci vaux $0.1$ l'AUC et le facteur
d'inflation de lm est presque égal à ceux de l'oracle mais le facteur
d'inflation croit jusqu'à plus de 30 et l'AUC décroit jusqu'à la moitié de celui
de l'oracle pour $\rho$ valant 1 (Figure ref:fig:method_comp B et D). Les
\pvalues de la méthode PCAlm sont toujours corréctement calibré puisque le
facteur d'inflation est toujours autour de 1 (Figure ref:fig:method_comp C et
D). Cependant la différence de l'oracle avec l'AUC de PCAlm de l'oracle croit
avec la proportion de vrais associations et le paramètre de corrélation $\rho$
(Figure ref:fig:method_comp A et B). Enfin sva-two-step et sva-irw renvoie des
\pvalues correctement qualibré sauf quand le paramèrte de corélation $\rho$ vaut
0.8 et 1.0 (Figure ref:fig:method_comp C et D). L'AUC de sva-irw est toujours en
dessous de l'AUC de l'oracle pour toute les proportion de vrais asociation des
simulations (Figure ref:fig:method_comp A) et la différence de l'AUC de sva-irw
avec de l'AUC de l'oracle croit avec le paramèter de corrélation $\rho$ (Figure
ref:fig:method_comp B). Nous obsevons egualement que l'AUC de sva-two-step est
très légèrement en dessous de l'AUC de l'oracle pour toute les proportion de
vrais asociation des simulations (Figure ref:fig:method_comp A) et comme pour
sva-irw la différence de l'AUC de sva-two-step avec de l'AUC de l'oracle croit
avec le paramèter de corrélation $\rho$ mais plus faiblement (Figure
ref:fig:method_comp B).

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[ht]
\centering
\includegraphics{./OUTPUT/Rplots/method_comp.pdf.png}
\caption{Comparaison des méthodes sur des simulations faites à partir du jeux de
  données 1000Genomes. A-B) Aire sous la courbe précision-rappel en fonction
  respectivement de la proportion de colonne de $\Y$ associé à $\X$ et la
  corrélation de la variable explicative $\X$ et les variables latentes. C-D)
  Facteur d'inflation calculé sur les variables nulles en fonction
  respectivement de la proportion de colonne de $\Y$ associé à $\X$ et la
  corrélation de la variable explicative $\X$ et les variables latentes.}
\label{fig:method_comp}
\end{sidewaysfigure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Échantillonnage des données
CLOSED: [2017-08-06 Sun 14:42]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_sampler
#+CAPTION: Le sampler qui a été utilisé pour la validation numérique. Dépend de [[code:1000g_G_valNum]]
#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  ## screePlot
  pl <- qplot(seq_along(var), var) +
    coord_cartesian(xlim = c(1,100))
  pl
  save_plot_png(pl, "valNum_screePlot.png")

#+end_src

#+RESULTS: code:num_val_sampler
[[./OUTPUT/Rplots/valNum_screePlot.png]]

#+NAME: code:num_val_dat
#+CAPTION: On sample les données. Dépend de [[code:num_val_sampler]]
#+begin_src R 
  ## sample all data
  library(MaTheseR)
  sampler <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  rep.nb.sampler <- 5
  prop.outlier <- c(0.01, 0.05, 0.1, 0.15, 0.2)
  rho.B <- 3
  rho.c <- c(0.1, 0.3, 0.5, 0.8, 1.0)
  nb.cluster <- 12
  library(foreach)
  library(doParallel)

  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  dat.files <-
    foreach(p = prop.outlier, .combine = 'c') %:%
    foreach(rho = rho.c, .combine = 'c') %:%
    foreach(i = 1:rep.nb.sampler, .combine = 'c') %dopar%
    {
      s <- sampler
      s$prop.outlier = p
      s$rho.B = rho.B
      s$rho.c = rho
      dat <- ExpRmouline(s)
      dat$meta$i <- i
      save_dat(dat, "ValNum", "1000g12", p = p, rho = rho, i = i, rho.B = rho.B)
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)
  save_dat(dat.files, "ValNum", "dat_list")

#+end_src
***** DONE Run des méthodes
CLOSED: [2017-08-14 lun. 11:28]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:28]
- Note taken on [2017-08-10 jeu. 10:24] \\
  ok mes méthodes performe bien :D on peut lancer le reste !!!
- Note taken on [2017-08-06 Sun 14:42] \\
  tail -f ValNum.y2017_m08_d06.log
- State "RUNNING"    from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_expr
#+CAPTION: Expérience de comparaison des méthodes sur les simulations. Dépend de [[code:num_val_dat]]
#+begin_src R 
  library(MaTheseR)
  library(foreach)
  library(doParallel)

  dat.files <- readRDS("./OUTPUT/Dat/ValNum/dat_list_cc6919e751d0b2b138c81d2abc21696a.rds")

  ## param
  K.method <- 5
  nb.cluster <- 4

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.K = 100,
                              relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method, method = "irw")
  m.sva_twostep <- method_sva(K.method, method = "two-step")
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param(force = FALSE, save = TRUE) +
    m.lm * param(force = FALSE, save = TRUE) +
    m.pca * param(force = FALSE, save = TRUE) +
    m.cate * param(force = FALSE, save = TRUE) +
    m.lasso * param(force = FALSE, save = TRUE) +
    m.oracle * param(force = FALSE, save = TRUE) + 
    m.sva_twostep * param(force = FALSE, save = TRUE) +
    m.sva_irw * param(force = FALSE, save = TRUE)
  ##   m.famt * param(force = FALSE, save = TRUE)

  ## main loop
  message("=== Main loop.")
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  df.res <-
    foreach(f = dat.files, .combine = 'rbind') %dopar%
    {
      dat <- readRDS(f)
      res <- data.frame()
      for (m in methods) {
        ## on force
        if (m$force) {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        } else if (exist_res(m , f)) {
          message("Retrieving", m$name)
          m.res <- retrieve_res(m , f)
        } else {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        }
        res <- ExpRextractor_fdr(dat, m.res, rep.sampler = dat$meta$i, rep.method = 1) %>%
          rbind(res)
        rm()
      }
      res
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save
  save_expr(df.res, "validation_numerique.rds")
  gc()

  ## plot auc
  toplot <- df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]

***** DONE Plots
CLOSED: [2017-08-14 lun. 11:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:47]
- State "RUNNING"    from "STARTED"    [2017-08-14 lun. 11:29]
- Note taken on [2017-08-08 mar. 13:48] \\
  j'attend que ca finisse ! et je filtrerais les couleurs et les nom des méthodes
  !
- State "STARTED"    from "RUNNING"    [2017-07-25 mar. 16:35]
- State "RUNNING"    from "DEBUG"      [2017-07-25 mar. 10:57]
- State "DEBUG"      from "TODO"       [2017-07-24 lun. 17:32]
- Note taken on [2017-07-24 lun. 17:31] \\
  Je sais pas ce j'ai foutu mais c'est super lourd !! ca doit être les test, faut
  que je les enleve du coup ! je vais le faire à part ! Et ca n'a pas exporter les
  bon res. ca plot pas les bonnes choses !
- Note taken on [2017-07-17 Lun 08:15] \\
  L'experience est fini il faut faire le plot et l'anova !!!
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:

#+NAME: code:num_val_auc_gif_df
#+CAPTION: Calcul de l'auc et le gif. Dépend de [[code:num_val_expr]]
#+begin_src R
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  auc.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_auc()
  save_expr(auc.df, "auc.df.rds")

  gif.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_gif()
  save_expr(gif.df, "gif.df.rds")
#+end_src

****** DONE Plots
CLOSED: [2017-08-14 lun. 11:46]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-08-14 lun. 11:46]
- Note taken on [2017-07-30 Sun 12:28] \\
  on attend que l'expr soit finis !!
- State "STARTED"    from "DONE"       [2017-07-30 Sun 12:28]
- State "DONE"       from "TODO"       [2017-07-30 Sun 12:28]
- Note taken on [2017-07-30 Sun 12:28] \\
  avec les barplot c'est pas mal !!
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_plot
#+CAPTION: Depend de [[code:num_val_auc_gif_df]]
#+begin_src R
  ## Compute plot !
  require(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(gridExtra)
  library(forcats)
  library(tidyverse)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds") 
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds") 


  ## filter and order method
  auc.df <- auc.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  auc.df$method %>% unique()
  gif.df <- gif.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  gif.df$method %>% unique()

  #################
  ## by prop outlier

  ## auc
  toplot <- auc.df %>%
    group_by(method, prop.outlier) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.prop.pl, "num_val_auc_prop.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, prop.outlier) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.prop.pl, "num_val_gif_prop.png")


  #################
  ## by rho

  ## auc
  toplot <- auc.df %>%
    group_by(method, rho.c) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.rho.pl, "num_val_auc_rho.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, rho.c) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.rho.pl, "num_val_gif_rho.png")


  ## plot for pdf
  ## helpers
  ## https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
  ## extract legend
  g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}

  ## C
  C.pl <- gif.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "bottom")
  mylegend <- g_legend(C.pl)
  C.pl <- C.pl +
    theme(legend.position = "none") +
    xlab("Proportion de vrais associations") +
    ylab("Facteur d'inflaction")

    ## A
    A.pl <- auc.prop.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("AUC")
    ## D
    D.pl <- gif.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab(TeX("Paramètre de corrélation entre et U et X ($\\rho$)")) +
      ylab("") 
    ## B
    B.pl <- auc.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("")

    pl <- cowplot::plot_grid(A.pl,B.pl,C.pl,D.pl,
                             ncol = 2, labels = c("A", "B", "C", "D"))

    ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 mylegend, nrow=2, heights=c(10, 1))
  })

  save_plot_png(pl.leg, filename = "method_comp.png")
  save_plot_MaTheseR(pl.leg, filename = "method_comp.pdf.png", height = 14, width = 20)
#+end_src

#+RESULTS: code:num_val_plot
[[./OUTPUT/Rplots/num_val_auc_prop.png]]
[[./OUTPUT/Rplots/num_val_gif_prop.png]]
[[./OUTPUT/Rplots/num_val_auc_rho.png]]
[[./OUTPUT/Rplots/num_val_gif_rho.png]]
[[./OUTPUT/Rplots/method_comp.png]]

****** CANCELLED Tests d'hypothèse
CLOSED: [2017-08-10 jeu. 11:30]
:LOGBOOK:
- State "CANCELLED"  from "STARTED"    [2017-08-10 jeu. 11:30]
- State "STARTED"    from "TODO"       [2017-07-30 Sun 12:28]
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_tests
#+CAPTION: Dépend de [[code:num_auc_gif_df]]
#+begin_src R 
  require(MaTheseR)
  library(broom)
  library(ggplot2)
  library(knitr)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds")
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds")

  auc.lm.res <- auc.df %>%
    mutate(method = as.factor(method)) %>%
    group_by(prop.outlier) %>%
    do(tidy(lm(auc ~ method, data = .))) %>%
    ungroup()
  toplot <- auc.lm.res %>%
    dplyr::filter(term != "(Intercept)")
  ggplot(toplot, aes(x = as.factor(prop.outlier),
                         color = p.value < 1e-5, y = estimate, fill = term)) +
    geom_bar(stat = "identity", position = "dodge")


  lm.res <- lm.res %>%
    dplyr::filter(term != "(Intercept)") %>%
    transmute(method = term, `-log10(p.value)` = -log10(p.value),
                estimate = estimate, prop.outlier = prop.outlier)
  kable(lm.res)

  ggplot(lm.res, ggplot2::aes(x = prop.outlier, y = p.value, color = as.factor(method))) +
    geom_boxplot()
#+end_src

*** Étude d'association entre des niveaux de méthylation de l'ADN et la polyarthrite rhumatoïde (EWAS)
<<sec:ewas>>

La polyarthrite rhumatoïde est une maladie auto-immune d'origine inconnue. Dans
cette étude nous souhaitons étudier le rôle de la méthylation de l'ADN dans le
développement de la polyarthrite rhumatoïde. La méthylation de l'ADN est un
processus au cours duquel un groupe méthyle est ajouté au molécule d'ADN. La
méthylation peut changer l'activité de l'ADN et en particulier modifier sa
transcription en protéine. Pour cette étude nous nous intéressons au niveau de
méthylation de $485 577$ site de l'ADN pour 354 individus atteints de
polyarthrite rhumatoïde et 335 individus sains. Il est connu que la methylation
de l'ADN dépend de l'âge, du sexe et de la consommation de tabac. Nous savons
aussi que le type de la cellule sur laquelle on pratique la mesure influence le
niveau de méthylation. Tous ces facteurs peuvent être des facteurs de confusion
pour l'étude d'association avec la maladie, ils ont d'ailleurs été pris en
compte dans les études d'association qui ont été faites à partir des mêmes
données que celle étudié ici cite:Rahmani_2016,Zou_2014,Liu_2013. Afin d'évaluer
la capacités des méthodes à bien corriger pour les facteurs de confusion, nous
ne prenons pas en compte les facteurs de confusion connus et nous comparons les
résultats à ceux obtenus par les études cite:Rahmani_2016 et cite:Zou_2014 qui
prennent en compte explicitement les facteurs de confusion connus.

De la même façon que dans cite:Zou_2014 nous avons filtré les sites avec un
niveau de methylation moyen constitutif, c'est à inférieur à 0.2 ou supérieur à
0.8. De plus, nous avons centré et divisé par l'écart type les données de
méthylation. Nous avons ensuite lancé les méthodes cate, lm, PCAlm, sva-irw,
sva-two-step, lassoLFMM, ridgeLFMM afin de trouver les sites de méthylation de
l'ADN associés à la polyarthrite.

Afin de choisir le nombre de facteurs latents nous avons représenté la variance  à été choisi à partir d et de la
validation croisée de l'estimateur $L_{2}$ de LFMM (voir Figure
ref:fig:ewas_params). Afin de choisir le 

Nous avons choisi $\K = 10$ pour le nombre de variable
latentes (voir Figure ref:fig:ewas_params A et B). 

Pour $\K = 10$, les valeurs du paramètre de régularisation $L_{2}$ $\lambRidge$
entre $10^{-10}$ et $1$ donnent les mêmes valeurs d'erreur de prédiction moyen
(Figure ref:fig:ewas_params C), nous avons choisi de prendre $\lambRidge =
10^{-5}$. On s'attend à détecter un petit nombre d'association nous avons choisi
une proportion de ligne non nulle pour l'estimateur $L_{1}$ de $\B$ valant 1\%.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre des sites
  méthylation de l'ADN et la maladie polyarthrite rhumatoïde. A) Proportion de
  variance expliquées par chacune des variables latentes estimées par
  l'algorithme ridgeLFMM pour différentes valeurs $\lambda$ du paramètre de
  régularisation $L_2$. B)C) Erreur de prédiction calculée grâce à la validation
  croisée des estimateurs $L_{2}$ des paramètres de LFMM pour différente valeurs
  du paramètre de régularisation $\lambda$ et du nombre variable latentes $\K$,
  le point représente l'erreur de prédiction moyen et les bar l'erreur standard.
  La ligne pointillée vertical marque le nombre de variables latentes choisies,
  c'est à dire 10.}
\label{fig:ewas_params}
\end{figure}
#+END_EXPORT

La figure A ref:fig:ewas_qqplot_top montre la distribution observé des \pvalues
renvoyé par chaque méthode contre la distribution théorique suivit par des
\pvalues sous l'hypothèse nulle. On constate une inflation du nombre de petites
\pvalues pour toutes les méthodes. Il y à une forte inflation pour lm et
sva-irw. La figure B ref:fig:ewas_qqplot_top quelle proportion dans candidat
pour l'assocaition qui ont été identifié par cite:Zou_2014,Rahmani_2016 sont
retrouvé dans les top liste pour chaque méthodes. Nous rappelons que les
cadidats identifié par cite:Zou_2014,Rahmani_2016 ont été identifié en prenant
en compte les facteurs latents tel que l'age le sex et des méthodes comparable à
l'ACP pour identifier la conposition cellulaire. Toutes les méthode retrouve ses
candidats dans leurs top 40 sauf lm et sva_irw. Pour la méthode lm il faut
prendre le top 11881 pour trouver le premier candidat de
cite:Zou_2014,Rahmani_2016 et le top 138038 pour tous les avoirs, pour la méthode
sva-irw ses candidats son tous identifié entre le top 5111 et 87659. 

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponetielle. B) Proportion des candidats proposé par \cite{Rahmani_2016} et \cite{Zou_2014}
  retrouvés dans la top liste revoyée par chaques méthodes.}
\label{fig:ewas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste renvoyé quand on contrôle
le taux de fausse découverte à 1\%. Toutefois les algorithme du FDR nécessite
que les \pvalues soit correctement calibrées. Pour cela nous avons les \pvalues
grâce à la méthode présenté dans la partie [[sec:calibration]]. Le contrôle du taux
de fausses découvertes à été fait à l'aide du package R qvalue cite:Storey_2011.
La figure ref:fig:ewas_venn montre les intersections entre les méthodes. Nous
avons écarté lm et sva-irw car il renvoyait des listes trop différentes des
autres. L'intersection de toutes les listes ont une intersection de 19 sites de
méthylation parmi laquelle on retrouve les 5 candidats identifiés dans
cite:Zou_2014,Rahmani_2016.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_venn.pdf.png}
\caption{A) Diagramme de Venn de la liste des candidats controlés à un taux de
  fausses de découvertes de 1 \%.}
\label{fig:ewas_venn}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Télécharger les données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_ddl
#+CAPTION: Téléchargement des données pour l'EWAS.
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC

#+NAME: code:ewas_format
#+CAPTION: Formatage des données pour l'EWAS. Dépend de [[code:ewas_ddl]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC

***** DONE Preprocessing des données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_prepross
#+CAPTION: Preprocessing des données pour l'EWAS. Dépend de [[code:ewas_format]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC

#+NAME: code:ewas_G_X
#+CAPTION: Centrage et normalisation des données pour l'EWAS. Dépend de [[code:ewas_prepross]].
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

***** DONE Sites candidats detectés dans d'autres études
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+NAME: code:ewas_candidates
#+CAPTION: Dépend de [[code:ewas_G_X]]
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
***** DONE Scree plot 
CLOSED: [2017-08-22 mar. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:31]
- State "TODO"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:18]
- State "DONE"       from "RUNNING"    [2017-07-25 mar. 18:05]
- Note taken on [2017-07-25 mar. 17:56] \\
  tail -f ewas_screeplot.y2017_m07_d25_krakenatorh_juil..log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:51]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:

#+NAME: code:ewas_screeplot
#+CAPTION: Dépend de [[code:ewas_G_X]] 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- "./Data/ThesisDataset/3Article/GSE42861/X.rds"

  lambdas <- c(1e-5, 1.0, 1e10)

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE, K = 300) * param(lambda = lambdas)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr, "ewas_screeplot_expr.rds")

  toplot <- expr$df.res %>%
    mutate(lambda = as.factor(lambda))
  pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,300))

  save_plot_png(pl, "ewas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-21 lun. 17:38]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:38]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:05]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 12:57]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 11:07]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 11:00]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 10:21]
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 10:49]
- Note taken on [2017-07-26 mer. 19:36]
- Note taken on [2017-07-26 mer. 18:05] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_cv_lambda.y2017_m07_d26.log
  tail -f /home/cayek/tmp/Logfiles/ewas_cv.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 17:56] \\
  On va relancer... il y avait des bug dans la CV...
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 17:56]
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+NAME: code:ewas_CV
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,20, 25,30, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

#+NAME: code:ewas_CV_encore
#+CAPTION: Dépend de [[ewas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(6,7,8,9))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:ewas_CV_encore_encore
#+CAPTION: Dépend de [[ewas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 11:19)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore_encore.png")
#+end_src


#+NAME: code:ewas_CV_lambda
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1.0, 1e5, 1e10)
  nb.cluster <- 5
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 9:11)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lambda_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda.png")

  ## plot smooth
  pl <- ggplot(res.cv$errs, aes(y = err, x = log(lambda))) +
    geom_smooth()
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda_smooth.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda_smooth.png]]
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda.png]]

***** DONE Étude du jeu de données
CLOSED: [2017-08-07 lun. 18:35]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-07 lun. 18:35]
- State "RUNNING"    from "DONE"       [2017-08-07 lun. 16:39]
- Note taken on [2017-08-07 lun. 16:35] \\
  j'ai rajouté sva two-step a l'arrache
  #+begin_src R :results output :exports both
    expr.all <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  
    expr.all$df.res$method[expr.all$df.res$method == "sva"] = "sva-irw"
  
    expr.all$df.res <- expr.all$df.res %>%
      rbind(expr$df.res)
  
    summarise(expr.all$df.res)
  
  
    save_expr(expr.all, "EWAS_all.rds")
  #+end_src
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 11:01]
- Note taken on [2017-07-26 mer. 19:44] \\
  Du coup j'ai relancé avec K = 10 et le bon lasso !!!!!! on va voir
- Note taken on [2017-07-26 mer. 19:43] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 19:43]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:

#+NAME: code:ewas_expr
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method)
  m.sva_2step <- method_sva(K.method, method = "two-step")

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva_irw * param() +
    m.sva_2step * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")

#+end_src

#+NAME: code:ewas_expr_log
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src shell :session *ssh krakenator* :results output 
  cat /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
#+end_src

#+RESULTS: code:ewas_expr_log
#+begin_example
  R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
  Copyright (C) 2017 The R Foundation for Statistical Computing
  Platform: x86_64-redhat-linux-gnu (64-bit)
  
  R est un logiciel libre livré sans AUCUNE GARANTIE.
  Vous pouvez le redistribuer sous certaines conditions.
  Tapez 'license()' ou 'licence()' pour plus de détails.
  
  R est un projet collaboratif avec de nombreux contributeurs.
  Tapez 'contributors()' pour plus d'information et
  'citation()' pour la façon de le citer dans les publications.
  
  Tapez 'demo()' pour des démonstrations, 'help()' pour l'aide
  en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
  Tapez 'q()' pour quitter R.
  
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  foreach: simple, scalable parallel programming from Revolution Analytics
  Use Revolution R for scalability, fault tolerance and more.
  http://www.revolutionanalytics.com
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
             disease.state
  GSM1051525     0.9720875
  GSM1051526     0.9720875
  GSM1051527     0.9720875
  GSM1051528     0.9720875
  GSM1051529     0.9720875
  GSM1051530     0.9720875
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
  +                             lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
  +   m.lm * param() +
  +   m.pca * param() +
  +   m.cate * param() +
  +   m.famt * param() +
  +   m.sva * param() +
  +   m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9528 on localhost:11939 at 19:35:29.343
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9538 on localhost:11939 at 19:35:33.199
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9548 on localhost:11939 at 19:35:37.112
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9558 on localhost:11939 at 19:35:41.000
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
  +              samplers = samplers,
  +              preprocessors = NULL,
  +              rep.nb.method = 1,
  +              methods = methods,
  +              extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  === Sampling data.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  === Main loop.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  Computing latent variables
  Computing latent variables
  running hp
          pvalue    colname index outlier     score rep.sampler rep.method method
  1 3.208532e-08 cg00000029     1   FALSE -5.593741           1          1     lm
    method.K method.lambda
  1       NA            NA
  Computing latent variables
  Computing latent variables
  Loading required package: impute
  running hp
  `Rows with missing values`
  integer(0)
  `Columns with missing values`
  integer(0)
  
  running hp
       pvalue    colname index outlier      score rep.sampler rep.method
  1 0.6757066 cg00000029     1   FALSE -0.4185102           1          1
       method method.K method.lambda
  1 ridgeLFMM       10         1e-04
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.9531602 cg00000029     1   FALSE 0.05876053           1          1  PCAlm
    method.K method.lambda
  1       10            NA
  Number of significant surrogate variables is:  10 
  Computing latent variables
  It = 1/100, err2 = 0.998548621190457
  It = 2/100, err2 = 0.652592023099809
  It = 3/100, err2 = 0.652018379539831
  [1] "Fitting Factor Analysis Model with 10 factors"
  It = 4/100, err2 = 0.651990819329085
  It = 5/100, err2 = 0.65201511610208
  Iteration (out of 5 ):It = 6/100, err2 = 0.65202139222764
  It = 7/100, err2 = 0.652022747619974
  === lambda = 0.184666840535516, no zero B proportion = 0.00564682358459127
  It = 1/100, err2 = 0.652023080891458
  It = 2/100, err2 = 0.651977189044589
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.6618566 cg00000029     1   FALSE -0.4373513           1          1   cate
    method.K method.lambda
  1       10            NA
  It = 3/100, err2 = 0.651967304634796
  It = 4/100, err2 = 0.651964288072884
  It = 5/100, err2 = 0.65196318471777
  === lambda = 0.138480594373303, no zero B proportion = 0.0549685876152507
  running hp
       pvalue    colname index outlier     score rep.sampler rep.method    method
  1 0.8961906 cg00000029     1   FALSE -0.130524           1          1 lassoLFMM
    method.K method.lambda
  1       10            NA
  1  2  [1] "Fitting Factor Analysis Model with 10 factors"
  3         pvalue    colname index outlier    score rep.sampler rep.method method
  1 1.13824e-05 cg00000029     1   FALSE 19.55117           1          1   famt
    method.K method.lambda
  1       10            NA
  4  5         pvalue    colname index outlier    score rep.sampler rep.method method
  1 3.94329e-12 cg00000029     1   FALSE 49.94426           1          1    sva
    method.K method.lambda
  1       10            NA
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")
  Expr save in ./OUTPUT/Expr/EWAS_all.rds


  >
#+end_example

****** DONE Charger l'expérience et les candidats
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_load_res
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS: code:ewas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:


#+NAME: code:ewas_calibration
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:ewas_calibration
#+begin_example
# A tibble: 8 x 3
        method        mad     median
         <chr>      <dbl>      <dbl>
1         cate  1.2870855 0.04677596
2         famt  6.2659293 4.33328808
3    lassoLFMM  1.2387777 0.02799659
4           lm  4.2127155 0.04534315
5        PCAlm  1.2268129 0.03996082
6    ridgeLFMM  1.2745703 0.04853927
7 sva_two-step  0.9842079 0.71781997
8      sva-irw 10.8418062 7.58318108
#+end_example

Pour sva_irw et sva_two-step les scores sont des Fscrore ! On ne peut pas
calibrer avec le MAD !!! C'est surement idem pour famt

****** DONE Les qqplots ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_qqplots
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+end_src

#+RESULTS: code:ewas_qqplots
[[./OUTPUT/Rplots/EWAS_qqplots.png]]
[[./OUTPUT/Rplots/EWAS_qqplots2.png]]


****** DONE Le top et rank des candidats
CLOSED: [2017-07-27 jeu. 11:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:35]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_top
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")

  ## rang du dernier candidats
  expr$df.res %>%
    mutate(outlier = index %in% candidates) %>%
    group_by(method) %>%
    dplyr::arrange(pvalue, method) %>%
    mutate(rk = seq_along(pvalue)) %>%
    summarise(rk.min = min(rk[outlier]),
              rk.max = max(rk[outlier]))
#+end_src

#+RESULTS: code:ewas_top
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+begin_example
# A tibble: 8 x 2
        method power
         <chr> <dbl>
1         cate   0.8
2         famt   0.0
3    lassoLFMM   1.0
4           lm   0.0
5        PCAlm   1.0
6    ridgeLFMM   1.0
7 sva_two-step   1.0
8      sva-irw   0.0
# A tibble: 8 x 3
        method rk.min rk.max
         <chr>  <int>  <int>
1         cate      1     37
2         famt   9326  27941
3    lassoLFMM      1     24
4           lm  11881 138038
5        PCAlm      1      8
6    ridgeLFMM      1     25
7 sva_two-step      1     18
8      sva-irw   5111  87659
#+end_example

****** DONE Contrôle du FDR à $0.01$
CLOSED: [2017-07-27 jeu. 11:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:37]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_fdr
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+end_src

#+RESULTS: code:ewas_fdr
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 7 x 2
        method power
         <chr> <dbl>
1         cate   1.0
2         famt   1.0
3    lassoLFMM   1.0
4        PCAlm   1.0
5    ridgeLFMM   1.0
6 sva_two-step   1.0
7      sva-irw   0.6
#+end_example

****** DONE Venn diagram fdr 0.01
CLOSED: [2017-07-27 jeu. 11:39]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(sva = toplot$index[toplot$method == "sva_two-step"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS: code:ewas_venn
: [[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

****** DONE Venn diagram top 100
CLOSED: [2017-08-07 lun. 18:02]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 18:02]
- State "TODO"       from "DONE"       [2017-08-07 lun. 17:57]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn_top
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  ## 0.05 % de p
  p <- max(expr$df.res$index)
  0.0005 * p

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(100) %>%
    ungroup() 


  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_top100_venn.png")
#+end_src

#+RESULTS: code:ewas_venn_top
[[./OUTPUT/Rplots/ewas_top100_venn.png]]
: [1] 81.019


****** DONE plot top * power
CLOSED: [2017-08-07 lun. 17:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 17:56]
- State "TODO"       from              [2017-08-07 lun. 17:26]
:END:
#+NAME: code:ewas_top_power
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :results output :exports both
  candidates
  m1 <- length(candidates)
  expr$df.res

  df <- expr$df.res %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50))
  pl
  save_plot_png(pl, "ewas_top_power.png")
#+end_src

#+RESULTS: code:ewas_top_power
[[./OUTPUT/Rplots/ewas_top_power.png]]

***** DONE Plots
CLOSED: [2017-08-06 Sun 14:25]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:25]
:END:

****** TODO Choix des paramètres
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "TODO"       [2017-08-08 mar. 15:08]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:
#+NAME: code:ewas_screeplot_CV
#+CAPTION: Dépend de [[code:ewas_screeplot]] [[code:ewas_CV]] [[code:ewas_CV_lambda]] [[code:ewas_CV_encore]] [[code:ewas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/ewas_screeplot_expr.rds")
  toplot <- expr$df.res %>%
      mutate(lambda = as.factor(lambda))
  plA <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 10, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "ewas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.4)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 10, linetype = "dashed") +
    coord_cartesian(xlim = c(1,30)) +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "ewas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = log(lambda), y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.2, 0.8))
  save_plot_png(plC, "ewas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "ewas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:ewas_screeplot_CV
: [[./OUTPUT/Rplots/ewas_screeplot.png]]
: [[./OUTPUT/Rplots/ewas_CV_K.png]]
: [[./OUTPUT/Rplots/ewas_CV_lambda.png]]
: [[./OUTPUT/Rplots/ewas_hyperparams.pdf.png]]

****** DONE Résultats des méthodes
CLOSED: [2017-08-09 mer. 13:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-09 mer. 13:56]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:

#+NAME: code:ewas_qqplot_top_venn
#+CAPTION: Dépend de [[code:ewas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  expr$df.res$method %>% unique()
  df.res <- expr$df.res %>%
    dplyr::filter(!(method %in% c("famt"))) %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "ewas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") + 
    xlab("Taille de la top liste") + 
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## pl.top
  save_plot_png(pl.top, filename = "ewas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "ewas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  ## we calibrate sva-two-step with gif ! 
  calibrate <- function(p) {
    score2 <- qchisq(p, df = 1, lower.tail = FALSE)
    gif <- median(score2) / qchisq(0.5, df = 1)
    score2 <- score2 / gif
    pchisq(score2, lower.tail = FALSE, df = 1)
  }
  p <- df.res$pvalue[df.res$method == "sva-two-step"]
  hist(p)
  p.calibrated <- calibrate(p)
  hist(p.calibrated)
  df.res$calibrated.pvalue[df.res$method == "sva-two-step"] <- p.calibrated

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               `sva-two-step` = toplot$index[toplot$method == "sva-two-step"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                        area1 = inter(1),
                        area2 = inter(2),
                        area3 = inter(3),
                        area4 = inter(4),
                        area5 = inter(5),
                        n12 = inter(1,2),
                        n13 = inter(1,3),
                        n14 = inter(1,4),
                        n15 = inter(1,5),
                        n23 = inter(2,3),
                        n24 = inter(2,4),
                        n25 = inter(2,5),
                        n34 = inter(3,4),
                        n35 = inter(3,5),
                        n45 = inter(4,5),
                        n123 = inter(1,2,3),
                        n124 = inter(1,2,4),
                        n125 = inter(1,2,5),
                        n134 = inter(1,3,4),
                        n135 = inter(1,3,5),
                        n145 = inter(1,4,5),
                        n234 = inter(2,3,4),
                        n235 = inter(2,3,5),
                        n245 = inter(2,4,5),
                        n345 = inter(3,4,5),
                        n1234 = inter(1,2,3,4),
                        n1235 = inter(1,2,3,5),
                        n1245 = inter(1,2,4,5),
                        n1345 = inter(1,3,4,5),
                        n2345 = inter(2,3,4,5),
                        n12345 = inter(1,2,3,4,5),
                        category = names(sets),
                        fill = color.values[names(sets)],
                        cat.col = color.values[names(sets)],
                        cat.cex = 1.2,
                        cat.pos = c(0.0, -30, 180, 180, 30),
                        cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                        margin = 0.07,
                        ind = TRUE
                       )

  save_plot_png(venn, filename = "ewas_venn.png")
  save_plot_MaTheseR(venn, "ewas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    res
  }
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)
#+END_SRC

#+RESULTS: code:ewas_qqplot_top_venn
[[./OUTPUT/Rplots/ewas_qqplot_notcalibrated_all.png]]
[[./OUTPUT/Rplots/ewas_top_power_all.png]]
[[./OUTPUT/Rplots/ewas_venn.png]]


*** Étude d'association entre des données génétiques et la maladie \celiac (GWAS)
<<sec:gwas>>

La maladie \celiac est une maladie auto-imune ayant une prévalence de près de
$1\%$ dans la population général cite:Gujral_2012. Bien que les mécanismes
d'apparition de cette maladie ne soit pas compris des études montres de forte
association avec certains gène cite:dubois2010multiple; lassant envisager des
causes génétiques à la maladie. Comme la maladie \celiac est très étudié faire
une étude d'association de celle-ci avec des données génomiques constitue un bon
test pour les méthodes de corréction pour les variables latentes. Nous pourrons
en effet comparer nos résultats à ceux des nombreuses autres GWAS de la maladie
\celiac. Pour cela nous avons utilisé GWAS catalog pour récupérer les SNPs ayant
été identifié dans d'autre étude comme étant associé avec la maladie \celiac.
Par ailleurs, nous s'avons que la stratification des individus en sous
population peut être un facteur de confusion dans les GWAS. Il est habituelle de
corriger les GWAS en utilisant les scores de l'ACP des données génétiques pour
représenter la structure de population cite:Price_2006. Nous proposons ici de
faire une étude d'association entre la maladie \celiac et des données génétique
présentées dans cite:dubois2010multiple. Ces données comportent 281122 SNPs
(single nucléotyde polimorphism) pour 15155 individus, 10659 individus sains et
4496 atteint de la maladie \celiac. Ce que nous appelons SNP est la mesure pour
une position données du génome, que l'on appel locus, du nucléotyde présent chez
les individu. On parle de "single nucléotyde polimorphism" car on s'intéresse
seulement au locus pour lesquels on a observé seulement deux variants dans la
population étudiée. Il faut de plus que le variant le moins fréquent soit au
moins observé chez $5\%$ des individus de la population. Ainsi pour cette GWAS
la matrice des variables expliquées est composée de 0, 1 et 2.

Avant de lancer les méthodes d'étude d'association nous avons filtré les données
génétique afin de garder seulement les SNPs ayant le variant le moins fréquent
présent dans au moins $5\%$ des observations. Nous avons de plus filtré les
individus aparenté, pour cela on mesure la probabilité qu'une séquence
consécutive de SNPs prise chez deux individus différents soit identique et si
celle-ci est supérieur à $0.08$ nous ne gardons qu'un des deux individus. Il est
connu que les SNPs sont corrélé le long du génome, nous avons donc filtrer les
SNPs trop corrélé entre eux, cette étape est idéntifié dans la litérature comme
LD pruning. Pour cela, pour chaque SNPs nous gardons que le SNIPs de variance
maximum sur une fenêtre de 100 SNPs et cela sur les SNPs ayant un coéficient de
corélation liénaire au carré est supérieure à $0.2$, cela nous as permit
d'identifier un sous ensemble de 80275 SNPs. Ces opérations de fitrage on été
faite à l'aide du logiciel plink cite:Purcell_2007. Enfin nous avons utilisé
beagle pour imputer les données manquante de la matrice de SNPs
cite:Browning_2016. Nous obtenons finalement un jeux de données composée 281122
SNPs et 15155 individus.

Afin d'estimer les variables latentes pour corriger le test d'association entre
les SNPS et la maladie \celiac nous avons lancer les méthode lm, lmPCA, cate,
ridgeLFMM et lassoLFMM sur le sous ensemble de SNPs identifé par l'étape de LD
pruning. Par la suite, nous avons effectuer le test d'hypothèse présenté dans la
partie [[sec:hypothese]] sur le jeux de données génétique complet mais avec
l'estimation des variables latentes caluclé sur le sous ensemble de SNPs. Nous
avons choisi 9 variables latentes car il car il n'y a plus d'amélioration
significative de l'erreur de prédiction et de la proportion de variance
expliquée par les variables latentes après cette valeur sur les graphiques A et
B de la Figure ref:fig:gwas_params. La validation croisée du paramètre
$\lambRidge$ ne permet pas de conclure (Figure ref:fig:gwas_params C), nous
avons choisi $1e^{-5}$ car nous avons remarqué dans nos expérimentation que les
petites valeurs du paramètres de régularisation $L_{2}$ donne les meilleur
résultats. Enfin comme on s'attend à detecter un petit nombre d'association nous
avons choisi une proportion de ligne non nulle pour l'estimateur $L_{1}$ de $\B$
valant 1\%.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_hyperparams.pdf.png}
\caption{Choix des paramètres pour la GWAS. A) Proportion de variance expliquées
  par chacune des variables latentes estimée par l'algorithme ridgeLFMM pour
  déférentes valeurs $\lambda$ du paramètre de régularisation $L_2$. B)C) Erreur
  de prédiction calculée grâce à la validation croisée de l'estimateur $L_{2}$
  des paramètre de LFMM pour différente valeurs du paramètre de régularisation
  $\lambda$ et du nombre variable lattentes $\K$. La ligne pointillée vertical
  marque le nombre de variables latentes choisi, 10.}
\label{fig:gwas_params}
\end{figure}
#+END_EXPORT

La figure A ref:fig:gwas_qqplot_top montre la distribution observé des \pvalues
renvoyé par chaque méthode contre la distribution théorique suivit par des
\pvalues sous l'hypothèse nulle. On constate que les méthodes sont toute bien
calibré et que la méthode la plus libérale est lm alors que PCAlm est la méthode
la plus conservative. La Figure ref:fig:gwas_qqplot_top B montre le nombre de
SNPs idéntifié dans le GWAS catalog comme étant associé avec la maladie celiac
qui sont retrouvé dans les top liste des différente méthodes. On observe que lm
retrouve moins facilement dans sa top liste les candidats du GWAS catalogue
($78\%$ des candidats du GWAS catalogue sont dans le top 3000 de lm contre
$83\%$ pour PCAlm et $88\%$ pour les trois méthodes restantes). 

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponetielle. B) Proportion des candidats du GWAS catalogue
  retrouvés dans la top liste revoyée par chaques méthodes.}
\label{fig:gwas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste renvoyée quand on contrôle
le taux de fausse découverte à 1\%, nous avons procédé de la même façon que pour
l'EWAS pour calculer cette liste (voir section [[sec:ewas]]). La Figure
ref:fig:gwas_venn montre l'intersection des listes de candidats controlés a un
FDR de $1\%$ entre les méthodes. C'est PCAlm qui donne la plus petite liste à
FDR contrôlé avec 777 candidats. Les méthodes cate et lm donne la plus grande
liste avec 1319 candidats. Nous constatons que l'intersection des liste à FDR
contrôlé de toutes les méthodes ne contient que $28\%$ des candidats du GWAS
catalog.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_venn.pdf.png}
\caption{A) Diagramme de Venn de la liste des candidats controlés à un taux de
  fausses de découvertes de 1 \%.}
\label{fig:gwas_venn}
\end{figure}
#+END_EXPORT


**** Scripts                                                    :noexport:
:LOGBOOK:
- Note taken on [2017-08-06 Sun 14:53] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
:END:
***** DONE Téléchargement des données
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=

#+NAME: code:gwas_ddl
#+CAPTION: 
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ls FinnuncorrNLITUK1UK3hap300.*
#+end_src

#+RESULTS: code:gwas_ddl
: 
: FinnuncorrNLITUK1UK3hap300.bed	FinnuncorrNLITUK1UK3hap300.bim	FinnuncorrNLITUK1UK3hap300.fam

***** DONE Contrôle qualité
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_CQ
#+CAPTION: Dépend de [[code:gwas_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300 --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
#+end_src

#+RESULTS: code:gwas_CQ
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
Options in effect:
  --autosome
  --bfile FinnuncorrNLITUK1UK3hap300
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out FinnuncorrNLITUK1UK3hap300_CQ
  --snps-only
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 72672 MB successfully, after larger attempt(s) failed.
287385 out of 295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999579.
67 variants removed due to missing genotype data (--geno).
--hwe: 17 variants removed due to Hardy-Weinberg exact test.
6179 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ.bed +
#+end_example

***** DONE Élagage (LD pruning)
CLOSED: [2017-08-16 mer. 17:49]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:49]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

Pour comprendre le LD pruning: 
- [[https://www.cog-genomics.org/plink/1.9/ld][doc de plink]]
- [[https://privefl.github.io/bigsnpr/reference/pruning-clumping.html][re-implementation du ld pruning de plink]]
- [[https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient][R2 = cor(Y,X)^2]]

****** DONE LD report
CLOSED: [2017-08-17 jeu. 10:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_ld_report
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --r2 --ld-window 10 --ld-window-kb 100 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --ld-window 10
    --ld-window-kb 100
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:gwas_ld_report_R
#+CAPTION: Dépend de [[code:gwas_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "gwas_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "gwas_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_ld_report_bin.png]]
[[./OUTPUT/Rplots/gwas_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:00]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:00]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_prunning
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --indep-pairwise 100 1 0.2 --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
#+end_src

#+RESULTS: code:gwas_prunning
#+begin_example

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --indep-pairwise 100 1 0.2
    --out FinnuncorrNLITUK1UK3hap300_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
  1%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  Pruned 15141 variants from chromosome 1, leaving 6399.
  Pruned 16905 variants from chromosome 2, leaving 6214.
  Pruned 14431 variants from chromosome 3, leaving 5343.
  Pruned 12416 variants from chromosome 4, leaving 4848.
  Pruned 12574 variants from chromosome 5, leaving 4932.
  Pruned 14081 variants from chromosome 6, leaving 4860.
  Pruned 10944 variants from chromosome 7, leaving 4341.
  Pruned 12291 variants from chromosome 8, leaving 4164.
  Pruned 10651 variants from chromosome 9, leaving 3896.
  Pruned 10176 variants from chromosome 10, leaving 4034.
  Pruned 9597 variants from chromosome 11, leaving 3753.
  Pruned 9754 variants from chromosome 12, leaving 3987.
  Pruned 7466 variants from chromosome 13, leaving 3019.
  Pruned 6364 variants from chromosome 14, leaving 2725.
  Pruned 5555 variants from chromosome 15, leaving 2484.
  Pruned 5528 variants from chromosome 16, leaving 2702.
  Pruned 5063 variants from chromosome 17, leaving 2564.
  Pruned 6770 variants from chromosome 18, leaving 2754.
  Pruned 3373 variants from chromosome 19, leaving 2035.
  Pruned 4698 variants from chromosome 20, leaving 2309.
  Pruned 3620 variants from chromosome 21, leaving 1416.
  Pruned 3449 variants from chromosome 22, leaving 1496.
  Pruning complete.  200847 of 281122 variants removed.
  Marker lists written to FinnuncorrNLITUK1UK3hap300_CQ.prune.in and
  FinnuncorrNLITUK1UK3hap300_CQ.prune.out .
  9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in
    --make-bed
    --out FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  --extract: 80275 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned.bed +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.bim +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.fam ... done.
#+end_example
***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-08-16 mer. 18:18]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:18]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 18:10]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:10]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
:END:
#+NAME: code:gwas_ibd
#+CAPTION: Dépend de [[code:gwas_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## ibd
  plink -bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  80275 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-16 mer. 18:12]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:12]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:gwas_ibd_visu
#+CAPTION: Dépend de [[code:gwas_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "celiac_ibd.png")


  ## We filter PI_HAT > 0.08
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.08) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS: code:gwas_ibd_visu
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
[[./OUTPUT/Rplots/celiac_ibd.png]]


On va filter les pour une proportion d'ibd à 0.08 (ca correspond à cousin au 4
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 18:15]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:15]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:gwas_ibd_filter
#+CAPTION: Dépend de [[code:gwas_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel

  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_norel
#+end_src

#+RESULTS: code:gwas_ibd_filter
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
80275 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999592.
80275 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bim +
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999597.
281122 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_norel.bim +
#+end_example


***** STARTED Imputation des données manquantes
:LOGBOOK:
- Note taken on [2017-08-17 jeu. 13:48] \\
  il va falloir le relancer ! ca prend du temps !!! > 1 jour, peut être
  augmenter nb thread et ram
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:48]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 18:53]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_impute
#+CAPTION: Dépend de [[code:gwas_ibd_filter]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## recode to vcf
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel --recode vcf bgz --out FinnuncorrNLITUK1UK3hap300_CQ_norel --threads 8
  ## run beagle
  java -Xmx40g -jar beagle.08Jun17.d8b.jar gt=FinnuncorrNLITUK1UK3hap300_CQ_norel.vcf.gz out=FinnuncorrNLITUK1UK3hap300_CQ_norel_imputed nthreads=8

  ##
#+end_src

***** TODO Conversion au format R et scaling
:LOGBOOK:
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
****** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
***** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
***** CANCELLED Conversion au format =bigmatrix=
CLOSED: [2017-07-23 Sun 15:46]
:LOGBOOK:
- Note taken on [2017-07-23 Sun 15:46] \\
  MDRRRRR: 
  Error in SetMatrixElements(x@address, as.double(j), as.double(i), as.double(value)) : 
  long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
  In addition: Warning message:
  In filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  No descriptor file given, it will be named G.big.bin.desc
- State "CANCELLED"  from              [2017-07-23 Sun 15:46]
- State "TODO"       from              [2017-07-23 Sun 15:29]
:END:
#+BEGIN_SRC R
  library(bigmemory)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "./Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.big.bin")
  colnames(G.big) <- colnames(G)
  rownames(G.big) <- rownames(G)
  saveRDS(G.big, "./Data/ThesisDataset/3Article/Celiac/G.big.rds")
#+END_SRC

***** STARTED SNPs détecté par d'autre analyse
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R :results output :exports both :session *ssh krakenator*
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")


  ## join by marker_ID
  celiac.outlier <- celiac$map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", nrow(celiac.outlier), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac$map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Le chargement a nécessité le package : bigmemory
Le chargement a nécessité le package : bigmemory.sri

Attachement du package : ‘bigmemory.sri’

The following object is masked from ‘package:testthat’:

    describe

Le chargement a nécessité le package : bigstatsr
Joining, by = "marker.ID"
nb of candidates: 60
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

*Candidates for G_clumped and test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  dat <- Article3_Celiac_sampler(clumped = FALSE) %>%
    sampl()

  snps.name <- colnames(dat$G)[dat$outlier]
  snps.name
  length(snps.name)


  ## for clumped dataset
  rm(dat)
  gc()
  G <- readRDS('~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds')
  candidates.clumped <- which(colnames(G) %in% snps.name)
  length(candidates.clumped)
  colnames(G)[candidates.clumped]
  saveRDS(candidates.clumped, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
#+end_src

#+RESULTS:
#+begin_example
  > snps.name
   [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
   [6] "rs859637"   "rs2157453"  "rs2816316"  "rs296547"   "rs13003464"
  [11] "rs10188217" "rs13015714" "rs917997"   "rs13010713" "rs7574865" 
  [16] "rs4675374"  "rs13098911" "rs6441961"  "rs17810546" "rs10936599"
  [21] "rs1464510"  "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
  [26] "rs2474619"  "rs10806425" "rs531930"   "rs802734"   "rs2327832" 
  [31] "rs1738074"  "rs212402"   "rs212388"   "rs6974491"  "rs9792269" 
  [36] "rs975730"   "rs1953126"  "rs1250552"  "rs10876993" "rs653178"  
  [41] "rs2762051"  "rs1958589"  "rs4899260"  "rs12928822" "rs2074404" 
  [46] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428" 
  > length(snps.name)
  [1] 49
  > length(candidates.clumped)
  [1] 10
  > colnames(G)[candidates.clumped]
   [1] "rs10903122" "rs859637"   "rs13010713" "rs1464510"  "rs1020388" 
   [6] "rs1738074"  "rs653178"   "rs1958589"  "rs1893217"  "rs157640" 
#+end_example
***** RUNNING Scree plot
:LOGBOOK:
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:59]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-07-30 Sun 11:28]
- Note taken on [2017-07-30 Sun 11:27] \\
  c'est fait mais la projection change rien !!
- State "RUNNING"    from "DEBUG"      [2017-07-26 mer. 18:09]
- Note taken on [2017-07-26 mer. 18:09] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:07] \\
  On va relancer sans Rspectra, ca prend trop de temps !!!!
- State "DEBUG"      from "DONE"       [2017-07-26 mer. 18:06]
- State "DONE"       from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "STARTED"    [2017-07-25 mar. 18:21]
- Note taken on [2017-07-25 mar. 18:19] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d25.log
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:

#+NAME: code:gwas_screeplot
#+CAPTION: Dépend de 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds"
  X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"

  lambdas <- c(1e-5, 1.0, 1e10)

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE, K = 101) * param(lambda = lambdas)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr, "gwas_screeplot_expr.rds")

  toplot <- expr$df.res %>%
    mutate(lambda = as.factor(lambda))
  pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "gwas_screeplot.png")

#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]
[[./OUTPUT/Rplots/gwas_screeplot.png]]

On prend K = 9 variables latentes.

***** RUNNING Validation croisée avec lfmmRidge
:LOGBOOK:
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:17]
- Note taken on [2017-08-17 Thu 18:16] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_CV_encore_encore.y2017_m08_d17.log
- Note taken on [2017-08-17 jeu. 13:47] \\
  il va falloir relancer gwas_CV_encore_encore !!!
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:47]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 15:08]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 09:53]
- Note taken on [2017-08-14 lun. 12:07] \\
  Il y a aussi gwas_CV_lambda qui tourne !
- Note taken on [2017-08-14 lun. 12:02] \\
  il y a [[gwas_CV_encore]] qui tourne
- State "RUNNING"    from "DEBUG"      [2017-08-09 mer. 15:26]
- Note taken on [2017-08-09 mer. 15:24] \\
  c'est reparti sur tail -f /home/cayek/tmp/Logfiles/gwas.y2017_m08_d09.log
- State "DEBUG"      from "RUNNING"    [2017-08-03 jeu. 14:17]
- Note taken on [2017-08-03 jeu. 14:16] \\
  ca buggé, le processus c'est fait tuer. Il en était a au bout de 5 jours...
  > res.cv <- ExpRmouline(cv, dat)
  === params
    lambda K
  1  1e-05 1
  === params
    lambda K
  2      1 1
  === params
    lambda K
  3  1e+10 1
  === params
    lambda K
  4  1e-05 2
  === params
    lambda K
  5      1 2
  === params
    lambda K
  6  1e+10 2
- State "RUNNING"    from "TODO"       [2017-07-30 Sun 11:31]
- Note taken on [2017-07-30 Sun 11:31] \\
  c'est parti : tail -f /home/cayek/tmp/Logfiles/gwas_CV.y2017_m07_d30.log
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+NAME: code:gwas_CV
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(1,2,5,9,50))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K.png]]

#+NAME: code:gwas_CV_encore
#+CAPTION: Dépend de [[code:gwas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(10,13,20))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore.png]]

#+NAME: code:gwas_CV_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 6:8)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore.png]]

#+NAME: code:gwas_CV_encore_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 3:4)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore_encore.png]]

#+NAME: code:gwas_CV_lambda
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(9))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda.png]]

#+NAME: code:gwas_CV_lambda_encore
#+CAPTION: Dépend de [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(8,10))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_encore.png")

#+end_src

***** DONE Étude du jeu de données 
CLOSED: [2017-07-28 ven. 09:25]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-28 ven. 09:25]
- Note taken on [2017-07-27 jeu. 13:50] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_run.y2017_m07_d27.log
- State "RUNNING"    from "DEBUG"      [2017-07-27 jeu. 13:50]
- State "DEBUG"      from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "DEBUG"      [2017-07-24 Mon 07:35]
- State "DEBUG"      from "DONE"       [2017-07-24 Mon 06:58]
- State "DONE"       from "RUNNING"    [2017-07-24 Mon 06:58]
- Note taken on [2017-07-23 Sun 16:13] \\
  C'est reparti !! sur krakenator en dehors de annaconda biensur !! pour que
  matter marche (pour avoir R 3.4)
- State "RUNNING"    from "DEBUG"      [2017-07-23 Sun 16:13]
- State "DEBUG"      from "DONE"       [2017-07-17 Lun 08:18]
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:18]
- Note taken on [2017-07-17 Lun 08:18] \\
  lasso c'est planté !! il faudra le relancer mais le reste est OK !!
- Note taken on [2017-07-13 jeu. 08:55] \\
  C'est reparti sur krak !!
- State "RUNNING"    from "STARTED"    [2017-07-13 jeu. 08:55]
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:

#+NAME: code:gwas_expr
#+CAPTION: Etude d'association des données Celiac avec cate ridgeLFMM LassoLFMM LM et LMPCAS. Dépend de 
#+begin_src R
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 9
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## methods
  methods <- list()
  methods$m.lm <- method_lm(col.mask = col.mask,
                            inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lm.rds",
                            inter.res.file = "./OUTPUT/Expr/celiac_inter_lm.rds")
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = K.method,
                                  col.mask = col.mask,
                                  inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds",
                                  inter.res.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds")
  methods$m.pca <- method_PCAlm(K = K.method,
                                col.mask = col.mask,
                                inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds",
                                inter.res.file = "./OUTPUT/Expr/celiac_inter_PCAlm.rds"
                                )
  methods$m.cate <- method_cate(K = K.method,
                        col.mask = col.mask,
                        inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        inter.res.file = "./OUTPUT/Expr/celiac_inter_cate.rds",
                        hp = "lm"
                        )
  methods$m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6,
                              col.mask = col.mask,
                              inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds",
                              inter.res.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds"
                              )

  run_celiac <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("celiac_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    if (file.exists(out.file.path)) {
      message("Reading ", out.file.path)
      df <- readRDS(out.file.path)
    } else {
      message("Running method")
      m <- ExpRmouline(m, dat)
      df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
      ## save expr
      message("Saving output in ", out.file)
      save_expr(df, out.file)
    }
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_celiac(m) %>%
      rbind(res.df)
  }
  save_expr(res.df, "celiac_all_df.rds")
#+end_src

#+RESULTS:
#+begin_example
  =============== lassoLFMM
  Running method
  mask data
  Computing latent variables
  It = 1/100, err2 = 0.999934015123588
  It = 2/100, err2 = 0.994766206506411
  === lambda = 0.130189891797758, no zero B proportion = 0.00059261140565309
  It = 1/100, err2 = 0.994766373173339
  === lambda = 0.0976286459727577, no zero B proportion = 0.000878334761950115
  It = 1/100, err2 = 0.994765532716069
  === lambda = 0.0732111562799394, no zero B proportion = 0.00126988158354233
  It = 1/100, err2 = 0.994764638534954
  === lambda = 0.05490062215286, no zero B proportion = 0.00164026371207552
  It = 1/100, err2 = 0.994763845022762
  === lambda = 0.0411696586411789, no zero B proportion = 0.0020106458406087
  It = 1/100, err2 = 0.994763196094342
  === lambda = 0.0308728886152139, no zero B proportion = 0.00292072764214737
  It = 1/100, err2 = 0.994762606837317
  It = 2/100, err2 = 0.99476121574158
  === lambda = 0.0231514003979148, no zero B proportion = 0.0106352582621671
  Saving intermediate res into./OUTPUT/Expr/celiac_inter_lassolfmm.rds
  unmask data
  running hp
       pvalue   colname index outlier    score rep.sampler rep.method    method
  1 0.5255378 rs3934834     1   FALSE 0.634847           1          1 lassoLFMM
    method.K method.lambda
  1        9            NA
  Saving output in celiac_df_lassoLFMM.rds
  Expr save in ./OUTPUT/Expr/celiac_df_lassoLFMM.rds

#+end_example
****** Que donne la calibration

#+NAME: code:gwas_expr_calibration
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  expr %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:gwas_expr_calibration
: # A tibble: 5 x 3
:      method      mad       median
:       <chr>    <dbl>        <dbl>
: 1      cate 1.052221  0.011781682
: 2 lassoLFMM 1.045186  0.012433327
: 3        lm 1.201294 -0.023610211
: 4     PCAlm 1.037876  0.009601749
: 5 ridgeLFMM 1.061488  0.007643094
****** Gwas catalogue et controle du fdr

#+NAME: code:gwas_expr_fdr
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  ## fdr 5%
  toplot <- expr %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.05)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "gwas_fdr01_inter.png")

#+end_src

#+RESULTS: code:gwas_expr_fdr
[[./OUTPUT/Rplots/gwas_fdr01_inter.png]]
: # A tibble: 5 x 2
:      method     power
:       <chr>     <dbl>
: 1      cate 0.7755102
: 2 lassoLFMM 0.7959184
: 3        lm 0.5714286
: 4     PCAlm 0.5102041
: 5 ridgeLFMM 0.7346939
****** DONE plot top * power
CLOSED: [2017-08-07 lun. 18:12]
:LOGBOOK:
- State "DONE"       from              [2017-08-07 lun. 18:12]
:END:
#+NAME: code:gwas_top_power
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  m1 <- length(candidates)
  expr

  df <- expr %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,3000))
  pl
  save_plot_png(pl, "gwas_top_power.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_top_power.png]]
***** TODO Plots
:LOGBOOK:
- State "TODO"       from              [2017-08-06 Sun 15:11]
:END:
****** TODO Choix des paramètres
:LOGBOOK:
- State "TODO"       from              [2017-08-14 lun. 11:40]
:END:
#+NAME: code:gwas_screeplot_CV
#+CAPTION: Dépend de [[code:gwas_screeplot]] [[code:gwas_CV]] [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/gwas_screeplot_expr.rds")
  toplot <- expr$df.res %>%
      mutate(lambda = as.factor(lambda))
  plA <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,50)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "gwas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "gwas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = log(lambda), y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.2, 0.2))
  save_plot_png(plC, "gwas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "gwas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:gwas_screeplot_CV
[[./OUTPUT/Rplots/gwas_screeplot.png]]
[[./OUTPUT/Rplots/gwas_CV_K.png]]
[[./OUTPUT/Rplots/gwas_CV_lambda.png]]

****** TODO Résultats des méthodes
:LOGBOOK:
- State "TODO"       from              [2017-08-14 lun. 11:50]
:END:
#+NAME: code:gwas_qqplot_venn
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme


  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  celiac.df$method %>% unique()
  df.res <- celiac.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "gwas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,6000)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") +
    xlab("Taille de la top liste") +
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## When to we have every candidates ?
  message("== Top list information ==")
  toplot %>% group_by(method) %>% summarise(top = min(which(power >= 1.0)))
  toplot %>% dplyr::filter(top == 3000)

  ## pl.top
  save_plot_png(pl.top, filename = "gwas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "gwas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  message("== List with fdr controle ==")
  toplot %>% group_by(method) %>% summarise(n = length(outlier),
                                            power = sum(outlier) / m1)

  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               lm = toplot$index[toplot$method == "lm"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                         area1 = inter(1),
                         area2 = inter(2),
                         area3 = inter(3),
                         area4 = inter(4),
                         area5 = inter(5),
                         n12 = inter(1,2),
                         n13 = inter(1,3),
                         n14 = inter(1,4),
                         n15 = inter(1,5),
                         n23 = inter(2,3),
                         n24 = inter(2,4),
                         n25 = inter(2,5),
                         n34 = inter(3,4),
                         n35 = inter(3,5),
                         n45 = inter(4,5),
                         n123 = inter(1,2,3),
                         n124 = inter(1,2,4),
                         n125 = inter(1,2,5),
                         n134 = inter(1,3,4),
                         n135 = inter(1,3,5),
                         n145 = inter(1,4,5),
                         n234 = inter(2,3,4),
                         n235 = inter(2,3,5),
                         n245 = inter(2,4,5),
                         n345 = inter(3,4,5),
                         n1234 = inter(1,2,3,4),
                         n1235 = inter(1,2,3,5),
                         n1245 = inter(1,2,4,5),
                         n1345 = inter(1,3,4,5),
                         n2345 = inter(2,3,4,5),
                         n12345 = inter(1,2,3,4,5),
                         category = names(sets),
                         fill = color.values[names(sets)],
                         cat.col = color.values[names(sets)],
                         cat.cex = 1.2,
                         cat.pos = c(0.0, -30, 180, 180, 30),
                         cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                         margin = 0.07,
                         ind = TRUE
                       )

  save_plot_png(venn, filename = "gwas_venn.png")
  save_plot_MaTheseR(venn, "gwas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)
#+END_SRC

#+RESULTS: code:gwas_qqplot_venn
#+begin_example
[1] "lassoLFMM" "cate"      "PCAlm"     "ridgeLFMM" "lm"
[1] lassoLFMM cate      PCAlm     ridgeLFMM lm       
Levels: lm PCAlm sva-two-step sva-irw lassoLFMM cate ridgeLFMM oracle
Warning message:
Removed 344 rows containing non-finite values (stat_qq).
[[./OUTPUT/Rplots/gwas_qqplot_notcalibrated_all.png]]
Warning message:
Removed 344 rows containing non-finite values (stat_qq).
== Top list information ==
# A tibble: 5 x 2
     method    top
     <fctr>  <int>
1        lm 213444
2     PCAlm 259689
3 lassoLFMM 151172
4      cate 156858
5 ridgeLFMM 168820
# A tibble: 5 x 7
     method  index       pvalue calibrated.pvalue outlier     power   top
     <fctr>  <int>        <dbl>             <dbl>   <lgl>     <dbl> <dbl>
1        lm 274194 0.0005994528       0.004013977   FALSE 0.7755102  3000
2     PCAlm  68895 0.0047379566       0.006679586   FALSE 0.8367347  3000
3 lassoLFMM 148728 0.0030905497       0.004813782   FALSE 0.8775510  3000
4      cate  86890 0.0027882883       0.004325066   FALSE 0.8775510  3000
5 ridgeLFMM 266748 0.0032799926       0.005477400   FALSE 0.8775510  3000
[[./OUTPUT/Rplots/gwas_top_power_all.png]]
Warning message:
Removed 344 rows containing non-finite values (stat_qq).
[[./OUTPUT/Rplots/gwas_qqplot_top.pdf.png]]
== List with fdr controle ==
# A tibble: 5 x 3
     method     n     power
     <fctr> <int>     <dbl>
1        lm  1319 0.4489796
2     PCAlm   777 0.3673469
3 lassoLFMM  1267 0.6122449
4      cate  1319 0.6734694
5 ridgeLFMM  1000 0.5510204
[[./OUTPUT/Rplots/gwas_venn.png]]
[[./OUTPUT/Rplots/gwas_venn.pdf.png]]
[1] 0.2857143
#+end_example


*** Étude d'association entre des données génétiques et un gradient environmental (GEAS)
<<sec:GEAS>>

Depuis Darwin nous s'avons que les organismes vivant s'adapte a leur en
ivironement cite:Darwin. Ainsi les orgnasime les mieux adapté à leur habitat on
plus de chance de survivre et de se reproduire. Si l'avantage adaptatif à des
cause génétique, c'est à dire qu'il existe une combinaison de gènes qui confère
a l'organisme une fonction lui permet d'etre mieux adapté a son habitat, alors
le patrimoine génétique qui confère l'avantage sera tranmis aux futures
génération. On peut donc alors chercher a detecter les signatures génétique
laissé par l'adptation à un envorinement. C'est l'objectif des associations
génétique-environement. Pour cela nous avons récupéré les données génétiques du
projet 1000génome phase 3 cite:1000Genome_2015. Ces données regroupes $84.4$
million de variants génétiques pour 2506 individus venant de 26 populations
différentes. Par ailleurs nous avons récupéré des données climatiques de la base
de données WorldClim 2.0 cite:Fick_2017. L'objectif est alors de comparer les
résutats de l'étude d'assoication entre les données du 1000Genome et un gradient
envorinmental calculé à partir des données WorlClim. 

De la même facon que pour la GWAS nous avons filtrer les individus trop
apparenté et les variants génétiques pas assez fréquents (voir Partie [[sec:gwas]]).
De plus pour faire une étude d'association entre un génotype et un environement
il faut garder des individus qui vive dans leur habitat depuis plusieurs
générations, nous avons donc enlever les populations afro-américaine et
africaine des caraïbes. Il reste 1409 individus et 5397214 locus. Enfin, de la
même facon que dans la GWAS nous avons identifier un sous ensemble de 296948
grace au LD pruning. Nous utilisons ce sous ensembled e locus pour calculer les
variables latentes avec les méthodes PCAlm, cate, lassoLFMM et ridgeLFMM. On
calcule ensuite des \pvaleurs pour chacun des 5397214 locus grace au test
d'hypothèse présenté dans la partie [[sec:hypothese]].

Afin de calculer le gradient environnemental utilisé dans l'étude d'assocaition
nous avons attribué un position géographique a chaque individu en prenant la
capital de leur pays d'origine. Cela nous a parmis de recupérer les données de
la base WorlClim. Nous ne gardons que la première composante principale des
variables revoyé par la base Wordclim. La Figure ref:fig:eas_gradient rerpésente
la valeur du gradient climatique pour chaque population. On remarque que celui
ci est très corélé avec la latitue. Comme les population sont à différente
latitute il y aura de la corrélation entre la structure de population et le
gradient envorinmental.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_climatic_gradient.pdf.png}
\caption{Gradient climatique utilisé pour l'assocaition génome-environement.}
\label{fig:eas_gradient}
\end{figure}
#+END_EXPORT

Nous avons lancer les méthodes cate ridgeLFMM, lassoLFMM et PCAlm avec 5
variables latentes. Ce choix a été motivé par la décroissance des valeurs
propre reprédsenté par la Figure ref:fig:eas_params A.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre un gradient
  environmental et un génome. A) Proportion de variance expliquées par chacune
  des variables latentes estimées par l'algorithme ridgeLFMM pour diférente valeur
  $\lambda$ du paramètre de régularisation $L_2$. B)C) Erreur de prédiction
  calculée grâce à la validation croisée de l'estimateur $L_{2}$ des paramètre
  de LFMM pour différente valeurs du paramètre de régularisation $\lambda$ et du
  nombre variable lattentes $\K$. La ligne pointillée vertical marque le nombre
  de variables latentes choisi, 10.}
\label{fig:eas_params}
\end{figure}
#+END_EXPORT


**** Scripts                                                    :noexport:
***** DONE Téléchargement du jeux de données
CLOSED: [2017-07-26 mer. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-07-26 mer. 18:17]
:END:
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.

#+NAME: code:1000g_ddl
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
***** DONE Contrôle qualité
CLOSED: [2017-07-27 jeu. 14:15]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 14:15]
- Note taken on [2017-07-26 mer. 19:35] \\
  tail -f /home/cayek/tmp/Logfiles/1000g.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:42] \\
  faudra recuperer la sortie dans emacs
- State "RUNNING"    from "TODO"       [2017-07-26 mer. 18:41]
- State "TODO"       from              [2017-07-26 mer. 18:30]
:END:

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+NAME: code:1000g_CQ
#+CAPTION: Dépend de [[code:1000g_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
  do
      echo "===== $file ====="
      plink --vcf $file --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out `basename $file .vcf.gz`_CQ
  done
#+end_src

#+NAME: code:1000g_CQ_log
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_CQ_log
#+begin_example

  > > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:27:19 2017

  Random number seed: 1501090039
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3837178 out of 3992219 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999945.
  806 variants removed due to missing genotype data (--geno).
  --hwe: 75986 variants removed due to Hardy-Weinberg exact test.
  3481563 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  278823 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:31:11 2017
  ============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:31:11 2017

  Random number seed: 1501090271
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3891530 out of 4045628 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  747 variants removed due to missing genotype data (--geno).
  --hwe: 74342 variants removed due to Hardy-Weinberg exact test.
  3548109 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  268332 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:35:22 2017
  ============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:35:22 2017

  Random number seed: 1501090522
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3710299 out of 3868428 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  657 variants removed due to missing genotype data (--geno).
  --hwe: 73200 variants removed due to Hardy-Weinberg exact test.
  3377092 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  259350 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:39:43 2017
  ============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:39:43 2017

  Random number seed: 1501090783
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2737034 out of 2857916 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  497 variants removed due to missing genotype data (--geno).
  --hwe: 52494 variants removed due to Hardy-Weinberg exact test.
  2484161 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  199882 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:42:43 2017
  ============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:42:43 2017

  Random number seed: 1501090963
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2548064 out of 2655067 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999952.
  479 variants removed due to missing genotype data (--geno).
  --hwe: 53291 variants removed due to Hardy-Weinberg exact test.
  2320025 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  174269 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:45:29 2017
  ============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:45:29 2017

  Random number seed: 1501091129
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2328557 out of 2424689 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  434 variants removed due to missing genotype data (--geno).
  --hwe: 51148 variants removed due to Hardy-Weinberg exact test.
  2123668 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  153307 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:47:54 2017
  ============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:47:54 2017

  Random number seed: 1501091274
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2607034 out of 2697949 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  518 variants removed due to missing genotype data (--geno).
  --hwe: 51346 variants removed due to Hardy-Weinberg exact test.
  2387326 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  167844 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:50:35 2017
  ============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:50:35 2017

  Random number seed: 1501091435
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2234710 out of 2329288 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  413 variants removed due to missing genotype data (--geno).
  --hwe: 46649 variants removed due to Hardy-Weinberg exact test.
  2044443 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  143205 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:52:53 2017
  ============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:52:53 2017

  Random number seed: 1501091573
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2178759 out of 2267185 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  392 variants removed due to missing genotype data (--geno).
  --hwe: 39690 variants removed due to Hardy-Weinberg exact test.
  1980142 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  158535 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:55:07 2017
  ============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:55:07 2017

  Random number seed: 1501091707
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1758443 out of 1832506 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999942.
  402 variants removed due to missing genotype data (--geno).
  --hwe: 36837 variants removed due to Hardy-Weinberg exact test.
  1591671 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  129533 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:56:55 2017
  ============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:56:55 2017

  Random number seed: 1501091815
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6216035 out of 6468094 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  1033 variants removed due to missing genotype data (--geno).
  --hwe: 128213 variants removed due to Hardy-Weinberg exact test.
  5676255 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  410534 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:03:16 2017
  ============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:03:16 2017

  Random number seed: 1501092196
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1745171 out of 1812841 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999959.
  278 variants removed due to missing genotype data (--geno).
  --hwe: 35426 variants removed due to Hardy-Weinberg exact test.
  1592817 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  116650 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:05:02 2017
  ============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:05:02 2017

  Random number seed: 1501092302
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1058549 out of 1105538 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999928.
  279 variants removed due to missing genotype data (--geno).
  --hwe: 23191 variants removed due to Hardy-Weinberg exact test.
  956556 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  78523 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:06:06 2017
  ============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:06:06 2017

  Random number seed: 1501092366
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1059735 out of 1103547 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999946.
  222 variants removed due to missing genotype data (--geno).
  --hwe: 25833 variants removed due to Hardy-Weinberg exact test.
  960163 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  73517 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:07:11 2017
  ============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:07:11 2017

  Random number seed: 1501092431
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6808742 out of 7081600 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  1184 variants removed due to missing genotype data (--geno).
  --hwe: 138884 variants removed due to Hardy-Weinberg exact test.
  6233305 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  435369 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:14:09 2017
  ============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:14:09 2017

  Random number seed: 1501092849
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5603261 out of 5832276 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  1069 variants removed due to missing genotype data (--geno).
  --hwe: 111493 variants removed due to Hardy-Weinberg exact test.
  5104864 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  385835 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:19:48 2017
  ============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:19:48 2017

  Random number seed: 1501093188
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5500093 out of 5732585 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  1080 variants removed due to missing genotype data (--geno).
  --hwe: 115329 variants removed due to Hardy-Weinberg exact test.
  4985272 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  398412 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:25:25 2017
  ============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:25:25 2017

  Random number seed: 1501093525
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5055536 out of 5265763 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  909 variants removed due to missing genotype data (--geno).
  --hwe: 91958 variants removed due to Hardy-Weinberg exact test.
  4620648 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  342021 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:30:32 2017
  ============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:30:32 2017

  Random number seed: 1501093832
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4816881 out of 5024119 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999935.
  1292 variants removed due to missing genotype data (--geno).
  --hwe: 101026 variants removed due to Hardy-Weinberg exact test.
  4346787 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  367776 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:35:26 2017
  ============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:35:26 2017

  Random number seed: 1501094126
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4533180 out of 4716715 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.99995.
  842 variants removed due to missing genotype data (--geno).
  --hwe: 87612 variants removed due to Hardy-Weinberg exact test.
  4119828 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  324898 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:40:01 2017
  ============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:40:01 2017

  Random number seed: 1501094401
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4434371 out of 4597105 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999944.
  921 variants removed due to missing genotype data (--geno).
  --hwe: 90154 variants removed due to Hardy-Weinberg exact test.
  4048413 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  294883 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:44:29 2017
  ============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:44:29 2017

  Random number seed: 1501094669
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3427241 out of 3560687 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  689 variants removed due to missing genotype data (--geno).
  --hwe: 68557 variants removed due to Hardy-Weinberg exact test.
  3121045 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  236950 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:47:57 2017
#+end_example

***** DONE Fusion de tous les chromosomes
CLOSED: [2017-07-27 jeu. 14:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 14:43]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** Ensuite, nous avons enlever les doublons
#+NAME: code:1000g_rm
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## snp to remove
  echo "rs6658405" > excluded_variant.txt
  echo "." >> excluded_variant.txt
  echo "rs141927528" >> excluded_variant.txt
  echo "rs145926341" >> excluded_variant.txt

  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed
  do
      echo "===== $file ====="
      plink --bfile `basename $file .bed` --exclude excluded_variant.txt --make-bed --out `basename $file .bed`_excluded
  done
#+end_src

#+NAME: code:1000g_rm_log
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_rm_log
#+begin_example

> > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:51 2017

Random number seed: 1501158411
193793 MB RAM detected; reserving 96896 MB for main workspace.
278823 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 278823 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999926.
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
268332 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 268332 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
259350 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 259348 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
259348 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
199882 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 199882 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
174269 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 174269 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
153307 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 153305 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
153305 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
167844 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 167844 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999899.
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
143205 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 143205 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
158535 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 158535 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
129533 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 129533 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
410534 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 410532 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999927.
410532 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
116650 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 116650 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999933.
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
78523 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 78523 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
73517 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 73517 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999913.
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
435369 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 435369 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:57 2017
============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:57 2017

Random number seed: 1501158417
193793 MB RAM detected; reserving 96896 MB for main workspace.
385835 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 385835 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:58 2017
============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:58 2017

Random number seed: 1501158418
193793 MB RAM detected; reserving 96896 MB for main workspace.
398412 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 398412 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
342021 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 342021 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999919.
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
367776 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 367776 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:00 2017
============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:00 2017

Random number seed: 1501158420
193793 MB RAM detected; reserving 96896 MB for main workspace.
324898 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 324898 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
294883 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 294881 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999914.
294881 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
236950 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 236950 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:02 2017
#+end_example

****** On concatène les genomes en 1 seul fichier
#+NAME: code:1000g_concat
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

  ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_CQ")

  system(cmd)
#+end_src

#+RESULTS: code:1000g_concat
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded
    --make-bed
    --merge-list ./file5534632e75c3.txt
    --out 1000GenomePhase3_CQ

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Performing single-pass merge (2504 people, 5398440 variants).
  Merged fileset written to 1000GenomePhase3_CQ-merge.bed +
  1000GenomePhase3_CQ-merge.bim + 1000GenomePhase3_CQ-merge.fam .
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ.bed + 1000GenomePhase3_CQ.bim +
  1000GenomePhase3_CQ.fam ... done.
#+end_example

****** Vérification
#+NAME: code:1000g_test
#+CAPTION: Dépend de [[code:1000g_concat]]
#+begin_src shell :session *ssh krakenator* :results output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS: code:1000g_test
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:5	rs66584056	0	36516119	T	A
***** DONE Élagage (LD pruning)
CLOSED: [2017-07-27 jeu. 15:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 15:01]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** DONE LD report
CLOSED: [2017-08-17 jeu. 11:23]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:23]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:01]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:1000g_ld_report
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --r2 --ld-window 10 --ld-window-kb 10 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --ld-window 10
    --ld-window-kb 10
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:1000g_ld_report_R
#+CAPTION: Dépend de [[code:1000g_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "1000g_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "1000g_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ld_report_bin.png]]
[[./OUTPUT/Rplots/1000g_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:01]
:LOGBOOK:
- State "DONE"       from              [2017-08-17 jeu. 11:01]
:END:

On fait un filtrage des SNPs (voir [[https://www.cog-genomics.org/plink/1.9/ld#indep][doc plink]])
#+NAME: code:1000g_prunning
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_CQ --threads 8
  plink --bfile 1000GenomePhase3_CQ --extract 1000GenomePhase3_CQ.prune.in --make-bed --out 1000GenomePhase3_CQ_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 100 1 0.2
    --out 1000GenomePhase3_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 383854 variants from chromosome 1, leaving 26678.
  Pruned 409475 variants from chromosome 2, leaving 25894.
  Pruned 362867 variants from chromosome 3, leaving 22968.
  Pruned 376230 variants from chromosome 4, leaving 22182.
  Pruned 321811 variants from chromosome 5, leaving 20210.
  Pruned 347157 variants from chromosome 6, leaving 20619.
  Pruned 305597 variants from chromosome 7, leaving 19301.
  Pruned 277562 variants from chromosome 8, leaving 17319.
  Pruned 221173 variants from chromosome 9, leaving 15777.
  Pruned 261581 variants from chromosome 10, leaving 17242.
  Pruned 252405 variants from chromosome 11, leaving 15927.
  Pruned 242512 variants from chromosome 12, leaving 16836.
  Pruned 187679 variants from chromosome 13, leaving 12203.
  Pruned 162767 variants from chromosome 14, leaving 11502.
  Pruned 142011 variants from chromosome 15, leaving 11294.
  Pruned 155528 variants from chromosome 16, leaving 12316.
  Pruned 131567 variants from chromosome 17, leaving 11638.
  Pruned 147436 variants from chromosome 18, leaving 11099.
  Pruned 119524 variants from chromosome 19, leaving 10009.
  Pruned 107571 variants from chromosome 20, leaving 9079.
  Pruned 72922 variants from chromosome 21, leaving 5601.
  Pruned 67200 variants from chromosome 22, leaving 6317.
  Pruning complete.  5056429 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ.prune.in and
  1000GenomePhase3_CQ.prune.out .


  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --extract 1000GenomePhase3_CQ.prune.in
    --make-bed
    --out 1000GenomePhase3_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned.nosex .
  --extract: 342011 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned.bed + 1000GenomePhase3_CQ_prunned.bim
  + 1000GenomePhase3_CQ_prunned.fam ... done.

#+end_example

***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-07-27 jeu. 16:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 16:21]
- Note taken on [2017-07-26 mer. 19:21] \\
  c'est la que ca commence !! il faut que je remplace par les vrais appel de plink !!!
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

On filtre les individus trop apparenté (voir [[https://www.cog-genomics.org/plink/1.9/ibd][doc de plink]]).


****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:
#+NAME: code:1000g_ibd
#+CAPTION: Dépend de [[code:1000g_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## ibd
  plink -bfile 1000GenomePhase3_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-14 lun. 13:55]
:LOGBOOK:
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:1000g_ibd_visu
#+CAPTION: Dépend de [[code:1000g_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "1000g_ibd.png")


  ## We filter PI_HAT > 0.125
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.125) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ibd.png]]

On va filter les pour une proportion d'ibd à 0.125 (ca correspond à cousin au 3
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:1000g_ibd_filter
#+CAPTION: Dépend de [[code:1000g_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ_prunned --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_prunned_norel

  plink --bfile 1000GenomePhase3_CQ --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_norel
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --make-bed
    --out 1000GenomePhase3_CQ_prunned_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.99989.
  342011 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned_norel.bed +
  1000GenomePhase3_CQ_prunned_norel.bim + 1000GenomePhase3_CQ_prunned_norel.fam
  ... done.

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --make-bed
    --out 1000GenomePhase3_CQ_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999904.
  5398440 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_norel.bed + 1000GenomePhase3_CQ_norel.bim +
  1000GenomePhase3_CQ_norel.fam ... done.
#+end_example

***** DONE Conversion dans format utilisable en R
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-08-03 jeu. 11:37]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R. 

****** DONE Données non prunnées
CLOSED: [2017-08-14 lun. 14:14]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:11]
- Note taken on [2017-08-03 jeu. 14:14] \\
  ca a bugger le pense ...a voir.
- State "TODO"       from "RUNNING"    [2017-08-03 jeu. 14:14]
- State "RUNNING"    from "DONE"       [2017-08-03 jeu. 13:26]
- State "DONE"       from "RUNNING"    [2017-08-02 mer. 16:51]
- Note taken on [2017-08-02 mer. 16:11] \\
  il ne veux pas mettre de nom au ligne et colonnes .... je sais pas pk mais c'est
  pas si grave !!
- State "RUNNING"    from              [2017-08-02 mer. 15:59]
:END:

#+NAME: code:1000g_G_bigsnpr
#+CAPTION: Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_norel.bed"

  snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")

  G <- snp_attach("bigsnpr_G/G.rds")
  ## G <- readRDS("bigsnpr_G/G.rds")
  dim(G$genotypes)

  ## G.r <- readRDS("G.rds")
  G.r <- attach.BM(G$genotypes)[,]
  ## rownames(G.r) <- G$fam$sample.ID
  ## attr(G.r, "rownames") <- G$fam$sample.ID
  ## colnames(G.r) <- G$map$marker.ID
  ## attr(G.r, "colnames") <- G$map$marker.ID

  saveRDS(G.r, "G.rds")
  #+END_SRC

#+RESULTS:
#+begin_example
  > snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")
  Creating directory "bigsnpr_G" which didn't exist..
  Read 5398440 rows and 6 (of 6) columns from 0.142 GB file in 00:00:22
  [1] "bigsnpr_G/G.rds"
  > 
  > G <- snp_attach("bigsnpr_G/G.rds")
  > dim(G$genotypes)
  [1]    1758 5398440
  > rownames(G.r) <- G$fam$sample.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
  > colnames(G.r) <- G$map$marker.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
#+end_example

****** DONE Données prunnées
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 17:17]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

#+NAME: code:1000g_G_prunned_bigsnpr
#+CAPTION: On converti les données prunnées en un format R. Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_prunned_norel.bed"

  snp_readBed(bedfile, "G_prunned", backingpath = "bigsnpr_G_prunned")

  G <- snp_attach("bigsnpr_G_prunned/G_prunned.rds")
  dim(G$genotypes)

  G.r <- attach.BM(G$genotypes)[,]
  typeof(G.r)
  rownames(G.r) <- G$fam$sample.ID
  colnames(G.r) <- G$map$marker.ID
  saveRDS(G.r, "G_prunned.rds")
  rm(G.r)
  gc()


  ## We only keep first chromosomes 1 and 2 for simulation numerique
  in.id <- which(G$map$chromosome %in% c(1,2))
  G.r <- readRDS("G_prunned.rds")
  G.numVal <- G.r[,in.id]
  saveRDS(G.numVal, "G_prunned_chr12.rds")


  ## save indiv data frame
  saveRDS(G$fam, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/indiv_df.rds")
  #+END_SRC

***** DONE Données utilisées pour la validation numérique lfmm
CLOSED: [2017-07-27 jeu. 17:26]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 17:26]
:END:
#+NAME: code:1000g_G_valNum
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- readRDS("G_prunned_chr12.rds")
  anyNA(G)
  G.noNa <- preprocessing_filter_na(G)
  anyNA(G.noNa)
  G.scale <- scale(G.noNa)
  saveRDS(G.scale, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds")
#+end_src

#+RESULTS:
#+begin_example
  proportion of removed loci = 0.00686677318724797
#+end_example

***** DONE Filtrage des individus pour la GEAS
CLOSED: [2017-08-14 lun. 15:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 15:37]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:28]
- State "DONE"       from "TODO"       [2017-07-28 ven. 14:18]
- State "TODO"       from              [2017-07-28 ven. 11:46]
:END:

Nous ne gardons que les individus non métisses.

#+NAME: code:eas_indiv_df
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]] [[code:1000g_ibd_visu]]
#+begin_src R
  library(MaTheseR)

  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds") %>% as_tibble()
  indiv.df

  ## keep only indiv with no rel
  out.indif <- read_delim(file = "./Data/1000Genomes/Phase3/out.indif.txt", delim = " ",
                          col_names = FALSE, col_types = cols(.default = col_character()))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(sample %in% out.indif$X1))
  indiv.df

  ## retrieve pop

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW", "ACB")))
  indiv.df

  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
#+end_src

#+RESULTS: code:eas_indiv_df
#+begin_example
# A tibble: 2,504 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00103   GBR       EUR   male
 8 HG00105   GBR       EUR   male
 9 HG00106   GBR       EUR female
10 HG00107   GBR       EUR   male
# ... with 2,494 more rows
# A tibble: 1,758 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,748 more rows
# A tibble: 1,409 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,399 more rows
#+end_example

***** DONE Scaling des données et valeurs manquantes pour GEAS

CLOSED: [2017-08-16 mer. 15:44]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:44]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

****** DONE Données non prunnées 
CLOSED: [2017-08-16 mer. 15:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:29]
- State "TODO"       from              [2017-07-28 ven. 10:34]
:END:

#+NAME: code:1000g_G_noNA_scaled
#+CAPTION: Dépend de [[code:1000g_G_bigsnpr]] [[code:eas_indiv_df]]
#+begin_src R 
  library(bigsnpr)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- snp_attach("bigsnpr_G/G.rds")
  G.r <- attach.BM(G$genotypes)
  dim(G.r) ## [1]    1758 5398440

  ## indiv to keep
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
  kept.indiv.id <- G$fam$sample %in% eas.indiv.df$sample

  ## NA mu sds
  nas <- 1:ncol(G.r)
  mus <- 1:ncol(G.r)
  sds <- 1:ncol(G.r)
  pb <- txtProgressBar(min = 1, max = ncol(G.r))
  for(j in 1:ncol(G.r)) {
    aux <- as.double(G.r[kept.indiv.id,j])
    nas[j] <- mean(is.na(aux))
    mus[j] <- mean(aux, na.rm = TRUE)
    sds[j] <- sd(aux, na.rm = TRUE)
    setTxtProgressBar(pb, j)
  }
  close(pb)

  ## test
  quantile(nas)
  quantile(mus)
  quantile(sds)
  sum(nas > 0.0)
  sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)

  ## filter
  col.ids <- which(sds > 0.095) 

  ## size matrix file 1409x5397214
  ## save col and row name
  saveRDS(G$fam$sample.ID[kept.indiv.id], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  saveRDS(G$map$marker.ID[col.ids], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")

  ## export to bin
  con <- file("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin", 'wb')
  for(j in col.ids) {
    aux <- as.double(G.r[kept.indiv.id,j])
    writeBin((aux - mus[j]) / sds[j], con)
  }
  flush(con)
  close(con)

  ############################################################################################
  ## matter matrix
  library(matter)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G.big <- readRDS("bigsnpr_G/G.rds")
  row.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  col.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")

  G.matter <- matter_mat(paths="~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin",
                         nrow = length(row.names),
                         ncol = length(col.names),
                         datamode = "double")
  rownames(G.matter) <- row.names
  colnames(G.matter) <- col.names

  ## test
  dim(G.matter)
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  G.matter[1409,5397214]

  saveRDS(G.matter, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

#+end_src

#+RESULTS:
#+begin_example
  > quantile(nas)
    0%  25%  50%  75% 100% 
     0    0    0    0    0 
  > quantile(mus)
         0%       25%       50%       75%      100% 
  0.9254791 1.3584102 1.6217175 1.7934705 2.0539390 
  > quantile(sds)
         0%       25%       50%       75%      100% 
  0.0000000 0.4419241 0.5679660 0.6762505 0.8825680 
  > sum(nas > 0.0)
  [1] 0
  > sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)
  [1] 1226

#+end_example
****** DONE Données prunnées
CLOSED: [2017-08-16 mer. 15:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:40]
- State "TODO"       from "DONE"       [2017-08-14 lun. 14:19]
- State "DONE"       from "TODO"       [2017-07-28 ven. 11:01]
- State "TODO"       from              [2017-07-27 jeu. 17:29]
:END:

On fait un pruning plus fort que celui de [[code:1000g_prunning]]

#+NAME: code:1000g_prunning_more
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 5000 1 0.2 --out 1000GenomePhase3_CQ_more --threads 8
#+end_src


#+RESULTS:
#+begin_example
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_more.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 5000 1 0.2
    --out 1000GenomePhase3_CQ_more
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_more.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 387086 variants from chromosome 1, leaving 23446.
  Pruned 413054 variants from chromosome 2, leaving 22315.
  Pruned 366259 variants from chromosome 3, leaving 19576.
  Pruned 379840 variants from chromosome 4, leaving 18572.
  Pruned 324752 variants from chromosome 5, leaving 17269.
  Pruned 350848 variants from chromosome 6, leaving 16928.
  Pruned 308455 variants from chromosome 7, leaving 16443.
  Pruned 280143 variants from chromosome 8, leaving 14738.
  Pruned 223125 variants from chromosome 9, leaving 13825.
  Pruned 263958 variants from chromosome 10, leaving 14865.
  Pruned 254728 variants from chromosome 11, leaving 13604.
  Pruned 244633 variants from chromosome 12, leaving 14715.
  Pruned 189373 variants from chromosome 13, leaving 10509.
  Pruned 164213 variants from chromosome 14, leaving 10056.
  Pruned 143194 variants from chromosome 15, leaving 10111.
  Pruned 156696 variants from chromosome 16, leaving 11148.
  Pruned 132527 variants from chromosome 17, leaving 10678.
  Pruned 148556 variants from chromosome 18, leaving 9979.
  Pruned 120363 variants from chromosome 19, leaving 9170.
  Pruned 108299 variants from chromosome 20, leaving 8351.
  Pruned 73482 variants from chromosome 21, leaving 5041.
  Pruned 67649 variants from chromosome 22, leaving 5868.
  Pruning complete.  5101233 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ_more.prune.in and
  1000GenomePhase3_CQ_more.prune.out .
#+end_example

#+NAME: code:1000g_G_noNA_scaled_prunned
#+CAPTION: On scale et enlève les données manquantes. Dépend de [[code:1000g_G_noNA_scaled]] [[code:1000g_prunning_more]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  prune.in <- read_delim(file = "~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/1000GenomePhase3_CQ_more.prune.in", delim = " ", col_names = FALSE, col_types = cols(col_character()))

  library(matter)
  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

  ## test
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  dim(G.matter)

  ## prunning
  keep.id <- colnames(G.matter) %in% prune.in$X1
  saveRDS(which(keep.id), "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")
  G.prunned <- G.matter[,keep.id]

  ## test
  length(colnames(G.prunned))
  dim(G.prunned)

  saveRDS(G.prunned, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds")
#+end_src

#+RESULTS:
#+begin_example
> dim(G.prunned)
[1]   1409 296948
#+end_example

***** DONE Annotation VEP
CLOSED: [2017-08-22 mar. 15:31]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 15:31]
- State "RUNNING"    from "TODO"       [2017-08-22 mar. 12:41]
- State "TODO"       from              [2017-08-22 mar. 11:53]
:END:

vep input format : [[http://www.ensembl.org/info/docs/tools/vep/vep_formats.html#input][here]]

#+NAME: code:1000g_vep_input
#+CAPTION: On creer un fichier input pour vep. Dépend de [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(matter)
  library(tidyverse)

  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")
  snps.info <- readRDS("./Data/1000Genomes/Phase3/bigsnpr_G/G.rds")$map
  snps.info <- snps.info %>%
    dplyr::filter(marker.ID %in% colnames(G.matter))

  vep.input <- snps.info %>%
    transmute(chromosome = chromosome,
              start = physical.pos,
              end = physical.pos,
              allele = paste0(allele1,"/", allele2),
              strand = NA,
              identifier = marker.ID)

  write.table(vep.input, file = "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.input.txt",
              row.names = FALSE, col.names = FALSE, na = "", quote = FALSE)

#+end_src

run vep option : [[http://www.ensembl.org/info/docs/tools/vep/script/vep_options.html][here]]

#+NAME: code:1000g_vep_run
#+CAPTION: Dépend de [[code:1000g_vep_input]]
#+begin_src shell
  cd ~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article//
  vep --cache -i vep.input.txt -o vep.output.txt
#+end_src

#+NAME: code:1000g_vep_output
#+CAPTION: Dépend de [[code:1000g_vep_run]]
#+begin_src R 
  vep.output <- data.table::fread("./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.txt", skip = "#Uploaded_variation", data.table = FALSE, na.strings = "-")

  vep.output <- vep.output %>% as_tibble()

  saveRDS(vep.output, "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")
#+end_src

***** DONE Calcule du gradient climatique
CLOSED: [2017-08-17 jeu. 11:52]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:52]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:57]
- State "TODO"       from              [2017-08-06 Sun 14:47]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:26]
- State "DONE"       from "TODO"       [2017-07-28 ven. 15:58]
- State "TODO"       from "DONE"       [2017-07-28 ven. 11:46]
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+NAME: code:eas_climatic_gradient
#+CAPTION: Dépend de [[code:eas_indiv_df]]
#+begin_src R 
  library(tidyverse)
  library(MaTheseR)

  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds") %>% as_tibble()
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df


  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"
  indiv.df[indiv.df$pop == "ESN",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "FIN",]$citie = "Finland"
  indiv.df[indiv.df$pop == "GBR",]$citie = "England"

  ## cities
  indiv.df %>%
    dplyr::select(pop, `Population Description`, citie) %>%
    group_by(pop, `Population Description`, citie) %>%
    summarise() %>%
    print.data.frame()


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  ## library(leaflet)
  ## m <- leaflet() %>%
  ##   addTiles() %>%  # Add default OpenStreetMap map tiles
  ##   addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  ## ## m  # Print the map
  ## ## to render in rstudio....
  ## save_expr(m, "eas_map.rds")
  ## ## save widget
  ## library(htmlwidgets)
  ## saveWidget(m, "~/Projects/Thesis/MaThese/OUTPUT/Rplots/eas_map.html", selfcontained = FALSE)

  ## plot map
  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  map.world <- get_map(location = "world")
  pl <- ggplot(cities, aes(x = lon, y = lat, color = `Population Description`)) +
    mapWorld +
    geom_point() +
    theme(legend.position='bottom')
  pl
  save_plot_png(pl, "eas_map_ggplot.png", 1000, 600)

  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  plot(pc.bio$sdev)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    mapWorld + 
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS: code:eas_climatic_gradient
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
Le chargement a nécessité le package : xml2

Attachement du package : ‘rvest’

The following object is masked from ‘package:readr’:

    guess_encoding
  Population Code
1             CHB
2             JPT
3             CHS
4             CDX
5             KHV
6             CEU
                                             Population Description
1                                      Han Chinese in Bejing, China
2                                          Japanese in Tokyo, Japan
3                                              Southern Han Chinese
4                               Chinese Dai in Xishuangbanna, China
5                                 Kinh in Ho Chi Minh City, Vietnam
6 Utah Residents (CEPH) with Northern and Western European Ancestry
  Super Population Code Sequence Data Available Alignment Data Available
1                   EAS                       1                        1
2                   EAS                       1                        1
3                   EAS                       1                        1
4                   EAS                       1                        1
5                   EAS                       1                        1
6                   EUR                       1                        1
  Variant Data Available
1                      1
2                      1
3                      1
4                      1
5                      1
6                      1
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation('ggmap') for details.

Attachement du package : ‘ggmap’

The following object is masked from ‘package:magrittr’:

    inset
Joining, by = "pop"
# A tibble: 1,409 x 9
    sample   pop super_pop gender        `Population Description`
     <chr> <chr>     <chr>  <chr>                           <chr>
 1 HG00096   GBR       EUR   male British in England and Scotland
 2 HG00097   GBR       EUR female British in England and Scotland
 3 HG00099   GBR       EUR female British in England and Scotland
 4 HG00100   GBR       EUR female British in England and Scotland
 5 HG00101   GBR       EUR   male British in England and Scotland
 6 HG00102   GBR       EUR female British in England and Scotland
 7 HG00105   GBR       EUR   male British in England and Scotland
 8 HG00106   GBR       EUR female British in England and Scotland
 9 HG00107   GBR       EUR   male British in England and Scotland
10 HG00108   GBR       EUR   male British in England and Scotland
# ... with 1,399 more rows, and 4 more variables: `Super Population
#   Code` <chr>, `Sequence Data Available` <int>, `Alignment Data
#   Available` <int>, `Variant Data Available` <int>
   pop                                            Population Description
1  BEB                                           Bengali from Bangladesh
2  CEU Utah Residents (CEPH) with Northern and Western European Ancestry
3  ESN                                                   Esan in Nigeria
4  FIN                                                Finnish in Finland
5  GBR                                   British in England and Scotland
6  GIH                               Gujarati Indian from Houston, Texas
7  GWD                        Gambian in Western Divisions in the Gambia
8  IBS                                       Iberian Population in Spain
9  ITU                                         Indian Telugu from the UK
10 JPT                                          Japanese in Tokyo, Japan
11 LWK                                            Luhya in Webuye, Kenya
12 MSL                                             Mende in Sierra Leone
13 PJL                                     Punjabi from Lahore, Pakistan
14 STU                                      Sri Lankan Tamil from the UK
15 TSI                                                 Toscani in Italia
16 YRI                                         Yoruba in Ibadan, Nigeria
            citie
1      Bangladesh
2  United Kingdom
3         Nigeria
4         Finland
5         England
6         Gujarat
7          Gambia
8           Spain
9       Telangana
10          Japan
11          Kenya
12   Sierra Leone
13       Pakistan
14      Sri Lanka
15         Italia
16        Nigeria
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=England&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Finland&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Spain&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Pakistan&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gambia&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Bangladesh&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sierra%20Leone&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sri%20Lanka&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Telangana&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=United%20Kingdom&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Kenya&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Japan&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Italia&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gujarat&sensor=false

Attaching package: ‘maps’

The following object is masked from ‘package:purrr’:

    map
Map from URL : http://maps.googleapis.com/maps/api/staticmap?center=world&zoom=10&size=640x640&scale=2&maptype=terrain&language=en-EN&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=world&sensor=false
[[./OUTPUT/Rplots/eas_map_ggplot.png]]
Le chargement a nécessité le package : sp

Attachement du package : ‘raster’

The following object is masked from ‘package:magrittr’:

    extract

The following object is masked from ‘package:dplyr’:

    select

The following object is masked from ‘package:tidyr’:

    extract
Joining, by = c("pop", "Population Description", "citie")
[1] 1409    1

Attachement du package : ‘plotly’

The following object is masked from ‘package:raster’:

    select

The following object is masked from ‘package:ggmap’:

    wind

The following object is masked from ‘package:stats’:

    filter

The following object is masked from ‘package:graphics’:

    layout

The following object is masked from ‘package:ggplot2’:

    last_plot
We recommend that you use the dev version of ggplot2 with `ggplotly()`
Install it with: `devtools::install_github('hadley/ggplot2')`
#+end_example

***** DONE Scree plot
CLOSED: [2017-08-22 mar. 09:31]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 13:25]
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 12:11]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 17:24]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 16:03]
- Note taken on [2017-07-25 mar. 17:52] \\
  faut que je reance avec lambda
- State "TODO"       from "RUNNING"    [2017-07-25 mar. 17:49]
- Note taken on [2017-07-25 mar. 17:46] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_screeplot.y2017_m07_d25_17h_37.log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:46]
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:

#+NAME: code:eas_screeplot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  lambda <- c(1e-5, 1.0,1e10)

  ## methods
  methods <- method_PCA(scale = FALSE, 101) * param(lambda = lambda)

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr, "geas_screeplot_expr.rds")

  toplot <- expr$df.res %>%
    mutate(lambda = as.factor(lambda))
    pl <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
      geom_point() +
      coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "geas_screeplot.png")


#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-17 Thu 18:09]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-17 Thu 18:09]
- State "RUNNING"    from "DONE"       [2017-08-17 jeu. 16:49]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 16:47]
- Note taken on [2017-08-17 jeu. 13:58] \\
  Faut que je relance eas_CV_lambda pour etre sur
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 13:26]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "STARTED"    [2017-08-17 jeu. 08:52]
- State "STARTED"    from "RUNNING"    [2017-08-16 mer. 18:55]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 17:23]
- State "TODO"       from "DONE"       [2017-08-06 Sun 14:48]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:

#+NAME: code:eas_CV
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "geas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "geas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_CV_lfmm_K.png]]

#+NAME: code:eas_CV_encore
#+CAPTION: Dépend de [[eas_CV]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                                X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                                outlier = NULL) %>%
      ExpRmouline()

  lambdas <- c(1e10)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)


  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/geas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "geas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:eas_CV_lambda
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(4,5,6))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "eas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda_lfmm_lambda.png]]

***** TODO Étude du jeu de données
:LOGBOOK:
- State "TODO"       from "RUNNING"    [2017-08-21 lun. 16:48]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 16:48]
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 16:41]
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:13]
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 12:11]
- State "RUNNING"    from "STARTED"    [2017-08-17 jeu. 09:11]
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
****** DONE Run all methods
CLOSED: [2017-08-21 lun. 17:28]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:28]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 16:49]
- State "TODO"       from              [2017-08-21 lun. 16:48]
:END:
#+NAME: code:eas_expr_rm
#+CAPTION: Pour supprimer les résultats avant de relancer ! 
#+begin_src shell :session *ssh krakenator*
  cd ~/Projects/Thesis/MaThese/OUTPUT/Expr/
  ## lm
  rm -f eas_inter_lm.rds
  rm -f eas_df_lm.rds
  ## ridge
  rm -f eas_inter_ridgeLFMM.rds
  rm -f eas_df_ridgeLFMM.rds
  ## lasso
  rm -f eas_inter_lassoLFMM.rds
  rm -f eas_df_lassoLFMM.rds
  ## cate
  rm -f eas_inter_cate.rds
  rm -f eas_df_cate.rds
  ## pca
  rm -f eas_inter_PCAlm.rds
  rm -f eas_df_PCAlm.rds

  ls eas*.rds
#+end_src

#+RESULTS: code:eas_expr_rm

#+NAME: code:eas_expr_lasso
#+CAPTION: lassoLFMM est un peut plus long on va le lancer a coté. Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]] [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 5
  nozero.prop <- 0.01

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")

  ## methods
  methods <- list()
  methods$m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                                      lambda.K = 100, lambda.eps = 0.001, lambda = 9.5e-2,
                                      relative.err.epsilon = 1e-6,
                                      col.mask = col.mask,
                                      inter.res.saving.file = "./OUTPUT/Expr/eas_inter_lassoLFMM.rds",
                                      inter.res.file = NULL
                                      )

  run_eas <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds"
    X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
    outlier <- c()
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("eas_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    message("Running method")
    m <- ExpRmouline(m, dat)
    df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
    ## save expr
    message("Saving output in ", out.file)
    save_expr(df, out.file)
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_eas(m) %>%
      rbind(res.df)
  }

#+end_src

#+RESULTS:
#+begin_example
  =============== lassoLFMM
  Running method
  mask data
  Computing latent variables
  It = 1/100, err2 = 0.999290276780934
  It = 2/100, err2 = 0.903643187921675
  It = 3/100, err2 = 0.903566451059916
  It = 4/100, err2 = 0.903540302588162
  It = 5/100, err2 = 0.903537790776936
  It = 6/100, err2 = 0.903543772139505
  It = 7/100, err2 = 0.903547531654694
  It = 8/100, err2 = 0.903549843083158
  It = 9/100, err2 = 0.903551197197631
  === lambda = 0.095, no zero B proportion = 0.0198856365424249
  Saving intermediate res into./OUTPUT/Expr/eas_inter_lassoLFMM.rds
  unmask data
  running hp
       pvalue     colname index outlier     score rep.sampler rep.method
  1 0.6466421 rs575272151     1   FALSE 0.4585309           1          1
       method method.K method.lambda
  1 lassoLFMM        5         0.095
#+end_example

#+NAME: code:eas_expr
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]] [[code:1000g_G_noNA_scaled]]
#+begin_src R
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 5
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")

  ## methods
  methods <- list()
  methods$m.lm <- method_lm(col.mask = col.mask,
                            inter.res.saving.file = "./OUTPUT/Expr/eas_inter_lm.rds",
                            inter.res.file = NULL
                            )
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = K.method,
                                  col.mask = col.mask,
                                  inter.res.saving.file = "./OUTPUT/Expr/eas_inter_ridgeLFMM.rds",
                                  inter.res.file = NULL
                                  )
  methods$m.pca <- method_PCAlm(K = K.method,
                                col.mask = col.mask,
                                inter.res.saving.file = "./OUTPUT/Expr/eas_inter_PCAlm.rds",
                                inter.res.file = NULL
                                )
  methods$m.cate <- method_cate(K = K.method,
                        col.mask = col.mask,
                        inter.res.saving.file = "./OUTPUT/Expr/eas_inter_cate.rds",
                        inter.res.file = NULL,
                        hp = "lm"
                        )
  ## methods$m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
  ##                             lambda.K = 100, relative.err.epsilon = 1e-6,
  ##                             col.mask = col.mask,
  ##                             inter.res.saving.file = "./OUTPUT/Expr/eas_inter_lassoLFMM.rds",
  ##                             inter.res.file = NULL
  ##                             )

  run_eas <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds"
    X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
    outlier <- c()
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("eas_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    if (file.exists(out.file.path)) {
      message("Reading ", out.file.path)
      df <- readRDS(out.file.path)
    } else {
      message("Running method")
      m <- ExpRmouline(m, dat)
      df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
      ## save expr
      message("Saving output in ", out.file)
      save_expr(df, out.file)
    }
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_eas(m) %>%
      rbind(res.df)
  }
  save_expr(res.df, "eas_all_df.rds")
#+end_src

#+NAME: code:eas_expr_log
#+CAPTION: Dépend de [[code:eas_expr]]
#+begin_src shell :session *ssh krakenator*
  cdL
  tail -n 20 eas_expr.y2017_m08_d17.log
#+end_src

#+RESULTS: code:eas_expr_log
#+begin_example

It = 25/100, err2 = 0.90324780008161
It = 26/100, err2 = 0.903249905129517
It = 27/100, err2 = 0.903251718074658
It = 28/100, err2 = 0.903253280197275
It = 29/100, err2 = 0.903254625943498
It = 30/100, err2 = 0.903255784660473
It = 31/100, err2 = 0.903256782150928
=== lambda = 0.0428274462631357, no zero B proportion = 0.625362016245269
Saving intermediate res into./OUTPUT/Expr/eas_inter_lassolfmm.rds
unmask data
running hp
     pvalue     colname index outlier     score rep.sampler rep.method
1 0.4445152 rs575272151     1   FALSE 0.7648066           1          1
     method method.K method.lambda
1 lassoLFMM        5            NA
Saving output in eas_df_lassoLFMM.rds
Expr save in ./OUTPUT/Expr/eas_df_lassoLFMM.rds
save_expr(res.df, "eas_all_df.rds")
Expr save in ./OUTPUT/Expr/eas_all_df.rds
#+end_example

****** DONE Rbind results
CLOSED: [2017-08-21 lun. 17:32]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:32]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:29]
- State "TODO"       from              [2017-08-21 lun. 16:49]
:END:
#+NAME: code:eas_expr_all
#+CAPTION: Dépend de [[code:eas_expr]] [[code:eas_expr_lasso]]
#+begin_src R 
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  files <- list.files("./OUTPUT/Expr/", "eas_df_.*\\.rds")

  res.df <- tibble()
  for (f in files) {
    message("==", f)
    res.df <- readRDS(paste0("./OUTPUT/Expr/",f)) %>%
      rbind(res.df)
  }
  save_expr(res.df, "eas_all_df.rds")

#+end_src

#+RESULTS:
#+begin_example
  ==eas_df_cate.rds
  ==eas_df_lassoLFMM.rds
  ==eas_df_lm.rds
  ==eas_df_PCAlm.rds
  ==eas_df_ridgeLFMM.rds
#+end_example

****** DONE compute qvalue
CLOSED: [2017-08-21 lun. 17:57]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from              [2017-08-21 lun. 16:42]
:END:
#+NAME: code:eas_qvalue
#+CAPTION: Dépend de [[code:eas_expr_all]]
#+BEGIN_SRC R
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/eas_all_df.rds")

  qval.df <- res.df %>%
    group_by(method) %>%
    dplyr::mutate(qvalue = qvalue::qvalue(calibrated.pvalue)$qvalues) %>%
    ungroup()

  save_expr(qval.df, "eas_all_qvalue_df.rds")
#+END_SRC

****** load expr res
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_load_res
#+CAPTION: Dépend de [[code:eas_qvalue]]
#+BEGIN_SRC R
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
#+END_SRC


#+RESULTS: code:eas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-08-22 mar. 09:36]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:36]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_calibration
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  res.df %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS: code:eas_calibration
: # A tibble: 5 x 3
:      method      mad     median
:       <chr>    <dbl>      <dbl>
: 1      cate 1.727900 0.12915235
: 2 lassoLFMM 1.171343 0.02114513
: 3        lm 8.760657 0.38152482
: 4     PCAlm 1.169850 0.02052600
: 5 ridgeLFMM 1.736133 0.13956344

****** TODO Les qqplots ?
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_qqplot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- res.df %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))

  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

****** DONE Comparaison des top listes
CLOSED: [2017-08-22 mar. 09:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:41]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_top
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- res.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS: code:eas_top
[[./OUTPUT/Rplots/eas_top_inter.png]]

****** TODO Comparaison des liste avec contrôle du FDR à $0.01$ and venn diag
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_fdr
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- res.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## matrix
  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")

  ## venn diagram
  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")

#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

****** TODO Annotation Biomart
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:

#+NAME: code:eas_annotation
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation union ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()


  message("== annotation lfmmRidge ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("ridgeLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation cate ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("cate")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation lasso ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("lassoLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation PCAlm ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("PCAlm")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

#+END_SRC

#+NAME: code:eas_annotation_inter
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation inter ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- list(lm = aux$index[aux$method == "lm"],
               cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  sets <- sets[2:5]
  candidates.snps.df <- aux %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  length(unique(candidates.snps.df$colname))
  aux2 <- candidates.snps.df %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux2 %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()


#+end_src

****** TODO Annotation Vep
:LOGBOOK:
- State "TODO"       from              [2017-08-22 mar. 11:46]
:END:



****** TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:

#+NAME: code:eas_manhattan_plot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src

***** TODO Plot
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 14:32]
:END:

****** TODO Gradient climatique
:LOGBOOK:
- State "TODO"       from              [2017-08-21 lun. 14:48]
:END:
#+NAME: code:eas_climatic_gradient_plot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  library(ggmap)
  MaTheseR.params <- get_MaTheseRparams()


  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    mapWorld + 
    geom_point() +
    MaTheseR.params$gtheme +
    scale_size_continuous(guide = FALSE) +
    xlab("Longitude") +
    xlab("Latitude")
  pl
  save_plot_MaTheseR(pl, "eas_climatic_gradient.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)



#+end_src
****** TODO Choix des paramètres
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-17 jeu. 16:47]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 16:46]
- State "TODO"       from              [2017-08-17 jeu. 14:33]
:END:

#+NAME: code:eas_screeplot_CV
#+CAPTION: Dépend de [[code:eas_screeplot]] [[code:eas_CV]] [[code:eas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/geas_screeplot_expr.rds")
  toplot <- expr$df.res %>%
      mutate(lambda = as.factor(lambda))
  plA <- ggplot(toplot, aes(x = index, y = singular.value, color = lambda)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 5, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "eas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/geas_CV_lfmm_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.5)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 5, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.8))
  save_plot_png(plB, "eas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/eas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = log(lambda), y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.8, 0.2))
  save_plot_png(plC, "eas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "eas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:eas_screeplot_CV
: [[./OUTPUT/Rplots/eas_screeplot.png]]
: [[./OUTPUT/Rplots/eas_CV_K.png]]
: [[./OUTPUT/Rplots/eas_CV_lambda.png]]
: [[./OUTPUT/Rplots/eas_hyperparams.pdf.png]]
****** TODO qqplot
:LOGBOOK:
- State "TODO"       from              [2017-08-21 lun. 16:50]
:END:

****** TODO Diagrame de venn
:LOGBOOK:
- State "TODO"       from              [2017-08-21 lun. 16:50]
:END:

** Discussion                                                     :noexport:
** SANDBOX                                                        :noexport:
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** CANCELLED ridgeLFMM et cate quand B et V sont corrélé :D
CLOSED: [2017-08-07 lun. 14:32]
:LOGBOOK:
- Note taken on [2017-08-07 lun. 16:22] \\
  cate marche bien, la regression robuste va eviter ce cas la !!!
- State "CANCELLED"  from              [2017-08-07 lun. 14:32]
:END:

Que se passe-t-il quand B et V sont corrélé :D

#+begin_src R :results output :exports both
  sampler
#+end_src

Voir cahier le 7/08/2017

* Perspectives et conclusion 
:LOGBOOK:
- Note taken on [2017-08-10 jeu. 12:05] \\
  Les données manquante :D il y en a beaucoups dans les gandes données ! tess3r
  devrais être quand il y a des données manquante. Enfin si il prennait en compre
  correctement les NA. Faire une petite simu d'un tess qui prend en compre bien
  les missing data :D !!!!
- Note taken on [2017-07-31 lun. 10:20] \\
  on va parler de : 
  - vers le big data ? (valeurs manquantes, données pas loadé en mémoire)
  - est ce que le modèle est polygénique ?
  - théorie stat (cf cate)
  - matrice de dosage
  - lien autre que linéaire ? (lien logistique)
- Note taken on [2017-07-30 Sun 13:56] \\
  matrice de dosage
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:49] \\
  strategie: il faut que je finisse tout le reste avec les versions actuelles
  (tess3r, et ce que j'ai fait pour le moment d'lfmm). Quand tout sera fini ! Je
  repenserai l'archi de tess3r (tout en R et une seul data en mémoire). Je pense
  que je n'arriverais pas faire de l'acces de très grosse données depui un fichier
  et la gestion des NA en même temps. Mais je peux montrer les deux séparément,
  cad on montre que on arrive a faire un algo robuste au NA pour tess3r et lfmm
  mais c'est pas complétement implémenté. ET on montre sur un très gros dataset
  une analyse complete pop et lfmm (le 1001 génome est top pour ca car on a une
  matrice imputé :D)
- Note taken on [2017-07-18 Tue 10:57] \\
  - traitement des données manquantes
  - acess au données (pas dans la ram, je peux parler des infracstructure big data
    classique)
  - si j'ai le temps j'implémente ces 2 feature cad: 
    - NA -> comparaison avec et sans NA et procedure naive
    - matrice en mémoriedans un BED -> on a seulement besoin du produit par X ! 
  
  c'est la suite logique de ma problématique cad : 
  - data de plus en plus grosse donc on veut pas les dupliquer, il y a des données
    manquantes
  - mon taf c'est de fournir des logicielles !
  
  
  Je peux ecrire cette partie comme un mini article ! cad
  intro 
  methode
  resultats
  discution 
  conclusion

- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:


bibliographystyle:apalike
bibliography:../biblio.bib

