# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:5 author:nil email:nil creator:nil timestamp:nil skip:nil toc:nil ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(D!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


# #+LaTeX_CLASS: book
#+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM

#+BEGIN_QUOTE
In Code we trust, all others bring data.
–William Edwards Deming (1900-1993).
#+END_QUOTE

* Introduction
:LOGBOOK:
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
** Contexte
:LOGBOOK:
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:

Cette dernière décennie a été marquée par une accumulation des données dans tous les
domaines de la sciences. Cette accumulation de données est une aubaine pour les
scientifiques. Cependant, que faire d'autant de données et comment en tirer
l'information qui permettrait de mieux comprendre le monde qui nous entoure ? Il
s'agit là d'un défi majeur pour les statistiques cite:slides_sfds2015_saporta. 

Les grandes données posent plusieurs problèmes. En effet, si l'on est capable d'obtenir
des données rapidement, on veut pouvoir les analyser rapidement. Cependant de
nombreux modèle statistiques classiques ne passent pas l'échelle des grands jeux
de données. Il est donc nécessaire de repenser les modèles et algorithmes afin
de les adapter au nous volumes des données. 
... parler de l'inversement du processus d'aquisition des données .. cf
seminaire Bosson



Dans le cadre de cette thèse nous nous sommes intéressé a développer des méthodes
statistiques utiles à deux problématique scientifiques. Le premier est l'estimation
de la structure de population à partir de données génomique. Le deuxièmes est les
problèmes des test d'association multiple. Toutes les méthodes statistiques
developper lors de cette thèse repose sur la factorisation de matrice. Nous
allons maintenant introduire plus en détails les problématiques ainsi que la
factorisation de matrice en statistique.


** La génomique des populations
:LOGBOOK:
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc
  - ewas: refactor
:END:
** Test d'association
** La factorisation de matrice en statistique
** Problématique et plan
* Données 
Nous décrivons dans cette partie les données réelles qui sont analysée dans
cette thèse. Afin de rendre les analyse le plus possible reproductible
reproductible, nous décrivons les étapes de pré traitement qui ont été affecté
sur ces jeux de données. Les scripts sont disponible dans la version de la thèse
avec le code.
** 1000 genome

---DECRIRE dataset----
*** Téléchargement du jeux de données
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
*** Contrôle qualité

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+begin_src R :results output :exports both
  ## file list
  setwd("./Data/1000Genomes/Phase3/")

  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)

  maf <- 0.05
  mind <- 0.05
  hwe <- 1e-10
  geno <- 0.05
  for (f in files) {
    cmd <- paste("plink",
                 "--vcf", f,
                 "--maf", maf,
                 "--mind", mind,
                 "--geno", geno,
                 "--hwe", hwe,
                 "--snps-only",
                 "--autosome",
                 "--make-bed",
                 "--out", paste0("./plink/", sub(".vcf.gz", "",f)),
                 ">> plink_GC.out")

    system("rm -f plink_QC.out")
    system(cmd)
  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cd ~/Projects/Thesis/Data/1000Genomes/Phase3/plink/
  for f in ALL.chr*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log
  do
      echo "=====FILE:$f====="
      cat "$f"
  done
#+end_src

#+RESULTS:
#+begin_example

> > > > =====FILE:ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:51:39 2017

Random number seed: 1495032699
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3837178 out of 3992219 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999945.
806 variants removed due to missing genotype data (--geno).
--hwe: 75986 variants removed due to Hardy-Weinberg exact test.
3481563 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:55:55 2017
=====FILE:ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:55:55 2017

Random number seed: 1495032955
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3891530 out of 4045628 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
747 variants removed due to missing genotype data (--geno).
--hwe: 74342 variants removed due to Hardy-Weinberg exact test.
3548109 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:00:10 2017
=====FILE:ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:00:10 2017

Random number seed: 1495033210
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3710299 out of 3868428 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
657 variants removed due to missing genotype data (--geno).
--hwe: 73200 variants removed due to Hardy-Weinberg exact test.
3377092 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
259350 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:04:16 2017
=====FILE:ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:04:16 2017

Random number seed: 1495033456
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2737034 out of 2857916 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
497 variants removed due to missing genotype data (--geno).
--hwe: 52494 variants removed due to Hardy-Weinberg exact test.
2484161 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:07:18 2017
=====FILE:ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:07:18 2017

Random number seed: 1495033638
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2548064 out of 2655067 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999952.
479 variants removed due to missing genotype data (--geno).
--hwe: 53291 variants removed due to Hardy-Weinberg exact test.
2320025 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:10:07 2017
=====FILE:ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:10:07 2017

Random number seed: 1495033807
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2328557 out of 2424689 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
434 variants removed due to missing genotype data (--geno).
--hwe: 51148 variants removed due to Hardy-Weinberg exact test.
2123668 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
153307 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:12:41 2017
=====FILE:ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:12:41 2017

Random number seed: 1495033961
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2607034 out of 2697949 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999947.
518 variants removed due to missing genotype data (--geno).
--hwe: 51346 variants removed due to Hardy-Weinberg exact test.
2387326 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:15:30 2017
=====FILE:ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:15:30 2017

Random number seed: 1495034130
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2234710 out of 2329288 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999951.
413 variants removed due to missing genotype data (--geno).
--hwe: 46649 variants removed due to Hardy-Weinberg exact test.
2044443 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:17:58 2017
=====FILE:ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:17:58 2017

Random number seed: 1495034278
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
2178759 out of 2267185 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
392 variants removed due to missing genotype data (--geno).
--hwe: 39690 variants removed due to Hardy-Weinberg exact test.
1980142 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:20:20 2017
=====FILE:ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:20:20 2017

Random number seed: 1495034420
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1758443 out of 1832506 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999942.
402 variants removed due to missing genotype data (--geno).
--hwe: 36837 variants removed due to Hardy-Weinberg exact test.
1591671 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:22:17 2017
=====FILE:ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 16:44:50 2017

Random number seed: 1495032290
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6216035 out of 6468094 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
1033 variants removed due to missing genotype data (--geno).
--hwe: 128213 variants removed due to Hardy-Weinberg exact test.
5676255 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
410534 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 16:51:39 2017
=====FILE:ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:29:40 2017

Random number seed: 1495034980
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1745171 out of 1812841 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999959.
278 variants removed due to missing genotype data (--geno).
--hwe: 35426 variants removed due to Hardy-Weinberg exact test.
1592817 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:31:43 2017
=====FILE:ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:31:43 2017

Random number seed: 1495035103
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1058549 out of 1105538 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999928.
279 variants removed due to missing genotype data (--geno).
--hwe: 23191 variants removed due to Hardy-Weinberg exact test.
956556 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:32:53 2017
=====FILE:ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:32:53 2017

Random number seed: 1495035173
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
1059735 out of 1103547 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999946.
222 variants removed due to missing genotype data (--geno).
--hwe: 25833 variants removed due to Hardy-Weinberg exact test.
960163 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:34:01 2017
=====FILE:ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:22:17 2017

Random number seed: 1495034537
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
6808742 out of 7081600 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999954.
1184 variants removed due to missing genotype data (--geno).
--hwe: 138884 variants removed due to Hardy-Weinberg exact test.
6233305 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:29:40 2017
=====FILE:ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:34:01 2017

Random number seed: 1495035241
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5603261 out of 5832276 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999949.
1069 variants removed due to missing genotype data (--geno).
--hwe: 111493 variants removed due to Hardy-Weinberg exact test.
5104864 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:40:14 2017
=====FILE:ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:40:14 2017

Random number seed: 1495035614
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5500093 out of 5732585 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
1080 variants removed due to missing genotype data (--geno).
--hwe: 115329 variants removed due to Hardy-Weinberg exact test.
4985272 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:46:21 2017
=====FILE:ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:46:21 2017

Random number seed: 1495035981
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
5055536 out of 5265763 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999953.
909 variants removed due to missing genotype data (--geno).
--hwe: 91958 variants removed due to Hardy-Weinberg exact test.
4620648 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:51:47 2017
=====FILE:ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:51:47 2017

Random number seed: 1495036307
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4816881 out of 5024119 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999935.
1292 variants removed due to missing genotype data (--geno).
--hwe: 101026 variants removed due to Hardy-Weinberg exact test.
4346787 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 17:57:03 2017
=====FILE:ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 17:57:03 2017

Random number seed: 1495036623
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4533180 out of 4716715 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99995.
842 variants removed due to missing genotype data (--geno).
--hwe: 87612 variants removed due to Hardy-Weinberg exact test.
4119828 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:01:58 2017
=====FILE:ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:01:58 2017

Random number seed: 1495036918
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
4434371 out of 4597105 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999944.
921 variants removed due to missing genotype data (--geno).
--hwe: 90154 variants removed due to Hardy-Weinberg exact test.
4048413 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
294883 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:06:48 2017
=====FILE:ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.log=====
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --autosome
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out ./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes
  --snps-only
  --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Wed May 17 18:06:48 2017

Random number seed: 1495037208
193793 MB RAM detected; reserving 96896 MB for main workspace.
--vcf:
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes-temporary.fam
written.
3427241 out of 3560687 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.nosex
.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999948.
689 variants removed due to missing genotype data (--geno).
--hwe: 68557 variants removed due to Hardy-Weinberg exact test.
3121045 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bim
+
./plink/ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.fam
... done.

End time: Wed May 17 18:10:32 2017
#+end_example
*** Fusion de tous les chromosomes
Ensuite, nous avons enlever 
#+begin_src R :results output :exports both
  setwd("./Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)

  ## exclude variant
  write("rs6658405\n.\nrs145926341\nrs141927528" , file = "excluded_variant.txt")

  for (f in prefix) {
    cmd <- paste("plink",
                 "--bfile", f,
                 "--exclude excluded_variant.txt",
                   "--make-bed",
                 "--out", paste0(f, "_excluded"))
    system(cmd)
  }
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS:
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bim:5	rs66584056	0	36516119	T	A

#+begin_src R :results output :exports both
  setwd("./Data/1000Genomes/Phase3/plink/")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

    ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_QC")

  system(cmd)
#+end_src

#+begin_src shell :session *ssh krakenator* :results output :exports both 
  cat 1000GenomePhase3_QC.log
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_excluded
  --make-bed
  --merge-list ./file290c4546eae6.txt
  --out 1000GenomePhase3_QC

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 09:55:14 2017

Random number seed: 1495094114
193793 MB RAM detected; reserving 96896 MB for main workspace.
Performing single-pass merge (2504 people, 5398440 variants).
Merged fileset written to 1000GenomePhase3_QC-merge.bed +
1000GenomePhase3_QC-merge.bim + 1000GenomePhase3_QC-merge.fam .
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC.bed + 1000GenomePhase3_QC.bim +
1000GenomePhase3_QC.fam ... done.

End time: Thu May 18 09:57:32 2017
#+end_example
*** Filtrage des individus trop apparenté
#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("~/Projects/Thesis/Data/1000Genomes/Phase3/plink")
  plink <- "/home/cayek/BiocompSoftware/plink/plink"
  bedfileQC <- "1000GenomePhase3_QC.bed"
  rel <- snp_plinkIBDQC(plink, bedfileQC, ncores = 4,
                        bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC),
                        pruning.args = NULL,
                        do.blind.QC = TRUE)

  bedfileQC2 <- snp_plinkRmSamples(
    plink, 
    bedfile.in = bedfileQC, 
    bedfile.out = sub("\\.bed$", "_norel.bed", bedfileQC), 
    df.or.files = subset(rel, PI_HAT > 0.08)
    )
  print(bedfileQC2)
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --genome
    --min 0.08
    --out 1000GenomePhase3_QC
    --threads 4

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC.nosex .
  Using up to 4 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing 1000GenomePhase3_QC.genome .
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_QC_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_QC
    --make-bed
    --out 1000GenomePhase3_QC_norel
    --remove /home/cayek/tmp/RtmpVBcWMh/file577662272180

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
  --remove: 919 people remaining.
  Warning: At least 146315 duplicate IDs in --remove file.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 919 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999923.
  5398440 variants and 919 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_QC_norel.bed + 1000GenomePhase3_QC_norel.bim +
  1000GenomePhase3_QC_norel.fam ... done.
#+end_example
*** Élagage 

Il est bien connue qu'il y a une forte corrélation en les SNPs que l'on appel
déséquilibre de liaision CITE. c'est un problème pour l'acp ect... cite 
Pour les analyse factorielle en général il est préférable d'enlever les qui sont
trés corrélé entre elles pour eviter de biaiser l'apprentissage des facteurs.
#+begin_src shell :results output :exports both 
  cd ./Data/1000Genomes/Phase3/plink/
  plink --bfile 1000GenomePhase3_QC_norel --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_QC_norel --threads 8
  plink --bfile 1000GenomePhase3_QC_norel --extract 1000GenomePhase3_QC_norel.prune.in --make-bed --out 1000GenomePhase3_QC_norel_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --indep-pairwise 100 1 0.2
  --out 1000GenomePhase3_QC_norel
  --threads 8

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/plink
Start time: Thu May 18 10:54:56 2017

Random number seed: 1495097696
193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
5398440 variants and 919 people pass filters and QC.
Note: No phenotypes present.
Pruned 383736 variants from chromosome 1, leaving 26796.
Pruned 409231 variants from chromosome 2, leaving 26138.
Pruned 362671 variants from chromosome 3, leaving 23164.
Pruned 376046 variants from chromosome 4, leaving 22366.
Pruned 321739 variants from chromosome 5, leaving 20282.
Pruned 346793 variants from chromosome 6, leaving 20983.
Pruned 305297 variants from chromosome 7, leaving 19601.
Pruned 277248 variants from chromosome 8, leaving 17633.
Pruned 221055 variants from chromosome 9, leaving 15895.
Pruned 261309 variants from chromosome 10, leaving 17514.
Pruned 252249 variants from chromosome 11, leaving 16083.
Pruned 242441 variants from chromosome 12, leaving 16907.
Pruned 187619 variants from chromosome 13, leaving 12263.
Pruned 162678 variants from chromosome 14, leaving 11591.
Pruned 141956 variants from chromosome 15, leaving 11349.
Pruned 155359 variants from chromosome 16, leaving 12485.
Pruned 131431 variants from chromosome 17, leaving 11774.
Pruned 147368 variants from chromosome 18, leaving 11167.
Pruned 119426 variants from chromosome 19, leaving 10107.
Pruned 107554 variants from chromosome 20, leaving 9096.
Pruned 72900 variants from chromosome 21, leaving 5623.
Pruned 67178 variants from chromosome 22, leaving 6339.
Pruning complete.  5053284 of 5398440 variants removed.
Marker lists written to 1000GenomePhase3_QC_norel.prune.in and
1000GenomePhase3_QC_norel.prune.out .

End time: Thu May 18 10:55:08 2017

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to 1000GenomePhase3_QC_norel_prunned.log.
Options in effect:
  --bfile 1000GenomePhase3_QC_norel
  --extract 1000GenomePhase3_QC_norel.prune.in
  --make-bed
  --out 1000GenomePhase3_QC_norel_prunned
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
919 people (0 males, 0 females, 919 ambiguous) loaded from .fam.
Ambiguous sex IDs written to 1000GenomePhase3_QC_norel_prunned.nosex .
--extract: 345156 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 919 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999904.
345156 variants and 919 people pass filters and QC.
Note: No phenotypes present.
--make-bed to 1000GenomePhase3_QC_norel_prunned.bed +
1000GenomePhase3_QC_norel_prunned.bim + 1000GenomePhase3_QC_norel_prunned.fam
... done.

#+end_example
*** Conversion au format R

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R.

#+begin_src R :results output :exports both
  library(bigsnpr)
  setwd("./Data/1000Genomes/Phase3/plink")
  bedfile <- "1000GenomePhase3_QC_norel_prunned.bed"

  snp_readBed(bedfile, "1000GenomePhase3")
#+end_src

#+begin_src R :results output :exports both
  library(bigsnpr)
  genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")

  names(genome1000)
  dim(genome1000$genotypes)

  ## G
  G <- attach.BM(genome1000$genotypes)[]
  rownames(G) <- genome1000$fam$sample.ID
  colnames(G) <- genome1000$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)
  saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  dim(G)
#+end_src

#+RESULTS:
#+begin_example
  > library(bigsnpr)
  > genome1000 <- snp_attach("backingfiles/1000GenomePhase3.rds")
  > 
  > names(genome1000)
  [1] "genotypes" "fam"       "map"       "savedIn"  
  > dim(genome1000$genotypes)
  [1]    919 345156
  > 
  > ## G
  > G <- attach.BM(genome1000$genotypes)[]
  > rownames(G) <- genome1000$fam$sample.ID
  > colnames(G) <- genome1000$map$marker.ID
  > n <- nrow(G)
  > L <- ncol(G)
  > saveRDS(G, "1000GenomePhase3_QC_norel_prunned.rds")
  > dim(G)
  [1]    919 345156
#+end_example
*** Scaling des données
Pour certaine analyse il est important de scaler les données. 

#+begin_src R :results output :exports both
  G <- readRDS("./Data/1000Genomes/Phase3/plink/1000GenomePhase3_QC_norel_prunned.rds")
  G <- scale(G)

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
#+end_src
*** Filtrage des données manquantes
Il reste certain SNPs avec des données manquantes ($0.7 \%$), nous les avons enlevé.
#+begin_src R :results output :exports both
  library(MaTheseR)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled.rds")
  G <- preprocessing_filter_na(G)
  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
#+end_src

#+RESULTS:
#+begin_example
  TRACE [2017-05-18 16:19:27] proportion of removed loci =  0.00775881050887135
  > dim(G)
  [1]    919 342478
#+end_example
** Arabidopsis Thaliana Regional Mapping Lines
** 1001 genome
** TODO Celiac GWAS
:LOGBOOK:
- Note taken on [2017-07-11 mar. 09:32] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
- State "TODO"       from              [2017-07-11 mar. 09:27]
:END:
*** Téléchargement des données
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=


*** Contrôle qualité
*** Filtrage des individus trop apparenté
*** Imputation des données manquantes
Avec bigsnpr et xgboost
*** Élagage
*** Conversion au format R et scaling
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
**** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
*** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
** AT EWAS
*** Téléchargement des données
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC
*** Formatage
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC
*** Preprocessing
Nour avons reproduit le preprocessing expliqué dans cite:Zou_2014.
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC
*** Scaling des données
Pour certaine analyse il est important de scaler les données. 
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

* Inférence rapide des coefficients de métissage à l'aide des données géographique
:LOGBOOK:
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
** Detection de la structure de population
** Test adaptation local 
** presentation de l'article 1
* Estimation des facteurs latents pour corriger les test d'association :3Article:
** before article 2
*** Les tests d'hypothèse multiple
*** Les modèle a facteur lattents pour ca
*** presentation de l'article 2
** Article
*** Introduction
*** Méthodes 
**** Modèle 
Nous introduisons dans cette partie le modèle et les notations. La plupart des
méthodes d'ajustement pour les facteurs de confusions repose sur le modèle
suivant  
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Comme dans cite:frichot13_testin_assoc_between_loci_envir, nous appellerons ce
modèle le modèle mixte à facteurs latents (LFMM pour latent factor mixed model
en anglais). Dans cette équation, $\Y$ est la matrice des variables expliquées
de taille $\Yrow \times \Ycol$, où $\Ycol$ est le variables et $\Yrow$ le nombre
d'observations. Par exemple, les variables expliquées peuvent être des SNPs ou
bien des niveau de méthylation. La matrice $\X$ de taille $\Xrox \times \Xcol$
représente les variables explicatives. Les variables explicatives peuvent être
par exemple une maladie ou un gradient environnementale comme la température. La
matrice des effets de taille $\Ycol \times \Xcol$ est notée $\B$. Les matrices
$\U$ et $\V$ sont respectivement de la matrice des coordonnées de taille $\Urow
\times \K$ et la matrice des axes factoriels $\Ycol\times\Ucol$. La matrice $\U$
est la matrice des $\K$ variable latentes et la matrice $\V$ représente les axes
des facteurs latents. Enfin la matrice $\E$ est la matrice d'erreur résiduelle
de taille $\Yrow\times\Ycol$.

Nous remarquons dans un premier temps que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. Nous posons 
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
la matrice latente. Si l'on suppose qu'il y à $\K$ variables latentes sont
indépendantes alors la matrice latentes $\W$ est de rang $\K$. Dans la suite
nous considérerons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce
à l'analyse en composante principale de la matrice latente $\W$.

**** Estimation des moindres carrées régularisés en norme $L_{2}$
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres de
LFMM défini par eqref:eq:model basé sur un problème des moindres carrées
régularisé en norme $L_{2}$. Nous montrerons que cette algorithme permet de
calculer un point de minimum global du problème d'optimisation.

***** Fonction objectif

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM nous posons la fonction
objectif suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lamba$ le paramètre de régularisation. 

Le terme premier terme de $\Lridge$ (terme d'attache aux données) correspond à
l'opposé de la log vraisemblance où la matrice de bruit $\E$ est Gaussienne,
isotrope et de moyenne nulle.

Le terme deuxième terme de $\Lridge$ (terme de régularisation) est indispensable
pour distinguer l'effet des variables latentes de celui des variables
explicatives. En effet, si
\begin{equation*}
\lambda = 0 
\end{equation*}
alors pour toutes matrices $\matr{T}$ de taille $\Xcol \times \Ycol$ on a 
\begin{equation*}
\Lridge(\U - \X \matr{T}, \V^{T}, \B + \V \matr{T}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Ainsi, les points minimuns d'une tel fonction objective ne serait pas pertinents pour
notre problème.

***** Algorithme
Afin d'estimer les paramètres de LFMM qui minimise $\Lridge$ nous commençons par
calculer la décomposition en valeurs singulières de la matrice des variables
explicatives $\X$
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T}
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, 
$\matr{R}$ une matrice unitaire de taille $\Xcol \times \Xcol$ et
$\matr{\Sigma}$ une matrice de taille $\Xrow \times \Xcol$ contenant les valeurs
singulières $\left \{ \sigma_{j} \left \}_{j = 1..\Xcol}$.
Les estimations sont calculé de la façon suivante 
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V} & =  \matr{Q} \matr{D}^{-1} \svd_{\K}( \matr{D} \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B} & = (\X^{T} \X + \lambda \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}).
\end{align}
Où $\svd_{\K}(\matr{A})$ est la meilleur approximation de rang $\K$ de la matrice
$\matr{A}$ données par la décomposition en valeurs singulières (SVD pour
singular value decomposition) et $\Id_{d}$ est la matrice identité de taille $d
\times d$. La matrice $\matr{D}$ est la matrice diagonale de taille $\Yrow
\times \Yrow$ qui contient les termes
\begin{equation*}
\left\{ \sqrt{\frac{\lambda}{\lambda + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambda}{\lambda + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latentes $\hat{\U} \hat{\V}$ dans
eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement de base
$\matr{Q}$. Les $\Xcol$ premiers axes de cette nouvelle base forment une base
orthonormal de l'espace vectoriel engendré par les variables explicatives. La
matrice diagonal $\matr{D}$ a pour effet de réduire la composante qui appartient
à l'espace engendré par $\X$. Si $\lambda$ vaut zéro la multiplication par
$\matr{D} \matr{Q}^{T}$ revient à prendre le résidu d'une régression linéaire
par $\X$, on enlève alors toute la corrélation linéaire avec $\X$. Si $\lambda$
est très grand alors $\obP$ tend vers la matrice identité. Dans ce cas, le
calcul de $\hat{\U} \hat{\V}$ revient à faire une analyse en composante
principale de la matrice $\Y$. Il est donc important de choisir une valeur de
$\lambda$ qui enlève la bonne proportion de corrélation avec les variables
explicatives $\X$. Nous expliquons dans la partie [[sec:hyperparametre]] plus en
détaille comment choisir les hyperparamètres.

L'estimation des paramètres régularisé en norme $\L_{2}$ est justifié par le
théorème suivant
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambda$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, défini un point de
minimum global de la fonction objective $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $ \hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$ qui soit un
minimum global de la fonction $\Lridge$. Commençons par remarquer que la
fonction $\Lridge$ est convexe le long de la variable $\B$ , on peut donc
trouver le point de minimum global en annulant la dérivé de $\Lridge$ par
rapport à $\B$
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambda \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V).
\end{equation}
Il suffit maintenant de minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeur singulière de $\X$ tel que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T}
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$.L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\matr{B} \matr{Q}^{T} (\Y - \U \V^{T})} + 
\frac{1}{2} \lambda \norm{\matr{C} \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
où $\matr{C}$ est une matrice de taille $\Xcol \times \Xrow$ remplie de zéro
sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambda}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\matr{B}$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \frac{\lambda}{\lambda + \sigma_{1}^{2}}, ..., 
\frac{\lambda}{\lambda + \sigma_{d}^{2}}, 
1, ..., 1 \right\}.
\end{equation*}
Nous pouvons enfin factoriser $\mathcal{L}^{'}$ de sorte que 
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\matr{D} \matr{Q}^{T} (\Y - \U \V^{T})}
\end{equation*}
où $\matr{D}$ est la matrice diagonale contenant les éléments 
\begin{equation*}
\left\{ \sqrt{\frac{\lambda}{\lambda + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambda}{\lambda + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Il s'agit du problème de la meilleur approximation de rang $\K$ de la matrice
\begin{equation*}
\matr{D} \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$
valeurs singulières les plus grandes.
Nous avons bien montré que
\begin{align*}
\hat{\U} \hat{\V} & =  \matr{Q} \matr{D}^{-1} \svd_{\K}( \matr{D} \matr{Q}^{T} \Y ) \\
\hat{\B} & = (\X^{T} \X + \lambda \Id_{d})^{-1} \X^{T} (G - \hat{\U} \hat{\V})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof


**** Estimation des moindres carrées régularisés en norme $L_{1}$  
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle LFMM défini par eqref:eq:model basé sur un problème des moindres carrées
régularisé en norme $L_{1}$. Nous montrerons que cette algorithme converge vers
un point de minimum global du problème d'optimisation.

***** Fonction objectif
Nous proposons la fonction objective suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\matr{A}}_{*}$ la norme nucléaire de la matrice
$\matr{A}$ définie comme la somme de ses valeurs singulières.

Le choix de la norme $L_{1}$ est motivé par le fait que l'on s'attend a ce que
seulement un certaine proportion de variable expliquées soit associées aux
variables explicatives. C'est à dire que seulement une certaine proportion des
lignes de la matrices des effets $\B$ doit être différent de zéro. Or la
régularisation $\L_{1}$ est connue pour produire des estimations parcimonieuses
cite:Tibshirani_1996.

La fonction $\Llasso$ fait aussi intervenir une régularisation sur la matrice
latentes $\W$. Plutôt que d'avoir des contraintes sur le rang de $\W$ nous avons
choisi d'ajouter une régularisation sur sa norme nucléaire. Ainsi la fonction
$\Llasso$ est convexe et nous savons le rang de $\hat{\W}$, un point minium de
$\Llasso$, décroit avec $\gamma$ le paramètre de régularisation devant la norme
nucléaire cite:bach2008consistency. 

***** Algorithme
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par bloque de coordonnées
qui permet d'estimer les paramètres de LFMM qui minimise la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg.

Nous commençons avec nulle tel que : 
\begin{align*}
\W_{t = 0} & = 0 \\
\B_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. calculer $\B_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{lasso}^{2}(\B) =  \frac{1}{2} ||(\Y - \W_{t-1}) - \X \B^T||_{F}^2 + \lambda ||\B||_1
   \end{equation}
2. calculer $\W_{t}$ le point minimum de  
   \begin{equation}
   \mathcal{L}_{lasso}^{1}(\W) = \frac{1}{2} ||(\Y - \X \B_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répété jusqu'a ce que l'algorithme est convergé ou bien que
$t$ est attend le nombre maximum d'itération.

La première étape de l'algorithme consiste à faire une régréssion régularisé en
norme $L_{1}$ de la matrice résiduelle 
\begin{equation}
\matr{E}^{1}_{t} = \Y - \W_{t-1}
\end{equation}
par les variables
explicatives $\X$. Il existe plusieurs algorithme pour estimer les paramètres de
la régression régulariser en norme $L_{1}$ comme par exemple l'algorithme de
descente par coordonnées cite:Friedman_2007. Cependant, si la matrice des
variables explicatives est tel que
\begin{equation}
\X^{T} \X = Id_{n}
\end{equation}
alors d'après cite:Tibshirani_1996 on a 
\begin{equation}
\B_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambda)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s)
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est le paramètre de la
régression linéaire classique données par 
\begin{equation*}
\bar{\B}_{t} = (\X^{T} \X + \lambda \Id_{d})^{-1} \X^{T} (\matr{E}^{1}_{t}).
\end{equation*}
Nous avons choisi d'implémenter ce cas particulier car il est possible de rentre
les variables explicatives indépendantes avant le calcule de l'algorithme présenté
ici. 

La deuxième étape de l'algorithme est un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \B_{t}^{T}
\end{equation}
Cette approximation est données grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T}
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. L'approximation est calculée en remplaçant les valeurs
singulières dans $\matr{S}$ par les valeurs seuillées $\left \{ (s_{j} -
\gamma)_{+} \left \}_{j = 1..\Yrow}$. Cette seuillage à pour effet de réduire le
rang de $\matr{E}^{2}_{t}$ et ramène vers zéro ses valeurs singulières
restantes.

L'algorithme de descente par bloque de coordonnées ne converge pas en général
vers un minimum quand la fonction n'est pas continument différentiable, comme
c'est le cas pour $\Llasso$. Cependant, $\Llasso$ est convexe et la partie non
différentiable est séparable, c'est à dire que l'on peut l'exprimer comme la
somme d'une fonction de $\W$ et $\B$. La parties non séparable est bien
continument différentiable. Ainsi d'après, le théorème 5.2 de cite:Tseng_2001
nous pouvons énoncer le résultat suivant :

#+BEGIN_corollaire
L'algorithme décrit dans la parie [[sec:lasso_algo]] converge vers un point de
minimum global de la fonction $\Llasso$ définie par eqref:eq:optim_lasso_reg.
#+END_corollaire

**** Choice of hyper-parameters
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

LassoLFMM and RidgeLFMM method results depend on two kinds of hyper-parameter,
the number of latent factors and the regularization parameters. We present here
practice solutions to assess these hyper-parameters. 

***** Cross validation
:LOGBOOK:
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:
Cross validation is a classic method to select hyper-parameter in factor
analysis cite:Owen_2009,Bro_2008. The cross validation algorithm we used is
explained in detail in annex. Cross validation procedure can be long to run in
particular on very big data set. Especially since LassoLFMM and RidgeLFMM have
each two hyper-parameters which can be cross-validated. We propose other procedure
to assess hyper-parameters that gave good results in our experiments.

****** COMMENT ANNEX Cross validation algorithm
We present here the cross validation algorithm which can be used to assess
hyper-parameter of LassoLFMM and RidgeLFMM.

We first split the observation output matrix into 
$$
\Y^{(-I)}
$$
and 
$$
\Y^{(I)}
$$ where matrices are respectively compose of 


. We write the training
data matrices $$ \Y^{(-i)}$$ and $$\X^{(-i)}.$$ These matrices are compose of
random lines of the observed output matrix and the primary matrix. Then we
compute (with RidgeLFMM or LassoLFMM) latent factor matrices $$\U^{(-i)}$$ and
$$\V^{(-i)}$$ and the primary effect matrix $$\B^{(-i)}.$$

In a second step we want to compute an estimation of test output matrix
$$\Y^{(i)}$$. However, to predict the output matrix with LFMM model
eqref:eq:model we must estimate the latent score matrix 
$$\U^{(i)}$$ 
for this the test data.
To avoid using test observation for the prediction, we split the test data
by selecting a random set of variables of the observed output matrix which we
note $$\Y^{(i)_{(-j}}$$. 

Then, if we assume that we know the primary effect size
matrix and the latent factor loading matrix for staying variables we write 

\begin{equation}
\label{eq:cvU}
U^{(i)}_{(-j)} = (\Y^{i}_{(-j)} - \X^{(i)}} \B^{(-j)}) \V_{(-j)}^{T}.
\end{equation}

The equation eqref:eq:cvU is given by optimal solution of $L$
ref:eq:optim_no_reg when $V$ and $B$ are fixed.

Finally, we compute the residual error on the test set such as 
\begin{equation}
Err = \norm{ \Y^{i}_{(j)} + \X^{(i)}} \B^{(-i)_{(j)} + \U^{(i)}_{(-j)} \V^{(-i)}
\end{equation}

***** Choice of K using singular value
Methods presented in this paper are very close to the Principal Component
Analysis (PCA), we can seen them as a PCA of $$\Y - \X \B^{T}$$ if we know the
primary effect matrix $\B$. Thus we propose to select the number of latent variables
$\K$ by visualizing the scree plot.

We empirically observed that this method leads to an overestimated number of
factor in the model described in eqref:eq:model since the co-variate would be
considered as a latent variable. However, because the goal of our methods is to
estimate latent variation while protecting variation explained by co-variate $\X$,
we observed that our algorithms was robust to overestimated $\K$.

***** Heuristic to choice of $\lambda$ for RidgeLFMM
:LOGBOOK:
- Note taken on [2017-06-01 jeu. 12:03] \\
  et la on fait le lien avec le model de cate :D
- Note taken on [2017-05-26 Fri 14:45] \\
  voir mon cahier (30/01/2017) et il va falloir normaliser lambda ?? a voir !!C'est chiant car
  j'ai deja lancé les experiences !!
:END:
In our experiments, we remarked that low values of $\lambda$ gave better
results. We try here to give insights to understood this remark.

Firstly we write the oblique projection of model equation eqref:eq:model as follow
\begin{equation}
\sqrt{\obP} \Y = \sqrt{\obP} (\U \V^{T} + \E)+ \sqrt{\obP} X \B^{T}.
\end{equation}
When $\lambda$ is close to zero the term 
\begin{equation}
\label{eq:obPXB}
\sqrt{\obP} X \B^{T}
\end{equation}
tends to zero. Thus if the latent score stored in $\U$ was not correlated with
$\X$ we must chose $\lambda$ equal zero and compute latent factors and primary
effects separately. As identified in cite:wang2015confounder, the complicated
case is when latent variables $\U$ and primary variables $\X$ are correlated. In
this case we want $\lambda$ to be small enough such that eqref:eq:obPXB tends
to zero and the SVD in ref:eq:RidgeLfmmEstomatorC to extract only the
latent variables. But if $\lambda$ is to close to zero the latent variables
should be hard to estimate with SVD in particular if there are highly correlated
with $\X$ and the number of output variables correlated with X is high.

We observed that for a centered and normalized output and primary matrices $\Y$
and $\X$, $\lambda = \frac{1}{\Yrow} 10^{-5}$ provided good results in our
experiments.

****** COMMENT cate model
In the article of \MethodCate method cite:wang2015confounder, authors propose to
explicitly model the relationship between the factor score matrix $\U$ and the
primary variables matrix $\X$. They assume that there is a linear relationship
between $\U$ and $\X$ such as 
\begin{equation}
\label{eq:CorUX}
\U = \X \matr{\alpha}^{T} + \matr{W},
\end{equation}
where
$\W$ is a $\Urow \times \K$ residual error matrix independent of $\X$ and $\E$
and $matr{\alpha}$ $\Xcol \times \Ucol$ characterizes the linear relationship
between $\U$ and $\X$. If $\matr{\alpha}$ is null, there is no problem of
confounding and $\U$, $\V$ and $\X$ can be estimated separately.  

***** Heuristic to choice of $\gamma$ for LassoLFMM
This hyper-parameter impact the rank of the $C$ matrix. To assess the gamma
value we compute singular values of $\Y$ $(\sigma_1, ..., \sigma_{\Yrow})$. Then
we set
$$
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2} 
$$
for $K$ the chosen number of latent factors. In our experiments, we observed
that for such computed $\gamma$ the rank of $\C$ returned by lasso algorithm was
$K$.


***** Heuristic to choice of $\lambda$ for LassoLFMM
:LOGBOOK:
- Note taken on [2017-06-13 Mar 15:21] \\
  changer dans le papier et dans le code + introduire la svd soft dans le papier !!
- Note taken on [2017-06-13 Mar 15:20] \\
  ce qui est implementé c'est reg de G - C avec la svd du couo il faut que je
  commence par la svd pas par la reg linear !!!
:END:
This hyper-parameter impact the number of line set to zero in $B$. We know that
only a part of observe variable $G_j$ are correlated with the variable $X$. So
we can interpret the proportion on non zero line in $B$ as the proportion of
variables which correlate with $X$. To find the lambda which correspond to the
proportion we propose an heuristic based on a regularization path of lambda
value inspired by cite:friedman10_regul_paths_gener_linear_model. 

We start with the smallest value of $\lambda$ such that the entire vector $$
\hat{\B} = \mathrm{argmin} \norm{(\Y - \C_{t = 1}) - \X \B^{T}} + \lambda |B|$$ equal
zero, here $$\Y - \C_{t = 1}$$ is residual of the singular value shrinkage
operator. This is the result of the lasso algorithm first step explain in
section [[sec:lasso_algo]].

Then we construct a sequence of m values of $\lambda$ decreasing from
$\lambda_{\mathrm{max}}$ to $\lambda_{\mathrm{min}}$ on the log scale. Typical
values are \epsilon = 0.001 and K = 100. The algorithm is run for decreasing
value of this sequence. Each time the algorithm converges for a $\lambda$ we
compute the number of non zero line in the computed $\B$ and stop if the
interested proportion of non zero in $\B$ is reached. Otherwise we continue with
the following value of $\lambda$ is the sequence.

**** Hypothesis testing
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Until now, we only presented how to estimate latent factor and primary effect
matrices. However, the purpose which motivate the estimation of latent factor by
considering the primary variable is the detection of observed output variables
associated with the variable of interest. We propose here to use latent factor
score matrix $\U$ as co-variables of a linear model.

***** Linear model with latent factor score
:LOGBOOK:
- Note taken on [2017-05-26 Fri 15:35] \\
  faut que je choississe les notations mieux que ca, je m'enmmèle la ...
:END:

After computing latent factors score matrices $\U$ with the lasso or ridge
algorithm, we use them as co-variables with $\X$ in a linear model. For each
observed output $\Y_{j}$ we have
\begin{equation}
\Y_{j} =  \U \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{\epsilon_{j}}
\end{equation}
where $\matr{\epsilon_{j}}$ is a Gaussian error with mean zero.
Then, we can compute the p-value to test the null hypothesis 
$$
\beta_j = 0.
$$


***** Hypothesis calibration
:LOGBOOK:
- Note taken on [2017-06-01 jeu. 14:45] \\
  Voir dans cite:gerard2017unifying la parti sur la calibration !
:END:

Even with latent factors correction we can observed not calibrated p-value. This
can be due to presence of not interested but small effects, correlation between
observations or remaining unobserved variables cite:Efron_2004. 

In true data analysis we expect that a small proportion of output variables will
be associated with the primary variables (not more than $1 \%$). Thus we used
empirical calibration for the variance and the mean of statistical test. In
particular, as in cite:wang2015confounder,gerard2017unifying, we used the median
and the mad as robust estimators of the mean and standard deviation of
statistical test under the null hypothesis.

*** Expériences                                                  :noexport:
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
**** Méthodes comparées
<<sec:similar_method>>
***** lm and lm + pca
We comparared results of our method to two well known method the linear model
and the linear model with PCA scores. 
***** cate

***** sva
***** famt
**** Simulation et vrai jeux de données

***** Generative model simulation

We used equation to generate generative model dataset. The latent factor
scores and loadings $U$ and $V$ were generated using a multivariate gaussian
distribution with a zero mean and a $K$ identity matrix for the covariance
matrix where is the number of latent factor. The error matrix $E$ was
generated using a multivariate gaussian distribution with a zero mean and a
$L$ identity matrix for the covariance matrix where $L$ is the number of
variables. The co-variable $X$ was generated with a normal distribution with
the mean equal to zero and the standard deviation equal to one such that the
Pearson linear correlation between $X$ and $U_1$ the first latent score
matrix equal to $c$.

***** Real data example
In this section we present the real data we used to compare lasso LFMM, ridge
LFMM with similar methods presented in section [[sec:similar_method]]. To evaluate
the utility of our methods on several situation we select study where correction
for confounding variables is an important step. We realized genome wide
association study (GWAS), an genome-wide association study (EWAS) and an
ecological association study (EAS). Before running algorithm $\G$ and $\X$
matrix was centered and normalized with standard deviation for all the study. We
now describe preprocessing step for each study.

****** Association study of DNA methylation with rheumatoid arthritis (EWAS)
For the EWAS we chose data from a recent association study of DNA methylation with
rheumatoid arthritis (RA) cite:Liu_2013. We retrieve the RA data from Gene
Expression Omnibus (GEO) database (accession number GSE42861). Following
cite:Zou_2014 we filtered out site if its average probe $\beta$ value was above
0.8 are below 0.2. We finally obtain $n = 689$ and $L = 162038$.

#+BEGIN_SRC R :session *ssh krakenator*
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/GSE42861/G.rds")
  dim(G)
#+END_SRC

#+RESULTS:
: [1]    689 162038

For this data set confounding variables (batch effect, age, gender, smoking
status, cell-type composition) are known but we did not use them in methods.
Thus, we can compare methods output with output of method considering explicitly
these variables cite:Rahmani_2016,Zou_2014.

****** Association study of genetic variants with Celiac disease (GWAS)
For the GWAS we chose data from an association study of SNPs with Celiac disease
citep:dubois2010multiple. Before running method we apply classic preprossessing
step with the software Plink cite:Purcell_2007. Firstly, we keep only individual
and SNPs with a proportion of missing value inferior to $5\%$. Then, we filter
out variants with minor allele frequency below $0.05$ and Hardy-Weinberg
equilibrium exact test \pvalue below $1e-10$. After that we filter out
individuals which have identity-by-descent proportion (first by pairs) superior
to $0.08$. Finally, we perform an linkage disequilibrium pruning to obtain SNPs
which are not correlated. The final dataset was of size $n = $ and $L = $.

#+BEGIN_SRC R :session *ssh krakenator*
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)
#+END_SRC

#+RESULTS:
#+begin_example
[1] 15155 94497
#+end_example

We also impute missing value with the sowtware 

****** Étude d'association des variants génétique avec un gradient climatique (EAS)
******* Preprocessing des données
Pour cette étude nous avons choisi d'utiliser les données 1000 genome. Après les
étapes de preprocessing présenter dans la section..., les individus metisse ont
été exclu. En effet pour une étude d'association à l'environement il n'est pas
pertinent de travailler avec individu issu du metissage de plusieurs
populations. Pour cette étude nous ne gardons que les individus pour lesquels
qui vivent dans leur un milieu naturel depuis plusieurs générations.

#+begin_src R :results output :exports both
  library(MaTheseR)
  G <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/1000GenomesPhase3_QC_norel_prunned_scaled_noNA.rds")
  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds")

  ## keep only indiv in G
  indiv.df <- indiv.df %>%
    dplyr::filter(sample %in% rownames(G))

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW")))
  indiv.df

  ## remove indiv
  G <- G[indiv.df$sample,]
  dim(G)

  ## filter sd, there are snps without variance !!
  sds <- apply(G, 2, sd)
  quantile(sds, 0.000001)
  G <- preprocessing_filter_sd(G, 0.0)
  dim(G)

  ## scale G
  G <- scale(G)
  anyNA(G)

  saveRDS(G, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds")
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
#+end_src

#+RESULTS:
#+begin_example
  > indiv.df
  # A tibble: 670 x 4
      sample   pop super_pop gender
       <chr> <chr>     <chr>  <chr>
   1 HG01527   IBS       EUR   male
   2 HG01531   IBS       EUR female
   3 HG01583   PJL       SAS   male
   4 HG01586   PJL       SAS   male
   5 HG01589   PJL       SAS   male
   6 HG01593   PJL       SAS female
   7 HG01625   IBS       EUR   male
   8 HG01628   IBS       EUR female
   9 HG01630   IBS       EUR   male
  10 HG01679   IBS       EUR female
  # ... with 660 more rows
  > 
  > ## remove indiv
  > G <- G[indiv.df$sample,]
  > dim(G)
  [1]    670 342478
  > 
  > ## filter sd, there are snps without variance !!
  > sds <- apply(G, 2, sd)
  > quantile(sds, 0.000001)
  0.0001% 
        0 
  > G <- preprocessing_filter_sd(G, 0.0)
  proportion of removed loci = 5.83979116906779e-06
  > dim(G)
  [1]    670 342476
  > 
  > ## scale G
  > G <- scale(G)
  > anyNA(G)
  [1] FALSE
  > 
#+end_example

******* DONE Calcul du gradient climatique
CLOSED: [2017-06-27 mar. 17:56]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+begin_src R :results output :exports both
  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df

  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "CDX",]$citie = "China"
  indiv.df[indiv.df$pop == "ACB",]$citie = "Barbados"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  library(leaflet)
  m <- leaflet() %>%
    addTiles() %>%  # Add default OpenStreetMap map tiles
    addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  m  # Print the map


  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save 
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS_indiv.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
  >   dim(X.eas)
  [1] 670   1

#+end_example

**** Description des expériences
***** STARTED Comparaisons numériques sur des simulations
:LOGBOOK:
- State "STARTED"    from "RUNNING"    [2017-07-11 mar. 10:26]
- Note taken on [2017-07-06 jeu. 17:52] \\
  sinon les resultats sont top :D
- Note taken on [2017-07-06 jeu. 17:50] \\
  je suis pas sur que c'est le dernier lfmm ridge .... Il faut que je trouve un
  moyen dire quelle version est installé sur krakenator !! avec les commit peut
  être a voir !!!
- State "RUNNING"    from "TODO"       [2017-07-06 jeu. 11:33]
- Note taken on [2017-07-05 mer. 18:11] \\
  j'ai lancé avec le lasso c'est pas mal du tout !! J'ai elevé l'oracle, je sais
  pas pk il merde... le lasso merde quand il y 20% d'outlier mais c'est normal je
  lui ai pas mis le bon nombre de non zero !! :D
- Note taken on [2017-07-03 lun. 16:13] \\
  il faudra le relancer avec un oracle qui marche bien !!
- State "TODO"       from "RUNNING"    [2017-07-03 lun. 16:13]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 18:05]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:
Afin de valider la méthodes et son implémentation nous avons comparé ridgeLFMM
et lassoLFMM aux autres méthodes de la littérature sur des simulations
générative. 

#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/Y_sample_p5e4_n919.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  pl <- qplot(seq_along(var), var)
  pl
  save_plot_png(pl, "file42874c17dae9.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/file42874c17dae9.png]]
#+begin_example
> save_plot_png(pl)
[[./OUTPUT/Rplots/file42874c17dae9.png]]
#+end_example

#+begin_src R 
  library(MaTheseR)

  ## param
  K.method <- 5
  nb.cluster <- 8
  rep.nb.sampler <- 5

  ## sampler
  s <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  s$rho.B <- 3.0
  sampler.env <- s$load.env
  samplers <-  s * param(prop.outlier = c(0.01, 0.05, 0.1, 0.15), rho.c = c(0.1, 0.3, 0.5, 0.8))

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.K = 100, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param() +
    m.oracle * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = rep.nb.sampler,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_fdr,
               sampler.env = sampler.env)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "validation_numerique.rds")

  ## plot auc
  toplot <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+begin_example
  > save_plot_png(pl, "validation_numerique_auc.png")
  [[./OUTPUT/Rplots/validation_numerique_auc.png]]
  > pll <- plot_gif_boxplot(toplot)
  > save_plot_png(pll, "validation_numerique_gif.png")
  [[./OUTPUT/Rplots/validation_numerique_gif.png]]
#+end_example

****** anova

****** plot all
***** TODO Influence de lambda sur les estimations
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 13:53] \\
  ca va faire des sup mat. C'est pour justifier le choix de lambda petit ! deux
  graphe: err X prop outlier et err X angle
- State "TODO"       from              [2017-06-29 jeu. 13:48]
:END:
***** TODO Influence des valeurs manquantes sur l'estimation des variables latentes
:LOGBOOK:
- State "TODO"       from              [2017-06-29 jeu. 13:47]
- State "TODO"       from              [2017-06-29 jeu. 13:45]
:END:
***** TODO Influence des hyper paramètres
:LOGBOOK:
- Note taken on [2017-07-10 lun. 09:12] \\
  Il faut que je montre comment les estimateur évolue en fonction de K, lambda et
  gamma. Montrer que la cross validation marche aussi !
- State "TODO"       from              [2017-07-10 lun. 09:12]
:END:
***** STARTED EAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-27 mar. 12:06]
:END:
****** DONE Scree plot du 1000 genome pour EAS
CLOSED: [2017-07-11 mar. 12:00]
:LOGBOOK:
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = NULL, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param()

  ## expr
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr)

  pl <- ExpRplot_sing_values(expr) + 
  coord_cartesian(xlim = c(1,100))

  save_plot_png(pl, "EAS_sree_plot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/EAS_sree_plot.png]]


****** DONE Validation croisée du modèle lfmmRidge sur 1000genome
CLOSED: [2017-07-11 mar. 14:36]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e8) / n
  nb.cluster <- 2
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,4,5,10,15))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "eas_CV_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "eas_CV_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda.png]]
[[./OUTPUT/Rplots/eas_CV_K.png]]

****** STARTED Étude du jeu de données
:LOGBOOK:
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 7
  nb.cluster <- 2
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_EAS.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/X_EAS.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EAS_all.rds")


#+end_src

******* Charger l'experience
#+BEGIN_SRC R
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EAS_all.rds")
#+END_SRC
******* Que donne la calibration ?
#+BEGIN_SRC R
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS:
#+begin_example
  # A tibble: 7 x 3
       method       mad     median
        <chr>     <dbl>      <dbl>
  1      cate 1.1636647 0.02952085
  2      famt 0.7583801 0.54186725
  3 lassoLFMM 0.9976638 0.01602369
  4        lm 2.1461003 0.57581267
  5     PCAlm 0.9873353 0.01161204
  6 ridgeLFMM 1.1645450 0.03903020
  7       sva 0.7385787 0.53293170
#+end_example

******* Les qqplots ?
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
  pll
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots.png]]
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

******* Le top 15
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(15)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_top_inter.png]]

******* Contrôle du FDR à $0.01$
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

******* Venn diagram
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")


  ## see common snps
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- sets[2:5]
  candidates.snps.df <- toplot %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  snps <- unique(candidates.snps.df$colname)
  snps
  ## annotation
  require(biomaRt)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att <- c("p_value", "ensembl_mart_snp")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]

******* TODO Annotation
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:
#+BEGIN_SRC R
  require(biomaRt)

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM")) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  att

  toplot <- toplot %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db, att)

  toplot %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()
#+END_SRC

******* TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src

***** STARTED GWAS
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
****** STARTED SNPs détecté par d'autre analyse
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R :results output :exports both :session *ssh krakenator*
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")


  ## join by marker_ID
  celiac.outlier <- celiac$map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", nrow(celiac.outlier), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac$map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Le chargement a nécessité le package : bigmemory
Le chargement a nécessité le package : bigmemory.sri

Attachement du package : ‘bigmemory.sri’

The following object is masked from ‘package:testthat’:

    describe

Le chargement a nécessité le package : bigstatsr
Joining, by = "marker.ID"
nb of candidates: 60
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

*Candidates for G_clumped and test*:
#+begin_src R :results output :exports both
  library(ThesisRpackage)
  dat <- Article3_Celiac_sampler(clumped = FALSE) %>%
    sampl()

  snps.name <- colnames(dat$G)[dat$outlier]
  snps.name
  length(snps.name)


  ## for clumped dataset
  rm(dat)
  gc()
  G <- readRDS('~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds')
  candidates.clumped <- which(colnames(G) %in% snps.name)
  length(candidates.clumped)
  colnames(G)[candidates.clumped]
  saveRDS(candidates.clumped, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates_clumped.rds")
#+end_src

#+RESULTS:
#+begin_example
  > snps.name
   [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
   [6] "rs859637"   "rs2157453"  "rs2816316"  "rs296547"   "rs13003464"
  [11] "rs10188217" "rs13015714" "rs917997"   "rs13010713" "rs7574865" 
  [16] "rs4675374"  "rs13098911" "rs6441961"  "rs17810546" "rs10936599"
  [21] "rs1464510"  "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
  [26] "rs2474619"  "rs10806425" "rs531930"   "rs802734"   "rs2327832" 
  [31] "rs1738074"  "rs212402"   "rs212388"   "rs6974491"  "rs9792269" 
  [36] "rs975730"   "rs1953126"  "rs1250552"  "rs10876993" "rs653178"  
  [41] "rs2762051"  "rs1958589"  "rs4899260"  "rs12928822" "rs2074404" 
  [46] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428" 
  > length(snps.name)
  [1] 49
  > length(candidates.clumped)
  [1] 10
  > colnames(G)[candidates.clumped]
   [1] "rs10903122" "rs859637"   "rs13010713" "rs1464510"  "rs1020388" 
   [6] "rs1738074"  "rs653178"   "rs1958589"  "rs1893217"  "rs157640" 
#+end_example
****** STARTED Scree plot
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:
#+begin_src R :results output :exports both
  library(ThesisRpackage)

  ## we keep only disease.state
  X <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  head(X)

  s <- TrueSampler(G.file = "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                   X.file = X,
                   outlier.file = NULL,
                   n = NULL,
                   L = NULL)
  expr <- PCAExperiment(s = s,
                        description = "celiac clumped PCA")
  expr <- runExperiment(expr)
  dumpExperiment(expr)
#+end_src

#+begin_src R :results output graphics :file Rplots/celiac_pca.png :exports both :width 600 :height 400 
  expr <- retrieveExperiment(124)
  expr$description
  variances <- expr$res.df$sdev / sum(expr$res.df$sdev)
  ## plot
  pl <- qplot(x = seq_along(variances), y = variances, geom='line') +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  pl
#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]

On prend K = 9 variables lattentes.

****** TODO Validation croisée avec lfmmRidge
:LOGBOOK:
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e5) / n
  nb.cluster <- 1
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,3,7,10,15))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_K.png")
#+end_src
****** STARTED Étude du jeu de données 
:LOGBOOK:
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:

#+begin_src R
  library(MaTheseR)
  library(MatrixFactorizationR)
  library(matter)

  ## param
  K.method <- 9
  lambda <- 1e-5
  nozero.prop <- 0.005
  nb.cluster <- 4

  ## mask
  col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## methods
  methods <- list()
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method,
                                  col.mask = col.mask,
                                  inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds",
                                  inter.res.file = "./OUTPUT/Expr/celiac_inter_ridgelfmm.rds")
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6,
                              col.mask = col.mask,
                              inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds",
                              inter.res.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds"
                              )
  methods$m.lm <- method_lm(col.mask = col.mask,
                            inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lm.rds",
                            inter.res.file = "./OUTPUT/Expr/celiac_inter_lm.rds")
  m.pca <- method_PCAlm(K = K.method,
                        col.mask = col.mask,
                        inter.res.saving.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds",
                        inter.res.file = "./OUTPUT/Expr/celiac_inter_lassolfmm.rds"
                        )
  m.cate <- method_cate(K = K.method,
                        )


  run_celiac <- function(m) {
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- LfmmMatterDat(Y, X, outlier)

    out.file <- paste0("celiac_df_", m$name, ".rds")
    out.file.path <- paste0("./OUTPUT/Expr/", out.file)
    if (file.exists(out.file.path)) {
      df <- readRDS(out.file.path)
    } else {
      message("run method")
      cl <- parallel::makeCluster(nb.cluster, outfile = "")
      doParallel::registerDoParallel(cl)
      m <- ExpRmouline(m, dat)
      doParallel::stopImplicitCluster()
      parallel::stopCluster(cl)
      df <- ExpRextractor_pvalue1_calibrated(dat, m, 1, 1)
      ## save expr
      message("saving output")
      message(out.file)
      save_expr(df, out.file)
    }
    df
  }

  res.df <- tibble()
  for (m in methods) {
    res.df <- run_celiac(m) %>%
      rbind(res.df)
  }
  save_expr(res.df, "celiac_all_df.rds")
#+end_src

#+RESULTS:
#+begin_example
  > run_celiac(m.lm)
  Empty dat!
  done
  Loading whole celia dataset !
  done
  Running hp
  Such a big matrix ! 
  done
       pvalue   colname index outlier     score rep.sampler rep.method method
  1 0.8476241 rs3934834     1   FALSE -0.192154           1          1     lm
    method.K method.lambda
  1       NA            NA
  saving output
  celiac_df_lm.rds
  Expr save in ./OUTPUT/Expr/celiac_df_lm.rds
  Warning message:
  executing %dopar% sequentially: no parallel backend registered 
#+end_example

***** DONE EWAS
CLOSED: [2017-07-11 mar. 11:45]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-07-11 mar. 11:45]
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- State "TODO"       from              [2017-06-29 jeu. 09:22]
:END:
****** Sites candidats detectés dans d'autres études
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
****** DONE Scree plot 
CLOSED: [2017-06-29 jeu. 09:42]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:
#+begin_src R  
 library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"

  ## samplers
  samplers <- ExpRsampler_trueData(Y = Y, X = NULL, outlier = NULL) * param()

  ## methods
  methods <- method_PCA(scale = FALSE) * param()

  ## exp r
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               rep.nb.method = 1,
               methods = methods,
               preprocessors = NULL,
               extractor = ExpRextractor_sing_values)
  expr <- ExpRmouline(expr)

  save_expr(expr)

  pl <- ExpRplot_sing_values(expr) + 
    coord_cartesian(xlim = c(1,300))

  save_plot_png(pl, "scree_plot_AT.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/scree_plot_AT.png]]
#+begin_example
  > save_plot_png(pl, "scree_plot_AT.png")
  [[./OUTPUT/Rplots/scree_plot_AT.png]]
#+end_example

****** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-07-03 lun. 16:18]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                                   X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10) / n
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,25, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

****** DONE Étude du jeu de données
CLOSED: [2017-07-11 mar. 11:45]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 25
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.K = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")


#+end_src

******* Charger l'expérience et les candidats
#+BEGIN_SRC R
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+END_SRC
******* Que donne la calibration ?
#+BEGIN_SRC R
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS:
#+begin_example
  # A tibble: 7 x 3
       method      mad        median
        <chr>    <dbl>         <dbl>
  1      cate 1.220559  0.0143364030
  2      famt 5.798501  3.9801590213
  3 lassoLFMM 1.138814 -0.0017840118
  4        lm 4.212716  0.0453431462
  5     PCAlm 1.135042  0.0002846393
  6 ridgeLFMM 1.193740  0.0135590474
  7       sva 4.003476  2.8316228410
#+end_example

******* Les qqplots ?
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EWAS_qqplots2.png]]
[[./OUTPUT/Rplots/EWAS_qqplots.png]]

******* Le top 15
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(15)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+begin_example
# A tibble: 7 x 2
     method power
      <chr> <dbl>
1      cate     1
2      famt     0
3 lassoLFMM     1
4        lm     0
5     PCAlm     1
6 ridgeLFMM     1
7       sva     0
#+end_example

******* Contrôle du FDR à $0.01$
#+BEGIN_SRC R
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 6 x 2
     method power
      <chr> <dbl>
1      cate     1
2      famt     1
3 lassoLFMM     1
4     PCAlm     1
5 ridgeLFMM     1
6       sva     1
#+end_example

******* Venn diagram
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

*** Résultats                                                    :noexport:

*** Discussion                                                   :noexport:
*** Figures et table
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
**** TODO Comparaisons des méthodes
:LOGBOOK:
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:
#+begin_src R
  require(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  ## by prop outlier
  toplot <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(x = prop.outlier)
  h1.gif.pl <- plot_gif(toplot, "proportion of H1")
  h1.auc.pl <- plot_AUC(toplot, "proportion of H1")

  ## by rho.c
  toplot <- expr$df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(x = rho.c)
  rho.gif.pl <- plot_gif(toplot, "rho")
  rho.auc.pl <- plot_AUC(toplot, "rho")

  pl <- cowplot::plot_grid(h1.auc.pl,
                           h1.gif.pl,
                           rho.auc.pl,
                           rho.gif.pl,
                           ncol = 2, labels = c("A", "B", "C", "D"))
  save_plot_png(pl, filename = "method_comp.png")
#+end_src

[[./OUTPUT/Rplots/method_comp.png]]

**** GWAS
**** TODO EWAS
:LOGBOOK:
- State "TODO"       from              [2017-07-10 lun. 15:49]
:END:

#+BEGIN_SRC R
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "ewas_results_venn.png")
#+END_SRC

[[./OUTPUT/Rplots/ewas_results_venn.png]]

**** EAS
*** Références

bibliographystyle:unsrt
bibliography:../biblio.bib

* Conclusion 


* COMMENT perspectives
:LOGBOOK:
- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:


