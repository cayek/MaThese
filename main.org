# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE: Méthodes de factorisation matricielle pour la génomique des populations et les tests d'association
#+AUTHOR:      Kevin Caye

#+LANGUAGE: fr
#+STARTUP: overview indent inlineimages logdrawer
#+OPTIONS: H:6 author:nil email:nil creator:nil timestamp:nil skip:nil toc:t ^:nil
#+TAGS: noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) RUNNING(r!) DEBUG(g!) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)


#+LaTeX_CLASS: these
# #+LaTeX_CLASS: article
#+LATEX_HEADER: \input{notations.tex}

#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler

#+PROPERTY: header-args    :exports none

#+latex_header: \usepackage{amsthm, bm}
#+latex_header: \newtheorem{theorem}{Théoreme}
#+latex_header: \newtheorem{corollaire}{Corollaire}
#+latex_header: \newtheorem{proposition}{Proposition}
#+latex_header: \renewcommand{\proofname}{Preuve}

#  LocalWords:  methylation polymorphism nucleotide Frobenius invertible SNP
#  LocalWords:  preprocessing dataset RidgeLFMM LassoLFMM hyperparamètre

# #+BEGIN_QUOTE
# In Code we trust, all others bring data.
# –William Edwards Deming (1900-1993).
# #+END_QUOTE

#+BEGIN_EXPORT latex
%% to review
\baselineskip 0.8cm
#+END_EXPORT

* Workenv                                                          :noexport:
** R
#+BEGIN_SRC R
  ## CRAN
  install.packages("tidyverse")
  install.packages("extrafont")
  install.packages("Devtools")
  install.packages("testthat")
  install.packages("foreach")
  install.packages("RSpectra")
  install.packages("doParallel")
  install.packages("DescTools")
  install.packages("roxygen2")
  install.packages("VennDiagram")
  install.packages("ggmap")
  install.packages("rvest")
  install.packages("raster")
  install.packages("latex2exp")
  install.packages('printr')
  install.packages("units", configure.args = "--with-udunits2-include=/usr/include/udunits2")
  install.packages("ggforce")
  install.packages("scatterpie")
  install.packages("sp")
  install.packages("raster")
  install.packages("rgeos")
  install.packages("rasterVis")
  install.packages("fields")

  ## bioconductor
  source("https://bioconductor.org/biocLite.R")
  biocLite("matter", ask = FALSE)
  biocLite("qvalue",ask = FALSE)
  biocLite("biomaRt",ask = FALSE)
  biocLite("LEA",ask = FALSE)
  biocLite("impute",ask = FALSE)
  biocLite("sva",ask = FALSE)

  install.packages("cate")
  install.packages("FAMT")
  install.packages("xgboost")
  install.packages("knitr")


  ## github
  devtools::install_github("privefl/bigsnpr")

  ## my pkgs
  devtools::install_github("cayek/MaTheseR/Rpackage")
  devtools::install_github("cayek/Thesis/ThesisRpackage")
  devtools::install_github("bcm-uga/tess3_encho_sen")
  devtools::install_github("bcm-uga/lfmm")
#+END_SRC
** Ligne de commande
*** ms
*** plink
*** vep
#+NAME: code:install_vep
#+CAPTION: Dépend de 
#+begin_src shell
  cd BiocompSoftware
  git clone https://github.com/Ensembl/ensembl-vep.git
  cd ensembl-vep
  perl INSTALL.pl
#+end_src

*RMK :* J'ai ddl les cache
- =47 : homo_sapiens_vep_89_GRCh38.tar.gz=

** python
* Introduction
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-07-20 Thu 17:52]
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:11] \\
  une remarque en passant: l'intro est pour moi la place pour définir le contexte
  général, les mots du titre, la pbq et le plan qui y répond ! 
  Ce n'est pas la que je fait un état de l'art. L'état de l'art est dans les deux
  grosse partis ! C'est deux grosse parties sont indépendantes l'une de l'autre !
  Donc si il y a des répétition, tant pis !!
- Note taken on [2017-06-09 ven. 16:37] \\
  Il faut que j'ai travailler sur deux méthodes ! Les deux répondes à deux
  problématique différentes et le tout s'inscrit dans un besoin t'outils adapté à
  la génétique du 21ieme siecle !!
- Note taken on [2017-06-09 Ven 11:44] \\
  dans l'intro il faut que je motive la problématique !! et le plan répond a cette
  problématique.
:END:
** Contexte
:LOGBOOK:
- Note taken on [2017-06-09 Ven 11:47] \\
  c'est un context de fouille de données trop grosse !! Il faut amener de
  l'information à un niveau inteligible.
- Note taken on [2017-06-05 Mon 10:38] \\
  Ca peut etre cool de replacer le context historique en partant de la niasance
  des stats (fisher etc) et de faire le parallele avec maintenant pour on a
  suffisament de données pour se rendre compte que nos test d'hypothèse sont faux
  :D et la on fait le lien avec les tests d'hypothèe multiple....
:END:
*** COMMENT 
Cette dernière décennie a été marquée par une accumulation des données dans tous les
domaines de la sciences. Cette accumulation de données est une aubaine pour les
scientifiques. Cependant, que faire d'autant de données et comment en tirer
l'information qui permettrait de mieux comprendre le monde qui nous entoure ? Il
s'agit là d'un défi majeur pour les statistiques cite:slides_sfds2015_saporta. 

Les grandes données posent plusieurs problèmes. En effet, si l'on est capable d'obtenir
des données rapidement, on veut pouvoir les analyser rapidement. Cependant de
nombreux modèle statistiques classiques ne passent pas l'échelle des grands jeux
de données. Il est donc nécessaire de repenser les modèles et algorithmes afin
de les adapter au nous volumes des données. 
... parler de l'inversement du processus d'aquisition des données .. cf
seminaire Bosson



Dans le cadre de cette thèse nous nous sommes intéressé a développer des méthodes
statistiques utiles à deux problématique scientifiques. Le premier est l'estimation
de la structure de population à partir de données génomique. Le deuxièmes est les
problèmes des test d'association multiple. Toutes les méthodes statistiques
developper lors de cette thèse repose sur la factorisation de matrice. Nous
allons maintenant introduire plus en détails les problématiques ainsi que la
factorisation de matrice en statistique.

** La génomique des populations
:LOGBOOK:
- Note taken on [2017-06-07 Mer 14:42] \\
  - analyse de la structure de variance covariance: PCA
  - analyse de la structure de population: structure, snmf, etc

 En faite je ne vais def ca ici ! c'est juste le genet des pops ici !!
  - ewas: refactor
  - gwas: gemma etc
  - eas: ...
:END:
** Test d'association
:LOGBOOK:
- Note taken on [2017-08-22 mar. 09:56] \\
  parler des méthode classsique pour controlé l hétérogénéité en stat (experience
  jardin commum, vidéo les stat expliqué a mon chat :D)
:END:
** La factorisation de matrice en statistique
:LOGBOOK:
- Note taken on [2017-07-18 Tue 08:55] \\
  Kenneth lange, factorisation de matrice = avenir des stat ! a retrouver !
:END:
** Problématique et objectifs de la thèse
* Inférence des coefficients de métissage à l'aide de données géographiques
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:07] \\
  Non je ne vais pas avoir le temps, je vais traduire l'article, étoffer un peu
  et basta. Je mettrais en perspective le traitement des données manquantes pour
  tess3r et sur un très gros dataset si j'ai le temps (1001 genome, avec une
  analyse de la population et une association environmental, pour ilustrer les
  deux feature gros dataset et NA)
- Note taken on [2017-06-05 Mon 13:44] \\
  Ce qui serais stylé c'est d'ajouté une cross validation propre pour tess3 :D, et
  de relancer les analyse sur AT, voir pk pas sur les très gros dataset AT :D !!!
  
  On ne toucherais pas à l'autre papier mais on lance sur ce dataset la même
  analyse mais très proprement :D, y compris pour l'étude stat à la fin
  (recalibration propre !)
:END:
** Introduction
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:

A voir utilisation du terme allèle ...

Pas claire ! voir : https://en.wikipedia.org/wiki/Population_stratification
https://www.ncbi.nlm.nih.gov/pubmed/10835412
https://www.ncbi.nlm.nih.gov/pubmed/12930761

Intro duire les données qu'on utilise avec notion de SNPs et locus et allèle
et 
l'ascendance !! les méthode d'estimation de l'acendance !!! on ne parle pas
structure de population


Les individus d'une même population se reproduisent entre eux, se transmettant
ainsi leurs patrimoines génétiques. Quand on observe les génomes d'individus
provenant de plusieurs populations différentes, on remarque des différences dans
les distributions des génotypes au sein des différentes populations. Pour
illustrer cela nous avons pris un jeux de données composé des mesures du
nucléotide pour plusieurs positions de l'ADN chez plusieurs individus humains
venant de populations européenne, africaine et afro-americaine des États Unis
d'Amérique. Les position de l'ADN observée sont choisi car on y a observé deux
variants de nucléotide possible. De plus la fréquence pour le nucleotide le
moins observé dans la population étudié est d'au moins $1 \%$, on nomme cette
variation de l'ADN un SNP pour single nucléotyde polimorphism. Chez l'humain les
SNPs représente $90 \%$ de l'ensemble des variations génétiques Les SNP. La
Figure ref:fig:tess3_intro A montre les fréquences des différentes version du
SNP rs499627 dans des populations européennes, africaines et afro-americaine.
Nous constatons une différence de distribution allélique dans les 3 populations
européenne, africaine et afro-américaine des États Unis d'Amérique.

En pratique la réalité est plus complexe que des populations isolés qui ne se
mélange pas. Le modèle de métissage en génétiques des populations suppose que
les individus observés sont le produit de la reproduction sexué entre des
individus provenant de plusieurs populations que l'on nomme populations
ancestrales. Le terme de population ancestrale fait référence au fait que les
individus métisses sont issu de la rencontre de populations qui dans le passé
était isolé les unes des autres. Connaissant les fréquences de génotype dans les
populations ancestrales il est possible d'estimer pour chaque individu la
proportion de génome observé provenant de chaque population ancestrale, il
s'agit du coefficient de métissage. Par exemple, la Figure ref:fig:tess3_intro B
montre l'estimation des coefficients de métissage d'une population
afro-americaine en supposant que cette population est composée d'individu
métisse venant des populations européennes et africaines. Bien souvent on ne
connait pas les fréquences de génotype dans les populations ancestrales ni même le
nombre de populations ancestrales. Toute la difficulté est alors d'estimer
conjointement avec les coefficients de métissage et les fréquences de génotype
dans les populations ancestrales en ayant choisi le nombre de populations
ancestrales. Nous parlons alors d'estimation de la structure de population.

L'inférence de la structure de population est une étape importante dans l'étude
de données génétique. La structure de population permet de visualiser la
variation provoquée par la stratification en population des données génétiques
qui sont des données volumineuse et multivariées. La stratification en
population ainsi observée fourni des information sur l'histoire et la
l'évolution démographique de l'espèce étudié cite:Li_2008. Par ailleurs, il est
indispensable de détecter la stratification des données génétiques en sous
population avant de réalisé une étude d'associations avec un phénotype, un
gradient environnementale ou encore une maladie cite:marchini2004effects. De
même, il existe de nombreuses application en médecine génétique nécessitant de
connaitre la structure de population comme par exemple le calcule d'un score de
risque génétique pour une maladie cite:Wray_2013.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_intro.pdf.png}
\caption{A) Distribution des allèle du SNP rs499627 dans des populations
  européennes, africaine et afro-américaines. B) Estimation de la proportion de
  génome observé pour chaque individu afro-américain provenant des populations ancestrales
  Africaines et Européenne.}
\label{fig:tess3_intro}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** STARTED Africain Européen et Afro américain 
:LOGBOOK:
- State "STARTED"    from              [2017-09-06 mer. 10:45]
:END:

Tudo pour les piechart : [[https://guangchuangyu.github.io/2016/12/scatterpie-for-plotting-pies-on-ggplot/][here]]
#+NAME: code:tess3_intro
#+CAPTION: Dépend de 
#+begin_src R :results output :exports both
  library("tidyverse")
  library(tess3r)
  library(MaTheseR)

  ## 1000Genome dataset
  dat <- readRDS("./Data/1000Genomes/Phase3/Eu_Af_Afam.chr1.maf.05.rds")
  dim(dat$G)

  expr <- list()
  ## compute Fst
  snmf.res <- sNMFMethod(K = 2) %>% fit(dat)
  expr$G <- snmf.res$G
  expr$Q <- snmf.res$Q
  expr$fst <- ComputeFst(expr$Q, expr$G, 3)

  ## keep info on dataset
  expr$indiv.df <- dat$indiv
  expr$snps.df <- dat$snps.info
  id <- which.max(expr$fst) 
  expr$indiv.df <- expr$indiv.df %>%
    mutate(snps = dat$G[,id])

  save_expr(expr, "tess3_intro.rds")
#+end_src

#+NAME: code:tess3_intro_plot
#+CAPTION: Dépend de [[code:tess3_intro]]
#+begin_src R 
  library("tidyverse")
  library(tess3r)
  library(cowplot)
  library(MaTheseR)
  library(scatterpie)
  MaTheseR.params <- get_MaTheseRparams()
  gtheme <- MaTheseR.params$gtheme


  expr <- readRDS("./OUTPUT/Expr/tess3_intro.rds")

  ## plot freq
  ## get location
  toplot <- expr$indiv.df %>%
    dplyr::distinct(pop) %>%
    mutate(citie = NA)
  toplot[toplot$pop == "LWK",]$citie = "Kenya"
  toplot[toplot$pop == "YRI",]$citie = "Nigeria"
  toplot[toplot$pop == "ASW",]$citie = "New-york"
  toplot[toplot$pop == "TSI",]$citie = "Italia"
  toplot[toplot$pop == "GBR",]$citie = "England"
  toplot <- cbind(toplot, ggmap::geocode(toplot$citie))

  ## frequencie
  id <- which.max(expr$fst)
  expr$snps.df[id,]
  freq.df <- expr$indiv.df %>% group_by(pop) %>%
    dplyr::summarise(freq = mean(snps) / 2)
  toplot <- toplot %>%
    inner_join(freq.df, by = c("pop"))
  toplot <- toplot %>%
    mutate(`allèle T` = freq, `allèle C` = 1 - freq)

  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  map.world <- ggmap::get_map(location = "world")
  pl <- ggplot(toplot, aes(x = lon, y = lat, color = pop)) +
    mapWorld + 
    MaTheseR.params$gtheme +
    scale_size_continuous(guide = FALSE) +
    xlab("Longitude") +
    ylab("Latitude")
  pl.res <- pl + geom_scatterpie(aes(x = lon, y = lat, r = 8), data = toplot, cols = c("allèle T", "allèle C")) +
    guides(fill = guide_legend(title = "SNP rs499627")) +
    scale_fill_manual(values = c("steelblue", "lightgreen")) +
    theme(legend.position="bottom")

  save_plot_png(pl.res, "tess3_intro_freq.png")

  ## barplot
  expr$indiv.df$pop %>% unique()
  Q <- expr$Q[expr$indiv.df$pop == "ASW", ]
  toplot <- data.frame(Q, index = seq_along(Q)) %>% reshape2::melt(id = "index") %>%
    mutate(`Population ancetrale` = factor(variable, labels = c("africaine",
                                                  "européenne")))
  brplot <- ggplot(toplot, aes(x = index, y = value)) +
    geom_bar(stat = "identity", aes(color =`Population ancetrale` , fill = `Population ancetrale`)) +
    xlab("Individus afro-américains") +
    ylab("Coefficient\nde métissage") +
    scale_y_continuous(breaks = c(0.0,0.5,1.0)) +
    gtheme + 
    theme(legend.position="bottom",
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  save_plot_png(brplot, "tess3_intro_barplot.png")

  ## gather plots
  pl <- plot_grid(pl.res, brplot, ncol = 1, labels = c("A", "B"),
                  rel_heights = c(6,4))
  save_plot_MaTheseR(pl, "tess3_intro.pdf.png",
                     height = 0.8 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3_intro_freq.png]]
[[./OUTPUT/Rplots/tess3_intro_barplot.png]]

*** Méthodes d'estimation de la structure de population
:LOGBOOK:
- Note taken on [2017-09-06 mer. 11:57] \\
  Rmk : ici je parle de modèle probabiliste au sens de Kevin p murphy :D
:END:

L'estimation de la structure de population a été largement éduiée et il existe
de nombreuse méthodes qui permète d'estimer à la fois les coéficient de
métissage et les fréquence de génotype dans les population ancestrale. On
distingue deux type d'approche pour l'inférence de la structure de population :
les approches repose sur un modèle probabiliste et les approches fondées sur
l'optimisation une fonction objective.

Parmi les approche reposant sur un modèle probabiliste on compte le logiciel
=structure= introduit par cite:Pritchard2000 à été le premier a proposer
l'estimation de structure de population à partir de données génétique. L'acces à
des données génétype de plus en plus grandes on provoquer l'émergence de
plusieurs algorithmes plus rapides que celui de =structure=. En effet
l'algorithme du logiciel =structure= implémente un algorithme d'echatillonage de
monte carlo pour estimer la distribution a posteriori des coefficient de
metissage et les fréquence de génotype dans les popualtions ancestrale. Cependant
les algorithmes de monte carlo ne passe à l'echelle sur les grand jeux de
donénes génétiques. Les améliorations du logicielle structure repose une
fonction de vraisemblance est définie pour la matrice des coefficients de
métissage et les fréquence de génotype dans les population ancestrale. L'estimation
est effectuée en maximisant la fonction log-vraisemblance. La première
amélioration de l'algorithme =structure= est basée sur un algorithme EM
(Expectation Maximisation) maximisant la fonction de vraisemblance
cite:Tang_2005. Des des algorithmes de vraisemblance plus récents sont
implémentés dans les programmes =admixture= et =fastStructure=
cite:Alexander_2011,Raj_2014.

Dans les approches reposant sur l'optimisation d'un fonction objective, les
coefficients de métissage sont estimés à l'aide de méthodes de moindres carrés
ou d'analyse factorielle. Pour estimer les matrices des coéficients de métissage
et de fréquence des génotypes ancestraux, cite:Engelhardt_2010 a proposé d'utiliser
l'analyse des facteurs parcimonieuse, cite:Frichot_2014 a utilisé des
algorithmes de factorisation de matrice non négative scindés et
cite:Popescu_2014 à utilise l'analyse en composantes principales. Les méthodes
reposant sur des problème d'optimisation permettent de reproduire avec précision
les résultats des approches basé sur une vraisemblance cite:Frichot_2014. En
outre, cette catégorie de méthodes fournissent des approches sont généralement
plus rapides que les méthodes fondé sur un modèle probabiliste.

*** Méthodes d'estimation de la structure dans des population continue spatialement

L'étude réalisé par cite:Novembre_2008 a montré que pour des individus répartis
en population continue spatialement il est possible de prédire la position des
individu a partir de l'étude la structure de population. De nombreuse méthodes
on permis d'améliorer la prédiction de la position géographique des individu à
partir de leur génome cite:Baran_2013,Yang_2012,Bhaskar_2016,Ra_ola_2014. Si la
structure de population permet de prédire la position spatial des individus
alors il est possible d'améliorer l'estimation de la structure de population en
utilisant l'information géographique. Cette idée a été exploité par pour
amméliorer le modèle bayésien de =structure= en incorporant des données les
géographiques à travers la loi de distribution à priori des coefficient de
métissage cite:CHEN_2007,Corander2008. Les algorithmes spatiaux fournissent des
estimations de la structure de population plus robustes que des algorithmes non
spatiaux qui peuvent conduire à des estimations biaisées du nombre de clusters
cite:Durand_2009. Certaines méthodes bayésiennes sont basées sur des algorithmes
de Monte Carlo de chaîne de Markov qui nécessite beaucoup de calcul
cite:FRAN_OIS_2010. Ainsi les méthodes d'estimation de structure de population
continue spatialement sont pas adapté au grand jeux de données. Nous proposons
donc une méthode d'estimation de la structure dans des population continue
spatialement reposant l'optimisation d'une fonction objective.

*** Plan du chapitre

Dans ce chapitre, nous présentons deux nouveaux algorithmes pour l'estimation
des matrices d'ascendance basées sur des données géographiques et génétiques.
Les nouveaux algorithmes résolvent un problème d'optimisation des moindres
carrés, l'un repose sur une optimisation quadratique alterné (AQP pour
alternated quadratic programing), l'autre sur un algorithme des moindres carrés
alternés projetés (APLS pour alternated projected least square). Le terme
alterné dans les deux algorithmes fait référence au fait que l'on alterne une
étape d'optimisation selon la matrice de coefficient de métissage puis la
matrice des fréquences de génotypes ancestraux. Alors que les algorithmes AQP ont un
fondement théorique bien établi par cite:Bertsekas_1997, ce n'est pas le cas des
algorithmes APLS. En utilisant des simulations coalescentes, nous montrons que
les estimations calculées par les algorithmes APLS sont de bonnes approximations
des solutions des algorithmes AQP. En outre, nous montrons que les performances
des algorithmes APLS s'élèvent aux dimensions des ensembles de données modernes.
Ensuite nous Nous discutons de l'application de nos algorithmes aux données des
écotypes européens de {\ it Arabidopsis thaliana}, pour lesquelles des données
géographiques individuelles et géométriques sont disponibles ~ \ citep
{Horton2012}.

** Nouvelles méthodes
Dans cette section, nous présentons deux nouveaux algorithmes pour estimer les
coefficients de métisse individuel et les fréquences de génotypes ancestraux en
supposant $\K$ populations ancestrales. En plus des génotypes, les nouveaux
algorithmes présenté ici nécessitent les coordonnées géographiques de chaque
individu.
*** Matrices $\Q$ et $\G$
Nous considérons une matrice de génotype, $\Y$, enregistrant des données de $n$
individus à des locus polymorphes $p$ pour une espèce ayant une ploidy de $d$,
c'est à dire qui possède un génome composé de $d$ exemplaire de chaque
chromosome. Pour les SNPs autosomiques dans un organisme diploïde, le génotype
au locus $\ell$ est un nombre entier, 0, 1 ou 2, correspondant au nombre
d'allèles de référence observé à ce locus. De même que dans cite:Frichot_2014,
dans nos algorithmes nous utilisons des formes disjonctives pour coder les
génotypes. Par exemple pour un organisme diploïde, le nombre d'allèle observé à
chaque locus $,0,1,2$ est encodée comme $100$, $010$ et $001$. Pour les
organismes de ploidy $d$, il existe $(d + 1)$ génotypes possibles à chaque
locus, et chaque valeur est encodée sous une forme disjonctif unique. 

De la même manière que dans cite:Frichot_2014, si l'on suppose qu'il y a $K$
populations ancestrales, nous cherchons à décomposer la matrice $\Y$ en une
matrice de coefficients de métissage $\Q$, de taille $n \times K$ et une matrice
de fréquences de génotypes dans les $K$ populations ancestrales $G$, de taille $p
\times K$. Nous notons $\Q_{i,k}$ le coefficient de métissage de l'individu $i$
pour la population ancestrale $k$. Nous avons de plus
\begin{equation}
\label{eq:QConst}
\Q \geq 0 \, , \quad \sum_{k=1}^K {\bf Q}_{i,k} = 1 .
\end{equation}
Nous notons $\G_{(d + 1)\ell + j, k}$ la fréquence du génotype $j$ au locus $\ell$
dans la population $k$ et nous avons
\begin{equation}
\label{eq:GConst}
\G \geq 0 \, , \quad \sum_{j=0}^{d} {\bf G}_{(d+1)\ell + j, k} = 1.
\end{equation}
Enfin, nous voulons estimer les matrices $\Q$ et $\G$ en factorisant la matrice
de génotype de la façon suivante
\begin{equation*}
\Y = \Q \G^{T}.
\end{equation*}
Ainsi le problème d'inférence peut être résolu en utilisant les méthodes de
factorization de matrice non négatives avec en plus les contraintes convexe
décrite par les équations ref:eq:QConst et ref:eq:GConst
cite:lee1999learning,Cichocki2009. Dans la suite, nous utiliserons les notations
$\DQ$ et $\DG$ pour représenter les ensembles formé à partir des contraintes sur
$\Q$ et $\G$.
*** Information géographique
L'information géographique est introduite dans le problème de factorisation de
matrice en utilisant des poids entre les individus. Les poids sont utilisés pour
imposer une contrainte de régularité de l'estimation des coefficients de
métissage sur l'espace géographique. En effet, nous souhaitons que des individus
proches dans l'espace géographique aient des coefficients de métissage proche.
Les poids sont définis à partir des coordonnées géographiques des individus que
l'on note $x_{i}$ pour chaque individu $i$. Nous attribuons aux individus
proches dans l'espace un poids plus grand que pour des individus éloignés. Les
poids sont calculés en construisant un graphe complet pondéré entre les
individus. Entre chaque individu $i$ et $j$, nous construisons la matrice des
poids du graphe $\W$ de la manière suivante
\begin{equation}
\label{eq:tess3Graph}
\W_{i,j} = \exp( - {\rm dist}( x_i, x_j )^2/ \sigma^2),
\end{equation}
où la fonction ${\rm dist}( x_i, x_j)$ définie n'importe quelle distance entre
les coordonnées géographique $x_{i}$ et $x_{j}$ des individus d'indice $i$ et $j$. 

Ensuite, nous introduisons la matrice laplacienne associée à la matrice des poids
géographique $\W$. La matrice laplacienne est définie de la manière suivante
\begin{equation}
\label{eq:tess3Laplace}
\Laplacienne = \D - \W,
\end{equation}
où $\D$ est la matrice diagonale tel que 
\begin{equation}
\label{eq:tess3Diag}
\left\{ \D_{i,i} \right\}_{i = 1..n}= \left\{\sum_{j = 1}^n \W_{i,j}\right\}_{i = 1..n}.
\end{equation}
Par le calcul, les auteurs de cite:DengCai2011 ont montré que 
\begin{equation}
\label{eq:tess3Reg}
{\rm Tr} (\Q^{T} \Laplacienne \Q)  = \frac{1}{2} \sum_{i,j = 1}^n  \W_{i,j}  \|   \Q_{i,.}  \Q_{j,.} \|^2.
\end{equation}
Dans notre approche, nous supposons que les individus géographiquement proches
ont plus de chance d'avoir des ancêtres communs que des individus éloigné. Ainsi
nous utilisons le terme défini par l'équation ref:eq:tess3Reg pour régulariser
l'estimateur de la matrice des coefficients de métissage $\Q$.

*** Problèmes d'optimisation des moindres carrés
L'estimation des matrices $\Q$ et $\G$ à partir de la matrice de génotype $\Y$
est réalisé en optimisant la fonction suivante
\begin{equation}
\mathcal{L}(\Q, \G) =   \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} +  \alpha {\rm Tr} (\Q^{T} \Laplacienne \Q), 
\label{eq:tess3LS}
\end{equation}
où la matrice $\Q$ appartient à $\DQ$ l'ensemble définie par les contraintes
ref:eq:QConst et la matrice $\G$ appartient à $\DG$ l'ensemble définie par les
contraintes ref:eq:GConst. La notation $\| \matr{M} \|_{\rm F}$ désigne la norme
de Frobenius de la matrice $\matr{M}$. Le paramètre de régularisation $\alpha$
contrôle la régularité des estimations des coefficients de métissage dans
l'espace géographique. Les grandes valeurs de $\alpha$ impliquent que les
coefficients de métissage ont des valeurs proches pour les personnes
géographiquement proches.

*** Algorithme d'optimisation quadratique alterné (AQP)
Parce que les polyèdres $\DQ$ et $\DG$ sont des ensembles convexes et que la
fonction $\LS$ est convexe par rapport à chaque variable $\Q$ ou $\G$ lorsque
l'autre est fixé, nous pouvons appliquer l'algorithme de descente par bloc de
coordonnées au problème ref:eq:tess3LS présenté à la page 267 de
cite:Bertsekas_1997. L'algorithme de descente par bloque de coordonnées consiste
à progresser dans l'ensemble de définition de la fonction a optimiser en
alternant des étapes d'optimisation selon chacune des coordonnées de la fonction
à optimiser. Cette algorithme permet de converger vers un minimum local du la
fonction à optimiser quand celle ci est convexe et définie du un ensemble
convexe. Le problème d'optimisation selon $\G$ quand $\Q$ est fixé est un
problème d'optimisation quadratique, il en va de même quand on échange les rôles
de $\G$ et $\Q$, c'est pour cela que l'algorithme est dit d'optimisation
quadratique alterné (AQP). L'algorithme APQ commence à partir de valeurs
initiales pour les matrices $\G$ et $\Q$, et alternent deux étapes
d'optimisation. La première étape calcule la matrice $\G$ tandis que $\Q$ est
fixé, et inversement. Nous supposons que $\Q$ est fixé et écrivons $\G$ sous une
forme vectorielle
\begin{equation*} 
g = {\rm vec}(\G) \in \mathbb{R} ^ {K(d +1)p}.
\end{equation*}
La première étape de l'algorithme résout le sous problème d'optimisation
quadratique suivant 
\begin{equation}
\begin{aligned}
\underset{g \in \DG}{\min}  ( -2  v^T_Q \, g + g^T \D_Q g ) ,
\end{aligned}
\label{eq:AQPg}
\end{equation}
où $\D_Q = \Id_{(d + 1) p} \otimes \Q^T \Q$ et $v_Q = {\rm vec} (\Q^T \Y)$. Ici,
$\otimes$ désigne le produit Kronecker et $\Id_{d}$ est la matrice identité de
taille $d$. La structure en bloc de la matrice $\D_Q$ nous permet de
décomposer le sous-problème ref:eq:AQPg en $p$ problèmes de
programmation quadratiques indépendants à $K(d + 1)$ variables.
Nous considérons ensuite que $\G$ est la valeur obtenue après la première
étape de l'algorithme, et écrivons $\Q$ sous une forme vectorielle 
\begin{equation}
q = {\rm vec}(\Q) \in \mathbb{R}^{nK} 
\end{equation}
La deuxième étape résout le sous-problème de programmation quadratique suivant
\begin{equation}
\begin{aligned}
\underset{q \in \DQ}{\min} ( -2 v^T_G \, q + q^T \D_G q ) ,
\end{aligned}
\label{eq:AQPq}
\end{equation}
où $\D_G = \Id_{n} \otimes \G^T \G + \alpha \Laplacienne \otimes \Id_K$ et $v_G
= {\rm vec}(\G^T \Y^T)$. Contrairement au sous-problème ref:eq:AQPg, le
sous-problème ref:eq:AQPq ne peut pas être séparer en plus petits problèmes.
Ainsi, la deuxième étape de l'algorithme AQP implique de résoudre un problème de
programmation quadratique à $nK$ variables qui peut être problématiques pour les
jeux de données avec beaucoup d'individus. Nous alternons ces deux étapes jusque
convergence de l'algorithme AQP en un minimum local de $\LS$. Par ailleurs, nous
pouvons énoncer le résultat de convergence suivant.
#+BEGIN_theorem
<<AQP_theorem>> L'algorithme AQP qui alterne les étapes d'optimisation définis
par ref:eq:AQPg et ref:eq:AQPq converge vers un minimum local de la fonction
$\mathcal{L}$ défini par l'équation ref:eq:tess3LS.
#+END_theorem

#+BEGIN_proof
La fonction $\mathcal{L}$ définie par l'équation ref:eq:tess3LS est convexe par
rapport à $\Q$ quand $\G$ est fixé et inversement. De plus les ensembles
définition $\DQ$ et $\DG$ sont convexe. Alors d'après le corollaire 2 de
cite:Grippo_2000 tout point limite de l'algorithme AQP converge vers un point de
minimum local de la fonction $\mathcal{L}$.
#+END_proof

*** Algorithme des moindres carrés alternés projetés (APLS)
Dans cette partie nous présentons l'algorithme APLS de calcul d'un minimum local
de la fonction $\LS$ définie par ref:eq:tess3LS. Contrairement à AQP, il n'y a
pas de résultat sur la convergence de d'APLS. Cependant l'algorithme APLS a une
complexité algorithme plus faible que l'algorithme AQP. L'algorithme APLS
commence par initialiser au hasard les matrices $\Q$ et $\G$ et alterne deux
étapes jusque la convergence de celui-ci. La matrice $\Q$ est mis à jour pendant
que la matrice $\G$ est fixé et vice versa. La première étape de mis a jour de
la matrice $\G$ consiste à calculer
\begin{equation}
\label{eq:tess3:apls:g}
{\bf G}^\star = \arg \min  \|  {\bf Y} - {\bf QG}^T \|^2_{\rm F} \, .
\end{equation}
Cette étape peut être séparée en $(d+1) p$ (le nombre de colonnes de $\Y$)
problèmes indépendants. Cette opération peut être parallélisé. Ensuite nous
projetons $\G^{\star}$ sur le polyèdre $\DG$. Pour la seconde étape nous
commençons par calculer la matrice des vecteurs propres de la matrice laplacienne
$\laplacienne$ que nous notons $\U$, ainsi que la matrice diagonale $\LapVp$
formée des valeurs propres de $\Laplacienne$. Comme la matrice laplacienne est
symétrique et positive ses valeurs propres sont des nombres réels non négatif.
D'après le théorème spectral nous avons
\begin{equation}
\Laplacienne = {\U}^T {\LapVp} \U.
\end{equation}
Après cette opération nous projetons la matrice des données $\Y$ sur la base des
vecteurs propres de la façon suivante
\begin{equation}
\label{eq:3}
\mathcal{P}(\Y) = \U \Y,
\end{equation}
et, pour chaque individu, nous calculons 
\begin{equation}
\label{eq:tess3:apls:q}
q_i^\star = \arg \min \| \mathcal{P}(\Y}_i - \G q) \|^{2}_{2} + \alpha \lambda_i \| q \|^{2}_{2}  ,
\end{equation}
où $\mathcal{P}(\Y)_{i}$ est ligne d'indice $i$ de la matrice des données
projetée, et $\lambda_{i}$ désigne la valeur propre d'indice $i$ de
$\Laplacienne$. Les solutions, $q_{i}^{\star}$, sont concaténées en une matrice,
$\hat{\Q}$, puis la matrice $\Q$ est mise à jour par la projection de $\U
\hat{\Q}$ sur le polyèdre $\DQ$. La complexité de l'étape ref:eq:tess3:apls:q
croit linéairement avec $\n$, le nombre d'individus. Alors que la propriété
théorique de convergence de algorithme AQP est perdu pour l'algorithme APLS,
l'algorithme APLS devrait être de bonne approximation de l'algorithme AQP. C'est
ce que nous observons dans nos expériences numériques.

*** Choix des hyperparamètres
Le choix des hyper paramètre est un problème qui est commum a toutes les
méthodes d'estimation de l'ascendance. La méthode que nous avons présenté ici
nécessite le choix a priori de 3 hyperparamètre : le nombre de facteurs, $K$, le
paramètre de régularisation, $\alpha$ et le paramètre d'échelle géographique,
$\sigma$. Nous présentons ici des méthodes qui permette d'aider le choix de ces
paramètres.

**** Le paramètre d'échelle géographique $\sigma$
Le test de la corrélation entre la variable génétique et géographique à une
longue tradition en génétique des populations. Des approches populaire sont basé
sur le test de Mantel cite:mantel1967 et la mesure de l'autocorélation spatial
cite:HARDY_1999,Epperson_1996. Avant d'utiliser notre méthode spatiale
d'estimation de l'ascendance, nous proposons de choisi des valeurs de l'echelle
géographique en visualisant le variogramme spatial cite:Cressie1993. Le
variogramme peut être étendu aux données génétique de la facons suivante 

\begin{equation}
\label{eq:tess3:variogram}
\gamma(h) = \frac{1}{2 |N(h)|} \sum_{i,j \in N(h)} \frac{1}{L} \sum_{l = 1}^{(p+1)L} |\Y_{i,l} - \Y_{j,l}|,
\end{equation}
où $N(h)$ est défini comme l'ensemble des individus à une distance géographique
$h$. Visualisé le variogramme fourni des informations sur le niveau de
l'autocorélation spatial dans les données génétique et donne une estimation
empirique de l'echelle géographique $\sigma$. Une autre approche consiste à
prendre pour paramètre d'echelle géographique la distance géographique moyenne
entre les individus.

**** Le paramètre de régularisation $\alpha$
:LOGBOOK:
- Note taken on [2017-09-09 sam. 17:08] \\
  Je ne sais pas ou est le détail de ce calcule :D
:END:
La valeur par défaut du paramètre de régularisation $\alpha$ a été choisi de
sorte que le terme t'attache au données et le terme de régularisation de la
fonction $\LS$ soit du même ordre de grandeur. Nous proposons de diviser chaque
terme par sa valeur maximal. Cela revient à considérer $\alha$ égal à $p /
\lambda_{max}$, où $\lambda_{max}$ est la plus grande valeur propre de la
matrice laplacienne. 

**** Le nombre de population ancestrale $K$
Le nombre de populations ancestrales, $K$, peut être évalué en utilisant une
technique de validation croisée basée sur l'imputation des génotypes masqués
cite:Wold_1978,Eastment_1982,Alexander_2011,Frichot_2014. La procédure de
validation croisée divise les entrées matricielles génotypiques en un ensemble
d'apprentissage et un ensemble de tests. Les probabilités de génotype pour les
entrées masquées sont prédites à partir des estimations de facteurs obtenues à
partir d'entrées non masquées. Ensuite, l'erreur de prédiction est calculé en
utilisant l'entropie croisée entre les fréquences de génotype prédite et le
génotype réellement observées.

*** Statistique de différentiation des populations ancestrales pour les cribles génomiques pour l'adaptation locale
Il faut que j'explique un peut pourquoi on fait ca : 
- il y a une différentiation de base entre le population 
- on veut trouver la différentiation annormal etc...

En supposant qu'il y à $K$ population ancestrale, les matrice $\Q$ et $\G$
obtenues a partir des algorithmes AQP et APLS peut être utilisé pour calculer
une statistique de différentiation entre les populations ancestrale pour chaque
locus. La statistique est calculé de la façon suivante cite:Martins_2016
\begin{equation}
F^{Q}_{\rm ST} = 1 - \sum_{k=1}^K q_k \frac{f_k (1-f_k)}{f(1-f)},
\end{equation}
où $q_{k}$ est la mesure du coéficient de métissage dans la population $k$
moyenné sur tous les individus 
\begin{equation}
q_k = \sum_{i =1}^n \Q_{i,k} / n,
\end{equation}
$f_{k}$ est la fréquence d'allèle dans la population $k$ au locus considéré 
\begin{equation}
f_k =  \sum_{j = 1}^p  j \G_{(p+1)(\ell) + j, k}/p,
\end{equation}
et 
\begin{equation}
f = \sum_{k = 1}^K q_k f_k.
\end{equation}
A un locus donné, la formule de $F^{Q}_{\mathrm{ST}}$ correspond à la proportion
de la variance génétique qui peut être expliqué par la structure de population
latente 
\begin{equation}
F^Q _{\rm ST}  =  \frac{\sigma^2_T - \sigma^2_S}{\sigma^2_T },
\end{equation}
où $ \sigma^2_T $ est la variance totale et $\sigma^2_S$ est la variance de
l'erreur cite:Weir1996. En suivant la théorie ANOVA nous utilisons les
statistiques $ F^Q_{\rm ST}$ pour effectuer des tests statistiques de neutralité
à chaque locus, en comparant les valeurs observées à la valeur de
différentiation génomique de fond.

Le test porte sur la statistique du $z$-score au carré, $z^2 = (nK) F^{Q}_{\rm
ST} / (1 - F^{Q}_{\rm ST})$ , pour lequel une distribution de chi2 $K-1$ degrés
de liberté est attendu sous l'hypothèse nulle. 

Pour éviter un
nombre accru de tests faussement positifs, nous avons adopté une approche
empirique de test d'hypothèse nulle qui recalibre l'hypothèse nulle pour un
niveau de base de la différenciation de population attendus pour des SNP qui ne
sont pas selectionné . L'étalonnage de l'hypothèse nulle a
été réalisé en utilisant le contrôle génomique pour ajuster les statistiques de
test ~ \ citep {Devlin1999, Francois2016}. Après un recalibrage de l'hypothèse
nulle, le contrôle du taux de découverte fausse a été obtenu en utilisant
l'algorithme Benjamini-Hochberg ~ \ citep {Benjamini1995}.
** Autres méthodes d'estimation de l'ascendance comparées
*** Tess 2.3
*** sNMF
** Données simulées et réelles
** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:
*** Analyse de la convergence et temps de calcul 

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_vitesse.pdf.png}
\caption{Nombre d'itérations et temps de calcul pour les algorithmes AQP et
  APLS. A-B) Nombre total d'itération avant que l'algorithmes ai atteint une
  solution stable. C-D) Temps de calcul d'une seul itération en secondes. Le
  nombre de SNPs a été fixé à $p = 50$k pour A et C. Le nombre d'individus a été
  fixé à $n = 150$ pour B et D.}
\label{fig:tess3:vitesse}
\end{sidewaysfigure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE Expérience 
CLOSED: [2017-09-11 lun. 12:21]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 12:21]
:END:
#+NAME: code:tess3:vitesse:run
#+CAPTION: Dépend de [[code:tess3:AhalianaRegMapLines]]
#+begin_src R 
  library(MaTheseR)

  ## loda data
  load("./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR8.RData")

  sample.data.at <- sampler.from.data(call_method_75_TAIR8.europe$X,
    call_method_75_TAIR8.europe$coord)

  data.list <- sample.data.at(50, 5000)

  cores = 16
  registerDoParallel(cores = cores)

  ns = c(1e2, 2e2, 3e2, 4e2, 5e2, 6e2)
  Ls = c(1e3, 5e3, 1e4, 5e4, 1e5, 2e5)
  rep = 5
  L = 50000
  n = 150
  K = 6
  tess3Old.alpha = 0.03

  df.n <- data.frame()
  df.n <- rbind(fig4.exp.n(sample.data = sample.data.at, ns = ns, rep = rep, L = L, K = K, tess3Old.alpha = tess3Old.alpha), df.n)

  df.L <- data.frame()
  df.L <- rbind(fig4.exp.L(sample.data = sample.data.at, Ls = Ls, rep = rep, n = n, K = K, tess3Old.alpha = tess3Old.alpha), df.L)

  expr <- list( df.L = df.L, df.n = df.n)
  save_expr(expr, "tess3_vitesse.rds")
#+end_src
***** DONE Plots
CLOSED: [2017-09-11 lun. 12:21]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 12:21]
:END:
#+NAME: code:tess3:vitesse:plot
#+CAPTION: Dépend de [[code:tess3:vitesse:run]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## expr res
  expr <- readRDS("./OUTPUT/Expr/tess3_vitesse.rds")

  g_legend <- function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}



  toplot <- expr$df.n  %>% group_by(method, n) %>%
    mutate(mean = mean(it), N = length(it), sd = sd(it), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.it.n <- ggplot(toplot ,aes(x = n, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se,
                      ymax = mean + se,
                      width = (max(n) - min(n)) * 0.02)) +
    theme_bw() +
    xlab("") +
    ylab("Nombre\nd'itérations") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.n  %>% group_by(n, method) %>%
    mutate(mean = mean(time.per.it.mean), N = length(time.per.it.mean), sd = sd(time.per.it.mean), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.time.n <- ggplot(toplot ,aes(x = n, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se,
                      width = (max(n) - min(n)) * 0.02)) +
    theme_bw() +
    scale_y_log10() +
    xlab(TeX("Nombre d'individus ($n$)")) +
    ylab("Temps par itération \n(seconds)") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.L  %>% group_by(method, L) %>%
    mutate(mean = mean(it), N = length(it), sd = sd(it), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  pl.it.L <- ggplot(toplot ,aes(x = L / 1000, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se,
                      ymax = mean + se,
                      width = (max(L) - min(L)) * 0.02 / 1000)) +
    theme_bw() +
    xlab("") +
    ylab("") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  toplot <- expr$df.L  %>% group_by(L, method) %>%
    mutate(mean = mean(time.per.it.mean), N = length(time.per.it.mean), sd = sd(time.per.it.mean), se = sd / sqrt(N)) %>%
    rename(Methods = method)

  pl.time.L <- ggplot(toplot ,aes(x = L / 1000, y = mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_line() +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se,
                      width = (max(L) - min(L)) * 0.02 / 1000)) +
    theme_bw() +
    scale_y_log10() +
    xlab(TeX("Nombre de locus $\\times 1000$ ($p$)")) +
    ylab("") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.61,0.22)) +
    Article2.env$scale.linetype +
    Article2.env$scale.color +
    guides(linetype = guide_legend(nrow = 2))

  pl <- cowplot::plot_grid(pl.it.n, pl.it.L, pl.time.n, pl.time.L, ncol = 2, labels = c("A", "B", "C", "D"))
  save_plot_png(pl, "tess3_vitesse.png")
  save_plot_MaTheseR(pl, "tess3_vitesse.pdf.png",
                     height = 14,
                     width = 20)
#+end_src

#+RESULTS: code:tess3:vitesse:plot
: [[./OUTPUT/Rplots/tess3_vitesse.png]]
: [[./OUTPUT/Rplots/tess3_vitesse.pdf.png]]

*** Comparaison avec une méthode spatial bayésienne : TESS 2.3

#+BEGIN_EXPORT latex
\begin{figure}[h!]\centering
\begin{minipage}{0.49\textwidth}
\includegraphics[width=\linewidth]{./OUTPUT/Rplots/tess3_tess2_3_rmseG.pdf}
\end{minipage}
\begin {minipage}{0.49\textwidth}
\includegraphics[width=\linewidth]{./OUTPUT/Rplots/tess3_tess2_3_rmseQ.pdf}
\end{minipage}
\caption{Erreurs statistiques des estimations de TESS3 (APLS) et TESS 2.3 sur
  des simulations de population métissé de populations ancestrale pour lesquelle
  on connait les coéficients de métissage. A) RMSEs des esimations de $\G$ en
  fonction du niveau de diférentiation entre les populations ancestrale $F_{\rm
    ST}$. B) RMSEs des esimations de $\Q$ en fonction du niveau de
  diférentiation entre les populations ancestrale $F_{\rm ST}$.}
\label{fig:tess3:tess23}
\end{figure}    


#+END_EXPORT

**** Scripts                                                    :noexport:
***** Experience
Code trop vieux...
***** Plots
*** Comparaison avec une méthode non spatial : sNMF

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_comp_rmse_snmf.pdf.png}
\caption{Erreurs statistiques des estimations de TESS3 (APLS) et sNMF sur
  des simulations de population métissé de populations ancestrale pour lesquelle
  on connait les coéficients de métissage.}
\label{fig:tess3:comp:rmse:snmf}
\end{figure}
#+END_EXPORT

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_comp_auc_snmf.pdf.png}
\caption{}
\label{fig:ewas_venn}
\end{figure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE RMSE APLS et sNMF
CLOSED: [2017-09-11 lun. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-09-11 lun. 18:17]
:END:
#+NAME: code:tess3:rmse:snmf
#+CAPTION: 
#+begin_src R 
  ######################################
  ## Setup

  ## Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # sNMF
  if (!require("LEA")) {
    source("https://bioconductor.org/biocLite.R")
    biocLite("LEA")
    if(!require("LEA",character.only = TRUE)) stop("Package not found")
  }

  res.dir <- "./"
  fig.dir <- "./"

                                          # personal packages
                                          #devtools::install_github("cayek/TESS3_encho_sen@experiment")
  require("tess3rExperiment")

                                          #devtools::install_github("cayek/TESS3_encho_sen@master")
  require("tess3r")

  cat(green(paste("DEBUG =", DEBUG,"\n")))
  ######################################
                                          # Functions


  fst.LEA <- function(project,run = 1, K, ploidy = 2){
                                          #require(LEA)
    ll = dim(LEA::G(project, K = K, run = run))[1]
    if (ploidy == 2) {freq = LEA::G(project, K = K, run = run)[seq(2,ll,by = 3),]/2 + LEA::G(project, K = K, run = run)[seq(3,ll,by = 3),] }
    else {freq = LEA::G(project, K = K, run = run)[seq(2,ll,by = 2),]}
    q = apply(LEA::Q(project, K = K, run = run), MARGIN = 2, mean)
    H.s = apply(freq*(1 - freq), MARGIN = 1, FUN = function(x) sum(q*x) )
    P.t = apply(freq, MARGIN = 1, FUN = function(x) sum(q*x) )
    return(1 - H.s/P.t/(1 - P.t))
  }


  tess3.wrapper <- function(data.list, K, method) {
    if (is.null(data.list$admixed.genotype)) {
      capture.output(res <- tess3rExperiment::tess3(X = data.list$X,
                                                    coord = data.list$coord,
                                                    K = K,
                                                    ploidy = data.list$ploidy,
                                                    lambda = 1.0,
                                                    W = data.list$W,
                                                    method = method,
                                                    max.iteration = 200,
                                                    tolerance = 1e-05,
                                                    openMP.core.num = 1,
                                                    Q.init = NULL,
                                                    mask = 0), file = "/dev/null")
    } else {
      capture.output(res <- tess3rExperiment::tess3(X = data.list$admixed.genotype,
                                                    coord = data.list$coord,
                                                    K = K,
                                                    ploidy = data.list$ploidy,
                                                    lambda = 1.0,
                                                    W = data.list$W,
                                                    method = method,
                                                    max.iteration = 200,
                                                    tolerance = 1e-05,
                                                    openMP.core.num = 1,
                                                    Q.init = NULL,
                                                    mask = 0), file = "/dev/null")
    }
    return(res)
  }


  snmf.wrapper <- function(data.list, K, alpha = 10) {
    file.geno <- paste0(tempfile(),".geno")
    if (is.null(data.list$admixed.genotype)) {
      LEA::write.geno(data.list$X, file.geno)
    } else {
      LEA::write.geno(data.list$admixed.genotype, file.geno)
    }
    capture.output(aux <- LEA::snmf(input.file = file.geno,
                                    K = K,
                                    project = "new",
                                    repetitions = 1,
                                    alpha = alpha,
                                    tolerance = 1e-05,
                                    entropy = FALSE,
                                    percentage = 0.05,
                                    I = 0,
                                    iterations = 200,
                                    ploidy = data.list$ploidy,
                                    seed = -1,
                                    CPU = 1,
                                    Q.input.file = ""), file = "/dev/null")
    snmf.run <- list(Q = LEA::Q(aux, K = K, run = 1),
                     G = LEA::G(aux, K = K, run = 1),
                     Fst = fst.LEA(aux, run = 1, K = K, ploidy = 1))
    return(snmf.run)
  }


  fig2.experiment <- function(simu.param, m.neutral, rep) {
    df <- foreach(m = m.neutral, .combine = 'rbind') %:%
      foreach(r = 1:rep, .combine = 'rbind') %dopar% {
        simu.param$m.neutral <- m
        boolFalse <- FALSE
        while (boolFalse == FALSE)
        {
          tryCatch({
            data.list <- sample.data(simu.param)
            boolFalse <- TRUE
          },error = function(e){
          },finally = {})
        }
        tess3.res <- tess3.wrapper(data.list, 2, "MCPA")
        snmf.res <- snmf.wrapper(data.list, 2)
        rbind( data.frame(rmseQ = tess3r::ComputeRmseWithBestPermutation(data.list$Q, tess3.res$Q),
                          rmseG = tess3r::ComputeRmseWithBestPermutation(data.list$Freq, GtoFreq(tess3.res$G, 1)),
                          method = "TESS3-APLS",
                          n = nrow(data.list$admixed.genotype),
                          L = ncol(data.list$admixed.genotype),
                          rep = r,
                          Fst = mean(data.list$Fst),
                          Fst.theorical = data.list$Fst.theorical,
                          m.neutral = m,
                          nsites.neutral = data.list$nsites.neutral,
                          migration.rate = 4 * m * simu.param$N0),
              data.frame(rmseQ = tess3r::ComputeRmseWithBestPermutation(data.list$Q, snmf.res$Q),
                         rmseG = tess3r::ComputeRmseWithBestPermutation(data.list$Freq, GtoFreq(snmf.res$G, 1)),
                         method = "sNMF",
                         n = nrow(data.list$admixed.genotype),
                         L = ncol(data.list$admixed.genotype),
                         rep = r,
                         Fst = mean(data.list$Fst),
                         Fst.theorical = data.list$Fst.theorical,
                         m.neutral = m,
                         nsites.neutral = data.list$nsites.neutral,
                         migration.rate = 4 * m * simu.param$N0))
      }
    return(df)
  }


  sample.data <- function(simu.param) {
    res <- tess3r::SampleGenoOFWithMs(n = simu.param$n,
                                      nsites.neutral = simu.param$nsites.neutral,
                                      nsites.selected = simu.param$nsites.selected,
                                      crossover.proba = simu.param$crossover.proba,
                                      m.neutral = simu.param$m.neutral,
                                      m.selected = simu.param$m.selected,
                                      mutation.rate.per.site = simu.param$mutation.rate.per.site,
                                      N0 = simu.param$N0,
                                      k = simu.param$k,
                                      min.maf = simu.param$min.maf,
                                      plot.debug = FALSE,
                                      tess3.ms = getOption("tess3.ms"))
    res$Fst.theorical <- 1 / (1 + 4 * simu.param$N0 * simu.param$m.neutral)
    return(res)
  }


  ######################################
                                          # Params

  cat(green("== Test params\n"))
  simu.param <- list(n = 500,
                     nsites.neutral = 1.2 * 1e5,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 3 * 1e-6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)
  data.list <- sample.data(simu.param)

  plot(data.list$coord, col = rep(rainbow(2),each = data.list$n / 2))
  mean(data.list$Fst)
  dim(data.list$admixed.genotype)


  barplot(t(data.list$Q), col = rainbow(2))
                                          # data.list$W <- NULL
  tess3.run <- tess3.wrapper(data.list, K = 2, method = "MCPA")
  barplot(t(tess3.run$Q), col = rainbow(2))

  snmf.run <- snmf.wrapper(data.list, K = 2)
  barplot(t(snmf.run$Q), col = rainbow(2))

  ComputeRmseWithBestPermutation(snmf.run$Q, data.list$Q)
  ComputeRmseWithBestPermutation(tess3.run$Q, data.list$Q)

  ComputeRmseWithBestPermutation(GtoFreq(snmf.run$G,1), data.list$Freq)
  ComputeRmseWithBestPermutation(GtoFreq(tess3.run$G,1), data.list$Freq)


  ######################################
                                          # Run experiments


  simu.param <- list(n = 500,
                     nsites.neutral = 1.5 * 1e5,
                     nsites.selected = 0,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 3 * 1e-6,
                     m.selected = NULL,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)

  cores = 16
  registerDoParallel(cores = cores)

  if (DEBUG) {
    m.neutral =  c(0.25 * 0.05 * 1e-6,
                   0.25 * 0.5 * 1e-6,
                   0.25 * 1 * 1e-6,
                   0.25 * 1.5 * 1e-6,
                   0.25 * 2 * 1e-6,
                   0.25 * 2.5 * 1e-6,
                   0.25 * 3 * 1e-6,
                   0.25 * 5 * 1e-6)
    rep <- 5
  } else {
    m.neutral =  c(0.25 * 0.05 * 1e-6,
                   0.25 * 0.5 * 1e-6,
                   0.25 * 1 * 1e-6,
                   0.25 * 1.5 * 1e-6,
                   0.25 * 2 * 1e-6,
                   0.25 * 2.5 * 1e-6,
                   0.25 * 3 * 1e-6,
                   0.25 * 5 * 1e-6)
    rep <- 5 #  do not work ... why?
  }

  df <- data.frame()

                                          # n = 50
  simu.param$n = 50
  ## L = 10k
  cat(green("== n = 50 & L = 10k \n"))
  simu.param$nsites.neutral = 1.5 * 1e4
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  ## L = 200k
  cat(green("== n = 50 & L = 100k \n"))
  simu.param$nsites.neutral = 1.2 * 1e5
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

                                          # n = 500
  simu.param$n = 500
  ## L = 10k
  cat(green("== n = 500 & L = 10k \n"))
  simu.param$nsites.neutral = 1.5 * 1e4
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  ## L = 100k
  cat(green("== n = 500 & L = 100k \n"))
  simu.param$nsites.neutral = 1.2 * 1e5
  df <- rbind(fig2.experiment(simu.param, m.neutral = m.neutral, rep = rep), df)

  cat(green("== Save result\n"))
  saveRDS(df, file = "./OUTPUT/Expr/tess3_comp_rmse_sNMF.rds")

#+end_src
***** DONE Plots RMSE APLS et sNMF
CLOSED: [2017-09-11 lun. 18:30]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:30]
- State "TODO"       from "DONE"       [2017-09-11 lun. 18:23]
- State "DONE"       from              [2017-09-11 lun. 18:23]
:END:
#+NAME: code:tess3:rmse:snmf:plot
#+CAPTION: Dépend de [[code:tess3:rmse:snmf]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## retrieve results
  df <- readRDS("./OUTPUT/Expr/tess3_comp_rmse_sNMF.rds")

  labbeler <- function(variable, value) {
    if (as.character(variable) == "n") {
      paste0("$n = ",value, "$")
    } else if (as.character(variable) == "L") {
      paste0("$L \\approx 10^", floor(log(value,base = 10)), "$")
    }
  }

  toplot <- df %>%
    group_by(nsites.neutral) %>%
    dplyr::mutate(L = round(mean(L))) %>%
    group_by(method, m.neutral, n, L) %>%
    dplyr::mutate(Fst = mean(Fst), rmse.mean = mean(rmseQ), N = length(rmseQ), sd = sd(rmseQ), se = sd / sqrt(N)) %>%
    rename(Methods = method )
  levels(toplot$Methods)[1] <- "APLS"


  pl <- ggplot(toplot ,
               aes(x = Fst.theorical,
                   y = rmse.mean,
                   col = Methods,
                   shape = Methods,
                   linetype = Methods)) +
    geom_errorbar(aes(ymin = rmse.mean - se, ymax = rmse.mean + se,
                      width = (max(Fst.theorical) - min(Fst.theorical)) * 0.02)) +
    geom_line() +
    geom_point(size = 2) +
    facet_grid(L ~ n, labeller = labbeler) +
    theme_bw() +
                                          # xlab("$Fst = 1 / (1 + 4 N_0 m)$") +
    xlab("Fixation index $(F_{\\rm ST})$") +
    ylab("RMSE") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.85,0.3)) +
    Article2.env$scale.color +
    Article2.env$scale.linetype
  save_plot_png(pl, "tess3_comp_rmse_snmf.png")
  save_plot_MaTheseR(pl, "tess3_comp_rmse_snmf.pdf.png",
                       height = 0.4 * MaTheseR.params$textheightcm,
                       width = MaTheseR.params$textwidthcm)

#+end_src

#+RESULTS: code:tess3:rmse:snmf:plot
: Warning message:
: The labeller API has been updated. Labellers taking `variable`and `value` arguments are now deprecated. See labellers documentation.
[[./OUTPUT/Rplots/tess3_comp_rmse_snmf.png]]
: [[./OUTPUT/Rplots/tess3_comp_rmse_snmf.pdf.png]]
***** DONE AUC APLS et sNMF
CLOSED: [2017-09-11 lun. 18:41]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:41]
- State "TODO"       from              [2017-09-11 lun. 18:35]
:END:
#+NAME: code:tess3:auc:snmf
#+CAPTION: Dépend de 
#+begin_src R 
  library(ThesisRpackage)
  Article2.env <- get_Article2()
  attach(Article2.env)

  simu.param <- list(n = 100,
                     nsites.neutral = 1 * 1e5,
                     nsites.selected = 1 * 1e2,
                     crossover.proba = 0.25 * 1e-8,
                     m.neutral = 0.25 * 10 * 1e-6,
                     m.selected = 0.25 * 0.1 * 1e-6,
                     mutation.rate.per.site = 0.25 * 1e-7,
                     N0 = 1e6,
                     k = 0.5,
                     min.maf = 0.05)

                                          # Experiment

  cores = 16
  registerDoParallel(cores = cores)

  m.ms <- c(10, 40, 80, 100, 150)

  df <- data.frame()
  df <- rbind(fig3.experiment(simu.param, m.ms = m.ms, rep = 10), df)

  saveRDS(df, "./OUTPUT/Expr/tess3_comp_auc_sNMF.rds")
#+end_src
***** DONE Plots AUC APLS et sNMF
CLOSED: [2017-09-11 lun. 18:57]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:57]
- State "TODO"       from              [2017-09-11 lun. 18:41]
:END:
#+NAME: code:tess3:auc:snmf:plots
#+CAPTION: Dépend de [[code:tess3:auc:snmf]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## retrieve data
  df <- readRDS("./OUTPUT/Expr/tess3_comp_auc_sNMF.rds")

  ## plot
  toplot <- df %>%
    group_by(method, m.ms) %>%
    dplyr::mutate(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N)) %>%
    rename(Methods = method)
  levels(toplot$Methods)[1] <- "APLS"
  levels(toplot$Methods)[3] <- "before-admixure"

  pl <- ggplot(toplot ,aes(x = m.ms, y = auc.mean, col = Methods, linetype = Methods, shape = Methods)) +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se,
                      width = (max(m.ms) - min(m.ms)) * 0.02)) +
    geom_line() +
    geom_point(size = 2) +
    theme_bw() +
    xlab("Intensity of selection ($m/m_s$)") +
    ylab("AUC") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.8,0.2)) +
    Article2.env$scale.linetype +
    Article2.env$scale.color

  save_plot_png(pl, "tess3_comp_auc_snmf.png")
  save_plot_MaTheseR(pl, "tess3_comp_auc_snmf.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+end_src

#+RESULTS: code:tess3:auc:snmf:plots
[[./OUTPUT/Rplots/tess3_comp_auc_snmf.png]]
: [[./OUTPUT/Rplots/tess3_comp_auc_snmf.pdf.png]]

*** Sensibilité des estimateurs aux erreurs dans les mesures spatiales
**** Scripts                                                    :noexport:
***** RUNNING Experience
:LOGBOOK:
- State "RUNNING"    from "DONE"       [2017-09-11 lun. 17:44]
- State "DONE"       from "TODO"       [2017-09-11 lun. 17:28]
- State "TODO"       from              [2017-09-11 lun. 15:07]
:END:
#+NAME: code:tess3:noise
#+CAPTION: 
#+begin_src R 
  library(ThesisRpackage)

  expr <- long_tess3_noisyCoord(ns = c(50, 500),
                               nsites.neutral = c(1.5 * 1e4,
                                                  1.2 * 1e5),
                               m.neutral =  c(0.25 * 0.5 * 1e-6,
                                              0.25 * 1 * 1e-6,
                                              0.25 * 1.5 * 1e-6,
                                              0.25 * 2 * 1e-6,
                                              0.25 * 2.5 * 1e-6,
                                              0.25 * 3 * 1e-6,
                                              0.25 * 5 * 1e-6),
                               noise.signal = c(0.0, 0.2, 0.5,0.8, 1.0, 2.0, 3.0),
                               nb.rep = 10,
                               compute.vario = TRUE,
                               cluster.nb = 4,
                               save = FALSE, bypass = TRUE)
  save_expr(expr, "tess3_noise.rds")


  pl.all <- plot_tess3_noisyCoord(expr)
  save_plot_png(pl.all, "tess3_noise_debug.png")
  pl.var <- plot_tess3_noisyCoord_vario(expr)
  save_plot_png(pl.var, "tess3_noise_var_debug.png")
#+end_src

***** TODO Plot
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 15:08]
:END:
#+NAME: code:tess3:noise:plot
#+CAPTION: Dépend de [[code:tess3:noise]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## get data
  expr <- readRDS("./OUTPUT/Expr/tess3_noise.rds")

  ## remove Fst <= 0.5
  expr$df.res <- expr$df.res %>%
    dplyr::filter(Fst.theorical <= 0.5) %>%
    dplyr::filter(noise.signal <= 3.0)

  toplot <- plot_tess3_noisyCoord_toplot(expr) %>%
    dplyr::mutate(Fst.theorical = format(Fst.theorical, digits = 2))


  labbeler <- function(variable, value) {
    if (as.character(variable) == "n") {
      paste0("n = ",value, "")
    } else if (as.character(variable) == "L") {
      paste0("p ~ 10^", ceiling(log(value,base = 10)), "")
    }
  }

  pl <- ggplot(toplot, aes(x = noise.signal, y = rel.diff.rmse.Q.mean,
                           color = as.factor(Fst.theorical),
                           shape = as.factor(Fst.theorical))) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin = rel.diff.rmse.Q.mean - rel.diff.rmse.Q.mean.se, ymax = rel.diff.rmse.Q.mean + rel.diff.rmse.Q.mean.se,
                      width = (max(noise.signal) - min(noise.signal)) * 0.02)) +
    facet_grid(L ~ n, labeller = labbeler) +
    theme_bw() +
                                          # xlab("$Fst = 1 / (1 + 4 N_0 m)$") +
    xlab("Rapport signal sur bruit") +
    ylab("Erreur relative") +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.75,0.63)) +
    guides( color = guide_legend(title = "Fst", nrow = 2),
           linetype = guide_legend(title = "Fst", nrow = 3),
           shape = guide_legend(title = "Fst", nrow = 3)) +
    scale_color_manual(values = Article2.env$cbPalette) + 
    geom_hline(yintercept = 0, alpha = 0.8, col = "grey")
  pl

  save_plot_png(pl, "tess3_noise.png")
  save_plot_MaTheseR(pl, "tess3_noise.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:tess3:noise:plot
: Error in plot_tess3_noisyCoord_toplot(expr) : 
:   could not find function "plot_tess3_noisyCoord_toplot"
: Warning message:
: The labeller API has been updated. Labellers taking `variable`and `value` arguments are now deprecated. See labellers documentation.
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found
: Error in FUN(X[[i]], ...) : object 'noise.signal' not found

*** Application à des données humaines
**** Scripts                                                    :noexport:
***** DONE Run de tess3r sur les données du 1000Genomes
CLOSED: [2017-09-06 mer. 09:24]
:LOGBOOK:
- State "DONE"       from              [2017-09-06 mer. 09:24]
:END:
#+NAME: code:tess3r_1000G
#+CAPTION: Dépend de 
#+begin_src R 
  ## lib
  require(tess3r)

  dat.file = "./Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.rds"
  K = 3
  openMP.core.num = 1
  save = TRUE

  dat <- readRDS(dat.file)


  ## compute XBin
  ploidy <- computePloidy(dat$G)
  XBin <- computeXBin(dat$G, ploidy)

  exp <- list()
  ## snmf
  message("Run of snmf")
  exp$snmf.method <- sNMFMethod(K = K,
                                openMP.core.num = ifelse(!is.null(openMP.core.num), openMP.core.num, 1))
  exp$snmf.method <- fit(m = exp$snmf.method, dat)


  ## tess3
  message("Run of tess3")
  exp$tess3r <- tess3r::tess3Main(X = NULL,
                                  XProba = XBin,
                                  coord = dat$coord,
                                  K = K,
                                  ploidy = ploidy,
                                  lambda = 1.0,
                                  W = dat$W,
                                  method = "projected.ls",
                                  max.iteration = 200,
                                  tolerance = 1e-5,
                                  openMP.core.num = openMP.core.num,
                                  Q.init = NULL,
                                  mask = 0.0,
                                  copy = FALSE,
                                  algo.copy = FALSE,
                                  verbose = TRUE,
                                  o wnly.ancestry = TRUE)


  ## save exp
  save_expr(exp, "tess3r_1000G.rds")


#+end_src
***** DONE Résultats
CLOSED: [2017-09-06 mer. 09:24]
:LOGBOOK:
- State "DONE"       from              [2017-09-06 mer. 09:24]
:END:
#+NAME: code:tess3r_1000G_res
#+CAPTION: Dépend de [[code:tess3r_1000G]]
#+begin_src R 
  exp <- readRDS("./OUTPUT/Expr/tess3_1000G.rds")
  dat <- readRDS("~/Projects/Thesis/Data/1000Genomes/Phase3/Eu_Af_Afam.maf.05.sample.rds")
  indiv <- dat$indiv

  df.res <- tibble()


  pops <- list()
  pops[["EU"]] <- c("TSI", "GBR")
  pops[["AFAM"]] <- c("ASW")
  pops[["AF"]] <- c("YRI", "LWK")
  pops[["AF_East"]] <- c("LWK")
  pops[["AF_West"]] <- c("YRI")

  ## tess3
  cluster.mean <- list()
  Q <- exp$tess3r$Q
  for (n in names(pops)) {
    cluster.mean[[n]] <- apply(Q[indiv$pop %in% pops[[n]],], 2, mean)
  }
  df.res <- as_tibble(cluster.mean) %>%
    mutate(method = "tess3") %>%
    rbind(df.res)

  ## snmf
  cluster.mean <- list()
  Q <- exp$snmf.method$Q
  for (n in names(pops)) {
    cluster.mean[[n]] <- apply(Q[indiv$pop %in% pops[[n]],], 2, mean)
  }
  df.res <- as_tibble(cluster.mean) %>%
    mutate(method = "snmf") %>%
    rbind(df.res)

  df.res
#+end_src

#+RESULTS:
#+begin_example
  # A tibble: 6 x 6
             EU       AFAM          AF     AF_East      AF_West method
          <dbl>      <dbl>       <dbl>       <dbl>        <dbl>  <chr>
  1 0.989908389 0.22213109 0.005763050 0.010570104 1.356584e-03   snmf
  2 0.002622910 0.68385885 0.580945529 0.177235864 9.510127e-01   snmf
  3 0.007468701 0.09401008 0.413291396 0.812194030 4.763065e-02   snmf
  4 0.013114647 0.51804568 0.516530277 0.325146852 6.919651e-01  tess3
  5 0.975247418 0.21433237 0.000639551 0.001319068 1.666043e-05  tess3
  6 0.011637935 0.26762196 0.482830172 0.673534080 3.080183e-01  tess3
#+end_example
*** Application à des données Arabidopsis Thaliana

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_params.pdf.png}
\caption{}
\label{fig:tess3:at:param}
\end{figure}
#+END_EXPORT


#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_map.pdf.png}
\caption{}
\label{fig:tess3:at:map}
\end{sidewaysfigure}
#+END_EXPORT

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/tess3_AT_manhattanplot.pdf.png}
\caption{}
\label{fig:tess3:at:manhattanplot}
\end{sidewaysfigure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** TODO Données AthalianaGegMapLines
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
****** TODO Get dataset
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 19:37]
:END:
#+NAME: code:tess3:AthalianaRegMapLines
#+CAPTION: Dépend de 
#+begin_src R 

#+end_src
****** TODO Vep annotation
:LOGBOOK:
- State "TODO"       from              [2017-09-11 lun. 19:37]
:END:
#+NAME: code:
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
                                          # Setup

                                          # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # personal packages
                                          #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")


  library(data.table)

  ################################################################################
  # load data
  at.dir <- "./Data/AthalianaGegMapLines/")

  TAIR9.snps <- t(fread(
    paste0(at.dir,"call_method_75/call_method_75_TAIR9.csv"), sep = ",",
    header=TRUE, skip = 1, data.table = FALSE))
  aux <- apply(TAIR9.snps[-(1:2),], 2, unique)
  # find col0, the reference genome
  call_method_75_info <- fread(
    paste0(at.dir,"call_method_75/call_method_75_info.tsv"))
  col0 <- call_method_75_info[grepl("Col", call_method_75_info$nativename)]
  ancestral.allele <- TAIR9.snps[as.character(col0$ecotype_id),]
  # find variants allele
  variant.allele <- sapply(seq_along(ancestral.allele), function(i) aux[which(!(aux[,i] %in% ancestral.allele[i])),i])
  alleles <- data.frame(variant.allele = variant.allele, ancestral.allele = ancestral.allele, chr = as.numeric(TAIR9.snps[1,]), pos = as.numeric(TAIR9.snps[2,]))
  # load data for colnames
  data.file <-
    paste0(data.dir, "AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData")
  load(data.file)

  ################################################################################
  # vep
  vep.input <- alleles %>% mutate(start = pos, end = pos, allele = paste0(ancestral.allele,"/",variant.allele), strand = NA, identifier = colnames(call_method_75_TAIR9.europe$X)) %>% select(chr, pos, start, end, allele, strand, identifier)

  # check if no error
  head(vep.input)
  tail(vep.input)

  .Options$vep = "variant_effect_predictor.pl"
  runVEP <- function(vep.input, vep = .Options$vep) {
    input <- tempfile()
    write.table(vep.input, file = input, row.names = FALSE, col.names = FALSE, na = "", quote = FALSE)
    output <- tempfile()
    cmd <- paste0("variant_effect_predictor.pl -i ", input, " -o ", output, " --cache --dir ../Data/vep/ --species arabidopsis_thaliana --format ensembl --genomes --cache_version 31")
    system(cmd)
    vep.output <- data.table::fread(output, skip = "#Uploaded_variation", data.table = FALSE, na.strings = "-")
    return(vep.output)
  }

  vep.res <- runVEP(vep.input)

  saveRDS(vep.res, "./OUTPUT/Expr/tess3_snpsTAIR9vepTAIR10.rds")

#+end_src
***** DONE Choix des params
CLOSED: [2017-09-11 lun. 19:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:09]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
****** DONE Variogram
CLOSED: [2017-09-11 lun. 18:58]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 18:58]
- State "TODO"       from              [2017-09-11 lun. 18:57]
:END:
#+NAME: code:tess3_AT_vario
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
  # Setup

  # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

  # personal packages
  #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")

  # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  # variogram
  vario.gen <- CalculateEmpiricalGenSemivariogram(call_method_75_TAIR9.europe$X, 1,  call_method_75_TAIR9.europe$coord)
  saveRDS(vario.gen, "./OUTPUT/Expr/tess3_AT_vario.rds")
#+end_src
****** DONE K selection
CLOSED: [2017-09-11 lun. 19:04]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:04]
- State "TODO"       from              [2017-09-11 lun. 18:58]
:END:
#+NAME: code:tess3_AT_K
#+CAPTION: Dépend de 
#+begin_src R 
    ################################################################################
    # Setup

    # Install if not function
    pkgTest <- function(x)
    {
      if (!require(x,character.only = TRUE))
      {
        install.packages(x,dep=TRUE)
        if(!require(x,character.only = TRUE)) stop("Package not found")
      }
    }


    pkgTest("raster")
    pkgTest("ggplot2")
    pkgTest("reshape2")
    pkgTest("dplyr")
    pkgTest("gridExtra")
    pkgTest("cowplot")
    pkgTest("DescTools")
    pkgTest("doParallel")
    pkgTest("foreach")
    pkgTest("devtools")
    pkgTest("permute")
    pkgTest("crayon")

    # personal packages
    #devtools::install_github("BioShock38/TESS3_encho_sen@master")
    require("tess3r")

  # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  XBin <- matrix(0.0, nrow(call_method_75_TAIR9.europe$X),
                 ncol(call_method_75_TAIR9.europe$X) * 2)
  X2XBin(call_method_75_TAIR9.europe$X, 1, XBin)
  coord <- call_method_75_TAIR9.europe$coord
  rm(call_method_75_TAIR9.europe) # free memory
  gc()

  # Run tess3
  cat(green(paste("== Runing TESS3 \n")))
  tess3.obj <- tess3(X = NULL,
                           XBin = XBin,
                           coord = coord,
                           K = 1:10,
                           ploidy = 1,
                           lambda = 1.0,
                           rep = 5,
                           W = NULL,
                           method = "MCPA",
                           max.iteration = 200,
                           tolerance = 1e-05,
                           openMP.core.num = 16,
                           Q.init = NULL,
                           mask = 0.05,
                           keep = "best",
                           copy = FALSE,
                           algo.copy = TRUE)


  cat(green(paste("== Save result\n")))
  saveRDS(tess3.obj, "./OUTPUT/Expr/tess3_AT_K110,rep5.rds"))

  # keep only rmse
  err.df <- data.frame()
  for (t in tess3.obj) {
    err.df <- rbind(err.df,
      data.frame(rmse = t$rmse,
                  crossvalid.rmse = t$crossvalid.rmse,
                  crossentropy = t$crossentropy,
                  crossvalid.crossentropy = t$crossvalid.crossentropy,
                  K = t$K,
                  rep = seq_along(t$rmse)))

  }
  saveRDS(err.df, "./OUTPUT/Expr/tess3_AT_K.rds")
#+end_src
****** DONE Plot
CLOSED: [2017-09-11 lun. 19:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:09]
- State "TODO"       from              [2017-09-11 lun. 18:57]
:END:
#+NAME: code:tess3_AT_params
#+CAPTION: Dépend de [[code:tess3_AT_K]] [[code:tess3_AT_vario]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env


  ## get variogram
  vario.gen <- readRDS("./OUTPUT/Expr/tess3_AT_vario.rds")
  err.df <- readRDS( "./OUTPUT/Expr/tess3_AT_K.rds")

  variogram.pl <- ggplot(vario.gen, aes(x = h, y = semi.variance, size = size)) +
    geom_point(shape = 1) +
    geom_vline(xintercept = 1.5, colour = "red") +
    labs(y = "Semivariogram",
         x = "$\\sigma$ ($100$ km)") +
    theme_gray(base_size = 12) +
    scale_size_continuous(range = c(1,3)) +
    guides(size = guide_legend(title = "Bin size", nrow = 3)) +
    MaTheseR.params$gtheme +
    theme(legend.position = c(0.6,0.25)) +
    scale_shape_discrete(solid = FALSE)



  ################################################################################
                                          # K selection
  toplot <- err.df %>% group_by(K) %>%
    summarise(med = median(rmse), min = min(rmse), max = max(rmse),
              mean = mean(rmse), sd = sd(rmse), se = sd/sqrt(length(rmse)))

  selection.pl <- ggplot(toplot) +
    geom_point(aes(x = as.factor(K), y = med)) +
    geom_line(aes(x = K, y = med)) +
                                          #geom_errorbar(aes(x = K, y = med,
                                          #                  ymin=min, ymax=max), width=.1) +
    labs(y = "Cross validation error", x = "$K$") +
    theme_gray() +
    theme(legend.position = "none") +
    MaTheseR.params$gtheme +
    geom_vline(xintercept = 6, colour = "red")



  pl <- cowplot::plot_grid(variogram.pl, selection.pl, nrow = 1, labels = c("A", "B"))

  save_plot_png(pl, "tess3_AT_params.png")
  save_plot_MaTheseR(pl, "tess3_AT_params.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+end_src

#+RESULTS: code:tess3_AT_params
: Warning message:
: Removed 11 rows containing missing values (geom_point).
[[./OUTPUT/Rplots/tess3_AT_params.png]]
: [[./OUTPUT/Rplots/tess3_AT_params.pdf.png]]

***** DONE Run de tess3r avec K = 6 et sigma = 1.5
CLOSED: [2017-09-11 lun. 19:15]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:15]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_run
#+CAPTION: Dépend de 
#+begin_src R 
  ################################################################################
                                          # Setup

                                          # Install if not function
  pkgTest <- function(x)
  {
    if (!require(x,character.only = TRUE))
    {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }


  pkgTest("raster")
  pkgTest("ggplot2")
  pkgTest("reshape2")
  pkgTest("dplyr")
  pkgTest("gridExtra")
  pkgTest("cowplot")
  pkgTest("DescTools")
  pkgTest("doParallel")
  pkgTest("foreach")
  pkgTest("devtools")
  pkgTest("permute")
  pkgTest("crayon")

                                          # personal packages
                                          #devtools::install_github("BioShock38/TESS3_encho_sen@master")
  require("tess3r")

                                          # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)

  # compute W
  W <- ComputeHeatKernelWeight(call_method_75_TAIR9.europe$coord,
                               sigma = 1.5)

  # Run tess3
  cat(green(paste("== Runing TESS3 \n")))
  tess3Main.obj <- tess3Main(X = call_method_75_TAIR9.europe$X,
                           XBin = NULL,
                           coord = call_method_75_TAIR9.europe$coord,
                           K = 6,
                           ploidy = 1,
                           lambda = 1.0,
                           W = W,
                           method = "MCPA",
                           max.iteration = 200,
                           tolerance = 1e-05,
                           openMP.core.num = 16)

  ## saving result
  cat(green(paste("== Save result\n")))
  saveRDS(tess3Main.obj, "./OUTPUT/Expr/tess3_AT_tess3r.rds")

#+end_src
***** DONE Map et barplot
CLOSED: [2017-09-11 lun. 19:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:35]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_map
#+CAPTION: Dépend de [[code:tess3_AT_run]]
#+begin_src R :session *R* :dir ~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## result
  tess3Main.obj <- readRDS("./OUTPUT/Expr/tess3_AT_tess3r.rds")

  ################################################################################
                                          # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)
  coord <- call_method_75_TAIR9.europe$coord
  rm(call_method_75_TAIR9.europe)

  ################################################################################
                                          # Q
  Q <- tess3Main.obj$Q
                                          # northen cluster
  id.northers <- which(apply(Q, 1, which.max) == 2)
  Q.notnorthers <- Q[!(1:nrow(Q) %in% id.northers),]
  coord.notnorthers <- coord[!(1:nrow(Q) %in% id.northers),]
  id <- sort(coord.notnorthers[,1], index.return = TRUE)
  Q.ordered <- rbind(Q[id.northers,], Q.notnorthers[id$ix,])

  ################################################################################
                                          # Color palette
  gg_color_hue <- function(n) {
    hues = seq(15, 375, length = n + 1)
    hcl(h = hues, l = 65, c = 100)[1:n]
  }
  n = 6
  cols = gg_color_hue(n)

  col.palette = list(
    colorRampPalette(c("white",cols[1]))(9)[5:9],
    colorRampPalette(c("white",cols[2]))(9)[5:9],
    colorRampPalette(c("white",cols[3]))(9)[5:9],
    colorRampPalette(c("white",cols[4]))(9)[5:9],
    colorRampPalette(c("white",cols[5]))(9)[5:9],
    colorRampPalette(c("white",cols[6]))(9)[5:9]
  )
                                          # plot(rep(1,5),col = col.palette[[2]],pch=19,cex=3)

  ################################################################################
                                          # Interpolation
  require(sp)
  require(raster)
  require(rworldmap)
  require(rgeos)
  require(rasterVis)
  require(fields)

  ## param
  window <- c(-16,42,33,67)
  resolution <- c(300, 300)
  theta <- 10

  ## get europe
  newmap <- getMap(resolution = "low")
  CP <- as(extent(window), "SpatialPolygons")
  europe <- gIntersection(newmap, CP)
                                          # Or
                                          # europe <- crop(newmap, extent(window))
  plot(europe)

  ## make grid
  raster.grid <- raster(extent(window), ncol = resolution[1], nrow = resolution[2], vals = 1)
                                          # plot(grid)

  ## interpolation with krig
  interpol <- stack()
  for (j in seq_along(Q[1,])) {
    model <- Krig(coord, Q[,j], theta = theta)
    interpol <- stack(interpolate(raster.grid, model), interpol)
  }
  interpol <- mask(interpol, europe)
                                          # plot(interpol)
                                          # levelplot(interpol)
  ## plot with tess3r package

                                          # plot(Q = Q,
                                          #      coord = coord, plot.type = "max",
                                          #      resolution = c(300, 300), window = c(-16,42,33,67), background = TRUE,
                                          #      raster.filename = NULL, interpolation.function = kriging(), col = NULL,
                                          #      col.palette = col.palette, map = TRUE, palette.step = 9,
                                          #      axes = FALSE, xlab = '', ylab = '', cex = 0.25)


  ################################################################################
                                          # Plot map

  toplot <- data.frame(rasterToPoints(interpol))
  ## compute breaks
  col.breaks <- apply(toplot[3:8], 2,
                      function(c) seq(min(c),
                                      max(c),
                                      length.out = length(col.palette[[1]]) + 1))
                                          # ## compute color for each tile
                                          # color <- function(coef, col.palette, col.breaks) {
                                          #   max.i <- which.max(coef)
                                          #   c <- max(which(col.breaks[,max.i] - as.numeric(coef[max.i]) >= 0)[1] - 1,1)
                                          #   return(col.palette[[max.i]][c])
                                          #   # return(c)
                                          # }
                                          # toplot$color <- apply(toplot[3:8], 1,
                                          #                       function(r) color(r, col.palette, col.breaks))

  ## with removed artefact
  color.rm.art <- function(r, col.palette, col.breaks) {
    coef <- r[3:8]
    pos <- r[1:2]
    if (pos[1] > 28 && pos[2] < 46) {
      max.i <- 5
    } else {
      max.i <- which.max(coef)
    }
    c <- max(which(col.breaks[,max.i] - as.numeric(coef[max.i]) >= 0)[1] - 1,1)
    return(col.palette[[max.i]][c])
                                          # return(c)
  }
  toplot$color <- apply(toplot[1:8], 1,
                        function(r) color.rm.art(r, col.palette, col.breaks))

  mappl <- ggplot() +
    geom_tile(data = toplot, aes(x = x, y = y, fill = color)) +
    scale_fill_identity() +
    geom_path(data = europe, aes(x = long, y = lat, group = group)) +
    coord_equal() +
    geom_point(data = as.data.frame(coord), aes(x = long, y = lat), size = 0.1) +
    MaTheseR.params$gtheme +
    xlab("Longitude (°E)") +
    ylab("Latitude (°N)")

  ################################################################################
                                          # barplot
  toplot <- data.frame(Q.ordered, index = seq_along(Q.ordered[,1])) %>% reshape2::melt(id = "index")
  brplot <- ggplot(toplot, aes(x = index, y = value)) +
    geom_bar(stat = "identity", aes(color = variable)) +
    MaTheseR.params$gtheme +
    theme(legend.position = "none",
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          panel.background = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
    xlab("Individual") +
    ylab("Admixture\n\ coefficient (Q)") +
    scale_y_continuous(breaks = c(0.0,0.5,1.0)) +
    scale_color_manual(values = cols)

  ################################################################################
                                          # Plot


  pl <- cowplot::plot_grid(mappl, brplot, ncol = 1, labels = c("A", "B"), rel_heights = c(3,1), vjust = c(1.5, -0.5))
  save_plot_png(pl, "tess3_AT_map.png")
  save_plot_MaTheseR(pl, "tess3_AT_map.pdf.png",
                     height = 14,
                     width = 20)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3_AT_map.png]]

***** DONE Manhattan plot
CLOSED: [2017-09-11 lun. 19:44]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-11 lun. 19:44]
- State "TODO"       from              [2017-09-11 lun. 18:48]
:END:
#+NAME: code:tess3_AT_manhattan
#+CAPTION: Dépend de [[code:tess3_AT_run]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(scales)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  Article2.env <- MaTheseR.params$Article2.env

  ## result
  tess3Main.obj <- readRDS("./OUTPUT/Expr/tess3_AT_tess3r.rds")
  vep.res <-readRDS("./OUTPUT/Expr/tess3_snpsTAIR9vepTAIR10.rds")

  ################################################################################
                                          # load data
  data.file <- "./Data/AthalianaGegMapLines/call_method_75/call_method_75_TAIR9.RData"
  load(data.file)
  coord <- call_method_75_TAIR9.europe$coord

  ################################################################################
                                          # flowering genes
                                          # search on http://plants.ensembl.org/
                                          # SHORT VEGETATIVE PHASE (SVP), a MADS box gene that negatively regulates the transition to flowering (Differentiating Fennoscandia and Eastern Europe/Russia)
  flowering.gene <- vep.res %>% dplyr::filter(Gene == "AT2G22540") %>% dplyr::mutate(label = "SVP")
                                          # COP1-interacting protein 4.1 (CIP4.1)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT4G00930") %>% dplyr::mutate(label = "CIP4.1"))
                                          # FRIGIDA (FRI)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT4G00650") %>% dplyr::mutate(label = "FRI"))
                                          # FLOWERING LOCUS C (FLC),
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT5G10140") %>% dplyr::mutate(label = "FLC"))
                                          # DELAY OF GERMINATION 1 (DOG1)
  flowering.gene <- rbind(flowering.gene, vep.res %>% dplyr::filter(Gene == "AT5G45830") %>% dplyr::mutate(label = "DOG1"))


  ################################################################################
                                          # Plot TESS3 manhattanplot
  toplot <- data.frame(fst = tess3Main.obj$Fst,
                       pvalue = tess3Main.obj$pvalue,
                       call_method_75_TAIR9.europe$locus.coord,
                       index = seq_along(tess3Main.obj$Fst)) %>%
    dplyr::mutate(Location = paste0(Chromosome,":",Positions))

  alert <- merge(toplot, flowering.gene, by = c("Location"))
  label <- alert %>% group_by(Gene) %>% filter(row_number(index) == 1)
  label$index[2] = label$index[2] + 8000
  label$index[3] = label$index[3] - 8000
  ## plot with annotation
  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue),
                           color = as.factor(Chromosome), fill = Chromosome)) +
    geom_point() +
    labs(y = "-log(pvalue)", x = "locus index") +
    theme_gray() +
    theme(legend.position = "none") +
    geom_point(data = alert, colour = "red") +
    geom_text(data = label, aes(x = index, y = 0, label = label), vjust = 1.8, check_overlap = FALSE)

  ## plot without annotation
  toplot <- toplot %>% dplyr::filter(pvalue != 0.0)
  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue),
                           color = as.factor(Chromosome), fill = Chromosome)) +
    geom_point(size = 0.25) +
    labs(y = "-log(pvalue)", x = "locus index") +
    scale_y_continuous(limits = c(0,510)) +
    scale_x_continuous(breaks = sapply(1:5, function(i) mean(toplot[toplot$Chromosome == i, ]$index)),
                       labels = 1:5) +
    xlab("Chromosome") +
    ylab("log(p-value)") +
    MaTheseR.params$gtheme +
    theme(legend.position = "none") +
    scale_color_manual(values = c(Article2.env$cbPalette[6], Article2.env$cbPalette[2],
                                  Article2.env$cbPalette[6], Article2.env$cbPalette[2],
                                  Article2.env$cbPalette[6]))


  ## rm data
  rm(call_method_75_TAIR9.europe)
  save_plot_png(pl, "tess3_AT_manhattanplot.png")
  save_plot_MaTheseR(pl, "tess3_AT_manhattanplot.pdf.png",
                     height = 14,
                     width = 20)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/tess3_AT_manhattanplot.png]]
** Discussion
* Estimation de facteurs latents pour corriger les tests d'association
** Introduction
*** Les études d'association
Au cours de la dernière décennie, les études d'association à grande échelle ont
été largement utilisées pour identifier les gènes candidats associés à une
maladie particulière ou un trait phénotypique d'intérêt. Selon le type de
marqueurs moléculaires examinés dans les génomes ou dans les cellules, plusieurs
catégories d'études d'association ont été menées pour détecter des corrélations
significatives de ses marqueurs avec le phénotype. Par exemple, les études
d'association à l'échelle du génome (GWAS genome-wide association studies) se
concentrent sur les polymorphismes à un seul nucléotide (SNP pour
single-nucleotide polymorphisms) en examinant des variants génétiques chez
différents individus cite:Balding_2006. Les GWAS ont été étendus à des études
d'association à l'échelle de l'épigenome (EWAS epigenome-wide association
studies) qui mesurent les niveaux de méthylation de l'ADN chez différents
individus pour des associations entre la variation épigénétique et les
phénotypes cite:Rakyan_2011. Des approches similaires ont été appliquées à la
caractérisation de la variation observée dans l'ARN par rapport à différents
environnements, traitements, phénotypes ou maladies cite:Slonim_2002. D'autres
exemples d'études d'association incluent des études d'association
génétique-environnement (GEAS) dans lesquelles les sites génétiques sont testés
pour leur corrélation avec des gradients écologiques afin de détecter les
signatures de sélection naturelle cite:rellstab15_pract_guide_to_envir_assoc.
Dans un court laps de temps, les études d'association ont permis des progrès
considérables dans l'identification des variants de gènes qui confèrent une
susceptibilité aux maladies ainsi qu'une compréhension plus approfondie de
l'évolution des génomes en réponse à la sélection naturelle.

*** Les facteurs confusions
<<sec:fact_conf>>

Basée sur l'analyse de la corrélation, les études d'association sont confrontées
aux problèmes des facteurs de confusion et de causalité. En effet lorsque l'on
détecte de la corrélation entre deux variables cela n'implique pas qu'il y a
lien de causalité entre celle-ci. Le lien de causalité entre ces deux variables
peut être bien plus complexe et notamment impliquer des lien avec d'autres
variables non observées. En particulier, il est possible de conclure une
association entre deux variables alors qu'elles sont en faite chacune associé à
une autre variable non considéré dans l'étude. On appelle alors cette variable
non observé un facteur de confusion. La figure [[graph:conf_factor]] illustre cette
situation. Le problème des facteurs de confusion est connue depuis longtemps. En
effet, on le retrouve déjà dans l'ouvrage /The Design of Experiement/ de Ronald
Fisher qui introduisit entre autre le concept de d'hypothèse nulle en
statistique cite:fisher1937design. Dans cette thèse nous nous intéressons aux
études d'association à très grande échelle. C'est a dire que nous avons d'une
part les observations de $\Ycol$ variables sur $\Yrow$ individus qui sont
rassemblées dans une matrice $\Y$ de taille $\Yrow \times \Ycol$, en général
$\Ycol$ est très grand devant $\Yrow$. Nous avons d'autre part l'observation
d'une variable sur les mêmes $\Xrow$ individus que l'on rassemble dans la
matrice $\X$ de taille $\Xrow \times 1$. L'objectif est alors de trouver parmi
les $\Ycol$ variables $\Y$ celles qui sont associées à $\X$. Nous supposons de
plus qu'il existe un certain nombre de variables non observées qui permettent
d'expliquer les variations de $\Y$. Ces variables non observées, que l'on
appellera variables latentes, sont potentiellement des facteurs de confusion
pour l'étude d'association entre $\Y$ et $\X$. C'est a dire que les variables
latentes sont potentiellement corrélées à $\X$, il faut donc les prendre en compte
dans l'étude d'association.

#+NAME: code:conf_factor
#+BEGIN_SRC dot :file Figures/conf_factor.png :exports results :eval no-export
  graph {
    graph [fontname = "serif"];
    node [fontname = "serif"];
    edge [fontname = "serif"];
    U -- Y;
    U -- X;
  }
#+END_SRC

#+NAME: graph:conf_factor
#+CAPTION: Graphe de corrélation entre la variable $y$ la variable $x$ et le facteur de confusion $u$. Dans cette situation si on ne prend pas en compte $u$ dans l'étude d'association alors $x$ et $y$ apparaitrons comme étant associées.
#+ATTR_LATEX: :width 5cm
#+RESULTS: code:conf_factor
[[file:Figures/conf_factor.png]]

*** Simulation numérique d'une association avec facteurs de confusions
<<sec:simu_ex>>

Dans cette partie nous proposons de montrer l'intérêt de prendre en
considération les facteurs de confusion dans les études d'association. Pour cela
nous simulation une variable $\X$ et une variable latente de sorte que leur
corrélation vaille $0.6$. Nous simulons ensuite une matrice de bruit gaussien
$\E$. La matrice des effets de la variable latente sur $\Y$ est aussi calculé a
l'aide de la loi normale, nous notons cette matrice $\V$. La matrice des effets
de $\X$ sur $\Y$, noté $\B$, est simulée de sorte que $1 \%$ de ses lignes soit
non nulle. Enfin, la matrice $\Y$ est calculée telles que 
\begin{equation} 
\Y = \U \V^{T} + \X \B^{T} + \E. 
\end{equation} 
Cette simulation correspond à une situation où 1 \% des colonnes de $\Y$ sont
associé avec $\X$ et la variable latente est bien facteur de confusion pour
cette étude d'association car $\U$ est corrélé avec $\X$. Afin de détecter les
variables expliquées associés à la variables explicative, nous avons réalisé une
régression linéaire avec seulement la variable $\X$ en variable explicative de
la régression. Nous effectuons une autre régression linéaire avec cette fois la
variable $\X$ ainsi que la variable latente $\U$ comme variable explicatives de
la régression. Nous avons ensuite réalisé un test de Student pour tester la
nullité des coefficient associé à la variable $\X$ dans chacune des deux
régressions. La figure ref:fig:simu_intro montre que quand on ne prend pas en
compte la variable latente plus de 40 \% des \pvalues sont proches de zéro, on
détecte alors beaucoup de candidats pour l'association avec la variable $\X$.
Alors que quand on prend en compte les facteurs latents la distribution des
\pvalues est bien uniforme comme on s'y attend. On s'attend a une distribution
uniforme des \pvaleur car la majorité des colonnes de $\Y$ ne sont pas associées
avec la variable $\X$, seulement 1\% par simulation. Dans le cas de cette
simulation il est impossible de ne pas prendre en compte la variable latente,
sans celle-ci on détecte presque la moitié des colonnes de $\Y comme étant
associées à $\X$.

#+NAME: code:confusion_plot
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(scales)

  dat <- ExpRsampler_generativeData(n = 200,
                                    p = 5000,
                                    K = 1,
                                    outlier.prop = 0.01,
                                    cs = c(0.6)) %>%
    ExpRmouline()

  ## lm
  lm.res <- method_lm() %>% ExpRmouline(dat)
  toplot <- data.frame(Régression = "Y ~ X",
                   pvalue = lm.res$pvalue)

  ## lm with U
  oracle.res <- method_oracle() %>% ExpRmouline(dat)


  ## qqplot
  toplot <- data.frame(Régression = "Y ~ X + U",
                       pvalue = oracle.res$pvalue) %>%
    rbind(toplot)
  toplot <- as_tibble(toplot)
  pl <- ggplot(toplot, aes(pvalue, fill = Régression)) +
    geom_histogram(position = "dodge", aes(y = (..count..)/sum(..count..))) +
    MaTheseR.params$gtheme +
    xlab("P-valeur") +
    ylab("Pourcentage") +
    scale_y_continuous(labels=percent)
  save_plot_MaTheseR(pl, "simu_intro.png",
                     height = 0.3 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/simu_intro.png}
\caption{Histogramme des \pvalues du test de nullité des coefficients
  de régression de la régression sans et avec le facteur de
  confusion.}
\label{fig:simu_intro}
\end{figure}
#+END_EXPORT

*** Méthodes de correction pour les facteurs latents
:LOGBOOK:
- Note taken on [2017-08-01 mar. 18:14] \\
  un exemple ici ?? lm, lm + PCA, lm + les facteurs latents comme dans stephens et
  2017 dans son intro,
:END:
Nous nous plaçons dans le cadre méthodologique des modèles de régression
linéaire. Il s'agit d'un cadre très utilisé en étude d'association que nous
pouvons formaliser de la façon suivante
\begin{equation}
\label{eq:statReg}
\Y_{j} = \X b_{j} + \E_{j}
\end{equation}
où $\Y_{j}$ est la matrice des observations de la variable d'indice $j$ sur
$\Yrow$ individus. Le coefficient $b_{j}$ représente l'effet de $\X$ sur
$\Y_{j}$. La matrice $\E_{j}$ est la matrice de l'erreur résiduelle. Il arrive
parfois que l'on fasse la régression dans l'autre sens, la régression s'écrit
alors
\begin{equation}
\label{eq:statRegRevers}
\X = \Y_{j} a_{j} + \E^{'}_{j},
\end{equation}
où $\a_{j}$ représente l'effet de $\Y_{j}$ sur $\X$. Dans la suite nous ne
parlerons de régression que dans le sens de l'équation eqref:eq:statReg. Aussi
$\X$ peut contenir plusieurs variable d'intérêt pour l'étude d'association. De
plus, sxi nous avons observé des variables supplémentaires qui sont des facteurs
de confusion pour notre étude, celle si sont être ajouté au coté des variables
explicatives du modèle de régression. Dans cette partie on considère le cas
simple d'une association avec une seul variable et autres observation de
variables de confusions. L'objectif est de trouver les coefficients $b_{j}$ qui
sont significativement différents de zéro. Dans ce cas on peut dire que $\Y_{j}$
est associée à $\X$. Comme nous l'avons évoqué dans la partie précédente avec
cette approche il est possible qu'une ou plusieurs variables latentes soit
corrélée à la fois à $\Y$ et à $\X$. Dans ce cas, si l'on ne considère les
variables latentes comme variables explicatives de la régression nous détectons
qu'un grand nombre de variables $\Y_{j}$ sont significativement corrélées à
$\X$, comme nous l'avons illustré par une simulation numérique dans la partie
précédente. Nous allons maintenant présenter les différentes approches possible
pour corriger les études d'association pour les facteurs de confusion.

**** Estimation des facteurs latent à priori
Une première approche consiste à trouver les variables latentes en faisant une
analyse factorielle de $\Y$. On fait l'analyse factorielle à priori et sans
prendre en compte la variable $\X$. Les variables latentes sont ensuite ajoutées
au modèle de régression au coté des autres variables explicatives de sorte que
\begin{equation}
\Y_{j} = \X b_{j} + \bar{\U} \V_{j}^{T} + \E_{j}
\end{equation}
où $\bare{\U}$ est la matrice des variables latents calculé à priori et $\V_{j}$
la matrice des effets des variables latentes sur $\Y_{j}$. Par exemple, les
méthodes EIGENSTRAT et Refactor calculent les variables latentes à l'aide de
l'analyse en composantes principales (ACP) de $\Y$ cite:Price_2006,Rahmani_2016.
**** Les modèles mixtes
Une autre approche de correction pour les facteurs de confusions est le modèle
mixte. Dans un tel modèle on ajoute un effet aléatoire à la régression
\begin{equation}
\Y_{j} = \X \B^{T} + \matr{\Gamma}_{j} + \E_{j}
\end{equation}
où $\matr{\Gamma}_{j}$ est la matrice des effets aléatoires à estimer. Dans les
modèles mixtes on suppose de plus que la matrice de covariance de l'effet
aléatoire est connue. On parle d'effet aléatoire mais il s'agit en faite du
facteur de confusion dont à parlé jusque ici. Ainsi, la matrice de covariance
doit correspondre à la variance du facteur de confusion, elle est en générale
calculé à partir de $\Y$. Les modèles mixtes ont été largement utilisés pour les
GWAS cite:Kang_2008,Zhou_2014. Dans le cas des GWAS, l'effet aléatoire permet
d'expliquer la variation de $\Y_{j}$ qui est dû à la structure de population.
Dans ce cas la matrice de covariance est estimé à priori sur les données
génétiques.
**** Les modèles mixtes à facteurs latents (LFMM latent factor mixted model)
Nous introduisons maintenant les modèles mixtes à facteurs latents. L'équation de
régression peut s'écrire comme ceci : 
\begin{equation}
\label{eq:glfmm}
\Y = \X \B^{T} + \U \V^{T} + \E.
\end{equation}
Dans cette équation $\U$ est la matrice des variables latentes et $\V$ est la
matrice des axes des facteurs latents. La différence majeur de LFMM avec les
autres modèles est qu'on ne suppose rien a priori sur les facteurs de confusion.
Dans les modèles dont nous avons parlés précédemment on estime à priori soit les
variables latentes directement soir leurs matrice de covariance. l'objectif de
LFMM est d'apprendre la variation systématique observées dans $\Y$ grâce aux
paramètres $\U$ et $\V$ tout en prenant en compte la variable $\X$. Il existe
différentes méthodes pour estimer les paramètres de LFMM. On distingue d'abord
des approches qui reposent sur des algorithmes de Monte Carlo
cite:frichot13_testin_assoc_between_loci_envir,carvalho08_high_dimen_spars_factor_model.
Ces approches repose sur une modélisation bayésienne de LFMM qui permet
d'échantillonner les lois à posteriori des paramètres. L'avantage de ces
méthodes est qu'elles permettent d'estimer la variance du paramètre $\B$. Cela
permet de faire un test de significativité statistique. Il y a aussi des
approches qui reposent sur des algorithmes EM (Expectation Maximisation)
cite:friguet09_factor_model_approac_to_multip,agarwal09_regres,zhou16_spars_multiv_factor_analy_regres.
Ces approches sont plus rapides que les méthodes utilisant des algorithmes de
Monte Carlo. Enfin, il y a les approches qui reposent sur une estimation des
variables latentes à partir d'une transformation de $\Y$
cite:gerard2017unifying,wang2015confounder,article_Leek_Storey_2007. Cette
transformation a pour but de séparer la variation de $\Y$ expliquée par les
variables latentes de celle expliquée par $\X$. Parmi cette dernière catégorie
de méthodes, on distingue des autres les méthodes dites à contrôles négatifs qui
suppose connu un sous ensemble de colonnes de $\Y$ qui ne sont pas associées
avec $\X$. Les méthodes à contrôles négatifs utilisent ces variables dîtes
nulles pour estimer les variables latentes.

*** Source de confusion                                          :noexport:
:LOGBOOK:
- Note taken on [2017-08-04 ven. 11:39] \\
  Je ferrais une expliation de la source de confusion pour chaque dataset !!
:END:
Les sources de confusion peuvent varier selon les différentes catégories
d'études d'association. Dans les GWAS et les GEAS, la confusion englobe des
différences systématiques dans l'ascendance génétique entre les individus
échantillonnés cite:Price_2006. Une autre source de confusion dans ces études
peut également découler d'interactions épistatiques entre les gènes
cite:Vilhj_lmsson_2012. Dans les études de profils d'expression des gènes, les
facteurs latents peuvent être les conditions expérimentales, l'âge et le sexe
des patients, leurs facteurs génétiques et l'hétérogénéité des échantillons de
tissus cite:Lazar_2012. Dans les EWAS, la confusion peut être due à des mélanges
cellulaires lorsque les cellules cibles purifiées ne sont pas disponibles
cite:jaffe14_accoun_cellul_heter_is_critic. Dans chaque catégorie, les facteurs
latents peuvent être confondus avec les variables explicatives en raison de la
nature observatoire de l'étude.

*** Plan du chapitre
Comme nous l'avons vu dans la partie précédente l'estimation des variables
latentes pour corriger les études d'association est un problème très vaste et
aucune méthode ne s'est imposée comme référence. Nous proposons ici, deux
méthodes d'estimation rapides et efficaces des paramètres du modèle LFMM. Nos
deux méthodes d'estimation consiste à isolé la variation de $\Y$ expliquée par
les variables latentes de celle expliquée par les variables explicatives. Les
méthodes que nous présentons sont comparable à SVA cite:article_Leek_Storey_2007;
et CATE cite:wang2015confounder; qui procède d'une façon très similaire, nous
décrivons plus en détail les méthodes CATE et SVA dans la partie
[[sec:similar_method]]. Chacun des algorithmes que nous présentons découle de
l'optimisation d'une fonction objectif. Nous montrons que nos algorithmes
d'estimation convergent vers le point de minimum global de leur fonction
objectif respective. Enfin, nous comparons nos méthodes à SVA et CATE sur des
simulations numériques ainsi que des exemples de GWAS, EWAS et GEA.

** Nouvelles méthodes 
*** Modèle mixte à facteurs latents
<<sec:model>>
Dans cette partie nous introduisons les notations du modèle mixtes à facteurs
latents que nous utilisons pour corriger les tests d'association : 
\begin{equation}
\label{eq:model}
\Y = \X \B^T + \U \V^T + \E.
\end{equation}
Dans cette équation, $\Y$ est la matrice, de taille $\Yrow \times \Ycol$, qui
rassemble les observations de $\Ycol$ variables sur $\Yrow$ individus. Par
exemple, la matrice $\Y$ peut contenir des SNPs, des niveaux de méthylation ou
bien des niveaux d'expression génique. Nous appellerons la matrice $\Y$ la
matrice des variable expliquées. La matrice $\X$, de taille $\Xrow \times \Xcol$,
regroupe toutes les variables explicatives. Ainsi les colonnes de $\X$ sont les
variables d'intérêt pour l'association, c'est à dire les variables pour
lesquelles on souhaite trouver les associations avec $\Y$. Les colonnes de $\X$
peuvent être par exemple un phénotype, comme une maladie, ou un gradient
environnemental, comme la température d'un habitat. La matrice des effets de
$\X$ sur $\Y$ de taille $\Ycol \times \Xcol$ est notée $\B$. Si l'on suppose
qu'il y a $K$ variable latentes alors la matrice $\U$ est la matrice des $\K$
variable latentes et $\V$ représente les axes des facteurs latents. Les matrices
$\V$ et $\U$ sont respectivement la matrice des axes factoriels, de taille
$\Ycol\times\Ucol$, et la matrice des coordonnées sur ses axes, de taille $\Urow
\times \K$. Enfin la matrice $\E$ est la matrice d'erreur résiduelle, de taille
$\Yrow\times\Ycol$.

Dans un premier temps, nous remarquons que les matrices $\U$ et $\V$ ne sont pas
définies de façon unique. En effet, comme ces deux matrices sont
multipliées entre elle dans l'équation eqref:eq:model, les matrices $\U$ et
$\V$ sont définies à une matrice inversible prêt puisque
\begin{equation}
\U \V^{T} = \U \matr{R} \matr{R}^{-1} \V^{T}
\end{equation}
où $\matr{R}$ est une matrice inversible de taille $\K \times \K$. Nous posons alors
\begin{equation}
\label{eq:W}
\W = \U \V^{T} 
\end{equation}
et nous appelons la matrice $\W$ la matrice latente. Si l'on suppose qu'il y a $\K$
variables latentes linéairement indépendantes cela est équivalent à faire
l'hypothèse que la matrice latente $\W$ est de rang $\K$. Dans la suite nous
considérons $\U$ et $\V$ comme étant les matrices uniques obtenues grâce à
l'analyse en composantes principales de la matrice latente $\W$.

*** Estimation des moindres carrés régularisée en norme $L_{2}$
<<sec:estimator_L2>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 16:21] \\
  faire bien le lien avec le mpdèle PCA +  lm et lambda = 0 implique on n'a pas de
  solution unique !!
- Note taken on [2017-06-29 jeu. 16:20] \\
  RidgeLFMM et LassoLFMM c'est les non des fonction mais dans les graphe on va
  mettre lasso estimator et ridge estimator.
:END:

Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par l'équation eqref:eq:model. L'algorithme d'estimation est basé
sur un problème des moindres carrées régularisé en norme $L_{2}$. Nous montrons
que cet algorithme calcule un minimum global du problème d'optimisation des
moindres carrés régularisé en norme $\L2$.

**** Fonction objectif 

Afin d'estimer les paramètres $\U$, $\V$ et $\B$ de LFMM, nous définissons la
fonction objectif de type ridge suivante
\begin{equation}
\label{eq:optim_ridge_reg}
\LfmmLridge
\end{equation}
où $\norm{.}_{F}$ est la norme de Frobenius, $\norm{.}_{2}$ est la norme $L_2$
et $\lambRidge$ le paramètre de régularisation. Le premier terme de $\Lridge$,
le terme d'attache aux données. Si il n'y a pas de variable explicative $\X$, le
terme d'attache aux données correspond à la fonction objective de l'analyse en
composantes principales. Le deuxième terme de $\Lridge$, le terme de
régularisation, est indispensable pour séparer les variations de $\Y$ expliquées
par les variables latentes de celles expliquées des variables explicatives. En
effet, si
\begin{equation*}
\lambRidge = 0, 
\end{equation*}
alors pour toute matrice $\matr{P}$, de taille $\Xcol \times \Ycol$, nous avons
\begin{equation*}
\Lridge(\U - \X \matr{P}, \V^{T}, \B + \V \matr{P}^T}) = \Lridge(\U, \V^{T}, \B).
\end{equation*}
Les points du minimum de la fonction objective ne sont pas définis de
manière univoque pour notre problème quand le paramètre de régularisation est
nulle.

**** Algorithme de minimisation de la fonction objectif $\Lridge$
Afin d'estimer les paramètres de LFMM minimisant $\Lridge$ nous commençons par
calculer la décomposition en valeurs singulières de $\X$
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$ de $\X$. Les estimateurs sont calculés de
la façon suivante
\begin{align}
\label{eq:RidgeLfmmEstomatorW}
\hat{\U} \hat{\V}^{T} & =  \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
\label{eq:RidgeLfmmEstomatorB}
\hat{\B}^{T} & = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T}),
\end{align}
où $\svd_{\K}(\matr{A})$ est la meilleure approximation de rang $\K$ de la
matrice $\matr{A}$, donnée par la décomposition en valeurs singulières et
$\Id_{d}$ est la matrice identité de taille $d \times d$. La matrice $\D$ est la
matrice diagonale de taille $\Yrow \times \Yrow$ qui contient les termes
diagonaux suivants
\begin{equation*}
\left\{ \D_{,i,i}\right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}

Notons que l'estimation de la matrice latente $\hat{\U} \hat{\V}^{T}$ dans
l'équation eqref:eq:RidgeLfmmEstomatorW fait intervenir la matrice de changement
de base $\matr{Q}$. Les $\Xcol$ premiers axes de la base canonique transformée
par $\Q$ forment une base orthonormale de l'espace vectoriel engendré par les
variable explicatives $\X$. La matrice diagonale $\D$ a pour effet de ramener
vers zéro la composante qui appartient à l'espace engendré par $\X$. Si
$\lambRidge$ tend vers zéro multiplier $\Y$ par $\D \matr{Q}^{T}$ revient à
prendre le résidu d'une régression linéaire de $\Y$ par $\X$, on enlève alors
toute la part de variance expliquée par $\X$. Mais $\D$ n'est plus inversible.
Si $\lambRidge$ est très grand alors $\D$ tend vers la matrice identité. Dans ce
cas, le calcul de $\hat{\U} \hat{\V}$ revient à faire une analyse en composante
principale de la matrice des variable expliquées $\Y$. Nous expliquons dans la
partie [[sec:hyperparametre]] plus en détail comment choisir l'hyperparamètre
$\lambRidge$.

L'estimation des paramètres régularisé en norme $L_{2}$ est justifier par le
théorème suivant
#+BEGIN_theorem
<<ridge_theorem>> 
Pour $\lambRidge$ strictement supérieur à zéro, l'estimation des
paramètres de LFMM régularisé en norme $L_{2}$, définie par
eqref:eq:RidgeLfmmEstomatorW et eqref:eq:RidgeLfmmEstomatorB, défini un 
minimum global de la fonction objective $\Lridge$.
#+END_theorem

#+BEGIN_proof
On veut trouver $\hat{\U} \in \RR^{\Urow \times \Ucol}$, $\hat{\V} \in
\RR^{\Vrow \times \Vcol}$ et $\hat{\B} \in \RR^{\Brow \times \Bcol}$
correspondant à un minimum global de la fonction $\Lridge$. Commençons par
remarquer que la fonction $\Lridge$ est convexe en la variable $\B$ , on peut
donc trouver le point de minimum global en annulant la dérivée de $\Lridge$ par
rapport à $\B$. Cela conduit a l'équation suivante
\begin{equation}
\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{\Bcol})^{-1} \X^{T} (\Y - \U \V^{T}).
\end{equation}
Il s'agit de l'estimateur ridge du modèle de la régression linéaire de $\Y - \U
\V^{T}$ par $\X$, en supposant que $\U$ et $\V$ sont connues.

Il faut maintenant minimiser la fonction
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \Lridge(\U, \V, \hat{\B}).
\end{align*}
Considérons la décomposition en valeurs singulières de $\X$ telle que 
\begin{equation*}
\X = \matr{Q} \matr{\Sigma} \matr{R}^{T},
\end{equation*}
où $\matr{Q}$ une matrice unitaire de taille $\Xrow \times \Xrow$, $\matr{R}$
une matrice unitaire de taille $\Xcol \times \Xcol$ et $\matr{\Sigma}$ une
matrice de taille $\Xrow \times \Xcol$ contenant les valeurs singulières $\left
\{ \sigma_{j} \left \}_{j = 1..\Xcol}$. L'écriture de $\mathcal{L}^{'}$ se
simplifie comme ceci
\begin{equation*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\D^{2} \matr{Q}^{T} (\Y - \U \V^{T})}^{2}_{F} + 
\frac{1}{2} \lambRidge \norm{\matr{C}_{\lambRidge} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{equation*}
où $\matr{C}_{\lambRidge}$ est une matrice de taille $\Xcol \times \Xrow$
remplie de zéro sauf sur la première diagonale qui contient les valeurs
\begin{equation*}
\left\{ \matr{C}_{\lambRidge, i, i} \right\}_{i = 1..d} = 
\left\{ \frac{\sigma_{i}}{\sigma_{i}^{2} + \lambRidge}\right\}_{i = 1..\Xcol}.
\end{equation*}
La matrice $\D$ est une matrice diagonale de taille $\Yrow \times \Xrow$
contenant les termes 
\begin{equation*}
\left\{ \matr{D}_{\lambRidge, i, i} \right\}_{i = 1..n} = 
\left\{ \sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{1}^{2}}}, ..., 
\sqrt{\frac{\lambRidge}{\lambRidge + \sigma_{d}^{2}}}, 
1, ..., 1 \right\}.
\end{equation*}
Les matrices $\D$ et $\matr{C}_{\lambRidge}$ étant diagonales, par le calcule il
est possible de montrer que
\begin{align*}
\mathcal{L}^{'}(\U, \V) & = \frac{1}{2} \norm{\sqrt{(\D^{2} + 
\matr{C}_{\lambRidge}^{2})} \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2} \\ 
& = \frac{1}{2} \norm{ \D \matr{Q}^{T} (\Y - \U \V^{T})}_{F}^{2}
\end{align*}
Enfin, optimiser la fonction objectif $\mathcal{L}^{'}$ est équivalent au
problème de trouver la meilleure approximation de rang $\K$ de la matrice
\begin{equation*}
\D \matr{Q}^{T} \Y,
\end{equation*}
qui est obtenue en tronquant la SVD pour ne garder que les $\K$ valeurs
singulières les plus grandes cite:Eckart_1936. Nous avons bien montré que
\begin{align*}
&\hat{\U} \hat{\V}^{T} = \matr{Q} \D^{-1} \svd_{\K}( \D \matr{Q}^{T} \Y ) \\
&\hat{\B}^{T} = (\X^{T} \X + \lambRidge \Id_{d})^{-1} \X^{T} (\Y - \hat{\U} \hat{\V}^{T})
\end{align*}
est un point de minimum global de $\Lridge$.
#+END_proof
*** Estimation des moindres carrées régularisée en norme $L_{1}$  
<<sec:estimator_L1>>
:LOGBOOK:
- Note taken on [2017-06-29 jeu. 14:47] \\
  Faire le lien avec les methodes de low rank approximation
:END:
Dans cette partie, nous présentons un algorithme d'estimation des paramètres du
modèle défini par eqref:eq:model basé sur un problème des moindres carrés
régularisé en norme $L_{1}$ et en norme nucléaire. Nous montrons que cet
algorithme calcule un minimum global du problème d'optimisation des moindres
carrés régularisé.

**** Fonction objectif 
Afin d’estimer les paramètres U, V et B de LFMM, nous définissons la fonction
objectif de type lasso suivante
\begin{equation}
\label{eq:optim_lasso_reg}
\LfmmLlasso,
\end{equation}
où $\W$ est la matrice latente définie en eqref:eq:W, $\norm{\B}_{1}$ la norme
$L_1$ de $\B$ et $\norm{\W}_{*}$ la norme nucléaire de la matrice $\W$, définie
comme la somme de ses valeurs singulières. Le choix de la norme $L_{1}$ est
motivé par le fait que l'on s'attend à ce que seulement une certaine proportion
des colonnes de $\Y$ soit associée à $\X$. C'est à dire que seulement une certaine
des lignes de la matrice des effets $\B$ doivent être non nulles. La
régularisation $L_{1}$ est connue pour produire des estimateurs parcimonieux de
$\B$ cite:Tibshirani_1996. La fonction $\Llasso$ fait aussi intervenir une
régularisation sur la matrice latente $\W$. Nous ajoutons cette régularisation
afin de lever la contrainte sur le rang de $\W$ qui ne permet pas de définir un
problème d'optimisation convexe. Avec le terme de régularisation de $\W$, la
fonction $\Llasso$ est convexe. De plus il a été montré que le rang d'un point
de minimum de $\Llasso$ décroît avec $\gamma$ le paramètre de régularisation de
$\W$ cite:bach2008consistency. La régularisation en norme nucléaire contraint le
rang de $\W$ et donc le nombre de variables latentes.

**** Algorithme de minimisation de la fonction objectif $\Llasso$
<<sec:lasso_algo>>

Nous présentons maintenant un algorithme de descente par blocs de coordonnées
qui permet d'estimer les paramètres de LFMM en minimisant la fonction objective
$\Llasso$ définie par eqref:eq:optim_lasso_reg. Nous initialisons l'algorithme
avec des matrices nulles :
\begin{align*}
\hat{\W}_{t = 0} & = 0 \\
\hat{\B}_{t = 0} & = 0.
\end{align*}
Nous alternons ensuite les deux étapes suivantes : 
1. Calculer $\hat{\B}_{t}$ le point minimum de 
   \begin{equation}
   \label{eq:lasso1}
   \mathcal{L}_{\mathrm{lasso}}^{'}(\B) =  \frac{1}{2} ||(\Y - \hat{\W}_{t-1}) - \X \B^T||_{F}^2 + \lambLasso ||\B||_1
   \end{equation}
2. Calculer $\hat{\W}_{t}$ le point minimum de  
   \begin{equation}
   \label{eq:lasso2}
   \mathcal{L}_{\mathrm{lasso}}^{''}(\W) = \frac{1}{2} ||(\Y - \X \hat{\B}_t^T)- \W ||_{F}^2 + \gamma ||\W||_{*}.
   \end{equation}
Ces deux étapes sont répétées jusqu'à ce que l'algorithme converge ou bien que
$t$ atteint le nombre maximum d'itérations. Nous allons maintenant expliquer
plus en détail les deux étapes de l'algorithme. 

La première étape de l'algorithme consiste à faire une régression linéaire
régularisée en norme $L_{1}$ de la matrice résiduelle
\begin{equation}
\matr{E}^{1}_{t} = \Y - \hat{\W}_{t-1}
\end{equation}
par les variables explicatives $\X$. Il existe plusieurs algorithmes pour
estimer les paramètres de cette régression comme par exemple l'algorithme de
descente par coordonnées cite:Friedman_2007. Dans le cas présent on s'intéresse
plus à l'estimation des variables latentes, qui permettrons ensuite de faire le
test d'association (voir la partie [[sec:hypothese]]). Nous supposons que les
variables explicatives $\X$ ont été transformées de sorte que
\begin{equation}
\X^{T} \X = \Id_{d}.
\end{equation}
On a alors d'après cite:Tibshirani_1996,
\begin{equation}
\hat{\B}_{t} = \sign(\bar{\B}_{t}) (\bar{\B}_{t} - \lambLasso)_{+}
\end{equation}
où 
\begin{equation}
s_{+} = \mathrm{max}(0, s),
\end{equation}
$\sign(s)$ est le signe de $s$ et $\bar{\B}_{t}$ est l'estimateur du paramètre
de la régression linéaire classique donné dans ce cas par
\begin{equation*}
\bar{\B}_{t} = \X^{T} \matr{E}^{1}_{t}.
\end{equation*}

La deuxième étape de l'algorithme est un problème d'approximation de rang faible
de la matrice résiduelle 
\begin{equation}
\matr{E}^{2}_{t} = \Y - \X \hat{\B}_{t}^{T},
\end{equation}
Cette approximation est donnée grâce à un seuillage des valeurs singulières de
la matrice $\matr{E}^{2}_{t}$ cite:cai10_singul_value_thres_algor_matrix_compl.
Pour cela, on commence par calculer la décomposition en valeurs singulières de
la matrice résiduelle :
\begin{equation}
\matr{E}^{2}_{t} = \matr{M} \matr{S} \matr{N}^{T},
\end{equation}
où $\matr{M}$ une matrice unitaire de taille $\Yrow \times \Yrow$, $\matr{N}$
une matrice unitaire de taille $\Ycol \times \Ycol$ et $\matr{S}$ une matrice de
taille $\Yrow \times \Ycol$ contenant les valeurs singulières $\left \{ s_{j}
\left \}_{j = 1..\Yrow}$. On a alors 
\begin{equation}
\hat{\W}_{t} = \matr{M} \bar{\matr{S}} \matr{N}^{T}
\end{equation}
où $\bar{\matr{S}}$ est la matrice diagonale formée par les valeurs singulières
de $\matr{S}$ seuillées de sorte que
\begin{equation*}
\bar{s}_{j} = (s_{j} - \gamma)_{+}, ~ j = 1,...,\Yrow.
\end{equation*}
Le seuillage produit des valeurs nulles et ramène vers zéro les valeurs
singulières restantes.

L'algorithme de descente par blocs de coordonnées ne converge pas en général
vers un point minimum quand la fonction objectif n'est pas continûment
différentiable, comme c'est le cas pour $\Llasso$. On peut trouver dans la
littérature des résultats généraux sur les algorithmes par blocs de coordonnées
dans des cas ou la fonction objective n'est pas différentiable cite:Tseng_2001 .
Cependant, les théorèmes démontrés dans cite:Tseng_2001 dépassent largement le
cadre de la convergence de l'algorithme d'estimation $L_{1}$ présenté ici et
complique l'extraction des résultats intéressants. Pour faciliter la
compréhension, nous proposons de démontrer un théorème plus faible qui
s'applique directement à notre cas. Pour cela nous introduisons quelques
notations. Soit la fonction $f$ définie sur son domaine
\begin{equation}
\label{eq:domf}
A = A_{1} \times A_{2} \times ... \times A_{m}
\end{equation}
un produit cartésien d'ensembles fermés et convexes. L'algorithme de descente
par blocs de coordonnées est défini par la formule de récurrence suivante :
\begin{equation}
\label{eq:blokAlgo}
x_{i}^{k+1} \in \mathrm{arg} \min_{\zeta \in X_{i}} f(x_{1}^{k}, ...,x_{i-1}^{k},\zeta,x_{i+1}^{k},..., x_{m}^{k}), ~
i = 1,...,m.
\end{equation}
En nous inspirant des résultats présentés dans cite:Tseng_2001 et de la
proposition 2.7.1 de cite:Bertsekas_1997 qui démontre la convergence de
l'algorithme de descente par bloc de coordonnées dans le cas où la fonction
objectif est différentiable, nous pouvons énoncer le théorème suivant :
#+BEGIN_theorem 
Si $f$ est une fonction continue de $A$ dans $\RR$, convexe et telle que
\begin{equation}
f(x_{1},..., x_{m}) = g(x_{1}, ..., x_{m}) + \sum_{i = 1}^{m} f_{i}(x_{i}),
\end{equation}
où g est convexe et différentiable et les fonctions $f_{i}$ sont continues et
convexes. Soit $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo. Alors tout
point limite de $\{x^{k}\}$ est un point de minimum global de $f$.
#+END_theorem

#+BEGIN_proof 
On note
\begin{equation*}
\bar{x} = (\bar{x}_{1}, ..., \bar{x}_{m})
\end{equation*}
un point limite de $\{x^{k}\}$ la suite générée par eqref:eq:blokAlgo, $\bar{x}$
est bien dans $A$ le domaine de définition de $f$ car cet ensemble est fermé.
Comme $g$ est convexe et différentiable on a pour tout $x \in A$
\begin{align}
\label{eq:lassoProof1}
f(x) - f(\bar{x}) & \geq & \nabla g(\bar{x})(x - \bar{x}) + 
\sum_{i = 1}^{m} (f_{i}(x_{i}) - f_{i}(\bar{x}_{i})) \\
 & & = \sum_{i = 1}^{m} ( \nabla_{i} g(\bar{x})(x_{i} - \bar{x}_{i}) + 
 f_{i}(x_{i}) - f_{i}(\bar{x}_{i}))
\end{align}
où $\nabla g(\bar{x})$ et $\nabla_{i} g(\bar{x})$ sont respectivement la dérivée
et la dérivée par rapport à la $i\text{-ième}$ variable de $g$ en $\bar{x}$.
D'autre part pour chaque variable d'indice $i$
\begin{align}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  (\nabla_{i} g(\bar{x}) + r_{i})(x - \bar{x}) 
\end{align}
où $r_{i}$ est n'importe quelle sous-dérivée de la fonction convexe $f_{i}$ en
$\bar{x}_{i}$. Or nous savons par construction de $\bar{x}$ que
\begin{equation}
\label{eq:lassoProof2}
f(\bar{x}) \leq f(\bar{x}_{1}, ...,x_{i},..., \bar{x}_{m}), ~ \forall x_{i} \in
A_{i}.
\end{equation}
Pour chaque variable $x_{i}$, on peut donc dire que zéro appartient à l'ensemble
des sous dérivées par rapport la variable $x_{i}$ de $f$ en $\bar{x}_{i}$. On
peut alors dire qu'il existe une sous dérivé $r_{i}$ telle quelle que 
\begin{equation}
\nabla_{i} g(\bar{x}) + r_{i} = 0.
\end{equation}
On a finalement pour chaque variable d'indice $i$
\begin{equation}
\label{eq:lassoProof3}
\nabla_{i} g(\bar{x})(x - \bar{x}) + f_{i}(x_{i}) - f_{i}(\bar{x}_{i}) & \geq  0
\end{equation}
Finalement, nous avons en utilisant
eqref:eq:lassoProof3 et eqref:eq:lasso1 que
\begin{equation}
f(x) - f(\bar{x}) \geq 0, ~ \forall x \in A.
\end{equation}
#+END_proof
Ce résultat démontre que l'algorithme d'estimation $L_{1}$ des paramètres du
modèle LFMM converge vers un point de minimum global de $\Llasso$.
*** Complexité des algorithmes
Dans cette partie nous abordons la complexité des algorithmes d'estimation des
paramètres présentés dans les sections précédentes. On peut distinguer deux
grandes étapes dans ces algorithmes. La première est le calcul de la
décomposition en valeurs singulières tronquée : calcul de la matrice latente
défini par l'équation eqref:eq:RidgeLfmmEstomatorW pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{'}$ définie par eqref:eq:lasso2 pour l'estimation
$L_{1}$. La seconde est le calcul de la projection orthogonale sur l'espace
engendré par les variables explicatives $\X$ : calcul de la matrice des effets
définie par l'équation eqref:eq:RidgeLfmmEstomatorB pour l'estimation $L_{2}$ et
la résolution du problème d'optimisation de la fonction
$\mathcal{L}_{\mathrm{lasso}}^{''}$ définie par eqref:eq:lasso1 pour
l'estimation $L_{1}$.

D'après cite:Halko_2011, le calcul des $K$ composantes dominantes de la
décomposition en valeurs singulières demande $O(\Yrow \Ycol \K)$ opérations.
Cette complexité peut être réduite à $O(\Yrow \Ycol \log(\K))$ opérations si on
utilise une méthode avec projections aléatoires, comme celle présentée dans
cite:Halko_2011.

La deuxième étape importante consiste en une projection du résidu de
l' approximation de rang faible sur l'espace engendré par $\X$. Le nombre précis
d'opération dépend des hypothèses qui sont faites sur la matrice $\X$. Dans
l'algorithme d'estimation $L_{1}$ aucune inversion de matrice n'est nécessaire
pour le calcul de $\hat{\B}_{t}$. Mais dans les deux algorithmes, si on s'intéresse
seulement au comportement asymptotique par rapport à $\Yrow$, $\Ycol$ et
$\Ucol$, alors on peut majorer la complexité par $O(\Ycol \Yrow +
\Ucol (\Ycol + \Yrow))$.

Finalement, pour les deux algorithmes, le nombre d'opération est majoré par
$O(\Yrow \Ycol \K)$. L'algorithme d'estimation $L_{1}$ est bien entendu plus
long car il réalise plusieurs fois les opérations de décomposition en valeurs
singulières et de projection. L'algorithme d'estimation $L_{2}$ ne les réalise
qu'une seule fois.

Outre la complexité temporelle il est important d'étudier la complexité de la
taille prise en mémoire, surtout pour ce genre d'algorithme qui prennent en
entrée des données potentiellement trop grandes pour la mémoire vive de
l'ordinateur (RAM). Les algorithmes d'estimation $L_{1}$ et $L_{2}$ ne
nécessitent pas de dupliquer la matrice des variables expliquées $\Y$. En effet,
$\Y$ est de taille $\Yrow \times \Ycol$ et donc la dupliquer pourrait poser des
problèmes sur des ordinateurs ne possédant pas assez de RAM. Il est possible
d'envisager de ne pas charger $\Y$ en RAM et d'accéder au données seulement
quand cela est nécessaire.

*** Choix des hyperparamètres 
<<sec:hyperparametre>>
:LOGBOOK:
- Note taken on [2017-05-25 Thu 11:52] \\
  Pour ridge faire ma petite heuristic pour trouver lambda.
  Pour lasso aussi (chemin de reg).
- Note taken on [2017-05-25 Thu 11:49] \\
  Pour une estimation precise des parametre il y a la cross validation. Sinon
  comme la méthode resemble a l'acp auquel on a enlevé la variance expliqué par X
  on peut utiliser les même éthodes que pour l'acp. Quite à surestimer le nombre
  de facteur lattent.
- Note taken on [2017-05-25 Thu 11:46] \\
  Bien preciser que on veut a tou pris eviter les truc du style j'impute a
  l'arrache avant etc...
:END:

La sélections des hyperparamètres est un problème commun a de nombreuses
méthodes en analyse de données. Nous présentons plusieurs approches pratiques
pour choisir les hyperparamètres qui interviennent dans les algorithmes que nous
avons présentés ici. Nous commençons par présenter les différentes approches
possibles pour choisir le nombre de variables latentes $K$. Nous présentons
ensuite plusieurs heuristiques qui permettent d'aider le choix des paramètres de
régularisation. Enfin nous présentons un algorithme de validation croisée adapté
aux algorithmes que nous avons présentés.

**** Nombre de variables latentes ($K$)
Pour trouver le nombre de variables latentes $\K$ nous proposons d'isoler les
variations de $\Y$ expliquées par les variables latentes à l'aide de la matrice
$\D$ utilisée dans l'estimation $L_{2}$ (voir la section [[sec:estimator_L2]]). Pour
cela on projette $\Y$ sur l'espace orthogonal à $\X$ en prenant $\lambRidge = 0$.
On a alors
\begin{equation}
 \matr{D}_{0} \Q^{T} \Y = \matr{D}_{0} \Q^{T}\U \V^{T} + \matr{D}_{0} \Q^{T} \E.
\end{equation}
On peut ainsi utiliser les méthodes d'estimation du nombre $\K$ de variables
latentes sur la matrice $\matr{D}_{0} \Q^{T} \Y$. Quand il n'y a plus de
variable explicative $\X$ les fonctions objectives des deux algorithmes
d'estimations $L_1$ et $L_2$ présentés ici correspondent à la fonction objective
de l'analyse en composante principales (ACP). Nous utilisons donc les méthodes
d'estimation du nombre composante dans l'ACP sur $\matr{D}_{0} \Q^{T} \Y$. Il
existe de nombreuses approches pour déterminer le nombre de composantes
principales de l'ACP, celle-ci sont très bien expliquées dans
cite:jolliffe1986principal. On peut grouper ses approches en trois catégories.
Les approches subjectives comme l'utilisation du scree plot, il s'agit du graphe
des valeurs singulières de la matrice des données. Les approches basées sur une
modélisation de la distribution des données observées, comme par exemple la
méthode présentée dans cite:choi2014selecting. Les approches basées sur la
validation croisée, comme celle que nous détaillons plus loin. Aucune méthode ne
s'est imposée comme la référence, et il est préférable d'en utiliser plusieurs.
Pour les expériences que nous avons réalisées sur des vraies données, le choix
du nombre de variables latentes $\K$ du modèle LFMM a été fait à partir du scree
plot de $\matr{D}_{0} \Q^{T} \Y$. Nous avons aussi utilisé l'algorithme de
validation croisée que nous présentons dans la section [[sec:CV]].

**** Paramètre de régularisation $L_{2}$
<<sec:paramL2>>
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 16:55]
- Note taken on [2017-07-20 Thu 16:54] \\
  j'y verrai plus claire quand j'aurais choisi lambda pour les vrai data set et
  une fois que la cross validation marchera ou pas...
:END:

Le paramètre de régularisation $L_{2}$ intervient dans le calcul de l'estimation
de la matrice latente décrit dans la partie [[sec:estimator_L2]] par le biais de la
matrice diagonale $\D$. Cette matrice permet de réduire la corrélation entre les
variables expliquées $\Y$ et les variables explicative $\X$ afin de pouvoir
estimer les variables latentes $\U$. Lorsque le paramètre de régularisation
$L_{2}$ tend vers zéro, les variables $\Y$ et $\X$ sont linéairement
décorrélées. Cependant on ne pourra plus inverser la matrice diagonale $\D$. De
plus dans le cas ou les variables latentes sont trop corrélées avec $\X$ alors
on risque de mal estimer celles-ci. Lorsque le paramètre tend vers l'infini
alors la matrice $\D$ tend vers la matrice identité l'estimation des variables
latentes sont données pas l'analyse en composantes principales de $\Y$, sans
prendre en compte $\X$. Le risque est alors d'expliquer par les variables
latentes une partie de la variance de $\Y$ qui devrait être expliquée par $\X$,
et don de passer à coté de certaines associations. Ainsi le choix du paramètre de
régularisation $L_{2}$ est une affaire de dosage, il doit être ni trop grand ni
trop petit. Nous avons remarqué dans les expériences que $\lambdaRidge$ petit
donne les meilleurs résultats dans de nombreux cas.

**** Paramètre de régularisation $L_{1}$
Le paramètre de régularisation $L_{1}$ à un impact sur le nombre de lignes non
nulles dans la matrice des effets $\B$. Seulement une partie des colonnes de
$\Y$ est corrélée avec les variables explicatives $\X$. Ainsi, il est possible
d'interpréter la proportion de lignes non nulles dans $\B$ comme la proportion
des variables qui sont corrélées avec $\X$. Plutôt que de choisir le paramètre
de régularisation, il est plus simple de choisir la proportion de variable
expliquées par $\X$ quand on prend en compte les variables latentes. Pour
trouver un paramètre de régularisation qui correspond à cette proportion nous
proposons une heuristique basée sur un chemin de régularisation inspirée par
cite:friedman10_regul_paths_gener_linear_model. Nous commençons par la plus
petite valeur du paramètre de régularisation $\lambLasso$ tel que le vecteur
\begin{equation}
\hat{\B}_{t = 1} = \sign(\bar{\B}_{t = 1}) (\bar{\B}_{t = 1} - \lambLasso)_{+}
\end{equation}
vaut zéro. Ceci est le résultat de la première étape de l'algorithme
d'estimation des moindres carrés régularisée en norme $L_{1}$ présenté dans la
partie [[sec:estimator_L1]]. Nous notons cette valeur $\lambLasso^{\mathrm{max}}$.
Ensuite, nous construisons une séquence de $m$ valeurs de $\lambLasso$ décroissant
selon une échelle logarithmique depuis $\lambLasso^{\mathrm{max}}$ jusqu'à
\begin{equation}
\lambLasso^{\mathrm{min}} = \epsilon \lambLasso^{\mathrm{max}}.
\end{equation}
Enfin, pour chaque valeur du paramètre de régularisation $\lambLasso$ nous
calculons le nombre de valeurs non nulle dans $\hat{\B}$, l'estimation de la
matrice des effets calculé par l'algorithme d'estimation $L_{1}$, et stoppons si
la proportion de valeurs non nulle souhaitée est dépassée.

**** Paramètre de régularisation de la norme nucléaire
Le paramètre de régularisation de la norme nucléaire dans l'algorithme
d'estimation $L_{1}$ à une influence sur le rang de la matrice latente $\W$. Il
est plus simple de choisir le rang de cette matrice, correspondant au nombre de
variables latentes $K$, que de choisir le paramètre de régularisation $\gamma$.
Nous proposons l'heuristique suivante pour calculer $\gamma$ à partir de $K$.
Nous commençons par calculer les valeurs singulières de la matrice des variable
explicative $\Y$, que l'on note $(\sigma_1, ..., \sigma_{\Yrow})$. Ensuite, nous
calculons
\begin{equation}
\gamma = \frac{(\sigma_{\K} + \sigma_{\K + 1})}{2}.
\end{equation}
Nous avons remarqué dans les expériences que ce choix de paramètre de
régularisation $\gamma$ a toujours fait converger l'algorithme d'estimation
$L_{1}$ vers une estimation de la matrice latente $\hat{\W}$ qui est de rang $\K$.

**** Validation croisée
:LOGBOOK:
- State "TODO"       from              [2017-07-20 Thu 17:00]
- Note taken on [2017-05-26 Fri 14:46] \\
  cf mon cahier
:END:
<<sec:CV>>

La validation croisée est une méthode d'évaluation d'un modèle très utilisée en
apprentissage statistique. Le principe est de séparer les individus en une
partie d'apprentissage et une partie de test. Les individus d'apprentissage sont
utilisées pour estimer les paramètres du modèle. On mesure ensuite l'erreur de
prédiction à l'aide des individus de tests. Pour que la validation croisée
fonctionne il est très important que les individus de test ne soit pas utilisées
pour estimer les paramètres du modèle. Dans le cas des modèles à facteurs
latents en général, les individus d'apprentissage ne permettent pas de calculer
les variables latentes pour les individus de tests (la matrice $\U$ dans pour
LFMM). Le plus simple est de séparer les variables des individus de test et d'en
utiliser une partie pour estimer les variables latentes et l'autre partie pour
calculer l'erreur de prédiction cite:Bro_2008. Nous présentons maintenant plus
formellement notre procédure de validation croisée.

Nous commençons par séparer les individus en une partie d'entraînement et une
partie de test, c'est a dire que nous séparons les matrices $\Y$ et $\X$ en deux
parties selon leurs lignes. Nous notons $I$ l'ensemble des indices des individus
choisies pour estimer l'erreur de prédiction. On estime à partir des individus
d'apprentissage la matrice des axes factoriels que l'on note $\hat{\V}_{-I}$ et
la matrice des effets que l'on note $\hat{\B}_{-I}$. Ensuite, nous la matrice de
test $\Y[I,]$ en deux partie selon ses colonnes afin d'estimer les variables
latentes sur les variables restantes. On notera $J$ l'ensemble des colonnes de
$\Y$ sélectionnées pour estimer de la matrice des variables latentes de la façon
suivante
\begin{equation}
\hat{\U}_{-J} = (\Y[I,-J] - \X[I,] (\hat{\B}_{-I}[J,])^{T}) \hat{\V}_{-I}[-J,]^{T}.
\end{equation}
Enfin, on peut calculer l'erreur de prédiction comme ceci
\begin{equation}
\label{eq:2}
\mathrm{err} = \frac{1}{|I| |J|} \norm{\Y[I, J] - \hat{\U}^{-J} \hat{\V}_{-I}[J,]^{T} - \X[I, ] \hat{\B}_{-I}[J,]^{T} }_{F}.
\end{equation}
Cette procédure permet bien de mesurer une erreur sur des observations des
variables expliquées qui n'ont pas été utilisées pour estimer les paramètres du
modèle.

*** Tests d'hypothèse corrigés pour les facteurs de confusions
<<sec:hypothese>>
:LOGBOOK:
- Note taken on [2017-08-04 ven. 17:14] \\
  Mais il y a aussi
  les autres variables observées qui doivent être prises en compte car elles sont
  potentiellement des facteurs de confusion pour l'association. Les variables
  explicatives qui ne sont pas d'intérêt pour l'association peuvent être par
  exemple l'age des individus, ou bien le sexe
- Note taken on [2017-05-25 Thu 11:55] \\
  parler de lm : G ~U + X 
  ET
  la recalibration par mad + median
:END:

Jusque ici, nous avons seulement abordé l'estimation des paramètres de LFMM.
Cependant, l'objectif initial est de trouver la liste des colonnes de $\Y$
associées aux variables $\X$ tout en prenant en compte les variables latentes.
Nous présentons dans cette partie un test d'hypothèse de nullité de l'effet de
$\X$ sur $\Y$ corrigé pour les variables latentes. Une approche simple consiste
à considérer l'estimation des variables latentes $\hat{\U}$ comme les vraies
valeurs de $\U$ et de les utiliser au coté des variables $\X$ du modèle mis en
place pour réaliser le test d'hypothèse. C'est une méthode très courante dans
les études d'associations qui a montré de très bons résultats quand il y suffisamment
d'individus
cite:gerard2017unifying,Price_2006,Song_2015,article_Leek_Storey_2008,Rahmani_2016.
Nous avons choisi de réaliser un test d'hypothèse qui repose sur la
régression linéaire car cela correspond au modèle LFMM quand on suppose que $\U$
est connue. Les estimations des variables latentes peuvent être traitées
comme variables explicatives dans n'importe quel modèle statistique. On pourrait
par exemple envisager d'utiliser une régression linéaire
généralisée. Afin de simplifier les notations et sans perte de généralité, nous
supposons qu'il n'y a qu'une seule variable explicative, c'est à dire que
$\Xcol$ vaut $1$. De plus, nous signalons qu'il est possible d'ajouter d'autres
variables à la régression, cela à un intérêt si l'on connait des variables qui
sont des facteurs de confusion pour notre étude d'association, comme par exemple
le l'age et le sexe des individus. Nous rappelons que l'estimation de la matrice
des $\K$ variables latentes $\hat{\U}$ est définie de façon unique grâce à l'ACP
de la matrice $\hat{\W}$. La matrice $\hat{\W}$ est estimé grâces aux
algorithmes d'estimation $L_{1}$ ou $L_{2}$ de la matrice latente du modèle
LFMM.

**** Calcul de la statistique de test
Pour chaque variable expliquée $\Y_{j}$ nous avons la régression linéaire
suivante
\begin{equation}
\Y_{j} =  \hat{\U} \matr{\gamma}_{j}^{T} + \X \beta_{j} + \matr{E_{j}},
\end{equation}
où la matrice $\hat{\U}$ est l'estimation de la matrice des variables latentes
du modèle LFMM. On suppose que l'erreur $E_{j}}$ est Gaussienne de moyenne
nulle. On veut tester l'hypothèse de nullité du coefficient de régression
$\beta_{j}$. Sous ces hypothèses on peut calculer pour chaque variable expliquée
$\Y_{j}$ une statistique de test $z_{j}$, assimilable à un z-score. La
statistique de test suit sous l'hypothèse nulle le loi de Student à $\Yrow -
\K - 1$ degrés de liberté. On peut donc calculer une \pvalue pour chaque
variable expliquées $\Y_{j}$. Le détail du calcul de la statistique de test est
donnée dans la section 3.2 de cite:Hastie_2009.


**** Calibration du test d'hypothèse
<<sec:calibration>> Il arrive parfois que la statistique de suive pas la
distribution théorique sous l'hypothèse nulle. On dit dans ce cas que le test
est mal calibré. On peut trouver dans cite:Efron_2004 des exemples de situations
qui peuvent aboutir à des tests mal calibrés. Dans les exemples que nous
présentons ici ont s'attend à ce que la majorité des variables expliquées
$\Y_{j}$ ne soit pas associé avec $\X$, ainsi une large majorité des
statistiques de test sont distribuées selon l'hypothèse nulle. Nous utilisons
l'approche choisie dans cite:Sun_2012, qui consiste à calculer la médiane et la
déviation absolue à la médiane (MAD pour median absolute déviation) directement
sur les $z$ statistiques. En effet, la médiane donne une estimation robuste de
la moyenne et le MAD de l'écart type. On a alors une nouvelle statistique de
test
\begin{equation}
\tilde{z_{j}} = \frac{z_{j} - \med(z_{1}, ..., z_{\Ycol})}{
\mad(z_{1}, ..., z_{\Ycol})}.
\end{equation}
Pour calculer les nouvelles \pvalues, on suppose que $\tilde{z_{j}}$ suit une loi
normal de moyenne nulle et d'écart type 1 sous l'hypothèse nulle.

**** Contrôle du taux de fausse découverte                      :noexport:
:LOGBOOK:
- Note taken on [2017-07-19 Wed 10:44] \\
  non si je fais une partie la dessus il va falloir que je developpe !! alors que
  je veux juste dire que j'ai utilisé qvalue....
:END:
Dans cette dernière partie, nous présentons en quelques mots les outils que nous
avons utiliser pour contrôler le taux de fausse découvertes dans les
experiences. Dans le cadre des test d'association nous voulons en sortie de la
méthode obtenir une liste de colonnes de $\Y$ candidates pour l'association avec
la variable explicative. Pour choisir cette liste Dans le cadre des test
d'association multiple....................

*** Implémentation en R
Les deux nouvelles méthodes de test d'association avec correction pour les
facteurs de confusion que nous avons développées dans cette thèse ont été
implémentées en R. Nous les avons appelées respectivement lassoLFMM pour
l'implémentation des estimateurs régularisées en norme $L_{1}$ et ridgeLFMM pour
les estimateurs régularisées en norme $L_{2}$. Les algorithmes lassoLFMM et
ridgeLFMM prennent en entrée la matrice $/X$ et la matrices $/Y$ à associer avec
$/X$. Ils prennent également le nombre de variables latentes $\K$. L'algorithme
ridgeLFMM prend une valeur pour $\lambLFMM$, le paramètre de régularisation
$\L_{2}$. L'algorithme lassoLFMM prend la proportion de lignes non nulles dans
la matrice $\B$, la matrice des effets de $\X$ sur $\Y$. Enfin les deux
algorithmes retournent les estimations pour les paramètres de LFMM ainsi qu'une
\pvaleur pour le test d'association de chaque colonne de $\Y$ avec $\X$.
** Autres méthodes existantes comparées
<<sec:similar_method>>

Dans cette section nous présentons des méthodes pour l'étude d'association avec
et sans correction pour les facteurs de confusions. Les méthodes que nous
présentons ici sont comparées aux méthodes lassoLFMM et ridgeLFMM dans la
section Résultats.

*** Régression linéaire simple et avec les scores de l'ACP
Dans lassoLFMM et ridgeLFMM, les tests d'hypothèses utilisés pour détecter les
associations reposent sur une régression linéaire de $\Y$ par $\X$ et
l'estimation des facteurs latents $\bar{\U)}$. Il est donc naturel de se
comparer à la méthode de test d'hypothèse nullité de l'effet dans la régression
linaire de $\Y$ par $\X$. Dans ce cas aucun facteur latent n'est pris en compte
dans l'étude d'association. De plus, nous nous comparons à une méthode qui
repose sur une estimation des variables latentes par l'ACP. Dans ce cas, il
s'agit alors de faire une régression de $\Y$ par $\X$ et $\bar{\U)}$ la matrice
des scores sur les $\K$ premières composantes principales. Ces deux méthodes ont
été implémentées en R et nous les appellerons respectivement lm et PCAlm.

*** COMMENT emma cite:Kang_2008
:LOGBOOK:
- Note taken on [2017-08-07 lun. 10:23] \\
  Non on va pas ajouter emma aux méthodes ca serais trop compliqué.
:END:
*** sva cite:article_Leek_Storey_2007
:LOGBOOK:
- Note taken on [2017-08-05 Sat 13:57] \\
  sva utilisé:[[file:Rpackage/R/ExpRmethod-sva.R::ExpRmouline.method_sva%20<-%20function(m,%20dat)%20{][sva function]]
:END:

Il existe deux versions de SVA : sva-two-step cite:article_Leek_Storey_2007 et
sva-irw cite:article_Leek_Storey_2008. La méthode sva-two-step se découpe en
deux étapes : une étape d'estimation de la matrice des axes factorielles $\V$ et
une étape d'estimation de la matrice des variables latentes $\U$. Lors de la
premières étape la méthode sva-two-step estime les axes factorielles en faisant
une ACP de la matrice résiduelles de la régression linaire de $\Y$ par $\X$.
Cela correspond à aire l'ACP de $\matr{D}_{(\lambRidge = 0)} \Q^{T} \Y$, en
utilisant les notations de la section [[sec:estimator_L2]]. Ensuite la méthode
sva-two-step calcule un sous-ensemble de colonnes de $\Y$ qui sont le moins
corrélées avec $\X$. Ce sous ensemble de colonnes est utilisées pour estimer la
matrice des variables latentes $\U$. Cette procédure peut facilement échouer car
une faible corrélation avec $\X$ n'implique pas qu'il n'y a pas d'association
avec $\X$. En effet une faible corrélation sans prendre en compte les facteurs
latents peut devenir une forte corrélation quand on les prend en compte.

La deuxième version de SVA est itérative. Plutôt que d'estimer les variables
latentes sur un sous ensemble de colonnes de $\Y$ la méthode sva-irw attribue un
poids à chacune d'entre elles. Pour chaque colonnes de $\Y$, on calcule la
probabilité que l'effet de $\X$ sur la colonne sachant les variables les
variables latentes calculées à l'itération précédente soir nul. Ensuite les
probabilités sont utilisées pour attribuer un poids à chaque colonne de $\Y$ et
une nouvelle estimation des variables latentes est calculée à l'aide d'une ACP
qui prend en compte ces poids. La méthode itère ces deux étapes un nombre de
fois choisi par l'utilisateur. Le désavantage de cette procédure est qu'on ne
sais pas vers quoi elle converge ni si elle converge. Nous avons utilisé le
package R sva fourni par ses auteurs.

*** cate cite:wang2015confounder

Nous présentons dans cette partie la méthode cate, nous considérons le cas où il
n'y à qu'une variable explicative $\X$ pour faciliter les explications. Dans la
méthode cate on commence par transformer la matrice des variables expliquées
$\Y$ afin d'isoler les variations expliquées par les facteurs latents. Pour cela
on applique une matrice de changement de base aux lignes de $\Y$ de sorte que le
premier axe de la nouvelle base soit colinéaire à $\X$. Cette transformation
permet d'avoir sur le premier axe les coefficients de la régression linéaire de
$\Y$ par $\X$ et sur tout les autres axes le projeté orthogonale de $\Y$ par
rapport à $\X$ correspondant aux résidus de cette régression. La méthode cate
utilise alors les $\Yrow - 1$ autres lignes pour calculer les axes factorielles
notés $\V$ dans nos notations. Cette première étape est comparable à l'étape de
calcul de $\V$ dans notre méthode ridgeLFMM (voir partie [[sec:estimator_L2]]). Dans
ridgeLFMM, plutôt que d'enlever complétement les variations de $\Y$ expliquées
par $\X$ nous la réduisons en fonction du paramètre de régularisation
$\lambRidge$. Comme cela a été montré dans cite:wang2015confounder sva et cate
estime la même matrice des axes factorielles qui correspond en faite à celle
estimée par ridgeLFMM dans le cas ou $\lambRidge$ vaux zéro. La méthode cate
diffère de sva dans sa façon de calculer les variables latents et les effets de
$\X$ sur $\Y$. Pour cela les auteurs de cate ont modélisé explicitement la
corrélation entre les variables explicatives $\X$ et les variables latentes $\U$
tel que
\begin{equation}
\label{eq:cateU}
\U = \X \bm{\alpha}^{T} + \matr{Z}.
\end{equation}
Comme la matrice $\Z$ est orthogonale à $\X$ elle est estimée en même temps que
la matrice des axes factorielles $\V$. Pour estimer la matrice $\bm{\alpha}$ la
méthode cate utilise la première ligne de la matrice $\Y$ transformées dans la
base où le premier axe est colinéaire à $\X$. En effet en injectant
eqref:eq:cateU dans l'équation de LFMM eqref:eq:model on peut écrire la matrice
des coefficients de régression de $\Y$ par $\X$, notée $\bm{\tau}$, comme ceci
\begin{equation}
\bm{\tau} = \B + \V \bm{\alpha}^{T},
\end{equation}
où $\B$ est la matrice des effets dans l'équation eqref:eq:model. La méthode
cate estime ensuite $\bm{\alpha}$ en faisant une régression linéaire robuste de
$\bm{\tau}$ par son estimation de la matrice des axe factorielles $\V$ et $\B$
est calculé comme le résidu de cette régression. La régression robuste permet
d'enlever de l'estimation de $\bm{\alpha}$ les effets atypiques qui
correspondent aux colonnes de $\Y$ associés à $\X$ que l'on cherche. Nous avons
utilisé le package R cate fourni par ses auteurs.

** Résultats
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none :session *krakR* :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
:END:

#+NAME: code:krakR
#+begin_src R 
  Sys.info()["nodename"]
  getwd()
#+end_src

#+RESULTS: code:krakR
:             nodename 
: "krakenator.imag.fr"
: [1] "/home/cayek/Projects/Thesis/MaThese"

Dans cette partie, nous présentons les expériences numériques que nous avons
réalisées pour évaluer la performance de nos algorithmes de correction pour les
facteurs confusions dans les études d'associations qui repose sur une estimation
$L_{1}$ et $L_{2}$ des paramètres de LFMM. Ces deux nouveaux algorithmes ont été
implémentés dans le langage de programmation R et seront appelés respectivement
ridgeLFMM pour l'estimation $L_{2}$ et lassoLFMM pour l'estimation $L_{1}$. Nous
nous sommes comparé aux méthodes que nous avons présentées dans la partie
[[sec:similar_method]]. Les méthodes de régression linéaires avec et sans les scores
de l'ACP ont été implémenté dans le langage R et sont respectivement appelées lm
et PCAlm. Pour les méthodes cate, sva-irw et sva-two-step nous avons
respectivement utilisé leurs implémentations R mises à disposition par leurs
auteurs respectifs.
*** Comparaison des méthodes sur des données simulées
**** Simulation à partir de données réelles
:LOGBOOK:
- Note taken on [2017-08-03 jeu. 16:10] \\
  [[file:Rpackage/R/ExpRsampler-fromTrueData.R::ExpRmouline.ExpRsampler_fromTrueData%20<-%20function(s)%20{][La fonction sampler]]
:END:
Afin de comparer la performance des méthodes sur une étude d'association pour
laquelle nous connaissons la vérité, c'est à dire les colonnes de $\Y$ qui sont
associé à $\X$, nous avons réalisé des simulations à partir d'une matrice $\Y$
issue d'un vrai jeu de données. Pour cela nous réalisons une analyse en
composante principale de $\Y$ et ne gardons que les $\K$ premières composantes
en fonction du nombre $\K$ de facteurs de confusion que l'on souhaite simuler.
On a alors
\begin{equation}
\Y = \U \V^{T} + \E
\end{equation}
où $\V$ est la matrice des $\K$ axes principaux orthogonaux et $\U$ la matrice
des variables latentes calculés par l'ACP. La matrice $\E$ est la matrice
residuelle. Nous simulons ensuite la variable d'intérêt pour l'association
$\X^{'}$ et $\K$ variables latentes $\U^{'}$ en choisissant la corrélation entre
chaque variable latente et $\X^{'}$. De plus les variables latentes sont
simulées de sorte quelles aient la même structure de covariance que les
variables latentes calculées par l'ACP. Les matrices $\U^{'}$ et $\X^{'}$ sont
simulées à l'aide de la loi normale multidimensionnelle. Enfin nous calculons
une matrice des effets $\B^{'}$ de sorte qu'une certaines proportion des lignes
de $\B^{'}$ soit non nul et tiré selon à une loi normale. Nous calculons alors
la nouvelle matrice des variables explicatives tel que
\begin{equation}
\Y^{'} = \U^{'} \V^{T} + \X^{'} \B^{'}^{T} + \E.
\end{equation}
Nous avons ainsi des données pour lesquelles nous savons quelles colonnes de
$\Y^{'}$ est associées avec la variable $\X^{'}$, il s'agit des lignes non
nulles de la matrice $\B^{'}$. Nous utilisons de plus la structure lattente
d'une matrice de données déjà existante ce qui permet d'avoir des simulations
plus réalistes.

Le vrai jeu de données que nous avons choisi pour réaliser les simulations est
issu du jeu de données 1000Genome que nous présentons dans la partie [[sec:GEAS]].
Nous avons gardé seulement le chromosome 1 et 2, cela permet de simuler une
matrice de variable expliquées $\Y^{'}$ composée de 52211 variables pour 1758
individus. Nous avons choisi de simuler 5 variables latentes pour plusieurs
valeurs de la corrélation entre $\X^{'}$ et ces 5 variables latentes. Pour
chaque variable latente une valeur entre $-1$ et $1$ de la corrélation avec
$\X^{'}$ est tirée selon une loi uniforme et multipliée par un coefficient que
l'on nome $\rho$ prenant une des valeurs suivantes: $0.1$, $0.3$, $0.5$, $0.8$
ou $1$. Le même coefficient $\rho$ est utilisé pour calculer toutes les
corrélations. Plus le coefficient $\rho$ est proche de 1 plus les variables
latentes seront corrélées à $\X^{'}$ et donc plus la confusion lors du test
d'association de $\X^{'}$ avec $\Y^{'}$ sera importante. Nous avons de plus
choisi une proportion des variables expliquées associées avec la variable
explicative valant $1\%$, $5\%$, $10\%$, $15\%$ ou $20\%$. Pour chaque paramètre
de simulation nous avons simulé $5$ jeux de données ce qui donne un total de 125
jeux de données.

**** Mesure de comparaison des performances
Pour comparer les méthodes entre elles nous avons choisi deux critères. Chaque
méthode renvoie une \pvalue pour chaque colonne de $\Y$. Afin d'évaluer la
capacité des méthodes à détecter le plus possible d'association sans se tromper
nous avons calculer l'aire sous la courbe de précision-rappel, noté AUC, pour
chacune des méthodes. Nous rappelons que pour une liste de candidats données la
précision est le nombre de vraies associations dans la liste divisé par la
taille de la liste et le rappel est le nombre de vraies associations retrouvées
dans la liste divisé par le nombre total des vraies associations. Le rappel est
parfois appelé puissance en statistique. Une méthode qui donne les plus petites
\pvalues permettant de séparer parfaitement les vraies associations du reste
donne une aire sous la courbe de précision-rappel de 1. 

Le deuxième critère de comparaison des méthodes permet d'évaluer la calibration
des \pvalues renvoyées par les méthodes. Pour cela nous calculons le facteur
d'inflation sur les \pvalues attribuées aux variables non associées avec $\X$.
Si les \pvalues sont bien calibrées alors la distribution des \pvalues
attribuées aux colonnes de $\Y$ non associées avec $\X$ suivent une loi uniforme
et donc le facteur d'inflation vaux 1. Une méthode qui renvoie des \pvalues
correctement calibrées permet de calculer une liste de candidats avec un taux de
fausses découvertes moyen contrôlé à une valeur choisie. Pour cela on peut par
exemple utiliser l'algorithme de Benjamini-Hoshberg
cite:benjamini1995controlling ou bien le package qvalue cite:Storey_2011. Une
bonne méthode doit donc à la fois être capable de détecter les vrais
associations sans se tromper mais aussi de fournir des \pvalues correctement
calibrées pour permettre une utilisation des algorithmes de contrôle du taux de
fausse découverte.

**** Résultats
Sur les 125 jeux de données simulés nous avons lancé les méthodes lm, PCAlm,
sva-irw, sva-two-step, cate et les deux méthodes présentées dans cette thèse
lassoLFMM et ridgeLFMM. De plus, nous avons considéré une méthode oracle qui
fait le test d'association entre $\Y$ et $\X$ en connaissant les variables
latentes de la simulation. Les résultats sont résumés dans la Figure
ref:fig:method_comp. Les méthodes cate, lassoLFMM et ridgeLFMM ont les mêmes
performances que l'oracle sur toutes les simulations. Nous constatons toutefois
une exception sur les simulations avec un paramètre $\rho$ de corrélation entre
la variable explicative $\X$ et les variable latentes de $1$ pour cate et
ridgeLFMM qui renvoie des \pvalues avec un taux d'inflation moyen de $3.3$ alors
que celui de lassoLFMM vaux $1.3$ et celui de l'oracle $1.0$ (Figure
ref:fig:method_comp D). Les méthodes cate et ridgeLFMM donnent des résultats
très proches sur toutes les simulations. Les performances de la méthode lm sont
sensible au paramètre de corrélation $\rho$, lorsque celui-ci vaux $0.1$ l'AUC
et le facteur d'inflation de lm est presque égal à ceux de l'oracle mais le
facteur d'inflation croit jusqu'à plus de 30 et l'AUC décroit jusqu'à la moitié
de celui de l'oracle pour $\rho$ valant 1 (Figure ref:fig:method_comp B et D).
Les \pvalues de la méthode PCAlm sont toujours correctement calibrées puisque le
facteur d'inflation est toujours autour de 1 (Figure ref:fig:method_comp C et
D). Cependant l'écart de l'AUC de PCAlm avec l'AUC obtenu par l'oracle croit
avec la proportion de vrais associations et le paramètre de corrélation $\rho$
(Figure ref:fig:method_comp A et B). Enfin sva-two-step et sva-irw renvoient des
\pvalues correctement calibrées sauf quand le paramètre de corrélation $\rho$
vaut 0.8 et 1.0 (Figure ref:fig:method_comp C et D). L'AUC de sva-irw est
toujours en dessous de l'AUC de l'oracle pour toute les proportions de vrais
associations dans les simulations (Figure ref:fig:method_comp A) et la
différence de l'AUC de sva-irw avec de l'AUC de l'oracle croit avec le paramètre
de corrélation $\rho$ (Figure ref:fig:method_comp B). Nous observons également
que l'AUC de sva-two-step est très légèrement en dessous de l'AUC de l'oracle
pour toute les proportions de vrais asociations dans les simulations (Figure
ref:fig:method_comp A) et comme pour sva-irw la différence de l'AUC de
sva-two-step avec de l'AUC de l'oracle croit avec le paramètre de corrélation
$\rho$ mais plus faiblement que pour sva-irw (Figure ref:fig:method_comp B).

#+BEGIN_EXPORT latex
\begin{sidewaysfigure}[ht]
\centering
\includegraphics{./OUTPUT/Rplots/method_comp.pdf.png}
\caption{Comparaison des méthodes sur des simulations faites à partir du jeux de
  données 1000Genomes. A-B) Aire sous la courbe précision-rappel en fonction
  respectivement de la proportion de colonnes de $\Y$ associées à $\X$ et la
  corrélation de la variable explicative $\X$ avec les variables latentes. C-D)
  Facteur d'inflation calculé sur les variables nulles en fonction
  respectivement de la proportion de colonnes de $\Y$ associées à $\X$ et la
  corrélation de la variable explicative $\X$ avec les variables latentes.}
\label{fig:method_comp}
\end{sidewaysfigure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Échantillonnage des données
CLOSED: [2017-08-06 Sun 14:42]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_sampler
#+CAPTION: Le sampler qui a été utilisé pour la validation numérique. Dépend de [[code:1000g_G_valNum]]
#+begin_src R 
  library(MaTheseR)
  ### The sampler
  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds"
  K <- 5
  s <- ExpRsampler_fromTrueData(Y = Y, K = 5, prop.outlier = 0.05, cs = NULL, rho.B = 1.0)
  saveRDS(s, "./OUTPUT/Sampler/validation_numerique.rds")

  sv <- s$load.env$svd$d
  var <- sv / sum(sv)

  ## screePlot
  pl <- qplot(seq_along(var), var) +
    coord_cartesian(xlim = c(1,100))
  pl
  save_plot_png(pl, "valNum_screePlot.png")

#+end_src

#+RESULTS: code:num_val_sampler
[[./OUTPUT/Rplots/valNum_screePlot.png]]

#+NAME: code:num_val_dat
#+CAPTION: On sample les données. Dépend de [[code:num_val_sampler]]
#+begin_src R 
  ## sample all data
  library(MaTheseR)
  sampler <- readRDS("./OUTPUT/Sampler/validation_numerique.rds")
  rep.nb.sampler <- 5
  prop.outlier <- c(0.01, 0.05, 0.1, 0.15, 0.2)
  rho.B <- 3
  rho.c <- c(0.1, 0.3, 0.5, 0.8, 1.0)
  nb.cluster <- 12
  library(foreach)
  library(doParallel)

  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  dat.files <-
    foreach(p = prop.outlier, .combine = 'c') %:%
    foreach(rho = rho.c, .combine = 'c') %:%
    foreach(i = 1:rep.nb.sampler, .combine = 'c') %dopar%
    {
      s <- sampler
      s$prop.outlier = p
      s$rho.B = rho.B
      s$rho.c = rho
      dat <- ExpRmouline(s)
      dat$meta$i <- i
      save_dat(dat, "ValNum", "1000g12", p = p, rho = rho, i = i, rho.B = rho.B)
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)
  save_dat(dat.files, "ValNum", "dat_list")

#+end_src
***** DONE Run des méthodes
CLOSED: [2017-08-14 lun. 11:28]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:28]
- Note taken on [2017-08-10 jeu. 10:24] \\
  ok mes méthodes performe bien :D on peut lancer le reste !!!
- Note taken on [2017-08-06 Sun 14:42] \\
  tail -f ValNum.y2017_m08_d06.log
- State "RUNNING"    from              [2017-08-06 Sun 14:42]
:END:
#+NAME: code:num_val_expr
#+CAPTION: Expérience de comparaison des méthodes sur les simulations. Dépend de [[code:num_val_dat]]
#+begin_src R 
  library(MaTheseR)
  library(foreach)
  library(doParallel)

  dat.files <- readRDS("./OUTPUT/Dat/ValNum/dat_list_cc6919e751d0b2b138c81d2abc21696a.rds")

  ## param
  K.method <- 5
  nb.cluster <- 4

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = NULL, lambda.num = 100,
                              relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method, method = "irw")
  m.sva_twostep <- method_sva(K.method, method = "two-step")
  m.oracle <- method_oracle()

  methods <- m.ridgeLfmm * param(force = FALSE, save = TRUE) +
    m.lm * param(force = FALSE, save = TRUE) +
    m.pca * param(force = FALSE, save = TRUE) +
    m.cate * param(force = FALSE, save = TRUE) +
    m.lasso * param(force = FALSE, save = TRUE) +
    m.oracle * param(force = FALSE, save = TRUE) + 
    m.sva_twostep * param(force = FALSE, save = TRUE) +
    m.sva_irw * param(force = FALSE, save = TRUE)
  ##   m.famt * param(force = FALSE, save = TRUE)

  ## main loop
  message("=== Main loop.")
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  df.res <-
    foreach(f = dat.files, .combine = 'rbind') %dopar%
    {
      dat <- readRDS(f)
      res <- data.frame()
      for (m in methods) {
        ## on force
        if (m$force) {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        } else if (exist_res(m , f)) {
          message("Retrieving", m$name)
          m.res <- retrieve_res(m , f)
        } else {
          message("Running", m$name)
          m.res <- ExpRmouline(m, dat)
          ## save
          if (m$save) {
            message("Saving", m$name)
            save_res(m, m.res, f)
          }
        }
        res <- ExpRextractor_fdr(dat, m.res, rep.sampler = dat$meta$i, rep.method = 1) %>%
          rbind(res)
        rm()
      }
      res
    }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save
  save_expr(df.res, "validation_numerique.rds")
  gc()

  ## plot auc
  toplot <- df.res %>%
    dplyr::filter(pvalue.index == "pvalue1") %>%
    dplyr::mutate(grid.x = prop.outlier, grid.y = rho.c)
  pl <- plot_AUC_boxplot(toplot)
  save_plot_png(pl, "validation_numerique_auc.png")
  pll <- plot_gif_boxplot(toplot)
  save_plot_png(pll, "validation_numerique_gif.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/validation_numerique_auc.png]]
[[./OUTPUT/Rplots/validation_numerique_gif.png]]

***** DONE Plots
CLOSED: [2017-08-14 lun. 11:47]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-14 lun. 11:47]
- State "RUNNING"    from "STARTED"    [2017-08-14 lun. 11:29]
- Note taken on [2017-08-08 mar. 13:48] \\
  j'attend que ca finisse ! et je filtrerais les couleurs et les nom des méthodes
  !
- State "STARTED"    from "RUNNING"    [2017-07-25 mar. 16:35]
- State "RUNNING"    from "DEBUG"      [2017-07-25 mar. 10:57]
- State "DEBUG"      from "TODO"       [2017-07-24 lun. 17:32]
- Note taken on [2017-07-24 lun. 17:31] \\
  Je sais pas ce j'ai foutu mais c'est super lourd !! ca doit être les test, faut
  que je les enleve du coup ! je vais le faire à part ! Et ca n'a pas exporter les
  bon res. ca plot pas les bonnes choses !
- Note taken on [2017-07-17 Lun 08:15] \\
  L'experience est fini il faut faire le plot et l'anova !!!
- State "TODO"       from              [2017-07-06 jeu. 15:24]
:END:

#+NAME: code:num_val_auc_gif_df
#+CAPTION: Calcul de l'auc et le gif. Dépend de [[code:num_val_expr]]
#+begin_src R
  require(MaTheseR)

  expr <- readRDS("./OUTPUT/Expr/validation_numerique.rds")

  auc.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_auc()
  save_expr(auc.df, "auc.df.rds")

  gif.df <- expr %>%
    group_by(method, prop.outlier, rho.c, rep.sampler, rep.method) %>%
    compute_gif()
  save_expr(gif.df, "gif.df.rds")
#+end_src

****** DONE Plots
CLOSED: [2017-08-14 lun. 11:46]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-08-14 lun. 11:46]
- Note taken on [2017-07-30 Sun 12:28] \\
  on attend que l'expr soit finis !!
- State "STARTED"    from "DONE"       [2017-07-30 Sun 12:28]
- State "DONE"       from "TODO"       [2017-07-30 Sun 12:28]
- Note taken on [2017-07-30 Sun 12:28] \\
  avec les barplot c'est pas mal !!
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_plot
#+CAPTION: Depend de [[code:num_val_auc_gif_df]]
#+begin_src R
  ## Compute plot !
  require(MaTheseR)
  MaTheseR.params <- get_MaTheseRparams()
  library(gridExtra)
  library(forcats)
  library(tidyverse)
  library(latex2exp)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds") 
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds") 


  ## filter and order method
  auc.df <- auc.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  auc.df$method %>% unique()
  gif.df <- gif.df %>%
    dplyr::mutate(method = factor(article3_method_name(method), method.ordered))
  gif.df$method %>% unique()

  #################
  ## by prop outlier

  ## auc
  toplot <- auc.df %>%
    group_by(method, prop.outlier) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.prop.pl, "num_val_auc_prop.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, prop.outlier) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.prop.pl <- ggplot(toplot, aes(x = as.factor(prop.outlier), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.prop.pl, "num_val_gif_prop.png")


  #################
  ## by rho

  ## auc
  toplot <- auc.df %>%
    group_by(method, rho.c) %>%
    summarise(auc.mean = mean(auc), N = length(auc), sd = sd(auc), se = sd / sqrt(N))
  auc.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = auc.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = auc.mean - se,
                      ymax = auc.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(auc.rho.pl, "num_val_auc_rho.png")

  ## gif
  toplot <- gif.df %>%
    group_by(method, rho.c) %>%
    summarise(gif.mean = median(gif), N = length(gif), sd = mad(gif), se = sd / sqrt(N))
  gif.rho.pl <- ggplot(toplot, aes(x = as.factor(rho.c), y = gif.mean, fill = method)) +
    geom_bar(position = "dodge", stat = "identity") +
    geom_errorbar(aes(ymin = gif.mean - se,
                      ymax = gif.mean + se),
                  width = 0.9,
                  position = "dodge") +
    scale_fill_manual(values = color.values) +
    gtheme
  save_plot_png(gif.rho.pl, "num_val_gif_rho.png")


  ## plot for pdf
  ## helpers
  ## https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
  ## extract legend
  g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)}

  ## C
  C.pl <- gif.prop.pl +
    MaTheseR.params$gtheme +
    theme(legend.position = "bottom")
  mylegend <- g_legend(C.pl)
  C.pl <- C.pl +
    theme(legend.position = "none") +
    xlab("Proportion de vrais associations") +
    ylab("Facteur d'inflaction")

    ## A
    A.pl <- auc.prop.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("AUC")
    ## D
    D.pl <- gif.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab(TeX("Paramètre de corrélation entre et U et X ($\\rho$)")) +
      ylab("") 
    ## B
    B.pl <- auc.rho.pl +
      MaTheseR.params$gtheme +
      theme(legend.position = "none") +
      xlab("") +
      ylab("")

    pl <- cowplot::plot_grid(A.pl,B.pl,C.pl,D.pl,
                             ncol = 2, labels = c("A", "B", "C", "D"))

    ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 mylegend, nrow=2, heights=c(10, 1))
  })

  save_plot_png(pl.leg, filename = "method_comp.png")
  save_plot_MaTheseR(pl.leg, filename = "method_comp.pdf.png", height = 14, width = 20)
#+end_src

#+RESULTS: code:num_val_plot
[[./OUTPUT/Rplots/num_val_auc_prop.png]]
[[./OUTPUT/Rplots/num_val_gif_prop.png]]
[[./OUTPUT/Rplots/num_val_auc_rho.png]]
[[./OUTPUT/Rplots/num_val_gif_rho.png]]
[[./OUTPUT/Rplots/method_comp.png]]

****** CANCELLED Tests d'hypothèse
CLOSED: [2017-08-10 jeu. 11:30]
:LOGBOOK:
- State "CANCELLED"  from "STARTED"    [2017-08-10 jeu. 11:30]
- State "STARTED"    from "TODO"       [2017-07-30 Sun 12:28]
- State "TODO"       from              [2017-07-28 ven. 16:06]
:END:

#+NAME: code:num_val_tests
#+CAPTION: Dépend de [[code:num_auc_gif_df]]
#+begin_src R 
  require(MaTheseR)
  library(broom)
  library(ggplot2)
  library(knitr)

  auc.df <- readRDS("./OUTPUT/Expr/auc.df.rds")
  gif.df <- readRDS("./OUTPUT/Expr/gif.df.rds")

  auc.lm.res <- auc.df %>%
    mutate(method = as.factor(method)) %>%
    group_by(prop.outlier) %>%
    do(tidy(lm(auc ~ method, data = .))) %>%
    ungroup()
  toplot <- auc.lm.res %>%
    dplyr::filter(term != "(Intercept)")
  ggplot(toplot, aes(x = as.factor(prop.outlier),
                         color = p.value < 1e-5, y = estimate, fill = term)) +
    geom_bar(stat = "identity", position = "dodge")


  lm.res <- lm.res %>%
    dplyr::filter(term != "(Intercept)") %>%
    transmute(method = term, `-log10(p.value)` = -log10(p.value),
                estimate = estimate, prop.outlier = prop.outlier)
  kable(lm.res)

  ggplot(lm.res, ggplot2::aes(x = prop.outlier, y = p.value, color = as.factor(method))) +
    geom_boxplot()
#+end_src

*** Étude d'association entre des niveaux de méthylation de l'ADN et la polyarthrite rhumatoïde (EWAS)
<<sec:ewas>>

La polyarthrite rhumatoïde est une maladie auto-immune d'origine inconnue. Dans
cette étude nous souhaitons étudier le rôle de la méthylation de l'ADN dans le
développement de la polyarthrite rhumatoïde. La méthylation de l'ADN est un
processus au cours duquel un groupe méthyle est ajouté aux molécules d'ADN. La
méthylation peut changer l'activité de l'ADN et en particulier modifier sa
transcription en protéine. Pour cette étude nous nous intéressons au niveau de
méthylation de $485 577$ sites de l'ADN pour 354 individus atteints de
polyarthrite rhumatoïde et 335 individus sains. Il est connu que la methylation
de l'ADN dépend de l'âge, du sexe et de la consommation de tabac. Nous savons
aussi que le type de la cellule sur laquelle on pratique la mesure influence le
niveau de méthylation. Tous ces facteurs peuvent être des facteurs de confusion
pour l'étude d'association avec la maladie, ils ont d'ailleurs été pris en
compte explicitement dans les études d'association qui ont été faites à partir
des mêmes données que celles étudiées ici cite:Rahmani_2016,Zou_2014,Liu_2013.
Afin d'évaluer la capacité des méthodes à bien corriger pour les facteurs de
confusion, nous ne prenons pas en compte les facteurs de confusion connus et
nous comparons les résultats à ceux obtenus par les études cite:Rahmani_2016 et
cite:Zou_2014 qui prennent en compte explicitement les facteurs de confusion
connus.

De la même façon que dans cite:Zou_2014 nous avons filtré les sites avec un
niveau de methylation moyen constitutif, c'est à dire inférieur à 0.2 ou
supérieur à 0.8. De plus, nous avons centré et divisé par l'écart type les
données de méthylation. Nous avons ensuite lancé les méthodes cate, lm, PCAlm,
sva-irw, sva-two-step, lassoLFMM, ridgeLFMM afin de trouver les sites de
méthylation de l'ADN associés à la polyarthrite. Nous avons choisi $\K = 10$
pour le nombre de variables latentes (voir Figure ref:fig:ewas_params A et B).
Pour $\K = 10$, les valeurs du paramètre de régularisation $L_{2}$ $\lambRidge$
entre $10^{-10}$ et $1$ donnent les mêmes valeurs d'erreur de prédiction moyen
(Figure ref:fig:ewas_params C), nous avons choisi de prendre $\lambRidge =
10^{-5}$ pour ridgeLFMM. Nous avons choisi la proportion de lignes non nulles
pour de la matrice des effets $\B$ valant $1 \%$ pour lassoLFMM.
#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre des sites
  méthylation de l'ADN et la maladie polyarthrite rhumatoïde. A) Proportion de
  variance expliquées de la projection de $\Y$ sur l'espace orthogonal à $\X$
  (c'est à dire $\matr{D}_{0} \Q^{T} \Y$) par chacune des composantes
  principales. B)C) Erreur de prédiction calculée grâce à la validation croisée
  des estimateurs $L_{2}$ des paramètres de LFMM pour différente valeurs du
  paramètre de régularisation $\lambda$ et du nombre variable latentes $\K$, le
  point représente l'erreur de prédiction moyen et les bar l'erreur standard. La
  ligne pointillée vertical marque sur A et B le nombre de variables latentes
  choisies, c'est à dire 10, et sur C le paramètre de régularisation choisie,
  c'est à dire $10^{-5}$. }
\label{fig:ewas_params}
\end{figure}
#+END_EXPORT

La figure ref:fig:ewas_qqplot_top A montre la distribution observée des \pvalues
pour chaque site de méthylation renvoyées par chaque méthode contre la
distribution théorique hypothèse nulle. On constate une inflation du nombre de
petites \pvalues pour toutes les méthodes. Il y à une forte inflation pour lm et
sva-irw. La figure ref:fig:ewas_qqplot_top B montre la proportion des candidats
identifiés par cite:Zou_2014,Rahmani_2016 qui sont retrouvés dans les top listes
de chaque méthode. Nous rappelons que les candidats identifiés par
cite:Zou_2014,Rahmani_2016 ont été identifiés en prenant en compte les facteurs
de confusion tel que l'age, le sexe et une estimation de la composition
cellulaire. Toutes les méthodes considéré dans notre analyse retrouvent les
candidats de la littérature dans leurs top 40 sauf lm et sva_irw. Pour la
méthode lm il faut prendre le top 11881 pour trouver le premier candidat de
cite:Zou_2014,Rahmani_2016 et le top 138038 pour tous les avoirs, pour la
méthode sva-irw les candidats de cite:Zou_2014,Rahmani_2016 sont tous identifiés
entre le top $5111$ et $87659$.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base 10 des
  \pvaleurs renvoyées par chaque méthode. Les quantiles théoriques suivent la
  loi exponetielle. B) Proportion des candidats proposés par \cite{Rahmani_2016}
  et \cite{Zou_2014} retrouvés dans la top liste revoyée par chaque méthode.}
\label{fig:ewas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste obtenue quand on contrôle
le taux de fausse découverte (FDR) à $1 \%$. Toutefois les algorithmes de
contrôle du FDR nécessitent que les \pvalues soient correctement calibrées. Pour
cela nous avons calibrées les \pvalues grâce à la méthode présentée dans la
partie [[sec:calibration]]. Le contrôle du FDR a été fait à l'aide du package R
qvalue cite:Storey_2011. La figure ref:fig:ewas_venn montre les intersections
entre les méthodes. Nous avons écarté lm et sva-irw car ils renvoyaient des
listes trop différentes des autres. Parmi les 19 sites de méthylation renvoyés
par toutes les méthodes on retrouve les 5 candidats identifiés dans
cite:Zou_2014,Rahmani_2016.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/ewas_venn.pdf.png}
\caption{Diagramme de Venn de la liste des candidats controlés à un taux de
  fausses de découvertes de 1 \%.}
\label{fig:ewas_venn}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
***** DONE Télécharger les données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_ddl
#+CAPTION: Téléchargement des données pour l'EWAS.
#+BEGIN_SRC R
  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("Biobase")

  ## try http:// if https:// URLs are not supported
  source("https://bioconductor.org/biocLite.R")
  biocLite("GEOquery")


  require(Biobase)
  require(GEOquery)

  ## get le jeu de données dans le format biobase
  obj861 <- getGEO("GSE42861",GSEMatrix = T)

  ## extrait les phenotypes (factors)
  disease.state <- pData(phenoData(obj861[[1]]))[,11]

  ## extrait les covariables (subject, age, gender, smocking.status)
  ## age est converti en numeric

  subject <- pData(phenoData(obj861[[1]]))[,12]

  age.f <- pData(phenoData(obj861[[1]]))[,13]
  write.table(file = "age.txt", as.character(age.f))
  age <- as.numeric(read.table(file = "age.txt")[,1])


  gender <- pData(phenoData(obj861[[1]]))[,14]

  smocking.status <- pData(phenoData(obj861[[1]]))[,15]

  ## download la matrice d'expression. Attention elle est transposée (individus en colonnes)
  expmat861 <- exprs(obj861[[1]])
#+END_SRC

#+NAME: code:ewas_format
#+CAPTION: Formatage des données pour l'EWAS. Dépend de [[code:ewas_ddl]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")

  ## load data send by OF
  load("exp861.RData")
  ls()

  ## save G and X
  G <- t(expmat861)
  ### G
  rm(expmat861)
  dim(G)
  saveRDS(G, "betanormalized_metylationlvl.rds")

  ## we scale and center data
  X <- data.frame(disease.state = as.numeric(disease.state),
                  age = as.numeric(age),
                  gender = as.numeric(gender),
                  smocking.status = as.numeric(smocking.status))
  X <- scale(X)
  X <- as.matrix(X)
  rownames(X) <- rownames(G)
  saveRDS(X, "X.rds")

  ## downsample for test
  sample.row <- sample.int(nrow(G), size = 100)
  sample.col <- sample.int(ncol(G), size = 2000)
  saveRDS(G[sample.row, sample.col], "betanormalized_metylationlvl.sample.rds")
  saveRDS(X[sample.row,], "X.sample.rds")

#+END_SRC

***** DONE Preprocessing des données
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
#+NAME: code:ewas_prepross
#+CAPTION: Preprocessing des données pour l'EWAS. Dépend de [[code:ewas_format]].
#+BEGIN_SRC R
  setwd("./Data/GSE42861/")
  X <- readRDS("X.rds")
  G <- readRDS("betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G.filtered <- G[,-out.index]
  dim(G.filtered)

  saveRDS(G.filtered, "betanormalized_metylationlvl.filtered.rds")

  ## linear reg res
  library(ThesisRpackage)
  ## G.filtered <- readRDS("betanormalized_metylationlvl.filtered.rds")
  lm.method <- ClassicLinearMethod()
  dat <- list(G = G.filtered, X = X[,-1])

  lm.method <- fit(lm.method, dat)
  saveRDS(lm.method$epsilon, "betanormalized_metylationlvl.filtered.LMresidu.rds")

  ## subsample
  ## G <- readRDS("betanormalized_metylationlvl.filtered.LMresidu.rds")
  G <- lm.method$epsilon
  row.sample <- sample.int(nrow(G), 100)
  col.sample <- sample.int(ncol(G), 1000)
  X.sample <- X[row.sample,,drop = FALSE]
  G.sample <- G[row.sample,col.sample]
  sds <- apply(G.sample, 2, sd)
  mean(sds == 0)
  saveRDS(G.sample, "betanormalized_metylationlvl.filtered.LMresidu.sample.rds")
  saveRDS(X.sample, "X.sample.rds")
#+END_SRC

#+NAME: code:ewas_G_X
#+CAPTION: Centrage et normalisation des données pour l'EWAS. Dépend de [[code:ewas_prepross]].
#+begin_src R :results output :exports both
  library(MaTheseR)

  X <- readRDS("./Data/GSE42861/X.rds")
  G <- readRDS("./Data/GSE42861/betanormalized_metylationlvl.rds")

  ## filter maf !
  maf <- apply(G, 2, function(l){p <- mean(l);min(p, 1 - p)})
  out.index <- which(maf <= 0.2)

  G <- G[,-out.index]
  dim(G)

  ## check variable without variance
  G <- preprocessing_filter_sd(G)
  dim(G)

  ## scale and center
  G <- scale(G)

  ## save
  saveRDS(G, "./Data/ThesisDataset/3Article/GSE42861/G.rds")
  saveRDS(X, "./Data/ThesisDataset/3Article/GSE42861/X.rds")
#+end_src

***** DONE Sites candidats detectés dans d'autres études
CLOSED: [2017-08-06 Sun 14:40]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:40]
:END:
Les loci relevé par cite:Rahmani_2016
#+begin_src R :results output :exports both
  rahmani.loci <- c("cg05428452",
                     "cg07839457",
                     "cg16411857")
#+end_src
Ceux de cite:Zou_2014
#+begin_src R :results output :exports both
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
#+end_src

On retrouve les 3 mêmes. On va prend cela  
#+NAME: code:ewas_candidates
#+CAPTION: Dépend de [[code:ewas_G_X]]
#+begin_src R :results output :exports both :session *ssh krakenator*
  G <- readRDS("./Data/ThesisDataset/3Article/GSE42861/G.rds")
  Zou.loci <- c("cg05428452",
                "cg07839457",
                "cg16411857",
                "cg25372449",
                "cg20821042")
  cols <- colnames(G)
  candidates <- which(colnames(G) %in% Zou.loci)
  cols[candidates]
  saveRDS(candidates, "./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS:
: [1] "cg05428452" "cg07839457" "cg16411857" "cg20821042" "cg25372449"

#+begin_src R :results output :exports both :session *ssh krakenator*
candidates
#+end_src

#+RESULTS:
: [1]  36714  51546 101455 125220 149131
***** DONE Scree plot 
CLOSED: [2017-08-22 mar. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:31]
- State "TODO"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:18]
- State "DONE"       from "RUNNING"    [2017-07-25 mar. 18:05]
- Note taken on [2017-07-25 mar. 17:56] \\
  tail -f ewas_screeplot.y2017_m07_d25_krakenatorh_juil..log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:51]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 09:42]
- State "RUNNING"    from              [2017-06-29 jeu. 09:36]
:END:

#+NAME: code:ewas_screeplot
#+CAPTION: Dépend de [[code:ewas_G_X]] 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- "./Data/ThesisDataset/3Article/GSE42861/X.rds"

  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "ewas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30))
  pl
  save_plot_png(pl, "ewas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-21 lun. 17:38]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:38]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 17:05]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 12:57]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 11:07]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 11:00]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 10:21]
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 10:49]
- Note taken on [2017-07-26 mer. 19:36]
- Note taken on [2017-07-26 mer. 18:05] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_cv_lambda.y2017_m07_d26.log
  tail -f /home/cayek/tmp/Logfiles/ewas_cv.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 17:56] \\
  On va relancer... il y avait des bug dans la CV...
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 17:56]
- State "DONE"       from "RUNNING"    [2017-07-03 lun. 16:18]
- State "RUNNING"    from "DONE"       [2017-07-03 lun. 14:42]
- State "DONE"       from "RUNNING"    [2017-06-29 jeu. 14:35]
- Note taken on [2017-06-29 jeu. 12:10] \\
  Pour K c'est bon c'est clair, on va prendre autour de 25 en gros. Par contre
  pour lambda c'est pas clair ce que ca apporte !! C'est parce qu'il y a peu
  d'outlier !!! Dans ce cas c'est mieux un lambda petit. Faudra l'expliquer !!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 09:48]
- State "TODO"       from              [2017-06-29 jeu. 09:44]
:END:

#+NAME: code:ewas_CV
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(1,2,5,10,20, 25,30, 50, 100))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "ewas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lfmm_lambda.png]]
[[./OUTPUT/Rplots/ewas_CV_lfmm_K.png]]

#+NAME: code:ewas_CV_encore
#+CAPTION: Dépend de [[ewas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = c(6,7,8,9))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:ewas_CV_encore_encore
#+CAPTION: Dépend de [[ewas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5, 1.0, 1e10)
  nb.cluster <- 10
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 11:19)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "ewas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "ewas_CV_lfmm_K_encore_encore.png")
#+end_src


#+NAME: code:ewas_CV_lambda
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/GSE42861/G.rds",
                              X = "./Data/ThesisDataset/3Article/GSE42861/X.rds",
                              outlier = "./Data/ThesisDataset/3Article/GSE42861/candidates.rds") %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1.0, 1e5, 1e10)
  nb.cluster <- 5
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 10,
                            lambdas = lambdas,
                            Ks = 9:11)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "ewas_CV_lambda_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda.png")

  ## plot smooth
  pl <- ggplot(res.cv$errs, aes(y = err, x = log(lambda))) +
    geom_smooth()
  pl
  save_plot_png(pl, "ewas_CV_lambda_lfmm_lambda_smooth.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda_smooth.png]]
[[./OUTPUT/Rplots/ewas_CV_lambda_lfmm_lambda.png]]

***** DONE Étude du jeu de données
CLOSED: [2017-08-07 lun. 18:35]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-07 lun. 18:35]
- State "RUNNING"    from "DONE"       [2017-08-07 lun. 16:39]
- Note taken on [2017-08-07 lun. 16:35] \\
  j'ai rajouté sva two-step a l'arrache
  #+begin_src R :results output :exports both
    expr.all <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  
    expr.all$df.res$method[expr.all$df.res$method == "sva"] = "sva-irw"
  
    expr.all$df.res <- expr.all$df.res %>%
      rbind(expr$df.res)
  
    summarise(expr.all$df.res)
  
  
    save_expr(expr.all, "EWAS_all.rds")
  #+end_src
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 11:01]
- Note taken on [2017-07-26 mer. 19:44] \\
  Du coup j'ai relancé avec K = 10 et le bon lasso !!!!!! on va voir
- Note taken on [2017-07-26 mer. 19:43] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
- State "RUNNING"    from "DONE"       [2017-07-26 mer. 19:43]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 11:45]
- Note taken on [2017-07-11 mar. 10:25] \\
  c'est reparti :D
- Note taken on [2017-07-11 mar. 10:23] \\
  ok c'est pas bon avec 5% !! pas étonnant 5% c'est trop !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 08:41]
- Note taken on [2017-07-11 mar. 08:41] \\
  je relance avec 5% de no zero pour le lasso !!
- State "DEBUG"      from "RUNNING"    [2017-07-07 ven. 18:49]
- State "RUNNING"    from "TODO"       [2017-07-07 ven. 13:59]
- State "TODO"       from              [2017-06-29 jeu. 11:17]
:END:

#+NAME: code:ewas_expr
#+CAPTION: Dépend de [[code:ewas_G_X]] [[code:ewas_candidates]]
#+begin_src R
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
                              lambda.num = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva_irw <- method_sva(K.method)
  m.sva_2step <- method_sva(K.method, method = "two-step")

  methods <- m.ridgeLfmm * param() +
    m.lm * param() +
    m.pca * param() +
    m.cate * param() +
    m.famt * param() +
    m.sva_irw * param() +
    m.sva_2step * param() +
    m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
               samplers = samplers,
               preprocessors = NULL,
               rep.nb.method = 1,
               methods = methods,
               extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")

#+end_src

#+NAME: code:ewas_expr_log
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src shell :session *ssh krakenator* :results output 
  cat /home/cayek/tmp/Logfiles/ewas_run.y2017_m07_d26.log
#+end_src

#+RESULTS: code:ewas_expr_log
#+begin_example
  R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
  Copyright (C) 2017 The R Foundation for Statistical Computing
  Platform: x86_64-redhat-linux-gnu (64-bit)
  
  R est un logiciel libre livré sans AUCUNE GARANTIE.
  Vous pouvez le redistribuer sous certaines conditions.
  Tapez 'license()' ou 'licence()' pour plus de détails.
  
  R est un projet collaboratif avec de nombreux contributeurs.
  Tapez 'contributors()' pour plus d'information et
  'citation()' pour la façon de le citer dans les publications.
  
  Tapez 'demo()' pour des démonstrations, 'help()' pour l'aide
  en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
  Tapez 'q()' pour quitter R.
  
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  foreach: simple, scalable parallel programming from Revolution Analytics
  Use Revolution R for scalability, fault tolerance and more.
  http://www.revolutionanalytics.com
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  library(MaTheseR)

  ## param
  K.method <- 10
  nb.cluster <- 4
  lambda <- 1e-5
  nozero.prop <- 0.01

  ## sampler
  Y <- "./Data/ThesisDataset/3Article/GSE42861/G.rds"
  X <- readRDS("./Data/ThesisDataset/3Article/GSE42861/X.rds")
  X <- X[,1, drop = FALSE]
  head(X)
             disease.state
  GSM1051525     0.9720875
  GSM1051526     0.9720875
  GSM1051527     0.9720875
  GSM1051528     0.9720875
  GSM1051529     0.9720875
  GSM1051530     0.9720875
  outlier <- "./Data/ThesisDataset/3Article/GSE42861/candidates.rds"
  samplers <- ExpRsampler_trueData(Y = Y, X = X, outlier = outlier) * param()

  ## methods
  m.ridgeLfmm <- method_ridgeLFMM(K = K.method)
  m.lasso <- method_lassoLFMM(K = K.method, nozero.prop = nozero.prop,
  +                             lambda.num = 25, relative.err.epsilon = 1e-6)
  m.lm <- method_lm()
  m.pca <- method_PCAlm(K = K.method)
  m.cate <- method_cate(K = K.method)
  m.famt <- method_famt(K.method)
  m.sva <- method_sva(K.method)

  methods <- m.ridgeLfmm * param() +
  +   m.lm * param() +
  +   m.pca * param() +
  +   m.cate * param() +
  +   m.famt * param() +
  +   m.sva * param() +
  +   m.lasso * param()

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9528 on localhost:11939 at 19:35:29.343
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9538 on localhost:11939 at 19:35:33.199
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9548 on localhost:11939 at 19:35:37.112
  Loading tidyverse: ggplot2
  Loading tidyverse: tibble
  Loading tidyverse: tidyr
  Loading tidyverse: readr
  Loading tidyverse: purrr
  Loading tidyverse: dplyr
  Conflicts with tidy packages ---------------------------------------------------
  (): 
  
  Attachement du package : ‘testthat’
  
  The following object is masked from ‘package:dplyr’:
  
      matches
  
  The following object is masked from ‘package:purrr’:
  
      is_null
  
  Le chargement a nécessité le package : ExpRiment
  Le chargement a nécessité le package : MaTheseR
  Le chargement a nécessité le package : foreach
  
  Attachement du package : ‘foreach’
  
  The following objects are masked from ‘package:purrr’:
  
      accumulate, when
  
  Le chargement a nécessité le package : magrittr
  
  Attachement du package : ‘magrittr’
  
  The following objects are masked from ‘package:testthat’:
  
      equals, is_less_than, not
  
  The following object is masked from ‘package:purrr’:
  
      set_names
  
  The following object is masked from ‘package:tidyr’:
  
      extract
  
  starting worker pid=9558 on localhost:11939 at 19:35:41.000
  doParallel::registerDoParallel(cl)
  expr <- ExpR(rep.nb.sampler = 1,
  +              samplers = samplers,
  +              preprocessors = NULL,
  +              rep.nb.method = 1,
  +              methods = methods,
  +              extractor = ExpRextractor_pvalue1_calibrated)
  expr <- ExpRmouline(expr)
  === Sampling data.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  === Main loop.
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  loaded ExpRiment and set parent environment
  Computing latent variables
  Computing latent variables
  running hp
          pvalue    colname index outlier     score rep.sampler rep.method method
  1 3.208532e-08 cg00000029     1   FALSE -5.593741           1          1     lm
    method.K method.lambda
  1       NA            NA
  Computing latent variables
  Computing latent variables
  Loading required package: impute
  running hp
  `Rows with missing values`
  integer(0)
  `Columns with missing values`
  integer(0)
  
  running hp
       pvalue    colname index outlier      score rep.sampler rep.method
  1 0.6757066 cg00000029     1   FALSE -0.4185102           1          1
       method method.K method.lambda
  1 ridgeLFMM       10         1e-04
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.9531602 cg00000029     1   FALSE 0.05876053           1          1  PCAlm
    method.K method.lambda
  1       10            NA
  Number of significant surrogate variables is:  10 
  Computing latent variables
  It = 1/100, err2 = 0.998548621190457
  It = 2/100, err2 = 0.652592023099809
  It = 3/100, err2 = 0.652018379539831
  [1] "Fitting Factor Analysis Model with 10 factors"
  It = 4/100, err2 = 0.651990819329085
  It = 5/100, err2 = 0.65201511610208
  Iteration (out of 5 ):It = 6/100, err2 = 0.65202139222764
  It = 7/100, err2 = 0.652022747619974
  === lambda = 0.184666840535516, no zero B proportion = 0.00564682358459127
  It = 1/100, err2 = 0.652023080891458
  It = 2/100, err2 = 0.651977189044589
       pvalue    colname index outlier      score rep.sampler rep.method method
  1 0.6618566 cg00000029     1   FALSE -0.4373513           1          1   cate
    method.K method.lambda
  1       10            NA
  It = 3/100, err2 = 0.651967304634796
  It = 4/100, err2 = 0.651964288072884
  It = 5/100, err2 = 0.65196318471777
  === lambda = 0.138480594373303, no zero B proportion = 0.0549685876152507
  running hp
       pvalue    colname index outlier     score rep.sampler rep.method    method
  1 0.8961906 cg00000029     1   FALSE -0.130524           1          1 lassoLFMM
    method.K method.lambda
  1       10            NA
  1  2  [1] "Fitting Factor Analysis Model with 10 factors"
  3         pvalue    colname index outlier    score rep.sampler rep.method method
  1 1.13824e-05 cg00000029     1   FALSE 19.55117           1          1   famt
    method.K method.lambda
  1       10            NA
  4  5         pvalue    colname index outlier    score rep.sampler rep.method method
  1 3.94329e-12 cg00000029     1   FALSE 49.94426           1          1    sva
    method.K method.lambda
  1       10            NA
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(expr, "EWAS_all.rds")
  Expr save in ./OUTPUT/Expr/EWAS_all.rds


  >
#+end_example

****** DONE Charger l'expérience et les candidats
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_load_res
#+CAPTION: Dépend de [[code:ewas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
#+end_src

#+RESULTS: code:ewas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:


#+NAME: code:ewas_calibration
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  expr$df.res %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:ewas_calibration
#+begin_example
# A tibble: 8 x 3
        method        mad     median
         <chr>      <dbl>      <dbl>
1         cate  1.2870855 0.04677596
2         famt  6.2659293 4.33328808
3    lassoLFMM  1.2387777 0.02799659
4           lm  4.2127155 0.04534315
5        PCAlm  1.2268129 0.03996082
6    ridgeLFMM  1.2745703 0.04853927
7 sva_two-step  0.9842079 0.71781997
8      sva-irw 10.8418062 7.58318108
#+end_example

Pour sva_irw et sva_two-step les scores sont des Fscrore ! On ne peut pas
calibrer avec le MAD !!! C'est surement idem pour famt

****** DONE Les qqplots ?
CLOSED: [2017-07-27 jeu. 11:32]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_qqplots
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))
  pl <- plot_qqplot(toplot)
  save_plot_png(pl, "EWAS_qqplots.png")
  pl


  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EWAS_qqplots2.png")
  pll
#+end_src

#+RESULTS: code:ewas_qqplots
[[./OUTPUT/Rplots/EWAS_qqplots.png]]
[[./OUTPUT/Rplots/EWAS_qqplots2.png]]


****** DONE Le top et rank des candidats
CLOSED: [2017-07-27 jeu. 11:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:35]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_top
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "ewas_top_inter.png")

  ## rang du dernier candidats
  expr$df.res %>%
    mutate(outlier = index %in% candidates) %>%
    group_by(method) %>%
    dplyr::arrange(pvalue, method) %>%
    mutate(rk = seq_along(pvalue)) %>%
    summarise(rk.min = min(rk[outlier]),
              rk.max = max(rk[outlier]))
#+end_src

#+RESULTS: code:ewas_top
[[./OUTPUT/Rplots/ewas_top_inter.png]]
#+begin_example
# A tibble: 8 x 2
        method power
         <chr> <dbl>
1         cate   0.8
2         famt   0.0
3    lassoLFMM   1.0
4           lm   0.0
5        PCAlm   1.0
6    ridgeLFMM   1.0
7 sva_two-step   1.0
8      sva-irw   0.0
# A tibble: 8 x 3
        method rk.min rk.max
         <chr>  <int>  <int>
1         cate      1     37
2         famt   9326  27941
3    lassoLFMM      1     24
4           lm  11881 138038
5        PCAlm      1      8
6    ridgeLFMM      1     25
7 sva_two-step      1     18
8      sva-irw   5111  87659
#+end_example

****** DONE Contrôle du FDR à $0.01$
CLOSED: [2017-07-27 jeu. 11:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:37]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_fdr
#+CAPTION: Dépend de [[code:ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "ewas_fdr01_inter.png")
#+end_src

#+RESULTS: code:ewas_fdr
[[./OUTPUT/Rplots/ewas_fdr01_inter.png]]
#+begin_example
# A tibble: 7 x 2
        method power
         <chr> <dbl>
1         cate   1.0
2         famt   1.0
3    lassoLFMM   1.0
4        PCAlm   1.0
5    ridgeLFMM   1.0
6 sva_two-step   1.0
7      sva-irw   0.6
#+end_example

****** DONE Venn diagram fdr 0.01
CLOSED: [2017-07-27 jeu. 11:39]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup() 


  sets <- list(sva = toplot$index[toplot$method == "sva_two-step"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_fdr01_venn.png")
#+end_src

#+RESULTS: code:ewas_venn
: [[./OUTPUT/Rplots/ewas_fdr01_venn.png]]

****** DONE Venn diagram top 100
CLOSED: [2017-08-07 lun. 18:02]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 18:02]
- State "TODO"       from "DONE"       [2017-08-07 lun. 17:57]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 11:39]
- State "TODO"       from              [2017-07-27 jeu. 11:32]
:END:

#+NAME: code:ewas_venn_top
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  ## 0.05 % de p
  p <- max(expr$df.res$index)
  0.0005 * p

  toplot <- expr$df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(100) %>%
    ungroup() 


  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets)

  save_plot_png(out, "ewas_top100_venn.png")
#+end_src

#+RESULTS: code:ewas_venn_top
[[./OUTPUT/Rplots/ewas_top100_venn.png]]
: [1] 81.019


****** DONE plot top * power
CLOSED: [2017-08-07 lun. 17:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-07 lun. 17:56]
- State "TODO"       from              [2017-08-07 lun. 17:26]
:END:
#+NAME: code:ewas_top_power
#+CAPTION: Dépend de [[ewas_load_res]]
#+begin_src R :results output :exports both
  candidates
  m1 <- length(candidates)
  expr$df.res

  df <- expr$df.res %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50))
  pl
  save_plot_png(pl, "ewas_top_power.png")
#+end_src

#+RESULTS: code:ewas_top_power
[[./OUTPUT/Rplots/ewas_top_power.png]]

***** DONE Plots
CLOSED: [2017-08-06 Sun 14:25]
:LOGBOOK:
- State "DONE"       from              [2017-08-06 Sun 14:25]
:END:

****** DONE Choix des paramètres
CLOSED: [2017-08-29 mar. 11:46]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-29 mar. 11:46]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "TODO"       [2017-08-08 mar. 15:08]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:
#+NAME: code:ewas_screeplot_CV
#+CAPTION: Dépend de [[code:ewas_screeplot]] [[code:ewas_CV]] [[code:ewas_CV_lambda]] [[code:ewas_CV_encore]] [[code:ewas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  df.res <- readRDS("./OUTPUT/Expr/ewas_screeplot_expr.rds")
  plA <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,30)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 10, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "ewas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lfmm_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.4)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 10, linetype = "dashed") +
    coord_cartesian(xlim = c(1,30)) +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "ewas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/ewas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.5)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    ylab("Erreur de\nprédiction") +
    geom_vline(xintercept = 1e-5, linetype = "dashed") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.15, 0.8))
  save_plot_png(plC, "ewas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "ewas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:ewas_screeplot_CV
: [[./OUTPUT/Rplots/ewas_screeplot.png]]
: [[./OUTPUT/Rplots/ewas_CV_K.png]]
: [[./OUTPUT/Rplots/ewas_CV_lambda.png]]
: [[./OUTPUT/Rplots/ewas_hyperparams.pdf.png]]

****** DONE Résultats des méthodes
CLOSED: [2017-08-09 mer. 13:56]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-09 mer. 13:56]
- State "TODO"       from              [2017-08-08 mar. 14:28]
:END:

#+NAME: code:ewas_qqplot_top_venn
#+CAPTION: Dépend de [[code:ewas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  expr <- readRDS("./OUTPUT/Expr/EWAS_all.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/GSE42861/candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  expr$df.res$method %>% unique()
  df.res <- expr$df.res %>%
    dplyr::filter(!(method %in% c("famt"))) %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "ewas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,50)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") + 
    xlab("Taille de la top liste") + 
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## pl.top
  save_plot_png(pl.top, filename = "ewas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "ewas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  ## we calibrate sva-two-step with gif ! 
  calibrate <- function(p) {
    score2 <- qchisq(p, df = 1, lower.tail = FALSE)
    gif <- median(score2) / qchisq(0.5, df = 1)
    score2 <- score2 / gif
    pchisq(score2, lower.tail = FALSE, df = 1)
  }
  p <- df.res$pvalue[df.res$method == "sva-two-step"]
  hist(p)
  p.calibrated <- calibrate(p)
  hist(p.calibrated)
  df.res$calibrated.pvalue[df.res$method == "sva-two-step"] <- p.calibrated

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               `sva-two-step` = toplot$index[toplot$method == "sva-two-step"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                        area1 = inter(1),
                        area2 = inter(2),
                        area3 = inter(3),
                        area4 = inter(4),
                        area5 = inter(5),
                        n12 = inter(1,2),
                        n13 = inter(1,3),
                        n14 = inter(1,4),
                        n15 = inter(1,5),
                        n23 = inter(2,3),
                        n24 = inter(2,4),
                        n25 = inter(2,5),
                        n34 = inter(3,4),
                        n35 = inter(3,5),
                        n45 = inter(4,5),
                        n123 = inter(1,2,3),
                        n124 = inter(1,2,4),
                        n125 = inter(1,2,5),
                        n134 = inter(1,3,4),
                        n135 = inter(1,3,5),
                        n145 = inter(1,4,5),
                        n234 = inter(2,3,4),
                        n235 = inter(2,3,5),
                        n245 = inter(2,4,5),
                        n345 = inter(3,4,5),
                        n1234 = inter(1,2,3,4),
                        n1235 = inter(1,2,3,5),
                        n1245 = inter(1,2,4,5),
                        n1345 = inter(1,3,4,5),
                        n2345 = inter(2,3,4,5),
                        n12345 = inter(1,2,3,4,5),
                        category = names(sets),
                        fill = color.values[names(sets)],
                        cat.col = color.values[names(sets)],
                        cat.cex = 1.2,
                        cat.pos = c(0.0, -30, 180, 180, 30),
                        cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                        margin = 0.07,
                        ind = TRUE
                       )

  save_plot_png(venn, filename = "ewas_venn.png")
  save_plot_MaTheseR(venn, "ewas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
        res <- base::intersect(res, sets[[i]])
    }
    res
  }
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)
#+END_SRC

#+RESULTS: code:ewas_qqplot_top_venn
[[./OUTPUT/Rplots/ewas_qqplot_notcalibrated_all.png]]
[[./OUTPUT/Rplots/ewas_top_power_all.png]]
[[./OUTPUT/Rplots/ewas_venn.png]]

*** Étude d'association entre des données génétiques et la maladie \celiac (GWAS)
<<sec:gwas>>

La maladie \celiac est une maladie auto-immune ayant une prévalence de près de
$1 \%$ dans la population générale cite:Gujral_2012. Bien que les mécanismes
d'apparition de cette maladie ne soit pas compris des études montres de fortes
associations avec certains gènes cite:dubois2010multiple; lassant envisager des
causes génétiques à la maladie. Comme la maladie \celiac est très étudiée faire
une étude d'association de celle-ci avec des données génomiques constitue un bon
test pour les méthodes de correction pour les variables latentes. Nous pourrons
en effet comparer nos résultats à ceux des nombreuses autres GWAS de la maladie
\celiac. Pour cela nous avons utilisé le GWAS catalog pour récupérer les SNPs
ayant été identifié dans d'autres études comme étant associés avec la maladie
\celiac. Par ailleurs, nous s'avons que la stratification des individus en sous
populations peut être un facteur de confusion dans les GWAS. Il est habituel de
corriger les GWAS en utilisant les scores de l'ACP des données génétiques pour
représenter la structure de population cite:Price_2006. Nous proposons ici de
faire une étude d'association entre la maladie \celiac et des données génétique
présentées dans cite:dubois2010multiple. Ces données comportent 281122 SNPs
(single nucléotyde polimorphism) pour 15155 individus, 10659 individus sains et
4496 atteints de la maladie \celiac. Ce que nous appelons SNP est la mesure pour
une position donnée du génome, que l'on appel locus, du nucleotide présent chez
l'individu observé. On parle de "single nucléotyde polimorphism" car on s'intéresse
seulement aux locus pour lesquels on a observé seulement deux variants dans la
population étudiée. Il faut de plus que le variant le moins fréquent soit au
moins observé chez $5\%$ des individus de la population. Ainsi pour cette GWAS
la matrice des variables expliquées est composée de 0, 1 et 2.

Avant de lancer les méthodes d'étude d'association nous avons filtré les données
génétique afin de garder seulement les SNPs ayant le variant le moins fréquent
présent dans au moins $5\%$ des observations. Nous avons de plus filtré les
individus trop apparentés, pour cela on mesure la probabilité qu'une séquence
consécutive de SNPs prise chez deux individus différents soit identique et si
celle-ci est supérieure à $0.08$ nous ne gardons qu'un des deux individus. Par
ailleurs, il est connu que les SNPs sont corrélés le long du génome, nous avons
donc filtrer les SNPs trop corrélé entre eux. Cette étape est identifié dans la
littérature comme le LD pruning. Pour cela, pour chaque SNP nous ne gardons que
le SNP de variance maximum sur une fenêtre de 100 SNPs et cela sur les SNPs
ayant un coefficient de corrélation linéaire au carré qui est supérieure à
$0.2$, cela nous a permis d'identifier un sous ensemble de 80275 SNPs. Ces
opérations de filtrage ont été effectuées à l'aide du logiciel plink
cite:Purcell_2007. Enfin nous avons utilisé beagle pour imputer les données
manquantes de la matrice de SNPs cite:Browning_2016. Nous obtenons finalement un
jeux de données complet composée 281122 SNPs observés sur 15155 individus.

Afin d'estimer les variables latentes pour corriger le test d'association entre
les SNPs et la maladie \celiac nous avons lancé les méthodes lm, lmPCA, cate,
ridgeLFMM et lassoLFMM sur le sous ensemble de 80275 SNPs identifié par l'étape
de LD pruning. Par la suite, nous avons effectué le test d'hypothèse présenté
dans la partie [[sec:hypothese]] sur les 281122 SNPs mais en utilisant l'estimation
des variables latentes calculées sur le sous ensemble de 80275 SNPs. Nous avons
choisi de lancer les méthodes lmPCA, cate, lassoLFMM et ridgeLFMM avec 9
variables latentes (voir Figure ref:fig:gwas_params A et B). Nous avons choisi
une proportion de lignes non nulles pour la matrice des effets $\B$ valant $1
\%$ pour lassoLFMM. La validation croisée du paramètre $\lambRidge$ tend à faire
choisir une forte valeur pour celui-ci (Figure ref:fig:gwas_params C), nous
avons choisi $1e^{3}$. La validation croisée présentée sur la Figure
ref:fig:gwas_params C tend à faire choisir une valeur plus grande que $1e^{3}$
cependant comme nous l'avons discuté dans la partie [[sec:paramL2]] si
$\lambdaRidge$ est trop grand alors ridgeLFMM renvoie les mêmes résultats que
PCAlm.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre génotype et la
  maladie \celiac. A) Proportion de variance expliquées de la projection de $\Y$
  sur l'espace orthogonal à $\X$ (c'est à dire $\matr{D}_{0} \Q^{T} \Y$) par
  chacune des composantes principales. B)C) Erreur de prédiction calculée grâce à
  la validation croisée des estimateurs $L_{2}$ des paramètres de LFMM pour
  différente valeurs du paramètre de régularisation $\lambda$ et du nombre
  variables latentes $\K$, le point représente l'erreur de prédiction moyenne et
  les bars l'erreur standard de la moyenne. La ligne pointillée vertical marque
  sur A et B le nombre de variables latentes choisies, c'est à dire 9, et sur C
  le paramètre de régularisation choisie, c'est à dire $10^3$.}
\label{fig:gwas_params}
\end{figure}
#+END_EXPORT

La Figure ref:fig:gwas_qqplot_top A montre la distribution observée des \pvalues
renvoyées par chaque méthode contre la distribution théorique sous l'hypothèse
nulle. On constate que les méthodes sont toutes bien calibrées et que la méthode
la plus libérale est lm alors que PCAlm est la méthode la plus conservative. La
Figure ref:fig:gwas_qqplot_top B montre le nombre de SNPs référencés dans le
GWAS catalog comme étant associés avec la maladie \celiac qui sont retrouvés
dans les top listes des différentes méthodes. On observe ainsi sur la Figure
ref:fig:gwas_qqplot_top B que lm sépare le moins facilement les SNPs du GWAS
catalog des autres SNPs, alors que ce sont ridgeLFMM et PCAlm qui séparent le
mieux les SNPs du GWAS catalog du reste. La liste top 1000 de ridgeLFMM et PCAlm
contiennent respectivement $63 \%$ et $57 \%$ des SNPs du GWAS catalog contre
$18 \%$, $14 \%$ et $12 \%$ pour lassoLFMM, cate et lm.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_qqplot_top.pdf.png}
\caption{A) Diagrame quantile-quantile de l'inverse du logarithme en base
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponetielle. B) Proportion des candidats du GWAS catalogue
  retrouvés dans la top liste revoyée par chaques méthodes.}
\label{fig:gwas_qqplot_top}
\end{figure}
#+END_EXPORT

Enfin pour chaque méthode nous avons calculé la liste obtenus en contrôlant le
FDR à $1 \%$. Nous avons procédé de la même façon que pour l'EWAS pour calculer
cette liste (voir la section [[sec:ewas]]). La Figure ref:fig:gwas_venn montre
l'intersection des listes contrôlés à un FDR de $1\%$ entre les méthodes. Ce
sont ridgeLFMM et PCAlm qui donnent les plus petites listes contrôlées avec 754
candidats pour ridgeLFMM et 777 candidats pour PCAlm. Les méthodes cate et lm
donne la plus grande liste avec le même nombre de 1319 candidats. Nous
constatons que l'intersection des listes à FDR contrôlé de toutes les méthodes
ne contient que $28\%$ des candidats du GWAS catalog.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/gwas_venn.pdf.png}
\caption{Diagramme de Venn des listes controlés à un taux de fausses de
  découvertes de $1 \%$ pour chaque méthode.}
\label{fig:gwas_venn}
\end{figure}
#+END_EXPORT

**** Scripts                                                    :noexport:
:LOGBOOK:
- Note taken on [2017-08-06 Sun 14:53] \\
  J'ai juste mis la dernière étape pour pouvoir lancer les analyses ! Les autres
  étapes sont juste un recopie de Notes.org
:END:
***** DONE Téléchargement des données
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
Ou ont elle été ddl ??? FP a recu dirrect =./Data/Celiac/dubois_2010/=

#+NAME: code:gwas_ddl
#+CAPTION: 
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ls FinnuncorrNLITUK1UK3hap300.*
#+end_src

#+RESULTS: code:gwas_ddl
: 
: FinnuncorrNLITUK1UK3hap300.bed	FinnuncorrNLITUK1UK3hap300.bim	FinnuncorrNLITUK1UK3hap300.fam

***** DONE Contrôle qualité
CLOSED: [2017-08-16 mer. 17:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:40]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_CQ
#+CAPTION: Dépend de [[code:gwas_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300 --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
#+end_src

#+RESULTS: code:gwas_CQ
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
Options in effect:
  --autosome
  --bfile FinnuncorrNLITUK1UK3hap300
  --geno 0.05
  --hwe 1e-10
  --maf 0.05
  --make-bed
  --mind 0.05
  --out FinnuncorrNLITUK1UK3hap300_CQ
  --snps-only
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 72672 MB successfully, after larger attempt(s) failed.
287385 out of 295453 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
0 people removed due to missing genotype data (--mind).
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Total genotyping rate is 0.999579.
67 variants removed due to missing genotype data (--geno).
--hwe: 17 variants removed due to Hardy-Weinberg exact test.
6179 variants removed due to minor allele threshold(s)
(--maf/--max-maf/--mac/--max-mac).
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ.bed +
#+end_example

***** DONE Élagage (LD pruning)
CLOSED: [2017-08-16 mer. 17:49]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 17:49]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

Pour comprendre le LD pruning: 
- [[https://www.cog-genomics.org/plink/1.9/ld][doc de plink]]
- [[https://privefl.github.io/bigsnpr/reference/pruning-clumping.html][re-implementation du ld pruning de plink]]
- [[https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient][R2 = cor(Y,X)^2]]

****** DONE LD report
CLOSED: [2017-08-17 jeu. 10:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_ld_report
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --r2 --ld-window 10 --ld-window-kb 100 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --ld-window 10
    --ld-window-kb 100
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:gwas_ld_report_R
#+CAPTION: Dépend de [[code:gwas_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "gwas_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "gwas_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_ld_report_bin.png]]
[[./OUTPUT/Rplots/gwas_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:00]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:00]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:gwas_prunning
#+CAPTION: Dépend de [[code:gwas_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --indep-pairwise 100 1 0.2 --out FinnuncorrNLITUK1UK3hap300_CQ --threads 8
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
#+end_src

#+RESULTS: code:gwas_prunning
#+begin_example

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --indep-pairwise 100 1 0.2
    --out FinnuncorrNLITUK1UK3hap300_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned --threads 8
  1%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999596.
  281122 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  Pruned 15141 variants from chromosome 1, leaving 6399.
  Pruned 16905 variants from chromosome 2, leaving 6214.
  Pruned 14431 variants from chromosome 3, leaving 5343.
  Pruned 12416 variants from chromosome 4, leaving 4848.
  Pruned 12574 variants from chromosome 5, leaving 4932.
  Pruned 14081 variants from chromosome 6, leaving 4860.
  Pruned 10944 variants from chromosome 7, leaving 4341.
  Pruned 12291 variants from chromosome 8, leaving 4164.
  Pruned 10651 variants from chromosome 9, leaving 3896.
  Pruned 10176 variants from chromosome 10, leaving 4034.
  Pruned 9597 variants from chromosome 11, leaving 3753.
  Pruned 9754 variants from chromosome 12, leaving 3987.
  Pruned 7466 variants from chromosome 13, leaving 3019.
  Pruned 6364 variants from chromosome 14, leaving 2725.
  Pruned 5555 variants from chromosome 15, leaving 2484.
  Pruned 5528 variants from chromosome 16, leaving 2702.
  Pruned 5063 variants from chromosome 17, leaving 2564.
  Pruned 6770 variants from chromosome 18, leaving 2754.
  Pruned 3373 variants from chromosome 19, leaving 2035.
  Pruned 4698 variants from chromosome 20, leaving 2309.
  Pruned 3620 variants from chromosome 21, leaving 1416.
  Pruned 3449 variants from chromosome 22, leaving 1496.
  Pruning complete.  200847 of 281122 variants removed.
  Marker lists written to FinnuncorrNLITUK1UK3hap300_CQ.prune.in and
  FinnuncorrNLITUK1UK3hap300_CQ.prune.out .
  9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ
    --extract FinnuncorrNLITUK1UK3hap300_CQ.prune.in
    --make-bed
    --out FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  281122 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  --extract: 80275 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  --make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned.bed +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.bim +
  FinnuncorrNLITUK1UK3hap300_CQ_prunned.fam ... done.
#+end_example
***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-08-16 mer. 18:18]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:18]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 18:10]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:10]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
:END:
#+NAME: code:gwas_ibd
#+CAPTION: Dépend de [[code:gwas_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## ibd
  plink -bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Allocated 72672 MB successfully, after larger attempt(s) failed.
  80275 variants loaded from .bim file.
  15283 people (6713 males, 8570 females) loaded from .fam.
  15283 phenotype values loaded from .fam.
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 15283 founders and 0 nonfounders present.
  Calculating allele frequencies... 0%echo 'org_babel_sh_eoe'
   done.
  Total genotyping rate is 0.999591.
  80275 variants and 15283 people pass filters and QC.
  Among remaining phenotypes, 4533 are cases and 10750 are controls.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-16 mer. 18:12]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:12]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:gwas_ibd_visu
#+CAPTION: Dépend de [[code:gwas_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "celiac_ibd.png")


  ## We filter PI_HAT > 0.08
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.08) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS: code:gwas_ibd_visu
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
[[./OUTPUT/Rplots/celiac_ibd.png]]


On va filter les pour une proportion d'ibd à 0.08 (ca correspond à cousin au 4
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 18:15]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 18:15]
- State "TODO"       from "DONE"       [2017-08-16 mer. 17:52]
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:gwas_ibd_filter
#+CAPTION: Dépend de [[code:gwas_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel

  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ --remove out.indif.txt --make-bed --out FinnuncorrNLITUK1UK3hap300_CQ_norel
#+end_src

#+RESULTS: code:gwas_ibd_filter
#+begin_example

PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
80275 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999592.
80275 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel.bim +
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to FinnuncorrNLITUK1UK3hap300_CQ_norel.log.
Options in effect:
  --bfile FinnuncorrNLITUK1UK3hap300_CQ
  --make-bed
  --out FinnuncorrNLITUK1UK3hap300_CQ_norel
  --remove out.indif.txt

193793 MB RAM detected; reserving 96896 MB for main workspace.
Allocated 54504 MB successfully, after larger attempt(s) failed.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
--remove: 15155 people remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15155 founders and 0 nonfounders present.
Total genotyping rate in remaining samples is 0.999597.
281122 variants and 15155 people pass filters and QC.
Among remaining phenotypes, 4496 are cases and 10659 are controls.
--make-bed to FinnuncorrNLITUK1UK3hap300_CQ_norel.bed +
FinnuncorrNLITUK1UK3hap300_CQ_norel.bim +
#+end_example

***** STARTED Imputation des données manquantes
:LOGBOOK:
- Note taken on [2017-08-17 jeu. 13:48] \\
  il va falloir le relancer ! ca prend du temps !!! > 1 jour, peut être
  augmenter nb thread et ram
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:48]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 18:53]
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:

#+NAME: code:gwas_impute
#+CAPTION: Dépend de [[code:gwas_ibd_filter]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/Celiac/dubois_2010/
  ## recode to vcf
  plink --bfile FinnuncorrNLITUK1UK3hap300_CQ_prunned_norel --recode vcf bgz --out FinnuncorrNLITUK1UK3hap300_CQ_norel --threads 8
  ## run beagle
  java -Xmx40g -jar beagle.08Jun17.d8b.jar gt=FinnuncorrNLITUK1UK3hap300_CQ_norel.vcf.gz out=FinnuncorrNLITUK1UK3hap300_CQ_norel_imputed nthreads=8

  ##
#+end_src

***** TODO Conversion au format R et scaling
:LOGBOOK:
- State "TODO"       from              [2017-08-06 Sun 14:52]
:END:
#+begin_src R :results output :exports both :session *ssh krakenator*
  library(bigsnpr)
  celiac <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")
  ind.clumping <- readRDS("./Data/Celiac/dubois_2010/celiacQC_flo/celiacQC_clumping_ind.rds")

  ## save clumped loci
  saveRDS(ind.clumping, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  ## filter correlated indiv to  0.08
  celiac.aux <- snp_attach("~/Projects/Thesis/Data/Celiac/dubois_2010/backingfiles/celiacQC.rds")
  ind.indiv <- which(celiac$fam$sample.ID %in% celiac.aux$fam$sample.ID)

  ## G
  G <- attach.BM(celiac$genotypes)[ind.indiv,]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID
  n <- nrow(G)
  L <- ncol(G)

  ## memory cleaning
  rm(celiac)
  rm(celiac.aux)
  gc()

  ## G <- scale(G) ## too much memory used...
  mu <- apply(G, 2, mean)
  sigma <- apply(G,2,sd)
  gc()
  G <- sweep(G, 2, mu)
  rm(mu)
  gc()
  G <- sweep(G, 2, sigma, FUN = "/")
  rm(sigma)
  gc()

  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  dim(G)


  ## G clumped
  G <- attach.BM(celiac$genotypes)[ind.indiv,ind.clumping]
  rownames(G) <- celiac$fam$sample.ID[ind.indiv]
  colnames(G) <- celiac$map$marker.ID[ind.clumping]
  n <- nrow(G)
  L <- ncol(G)
  G <- scale(G)
  saveRDS(G, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  dim(G)

  ## X
  X <- matrix(celiac$fam$affection[ind.indiv], n, 1)
  X <- scale(X)
  rownames(X) <- celiac$fam$sample.ID[ind.indiv]
  saveRDS(X, "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/X.rds")
  dim(X)
#+end_src

#+RESULTS:
: [1]  15155 281122
: [1] 15155 94497
: [1] 15155     1
****** Un petit test sur les données
#+begin_src R :results output :exports both
  G <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G.rds")
  G.clumped <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/G_clumped.rds")
  ind.clumping <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")

  mean(abs(G[,ind.clumping] - G.clumped))
#+end_src

#+RESULTS:
#+begin_example
  [1] 2.356696e-17
#+end_example
***** DONE Conversion au format =matter=
CLOSED: [2017-07-12 mer. 17:00]
:LOGBOOK:
- Note taken on [2017-07-12 mer. 17:00] \\
  Ok c'est fait mais attention !!! ce qu'il y a avant risque de changer !!!
- State "DONE"       from "STARTED"    [2017-07-12 mer. 17:00]
- State "STARTED"    from              [2017-07-12 mer. 15:58]
:END:
#+BEGIN_SRC R
  library(matter)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.matter <- matter::matter_mat(data = G,
                                 nrow = nrow(G), ncol = ncol(G))
  colnames(G.matter) <- colnames(G)
  rownames(G.matter) <- rownames(G)
  file.copy(paths(G.matter), "./Data/ThesisDataset/3Article/Celiac/G.matter.bin")
  paths(G.matter) <- "./Data/ThesisDataset/3Article/Celiac/G.matter.bin"
  ## G.matter <- matter_mat(path = "./Data/ThesisDataset/3Article/Celiac/G.matter.bin", nrow = 15155, ncol = 281122)
  saveRDS(G.matter, "./Data/ThesisDataset/3Article/Celiac/G.matter.rds")
#+END_SRC
***** CANCELLED Conversion au format =bigmatrix=
CLOSED: [2017-07-23 Sun 15:46]
:LOGBOOK:
- Note taken on [2017-07-23 Sun 15:46] \\
  MDRRRRR: 
  Error in SetMatrixElements(x@address, as.double(j), as.double(i), as.double(value)) : 
  long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
  In addition: Warning message:
  In filebacked.big.matrix(nrow = nrow, ncol = ncol, type = type,  :
  No descriptor file given, it will be named G.big.bin.desc
- State "CANCELLED"  from              [2017-07-23 Sun 15:46]
- State "TODO"       from              [2017-07-23 Sun 15:29]
:END:
#+BEGIN_SRC R
  library(bigmemory)

  G <- readRDS("./Data/ThesisDataset/3Article/Celiac/G.rds")
  G.big <- as.big.matrix(G,
                         backingpath = "./Data/ThesisDataset/3Article/Celiac/",
                         backingfile = "G.big.bin")
  colnames(G.big) <- colnames(G)
  rownames(G.big) <- rownames(G)
  saveRDS(G.big, "./Data/ThesisDataset/3Article/Celiac/G.big.rds")
#+END_SRC

***** DONE SNPs détecté par d'autre analyse
CLOSED: [2017-09-12 mar. 14:25]
:LOGBOOK:
- State "DONE"       from "STARTED"    [2017-09-12 mar. 14:25]
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:04] \\
  Il y a du ménage a faire ici !!
- State "TODO"       from              [2017-07-11 mar. 10:04]
:END:
We retrieve SNPs associated with Celiac disease in GWAS catalogue.
#+begin_src R 

  ## all the GWAS catalogue
  GWAS.catalog <- readRDS("~/Projects/Thesis/Data/GWASCatalog/gwas_catalog_v1.0.1-associations_e88_r2017-04-24.rds")

  ## filter for celiac desease
  celiac.catalog <- GWAS.catalog %>%
    dplyr::filter(grepl(".*[cC]eliac.*", `DISEASE/TRAIT`)) %>%
    mutate(marker.ID = SNPS)

  celiac.map <- readRDS("~/Projects/Thesis/Data/Celiac/dubois_2010/celiacQC_flo/backingfiles/celiacQC_flo.rds")$map

  ## join by marker_ID
  celiac.outlier <- celiac.map %>%
    inner_join(celiac.catalog) %>%
    as_tibble()

  ## filter dubois outlier
  celiac.outlier.dubois <- celiac.outlier %>% 
    dplyr::filter(grepl(".*[Dd]ubois.*", `FIRST AUTHOR`))

  celiac.outlier.dubois$`FIRST AUTHOR`

  ## not same pos
  ## celiac.outlier %>%
  ##   dplyr::select(marker.ID, chromosome, physical.pos, CHR_ID, CHR_POS) %>%
  ##   print.data.frame()

  ## a candidate list
  cat("nb of candidates:", length(celiac.outlier$SNPS %>% unique()), "\n")
  celiac.outlier$SNPS
  candidates <- which(celiac.map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  ## dubois candidate list
  cat("nb of dubois candidates:", length(celiac.outlier.dubois$SNPS %>% unique()), "\n")
  celiac.outlier.dubois$SNPS
  candidates <- which(celiac.map$marker.ID %in% celiac.outlier$SNPS)
  saveRDS(candidates,
          "~/Projects/Thesis/Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
#+end_src

#+RESULTS:
#+begin_example
Joining, by = "marker.ID"
nb of candidates: 49
 [1] "rs3748816"  "rs12727642" "rs10903122" "rs6691768"  "rs864537"  
 [6] "rs864537"   "rs859637"   "rs2157453"  "rs2816316"  "rs2816316" 
[11] "rs296547"   "rs13003464" "rs10188217" "rs13015714" "rs917997"  
[16] "rs13010713" "rs7574865"  "rs4675374"  "rs13098911" "rs6441961" 
[21] "rs17810546" "rs17810546" "rs10936599" "rs1464510"  "rs1464510" 
[26] "rs13151961" "rs13151961" "rs1020388"  "rs1033180"  "rs2187668" 
[31] "rs2187668"  "rs2474619"  "rs10806425" "rs531930"   "rs802734"  
[36] "rs2327832"  "rs1738074"  "rs1738074"  "rs212402"   "rs212388"  
[41] "rs6974491"  "rs9792269"  "rs975730"   "rs1953126"  "rs1250552" 
[46] "rs10876993" "rs653178"   "rs653178"   "rs653178"   "rs2762051" 
[51] "rs1958589"  "rs4899260"  "rs12928822" "rs2074404"  "rs1893217" 
[56] "rs1893217"  "rs157640"   "rs4819388"  "rs2298428"  "rs2298428"
#+end_example

Je ne sais pas ou Flo a récupéré ces datas mais c'est surement que la release du
genome humain est GRCh37, alors que ce que j'ai ddl sur gwas catalog repose sur
GRCh38. 

*Ccl*: on va prendre ces outliers car les rs reste les mêmes d'après Thomas K.

***** DONE Scree plot
CLOSED: [2017-08-30 mer. 09:31]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 09:31]
- State "RUNNING"    from "DONE"       [2017-08-29 mar. 12:01]
- State "DONE"       from "RUNNING"    [2017-08-29 mar. 11:56]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:59]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-07-30 Sun 11:28]
- Note taken on [2017-07-30 Sun 11:27] \\
  c'est fait mais la projection change rien !!
- State "RUNNING"    from "DEBUG"      [2017-07-26 mer. 18:09]
- Note taken on [2017-07-26 mer. 18:09] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:07] \\
  On va relancer sans Rspectra, ca prend trop de temps !!!!
- State "DEBUG"      from "DONE"       [2017-07-26 mer. 18:06]
- State "DONE"       from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "STARTED"    [2017-07-25 mar. 18:21]
- Note taken on [2017-07-25 mar. 18:19] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_screeplot.y2017_m07_d25.log
- State "STARTED"    from "TODO"       [2017-07-11 mar. 10:26]
- Note taken on [2017-07-11 mar. 10:03] \\
  J'utilise ThesisRpackage, il faudra changer ca si je veux que la thèse soit
  stand alone
- State "TODO"       from              [2017-07-11 mar. 10:03]
:END:

#+NAME: code:gwas_screeplot
#+CAPTION: Dépend de 
#+begin_src R  
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds"
  X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"


  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "gwas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  save_plot_png(pl, "gwas_screeplot.png")

#+end_src

#+RESULTS:
[[file:../Rplots/celiac_pca.png]]
[[./OUTPUT/Rplots/gwas_screeplot.png]]

On prend K = 9 variables latentes.

***** DONE Validation croisée avec lfmmRidge
CLOSED: [2017-08-31 jeu. 10:03]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 10:03]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 09:37]
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 08:42]
- State "RUNNING"    from "DONE"       [2017-08-28 lun. 15:47]
- State "DONE"       from "RUNNING"    [2017-08-28 lun. 11:53]
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:17]
- Note taken on [2017-08-17 Thu 18:16] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_CV_encore_encore.y2017_m08_d17.log
- Note taken on [2017-08-17 jeu. 13:47] \\
  il va falloir relancer gwas_CV_encore_encore !!!
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 13:47]
- State "RUNNING"    from "DONE"       [2017-08-16 mer. 15:08]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 09:53]
- Note taken on [2017-08-14 lun. 12:07] \\
  Il y a aussi gwas_CV_lambda qui tourne !
- Note taken on [2017-08-14 lun. 12:02] \\
  il y a [[gwas_CV_encore]] qui tourne
- State "RUNNING"    from "DEBUG"      [2017-08-09 mer. 15:26]
- Note taken on [2017-08-09 mer. 15:24] \\
  c'est reparti sur tail -f /home/cayek/tmp/Logfiles/gwas.y2017_m08_d09.log
- State "DEBUG"      from "RUNNING"    [2017-08-03 jeu. 14:17]
- Note taken on [2017-08-03 jeu. 14:16] \\
  ca buggé, le processus c'est fait tuer. Il en était a au bout de 5 jours...
  > res.cv <- ExpRmouline(cv, dat)
  === params
    lambda K
  1  1e-05 1
  === params
    lambda K
  2      1 1
  === params
    lambda K
  3  1e+10 1
  === params
    lambda K
  4  1e-05 2
  === params
    lambda K
  5      1 2
  === params
    lambda K
  6  1e+10 2
- State "RUNNING"    from "TODO"       [2017-07-30 Sun 11:31]
- Note taken on [2017-07-30 Sun 11:31] \\
  c'est parti : tail -f /home/cayek/tmp/Logfiles/gwas_CV.y2017_m07_d30.log
- Note taken on [2017-07-11 mar. 10:10] \\
  On va voir si ca passe :D
- State "TODO"       from              [2017-07-11 mar. 10:10]
:END:

#+NAME: code:gwas_CV
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(1,2,5,9,50))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K.png]]

#+NAME: code:gwas_CV_encore
#+CAPTION: Dépend de [[code:gwas_CV]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(10,13,20))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore.png]]

#+NAME: code:gwas_CV_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 6:8)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore.png]]

#+NAME: code:gwas_CV_encore_encore_encore
#+CAPTION: Dépend de [[code:gwas_CV_encore_encore]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 3:4)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lfmm_encore_encore_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "gwas_CV_lfmm_K_encore_encore_encore.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lfmm_K_encore_encore_encore.png]]

#+NAME: code:gwas_CV_lambda
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(9))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## save expr
  save_expr(res.cv, "gwas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda.png]]

#+NAME: code:gwas_CV_lambda_encore
#+CAPTION: Dépend de [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(8,10))

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_encore.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_encore.png]]

#+NAME: code:gwas_CV_lambda_round2
#+CAPTION: Dépend de 
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)
  lambdas <- c(1e-5, 1, 10, 1e3, 1e10)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 9)

  ## run
  res.cv <- ExpRmouline(cv, dat)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_round2.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_round2.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_round2.png]]

#+NAME: code:gwas_CV_lambda_round2_encore
#+CAPTION: Dépend de [[code:gwas_CV_lambda_round2]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/Celiac/G_clumped.rds",
                              X = "./Data/ThesisDataset/3Article/Celiac/X.rds",
                              outlier = NULL) %>% ExpRmouline()
  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e5, 1e20)
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 9)

  ## run
  res.cv <- ExpRmouline(cv, dat)

  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm_round2.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "gwas_CV_lambda_lfmm_round2_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "gwas_CV_lambda_lfmm_lambda_round2_encore.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_CV_lambda_lfmm_lambda_round2_encore.png]]

***** DONE Étude du jeu de données 
CLOSED: [2017-09-01 ven. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:31]
- State "TODO"       from "DONE"       [2017-09-01 ven. 09:27]
- State "DONE"       from "RUNNING"    [2017-09-01 ven. 09:27]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 09:28]
- State "DONE"       from "RUNNING"    [2017-07-28 ven. 09:25]
- Note taken on [2017-07-27 jeu. 13:50] \\
  tail -f /home/cayek/tmp/Logfiles/gwas_run.y2017_m07_d27.log
- State "RUNNING"    from "DEBUG"      [2017-07-27 jeu. 13:50]
- State "DEBUG"      from "RUNNING"    [2017-07-26 mer. 18:06]
- State "RUNNING"    from "DEBUG"      [2017-07-24 Mon 07:35]
- State "DEBUG"      from "DONE"       [2017-07-24 Mon 06:58]
- State "DONE"       from "RUNNING"    [2017-07-24 Mon 06:58]
- Note taken on [2017-07-23 Sun 16:13] \\
  C'est reparti !! sur krakenator en dehors de annaconda biensur !! pour que
  matter marche (pour avoir R 3.4)
- State "RUNNING"    from "DEBUG"      [2017-07-23 Sun 16:13]
- State "DEBUG"      from "DONE"       [2017-07-17 Lun 08:18]
- State "DONE"       from "RUNNING"    [2017-07-17 Lun 08:18]
- Note taken on [2017-07-17 Lun 08:18] \\
  lasso c'est planté !! il faudra le relancer mais le reste est OK !!
- Note taken on [2017-07-13 jeu. 08:55] \\
  C'est reparti sur krak !!
- State "RUNNING"    from "STARTED"    [2017-07-13 jeu. 08:55]
- State "STARTED"    from "TODO"       [2017-07-12 mer. 08:40]
- State "TODO"       from              [2017-07-11 mar. 11:37]
:END:
****** DONE Run des méthodes
CLOSED: [2017-09-01 ven. 09:27]
:LOGBOOK:
- State "DONE"       from              [2017-09-01 ven. 09:27]
:END:
#+NAME: code:gwas_expr
#+CAPTION: Etude d'association des données Celiac avec cate ridgeLFMM LassoLFMM LM et LMPCAS. Dépend de 
#+begin_src R
  library(MaTheseR)
  library(lfmm)
  library(matter)
  library(foreach)
  library(doParallel)


  rerun <- FALSE
  nb.cluster <- 2
  ## param
  param <- list(K.method = 9, lambda = 1e3,
                nozero.prop = 0.01,lambda.num = 25,
                relative.err.epsilon = 1e-6)


  ## methods
  methods <- list()
  methods$m.lm <- method_lm()
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = param$K.method, lambda = param$lambda)
  methods$m.pca <- method_PCAlm(K = param$K.method)
  methods$m.cate <- method_cate(K = param$K.method)
  methods$m.lasso <- method_lassoLFMM(K = param$K.method,
                                      nozero.prop = param$nozero.prop,
                                      lambda.num = param$lambda.num,
                                      relative.err.epsilon = param$relative.err.epsilon)

  run_celiac <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/Celiac/G.matter.rds"
    X <- "./Data/ThesisDataset/3Article/Celiac/X.rds"
    outlier <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
    dat <- MaTheseR::LfmmMatterDat(Y, X, outlier)
    col.mask <- readRDS("./Data/ThesisDataset/3Article/Celiac/ind.clumpling.rds")
    out.file.res.df <- paste0("./OUTPUT/Expr/Celiac_df","_", m$name)
    out.file.U <- paste0("./OUTPUT/Expr/Celiac_U","_", m$name)

    if (!exist_res(m, out.file.res.df) && !rerun) {
      ## mask data
      message("mask data")
      dat.masked <- lfmm::LfmmDat(Y = NULL, X = dat$X, missing = FALSE)
      dat.masked$Y <- dat$Y[,col.mask]

      ## compute lattente variable
      message("computing U")
      if (!exist_res(m, out.file.U)) {
        m.U <- ExpRmouline(m, dat.masked)
        save_res(m, m.U, out.file.U)
      } else {
        m.U <- retrieve_res(m, out.file.U)
      }

      ## unmask
      message("unmask data")
      rm(dat.masked)
      gc()

      ## run HP
      message("running HP")
      m.res <- m
      X <- cbind(dat$X, m.U$U)
      d <- ncol(dat$X)
      hp <- lfmm::hypothesis_testing_lm(dat, X)
      m.res$score <- hp$score[,1:d, drop = FALSE]
      m.res$pvalue <- hp$pvalue[,1:d, drop = FALSE]
      m.res$B.hp <- hp$B[,1:d, drop = FALSE]
      ## saving res
      message("saving res.df")
      df <- ExpRextractor_pvalue1_calibrated(dat, m.res, 1, 1)
      save_res(m, df, out.file.res.df)
    } else {
      message("res.df exist !! ")
    }
  }


  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  foreach(m = methods) %dopar% {
    run_celiac(m)
  }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## cbind res
  res.df <- tibble()
  for (m in methods) {
    out.file.res.df <- paste0("./OUTPUT/Expr/Celiac_df","_", m$name)
    if (exist_res(m, out.file.res.df)) {
      message("=============== ", m$name)
      res.df <- res.df %>%
        rbind(retrieve_res(m, out.file.res.df))
    }
  }

  save_expr(res.df, "celiac_all_df.rds")
#+end_src

****** DONE Que donne la calibration
CLOSED: [2017-09-01 ven. 09:28]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:28]
- State "TODO"       from              [2017-08-31 jeu. 09:10]
:END:

#+NAME: code:gwas_expr_calibration
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  res.df %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+end_src

#+RESULTS: code:gwas_expr_calibration
: # A tibble: 5 x 3
:      method      mad       median
:       <chr>    <dbl>        <dbl>
: 1      cate 1.052221  0.011781682
: 2 lassoLFMM 1.045186  0.012433327
: 3        lm 1.201294 -0.023610211
: 4     PCAlm 1.037876  0.009601749
: 5 ridgeLFMM 1.041061  0.009624663

****** DONE Gwas catalogue et controle du fdr
CLOSED: [2017-09-01 ven. 09:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:29]
- State "TODO"       from              [2017-08-31 jeu. 09:10]
:END:

#+NAME: code:gwas_expr_fdr
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  expr <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  ## fdr 5%
  toplot <- expr %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.05)

  ## candidats
  toplot %>% group_by(method) %>%
    summarise(power = mean(candidates %in% index))

  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "gwas_fdr01_inter.png")

#+end_src

#+RESULTS: code:gwas_expr_fdr
[[./OUTPUT/Rplots/gwas_fdr01_inter.png]]
: # A tibble: 5 x 2
:      method     power
:       <chr>     <dbl>
: 1      cate 0.7755102
: 2 lassoLFMM 0.7959184
: 3        lm 0.5714286
: 4     PCAlm 0.5102041
: 5 ridgeLFMM 0.5306122
****** DONE plot top * power
CLOSED: [2017-09-01 ven. 09:31]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:31]
- State "TODO"       from "DONE"       [2017-08-31 jeu. 09:10]
- State "DONE"       from              [2017-08-07 lun. 18:12]
:END:
#+NAME: code:gwas_top_power
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")

  m1 <- length(candidates)
  res.df

  df <- res.df %>%
    transmute(method = method,
              index = index,
              pvalue = pvalue,
              outlier = index %in% candidates) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup()

  df <- df %>%
    add_row(method = unique(df$method), top = 0, power = 0)

  pl <- ggplot(df, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,3000))
  pl
  save_plot_png(pl, "gwas_top_power.png")

#+end_src

#+RESULTS: code:gwas_top_power
[[./OUTPUT/Rplots/gwas_top_power.png]]
#+begin_example
# A tibble: 1,405,610 x 14
       pvalue    colname index outlier        score rep.sampler rep.method
        <dbl>      <chr> <int>   <lgl>        <dbl>       <dbl>      <dbl>
 1 0.84762413  rs3934834     1   FALSE -0.192154026           1          1
 2 0.13045046  rs3737728     2   FALSE  1.512409930           1          1
 3 0.09462707  rs6687776     3   FALSE  1.671583791           1          1
 4 0.47099482  rs9651273     4   FALSE  0.720879427           1          1
 5 0.99457651  rs4970405     5   FALSE -0.006797506           1          1
 6 0.82921368 rs12726255     6   FALSE  0.215713881           1          1
 7 0.70303213  rs2298217     7   FALSE -0.381237819           1          1
 8 0.62074572  rs4970362     8   FALSE  0.494803906           1          1
 9 0.76159116  rs9660710     9   FALSE -0.303397447           1          1
10 0.24429269  rs4970420    10   FALSE -1.164369349           1          1
# ... with 1,405,600 more rows, and 7 more variables: method <chr>,
#   method.K <dbl>, method.lambda <dbl>, median <dbl>, mad <dbl>,
#   calibrated.score <dbl>, calibrated.pvalue <dbl>
#+end_example
****** DONE histogrammes
CLOSED: [2017-09-01 ven. 10:20]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 10:20]
- State "TODO"       from              [2017-09-01 ven. 10:13]
:END:

#+NAME: code:gwas_histogram
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")

  pl <- ggplot(res.df, aes(pvalue, color = method)) +
    geom_histogram() +
    facet_grid(method ~ .)
  save_plot_png(pl, "gwas_hist_pvalue.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_hist_pvalue.png]]
****** DONE Clumping
CLOSED: [2017-09-12 mar. 13:59]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 13:59]
- State "TODO"       from "DONE"       [2017-09-12 mar. 13:38]
- State "DONE"       from "TODO"       [2017-09-12 mar. 13:12]
- State "TODO"       from              [2017-09-12 mar. 11:22]
:END:

[[http://zzz.bwh.harvard.edu/plink/clump.shtml][doc plink pour le cluming]]

#+NAME: code:gwas_clumping
#+CAPTION: Dépend de [[code:gwas_expr]]
#+begin_src R 
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")


  ## how much pvalue are less than 0.001
  th <- 0.05
  message("Pvalue less than ", th)
  res.df %>% group_by(method) %>%
    summarise(count = sum(pvalue < th))

  methods <- res.df$method %>% unique()
  methods

  res <- tibble()
  for (m in methods) {
    tmp.file <- tempfile(tmpdir = "~/Projects/Thesis/Data/Celiac/dubois_2010/")
    res.df %>% dplyr::filter(method == m) %>%
      dplyr::transmute(P = pvalue, SNP = colname) %>%
      readr::write_delim(path = tmp.file, delim = "\t")
    plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                       "--bfile ~/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ",
                       "--clump",
                        tmp.file,
                        "--clump-p1 0.05",
                        "--clump-p2 0.1",
                        "--clump-r2 0.20",
                        "--clump-kb 250",
                        "--out plink.clump",
                       "--threads 8")
    system(plink.cmd)

    ## retrieve res
    ## clumping.res <- readr::read_table2(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
    ##                                   col_types = cols(
    ##                                     CHR = col_integer(),
    ##                                     F = col_integer(),
    ##                                     SNP = col_character(),
    ##                                     BP = col_integer(),
    ##                                     P = col_character(),
    ##                                     TOTAL = col_integer(),
    ##                                     NSIG = col_integer(),
    ##                                     S05 = col_integer(),
    ##                                     S01 = col_integer(),
    ##                                     S001 = col_integer(),
    ##                                     S0001 = col_integer(),
    ##                                     SP2 = col_character()))
    clumping.res <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                      data.table = FALSE) %>% as_tibble()

    res <- clumping.res %>%
      mutate(method = m) %>%
      rbind(res)

    file.remove(tmp.file)
  }

  ## saving
  save_expr(res, "celiac_all_clumped.rds")

#+end_src

#+RESULTS: code:gwas_clumping
#+begin_example
Pvalue less than 0.05
# A tibble: 5 x 2
     method count
      <chr> <int>
1      cate 19662
2 lassoLFMM 19261
3        lm 30645
4     PCAlm 18086
5 ridgeLFMM 18345
[1] "lm"        "ridgeLFMM" "PCAlm"     "cate"      "lassoLFMM"
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea243372aa
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 15788 clumps formed from 30645 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea6381dade
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10033 clumps formed from 18345 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea1f19c5ca
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 9905 clumps formed from 18086 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea7bc86cf
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10535 clumps formed from 19662 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010/FinnuncorrNLITUK1UK3hap300_CQ
  --clump /home/cayek/Projects/Thesis/Data/Celiac/dubois_2010//file69ea38ddb236
  --clump-kb 250
  --clump-p1 0.05
  --clump-p2 0.1
  --clump-r2 0.20
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
281122 variants loaded from .bim file.
15283 people (6713 males, 8570 females) loaded from .fam.
15283 phenotype values loaded from .fam.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 15283 founders and 0 nonfounders present.
Calculating allele frequencies... 0%1%2%3%4%5%6%7%8%9%10%11%12%13%14%15%16%17%18%19%20%21%22%23%24%25%26%27%28%29%30%31%32%33%34%35%36%37%38%39%40%41%42%43%44%45%46%47%48%49%50%51%52%53%54%55%56%57%58%59%60%61%62%63%64%65%66%67%68%69%70%71%72%73%74%75%76%77%78%79%80%81%82%83%84%85%86%87%88%89%90%91%92%93%94%95%96%97%98%99% done.
Total genotyping rate is 0.999596.
281122 variants and 15283 people pass filters and QC.
Among remaining phenotypes, 4533 are cases and 10750 are controls.
--clump: 10381 clumps formed from 19261 top variants.
Results written to plink.clump.clumped .
Warning messages:
1: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '1.25e-320'. It was read using (double)strtold() as numeric value 1.2499860839783538E-320 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
2: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '1.38e-322'. It was read using (double)strtold() as numeric value 1.3833838083554903E-322 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
3: In data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",  :
  C function strtod() returned ERANGE for one or more fields. The first was string input '4.96e-313'. It was read using (double)strtold() as numeric value 4.9599999999789495E-313 (displayed here using %.16E); loss of accuracy likely occurred. This message is designed to tell you exactly what has been done by fread's C code, so you can search yourself online for many references about double precision accuracy and these specific C functions. You may wish to use colClasses to read the column as character instead and then coerce that column using the Rmpfr package for greater accuracy.
Expr save in ./OUTPUT/Expr/celiac_all_clumped.rds
#+end_example

****** DONE plot clumped top * power
CLOSED: [2017-09-12 mar. 14:55]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 14:55]
- State "TODO"       from              [2017-09-12 mar. 13:13]
:END:
#+NAME: code:gwas_top_power_clumped
#+CAPTION: Dépend de [[code:gwas_expr]] [[code:gwas_clumping]]
#+begin_src R 
  library(MaTheseR)
  library(stringr)
  res.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  clumped.res.df <- readRDS("./OUTPUT/Expr/celiac_all_clumped.rds")

  candidates.snp <- (res.df %>% dplyr::filter(index %in% candidates))$colname %>% unique()

  df <- clumped.res.df %>%
    transmute(method = method,
              pvalue = P,
              outlier.SNP = SNP %in% candidates.snp,
              outlier.SP2.count = str_count(SP2, paste(candidates.snp, collapse = "|")),
              outlier = outlier.SNP | (outlier.SP2.count >= 1)) %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(candidate = cumsum(outlier), clumped.top = seq_along(pvalue)) %>%
    ungroup()

  sum(df$outlier) / 5 ## the number of method

  df <- df %>%
    add_row(method = unique(df$method), clumped.top = 0, candidate = 0)

  pl <- ggplot(df, aes(x = clumped.top, y = candidate, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,1000))
  pl
  save_plot_png(pl, "gwas_clumped_top_power.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/gwas_clumped_top_power.png]]

***** DONE Plots
CLOSED: [2017-09-01 ven. 13:13]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:13]
- State "TODO"       from              [2017-08-06 Sun 15:11]
:END:
****** DONE Choix des paramètres
CLOSED: [2017-09-01 ven. 09:35]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 09:35]
- State "TODO"       from              [2017-08-14 lun. 11:40]
:END:
#+NAME: code:gwas_screeplot_CV
#+CAPTION: Dépend de [[code:gwas_screeplot]] [[code:gwas_CV]] [[code:gwas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  df.res <- readRDS("./OUTPUT/Expr/gwas_screeplot_expr.rds")
  plA <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,50)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "gwas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lfmm_encore_encore_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plB, "gwas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/gwas_CV_lambda_lfmm_round2_encore.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() +
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    geom_vline(xintercept = 1e3, linetype = "dashed") +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.2, 0.2))
  save_plot_png(plC, "gwas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "gwas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:gwas_screeplot_CV
[[./OUTPUT/Rplots/gwas_screeplot.png]]
[[./OUTPUT/Rplots/gwas_CV_K.png]]
[[./OUTPUT/Rplots/gwas_CV_lambda.png]]

****** DONE Résultats des méthodes
CLOSED: [2017-09-01 ven. 13:13]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:13]
- State "TODO"       from              [2017-08-14 lun. 11:50]
:END:
#+NAME: code:gwas_qqplot_venn
#+CAPTION: Dépend de [[code:gwas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme


  celiac.df <- readRDS("./OUTPUT/Expr/celiac_all_df.rds")
  candidates <- readRDS("./Data/ThesisDataset/3Article/Celiac/gwas_catalog_candidates.rds")
  m1 <- length(candidates)

  ## filter and order method
  ## celiac.df$method %>% unique()
  df.res <- celiac.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              outlier = index %in% candidates)
  df.res$method %>% unique()

  ## qqplot
  pl.qq <- ggplot(df.res, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom")
  legend <- g_legend(pl.qq)
  pl.qq <- pl.qq + 
    theme(legend.position="none") +
    xlab("Quantiles théoriques") + 
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "gwas_qqplot_notcalibrated_all.png")

  ## top * power plot
  toplot <-  df.res %>%
    group_by(method) %>%
    arrange(method, pvalue) %>%
    mutate(power = cumsum(outlier) / m1, top = seq_along(pvalue)) %>%
    ungroup() 
  toplot <- toplot  %>%
    add_row(method = unique(toplot$method), top = 0, power = 0)

  pl.top <- ggplot(toplot, aes(x = top, y = power, color = method)) +
    geom_line() +
    coord_cartesian(xlim = c(0,1500)) +
    scale_color_manual(values = color.values) +
    gtheme +
    theme(legend.position="none") +
    xlab("Taille de la top liste") +
    ylab("Candidats retrouvés") +
    scale_y_continuous(labels=percent)

  ## When to we have every candidates ?
  message("== Top all ==")
  toplot %>% group_by(method) %>% summarise(top = min(which(power >= 1.0))) %>% knitr::kable()
  message("== Top 3000 ==")
  toplot %>% dplyr::filter(top == 3000) %>% knitr::kable()
  message("== Top 1000 ==")
  toplot %>% dplyr::filter(top == 1000) %>% knitr::kable()

  ## pl.top
  save_plot_png(pl.top, filename = "gwas_top_power_all.png")

  ## gather plot
  pl <- plot_grid(pl.qq, pl.top, ncol = 1, labels = c("A", "B"))
  ## add legend
  pl.leg <- drawable(function() {
    grid.arrange(pl,
                 legend, nrow=2, heights=c(10, 1))
  })
  save_plot_MaTheseR(pl.leg, "gwas_qqplot_top.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  toplot <- df.res %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_threshold(0.01) %>%
    ungroup()
  message("== List with fdr controle ==")
  toplot %>% group_by(method) %>% summarise(n = length(outlier),
                                            power = sum(outlier) / m1)

  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"],
               lm = toplot$index[toplot$method == "lm"]
               )

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quintuple.venn(
                         area1 = inter(1),
                         area2 = inter(2),
                         area3 = inter(3),
                         area4 = inter(4),
                         area5 = inter(5),
                         n12 = inter(1,2),
                         n13 = inter(1,3),
                         n14 = inter(1,4),
                         n15 = inter(1,5),
                         n23 = inter(2,3),
                         n24 = inter(2,4),
                         n25 = inter(2,5),
                         n34 = inter(3,4),
                         n35 = inter(3,5),
                         n45 = inter(4,5),
                         n123 = inter(1,2,3),
                         n124 = inter(1,2,4),
                         n125 = inter(1,2,5),
                         n134 = inter(1,3,4),
                         n135 = inter(1,3,5),
                         n145 = inter(1,4,5),
                         n234 = inter(2,3,4),
                         n235 = inter(2,3,5),
                         n245 = inter(2,4,5),
                         n345 = inter(3,4,5),
                         n1234 = inter(1,2,3,4),
                         n1235 = inter(1,2,3,5),
                         n1245 = inter(1,2,4,5),
                         n1345 = inter(1,3,4,5),
                         n2345 = inter(2,3,4,5),
                         n12345 = inter(1,2,3,4,5),
                         category = names(sets),
                         fill = color.values[names(sets)],
                         cat.col = color.values[names(sets)],
                         cat.cex = 1.2,
                         cat.pos = c(0.0, -30, 180, 180, 30),
                         cat.dist = c(0.2,0.25,0.2,0.2,0.25),
                         margin = 0.07,
                         ind = TRUE
                       )

  save_plot_png(venn, filename = "gwas_venn.png")
  save_plot_MaTheseR(venn, "gwas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)


  ## list de l'intersection total
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  message("== Prop of candidate in inter all ==")
  l <- inter.list(1,2,3,4,5)
  mean(candidates %in% l)
  message("== Prop of candidate in inter cate lfmm pcalm ==")
  l <- inter.list(1,2,3)
  mean(candidates %in% l)
#+END_SRC

#+RESULTS: code:gwas_qqplot_venn
#+begin_example
  [1] lm        ridgeLFMM PCAlm     cate      lassoLFMM
  Levels: lm PCAlm sva-two-step sva-irw lassoLFMM cate ridgeLFMM oracle
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  [[./OUTPUT/Rplots/gwas_qqplot_notcalibrated_all.png]]
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  == Top all ==


  |method    |    top|
  |:---------|------:|
  |lm        | 213444|
  |PCAlm     | 259689|
  |lassoLFMM | 151172|
  |cate      | 156858|
  |ridgeLFMM | 247464|
  == Top 3000 ==


  |method    |  index|    pvalue| calibrated.pvalue|outlier |     power|  top|
  |:---------|------:|---------:|-----------------:|:-------|---------:|----:|
  |lm        | 274194| 0.0005995|         0.0040140|FALSE   | 0.7755102| 3000|
  |PCAlm     |  68895| 0.0047380|         0.0066796|FALSE   | 0.8367347| 3000|
  |lassoLFMM | 148728| 0.0030905|         0.0048138|FALSE   | 0.8775510| 3000|
  |cate      |  86890| 0.0027883|         0.0043251|FALSE   | 0.8775510| 3000|
  |ridgeLFMM |  28408| 0.0045857|         0.0062832|FALSE   | 0.8367347| 3000|
  == Top 1000 ==


  |method    |  index|    pvalue| calibrated.pvalue|outlier |     power|  top|
  |:---------|------:|---------:|-----------------:|:-------|---------:|----:|
  |lm        | 103211| 0.0000000|          0.000000|FALSE   | 0.1224490| 1000|
  |PCAlm     | 103161| 0.0001711|          0.000303|FALSE   | 0.5714286| 1000|
  |lassoLFMM | 102648| 0.0000000|          0.000000|FALSE   | 0.1836735| 1000|
  |cate      | 103120| 0.0000000|          0.000000|FALSE   | 0.1428571| 1000|
  |ridgeLFMM |  28634| 0.0001809|          0.000310|FALSE   | 0.6326531| 1000|
  [[./OUTPUT/Rplots/gwas_top_power_all.png]]
  Warning message:
  Removed 310 rows containing non-finite values (stat_qq).
  [[./OUTPUT/Rplots/gwas_qqplot_top.pdf.png]]
  == List with fdr controle ==
  # A tibble: 5 x 3
       method     n     power
       <fctr> <int>     <dbl>
  1        lm  1319 0.4489796
  2     PCAlm   777 0.3673469
  3 lassoLFMM  1267 0.6122449
  4      cate  1319 0.6734694
  5 ridgeLFMM   754 0.3673469
  [[./OUTPUT/Rplots/gwas_venn.png]]
  [[./OUTPUT/Rplots/gwas_venn.pdf.png]]
  == Prop of candidate in inter all ==
  [1] 0.2857143
  == Prop of candidate in inter cate lfmm pcalm ==
  [1] 0.3673469
#+end_example

*** Étude d'association entre des données génétiques et un gradient environmental (GEAS)
<<sec:GEAS>>

Depuis Darwin nous s'avons que les organismes vivants s'adaptent à leur
environnement cite:Darwin. Ainsi les organismes les mieux adaptées à leur
habitat ont plus de chance de survivre et de se reproduire. Si l'avantage
adaptatif à des causes génétiques, c'est à dire qu'il existe une combinaison de
gènes qui confère à l'organisme une fonction lui permettant d'être mieux adapté
à son habitat, alors le patrimoine génétique qui confère l'avantage adaptatif
est transmis aux futures générations. On peut donc alors chercher à détecter les
signatures génétiques laissées par l'adaptation à un environnement. C'est
l'objectif des associations génotype-environement. Pour cela nous avons récupéré
les données génétiques du projet 1000Genome phase 3 cite:1000Genome_2015. Ces
données regroupes $84.4$ millions de variants génétiques pour 2506 individus
venant de 26 populations différentes. Par ailleurs nous avons récupéré des
données climatiques à partir de la base de données WorldClim 2.0 cite:Fick_2017.
Nous avons comparé les résultats des méthodes lm, PCAlm, cate, ridgeLFMM et
lassoLFMM lancé sur d'association entre les données du 1000Genome et un gradient
environnemental.

De la même façon que pour la GWAS nous avons filtré les individus trop
apparentés et les variants génétiques pas assez fréquents (voir Partie
[[sec:gwas]]). De plus pour faire une étude d'association entre un génotype et un
environnemental, il faut garder les individus qui vivent dans leurs habitats
depuis plusieurs générations, nous avons donc enlevé les populations
afro-américaine et africaine des caraïbes. Il reste alors 1409 individus et
5397214 locus. Enfin, de la même façon que pour la GWAS nous avons identifié un
sous ensemble de 296948 SNPs grâce au LD pruning des 5397214 locus. Nous avons
utilisé ce sous ensemble de locus pour calculer les variables latentes avec les
méthodes PCAlm, cate, lassoLFMM et ridgeLFMM. Nous avons calculé ensuite des
\pvalues pour chacun des 5397214 locus grâce au test d'hypothèse présenté dans
la partie [[sec:hypothese]].

Afin de calculer le gradient environnemental utilisé pour l'étude d'association
nous avons attribué une position géographique à chaque individu en prenant la
capital de son pays d'origine. Cela nous a parmi de récupérer les données de la
base WorlClim pour les positions géographiques ainsi calculées. Nous ne gardons
que la première composante principale des variables de la base Wordclim. La
Figure ref:fig:eas_gradient représente la valeur du gradient climatique pour
chaque population. On remarque que celui-ci est très corrélé avec la latitude.
En effet, comme les populations sont à différentes latitudes il y a de la
corrélation entre la structure de population et le gradient environnemental.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_climatic_gradient.pdf.png}
\caption{Gradient climatique $\X$ utilisé pour l'association génotype-environement.}
\label{fig:eas_gradient}
\end{figure}
#+END_EXPORT

Nous avons lancer les méthodes cate, ridgeLFMM, lassoLFMM et PCAlm avec 9
variables latentes. Les figures ref:fig:eas_params A et B semble plutôt indiquer
5 variables latentes mais nous avons préféré prendre un nombre légèrement plus
élevé car les individus proviennent de 16 populations différentes. Nous avons
choisi $\lambdaRidge = 10^{-5}$ pour ridgeLFMM et une proportion de lignes non
nulles de $\B$ valant $1 \%$ pour lassoLFMM.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_hyperparams.pdf.png}
\caption{Choix des paramètres pour l'étude d'association entre un génotype et un
  gradient environnemental. A) Proportion de variance expliquées de la
  projection de $\Y$ sur l'espace orthogonal à $\X$ (c'est à dire $\matr{D}_{0}
  \Q^{T} \Y$) par chacune des composantes principales. B)C) Erreur de prédiction
  calculée grâce à la validation croisée des estimateurs $L_{2}$ des paramètres
  de LFMM pour différentes valeurs du paramètre de régularisation $\lambdaRidge$
  et du nombre de variables latentes $\K$, le point représente l'erreur de
  prédiction moyenne et les bars l'erreur standard. Les lignes pointillées
  verticales marquent sur A et B le nombre de variables latentes choisi, c'est à
  dire 9, et sur C le paramètre de régularisation $L_2$ choisi, c'est à dire
  $10^3$.}
\label{fig:eas_params}
\end{figure}
#+END_EXPORT

La figure ref:fig:geas_qqplot montre la distribution observée des \pvalues
renvoyées par chaque méthode contre la distribution théorique sous l'hypothèse
nulle. On constate une forte inflation de la méthode lm, le MAD des \pvalues
renvoyées par lm est de $8.7$. De plus on remarque que le diagramme
quantile-quantile de lm forme une droite. Cela signifie qu'il n'y a de pas de
surplus de \pvalues atypiques alors que c'est dans ce surplus de \pvalues
atypiques que l'on trouve les variables candidates pour l'association avec $\X$.
En d'autre terme lm ne renvoie pas plus de \pvalues outlier que le hasard en
donnerait. Par contre, on observe un surplus \pvalues atypiques dans les
\pvalues renvoyées par les autre méthodes. Pour les méthodes PCAlm, ridgeLFMM,
lassoLFMM et cate nous avons calculé la liste candidats quand on contrôle le FDR
à $1 \%$, nous avons procédé de la même façon que pour l'EWAS et la GWAS pour
calculer cette liste (voir la section [[sec:ewas]]). La méthode lm a été écartée
pour les raisons que nous venons d'évoquer. La Figure ref:fig:gwas_venn montre
l'intersection des listes de candidats contrôlés à un FDR de $1\%$ entre les
méthodes. L'union des candidats retournés par ces quatre méthodes donne 836
SNPs. Le logiciel VEP permet d'annoter l'effet d'une mutation sur l'expression
des gènes cite:McLaren_2016. Les annotations retournés par VEP sont classées en
degré d'importance: LOW, MODERATE et HIGH. Nous avons étudié la
sur-représentation de chacun de des degré d'annotation de vep dans la sous
listes des 836 SNPs par rapport à la liste complète de SNPs. Nous constatons
qu'il y a en proportion 22 fois plus d'annotation HIGH, 8 fois plus de MODERATE
et $1.7$ fois plus de LOW dans la les 836 SNPs que dans les 5397214 SNPs. Nous
avons de plus testé si chaque rapport de proportion est significativement
supérieur à 1 à l'aide d'un test exacte de Fisher et les trois tests renvoie une
\pvalue inférieure à $0.005$.

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_qqplot_notcalibrated_all.pdf.png}
\caption{Diagrame quantile-quantile de l'inverse du logarithme en base 10 des
  \pvaleur renvoyé par chaques méthodes. Les quantiles théoriques suivent la loi
  exponentielle.}
\label{fig:geas_qqplot}
\end{figure}
#+END_EXPORT

#+BEGIN_EXPORT latex
\begin{figure}[!t]
\centering
\includegraphics{./OUTPUT/Rplots/eas_venn.pdf.png}
\caption{Diagramme de Venn des listes controlés à un taux de fausses de
  découvertes de $1 \%$ pour chaque méthode.}
\label{fig:geas_venn}
\end{figure}
#+END_EXPORT
**** Scripts                                                    :noexport:
***** DONE Téléchargement du jeux de données
CLOSED: [2017-07-26 mer. 18:17]
:LOGBOOK:
- State "DONE"       from              [2017-07-26 mer. 18:17]
:END:
Nous avons téléchargé la dernière version du 1000 genome, il s'agit à
ce jour de la phase 3.

*Remarque* : il faut utiliser GRCh37 !! [[http://www.internationalgenome.org/faq/which-reference-assembly-do-you-use/][here]]

#+NAME: code:1000g_ddl
#+CAPTION: Dépend de 
#+BEGIN_SRC R
  setwd("./Data/1000Genomes/Phase3")
  ids <- 1:22
  for (i in ids) {
  url <- paste0("ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr", i, ".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz")
  system(paste("curl -O",url))
  }
#+END_SRC
***** DONE Contrôle qualité
CLOSED: [2017-07-27 jeu. 14:15]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-07-27 jeu. 14:15]
- Note taken on [2017-07-26 mer. 19:35] \\
  tail -f /home/cayek/tmp/Logfiles/1000g.y2017_m07_d26.log
- Note taken on [2017-07-26 mer. 18:42] \\
  faudra recuperer la sortie dans emacs
- State "RUNNING"    from "TODO"       [2017-07-26 mer. 18:41]
- State "TODO"       from              [2017-07-26 mer. 18:30]
:END:

Tout le pré traitement a été fait avec le logicielle =plink= cite:Purcell_2007.
Le jeux de données a d'abord été filtrer avec les opérations suivantes: 
- on ne garde que les SNPs ayant une fréquence d'allele supérieur à $0.05$
- ... voir doc de plink

#+NAME: code:1000g_CQ
#+CAPTION: Dépend de [[code:1000g_ddl]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
  do
      echo "===== $file ====="
      plink --vcf $file --maf 0.05 --mind 0.05 --geno 0.05 --hwe 1e-10 --snps-only --autosome --make-bed --out `basename $file .vcf.gz`_CQ
  done
#+end_src

#+NAME: code:1000g_CQ_log
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_CQ_log
#+begin_example

  > > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:27:19 2017

  Random number seed: 1501090039
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3837178 out of 3992219 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999945.
  806 variants removed due to missing genotype data (--geno).
  --hwe: 75986 variants removed due to Hardy-Weinberg exact test.
  3481563 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  278823 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:31:11 2017
  ============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:31:11 2017

  Random number seed: 1501090271
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3891530 out of 4045628 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  747 variants removed due to missing genotype data (--geno).
  --hwe: 74342 variants removed due to Hardy-Weinberg exact test.
  3548109 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  268332 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:35:22 2017
  ============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:35:22 2017

  Random number seed: 1501090522
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3710299 out of 3868428 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  657 variants removed due to missing genotype data (--geno).
  --hwe: 73200 variants removed due to Hardy-Weinberg exact test.
  3377092 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  259350 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:39:43 2017
  ============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:39:43 2017

  Random number seed: 1501090783
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2737034 out of 2857916 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  497 variants removed due to missing genotype data (--geno).
  --hwe: 52494 variants removed due to Hardy-Weinberg exact test.
  2484161 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  199882 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:42:43 2017
  ============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:42:43 2017

  Random number seed: 1501090963
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2548064 out of 2655067 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999952.
  479 variants removed due to missing genotype data (--geno).
  --hwe: 53291 variants removed due to Hardy-Weinberg exact test.
  2320025 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  174269 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:45:29 2017
  ============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:45:29 2017

  Random number seed: 1501091129
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2328557 out of 2424689 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  434 variants removed due to missing genotype data (--geno).
  --hwe: 51148 variants removed due to Hardy-Weinberg exact test.
  2123668 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  153307 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:47:54 2017
  ============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:47:54 2017

  Random number seed: 1501091274
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2607034 out of 2697949 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999947.
  518 variants removed due to missing genotype data (--geno).
  --hwe: 51346 variants removed due to Hardy-Weinberg exact test.
  2387326 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  167844 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:50:35 2017
  ============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:50:35 2017

  Random number seed: 1501091435
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2234710 out of 2329288 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999951.
  413 variants removed due to missing genotype data (--geno).
  --hwe: 46649 variants removed due to Hardy-Weinberg exact test.
  2044443 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  143205 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:52:53 2017
  ============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:52:53 2017

  Random number seed: 1501091573
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  2178759 out of 2267185 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  392 variants removed due to missing genotype data (--geno).
  --hwe: 39690 variants removed due to Hardy-Weinberg exact test.
  1980142 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  158535 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:55:07 2017
  ============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:55:07 2017

  Random number seed: 1501091707
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1758443 out of 1832506 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999942.
  402 variants removed due to missing genotype data (--geno).
  --hwe: 36837 variants removed due to Hardy-Weinberg exact test.
  1591671 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  129533 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 19:56:55 2017
  ============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 19:56:55 2017

  Random number seed: 1501091815
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6216035 out of 6468094 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  1033 variants removed due to missing genotype data (--geno).
  --hwe: 128213 variants removed due to Hardy-Weinberg exact test.
  5676255 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  410534 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:03:16 2017
  ============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:03:16 2017

  Random number seed: 1501092196
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1745171 out of 1812841 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999959.
  278 variants removed due to missing genotype data (--geno).
  --hwe: 35426 variants removed due to Hardy-Weinberg exact test.
  1592817 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  116650 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:05:02 2017
  ============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:05:02 2017

  Random number seed: 1501092302
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1058549 out of 1105538 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999928.
  279 variants removed due to missing genotype data (--geno).
  --hwe: 23191 variants removed due to Hardy-Weinberg exact test.
  956556 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  78523 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:06:06 2017
  ============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:06:06 2017

  Random number seed: 1501092366
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  1059735 out of 1103547 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999946.
  222 variants removed due to missing genotype data (--geno).
  --hwe: 25833 variants removed due to Hardy-Weinberg exact test.
  960163 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  73517 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:07:11 2017
  ============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:07:11 2017

  Random number seed: 1501092431
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  6808742 out of 7081600 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999954.
  1184 variants removed due to missing genotype data (--geno).
  --hwe: 138884 variants removed due to Hardy-Weinberg exact test.
  6233305 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  435369 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:14:09 2017
  ============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:14:09 2017

  Random number seed: 1501092849
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5603261 out of 5832276 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999949.
  1069 variants removed due to missing genotype data (--geno).
  --hwe: 111493 variants removed due to Hardy-Weinberg exact test.
  5104864 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  385835 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:19:48 2017
  ============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:19:48 2017

  Random number seed: 1501093188
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5500093 out of 5732585 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  1080 variants removed due to missing genotype data (--geno).
  --hwe: 115329 variants removed due to Hardy-Weinberg exact test.
  4985272 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  398412 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:25:25 2017
  ============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:25:25 2017

  Random number seed: 1501093525
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  5055536 out of 5265763 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999953.
  909 variants removed due to missing genotype data (--geno).
  --hwe: 91958 variants removed due to Hardy-Weinberg exact test.
  4620648 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  342021 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:30:32 2017
  ============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:30:32 2017

  Random number seed: 1501093832
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4816881 out of 5024119 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999935.
  1292 variants removed due to missing genotype data (--geno).
  --hwe: 101026 variants removed due to Hardy-Weinberg exact test.
  4346787 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  367776 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:35:26 2017
  ============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:35:26 2017

  Random number seed: 1501094126
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4533180 out of 4716715 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.99995.
  842 variants removed due to missing genotype data (--geno).
  --hwe: 87612 variants removed due to Hardy-Weinberg exact test.
  4119828 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  324898 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:40:01 2017
  ============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:40:01 2017

  Random number seed: 1501094401
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  4434371 out of 4597105 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999944.
  921 variants removed due to missing genotype data (--geno).
  --hwe: 90154 variants removed due to Hardy-Weinberg exact test.
  4048413 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  294883 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:44:29 2017
  ============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ=============
  PLINK v1.90b4.3 64-bit (9 May 2017)
  Options in effect:
    --autosome
    --geno 0.05
    --hwe 1e-10
    --maf 0.05
    --make-bed
    --mind 0.05
    --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
    --snps-only
    --vcf ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

  Hostname: krakenator.imag.fr
  Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
  Start time: Wed Jul 26 20:44:29 2017

  Random number seed: 1501094669
  193793 MB RAM detected; reserving 96896 MB for main workspace.
  --vcf:
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bed
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.bim
  +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ-temporary.fam
  written.
  3427241 out of 3560687 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.nosex .
  0 people removed due to missing genotype data (--mind).
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999948.
  689 variants removed due to missing genotype data (--geno).
  --hwe: 68557 variants removed due to Hardy-Weinberg exact test.
  3121045 variants removed due to minor allele threshold(s)
  (--maf/--max-maf/--mac/--max-mac).
  236950 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bim +
  ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.fam ...
  done.

  End time: Wed Jul 26 20:47:57 2017
#+end_example

***** DONE Fusion de tous les chromosomes
CLOSED: [2017-07-27 jeu. 14:43]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 14:43]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** Ensuite, nous avons enlever les doublons
#+NAME: code:1000g_rm
#+CAPTION: Dépend de [[code:1000g_CQ]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## snp to remove
  echo "rs6658405" > excluded_variant.txt
  echo "." >> excluded_variant.txt
  echo "rs141927528" >> excluded_variant.txt
  echo "rs145926341" >> excluded_variant.txt

  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ.bed
  do
      echo "===== $file ====="
      plink --bfile `basename $file .bed` --exclude excluded_variant.txt --make-bed --out `basename $file .bed`_excluded
  done
#+end_src

#+NAME: code:1000g_rm_log
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  for file in ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.log
  do
      echo "============"`basename $file .log`"============="
      cat $file
  done
#+end_src

#+RESULTS: code:1000g_rm_log
#+begin_example

> > > > ============ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:51 2017

Random number seed: 1501158411
193793 MB RAM detected; reserving 96896 MB for main workspace.
278823 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 278823 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999926.
278823 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr10.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
268332 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 268332 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
268332 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr11.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:52 2017
============ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:52 2017

Random number seed: 1501158412
193793 MB RAM detected; reserving 96896 MB for main workspace.
259350 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 259348 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999923.
259348 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr12.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
199882 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 199882 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
199882 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr13.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:53 2017
============ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:53 2017

Random number seed: 1501158413
193793 MB RAM detected; reserving 96896 MB for main workspace.
174269 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 174269 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
174269 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr14.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
153307 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 153305 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
153305 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr15.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
167844 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 167844 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999899.
167844 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
143205 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 143205 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
143205 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr17.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:54 2017
============ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:54 2017

Random number seed: 1501158414
193793 MB RAM detected; reserving 96896 MB for main workspace.
158535 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 158535 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999924.
158535 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr18.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
129533 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 129533 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.99992.
129533 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:55 2017
============ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:55 2017

Random number seed: 1501158415
193793 MB RAM detected; reserving 96896 MB for main workspace.
410534 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 410532 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999927.
410532 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
116650 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 116650 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999933.
116650 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
78523 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 78523 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
78523 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr21.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
73517 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 73517 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999913.
73517 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:56 2017
============ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:56 2017

Random number seed: 1501158416
193793 MB RAM detected; reserving 96896 MB for main workspace.
435369 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 435369 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
435369 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:57 2017
============ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:57 2017

Random number seed: 1501158417
193793 MB RAM detected; reserving 96896 MB for main workspace.
385835 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 385835 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
385835 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr3.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:58 2017
============ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:58 2017

Random number seed: 1501158418
193793 MB RAM detected; reserving 96896 MB for main workspace.
398412 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 398412 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
398412 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr4.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
342021 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 342021 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999919.
342021 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:26:59 2017
============ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:26:59 2017

Random number seed: 1501158419
193793 MB RAM detected; reserving 96896 MB for main workspace.
367776 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 367776 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999922.
367776 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr6.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:00 2017
============ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:00 2017

Random number seed: 1501158420
193793 MB RAM detected; reserving 96896 MB for main workspace.
324898 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 324898 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999925.
324898 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr7.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
294883 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 294881 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999914.
294881 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr8.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:01 2017
============ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded=============
PLINK v1.90b4.3 64-bit (9 May 2017)
Options in effect:
  --bfile ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ
  --exclude excluded_variant.txt
  --make-bed
  --out ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded

Hostname: krakenator.imag.fr
Working directory: /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3
Start time: Thu Jul 27 14:27:01 2017

Random number seed: 1501158421
193793 MB RAM detected; reserving 96896 MB for main workspace.
236950 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.nosex
.
--exclude: 236950 variants remaining.
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Calculating allele frequencies... done.
Total genotyping rate is 0.999921.
236950 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--make-bed to
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim
+
ALL.chr9.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.fam
... done.

End time: Thu Jul 27 14:27:02 2017
#+end_example

****** On concatène les genomes en 1 seul fichier
#+NAME: code:1000g_concat
#+CAPTION: Dépend de [[code:1000g_rm]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ## list prefix
  file.pattern <- "ALL.chr[0-9]*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bed$"
  files <- list.files()
  files <- grep(file.pattern, files, value = TRUE)
  prefix <- sub(pattern = ".bed", replacement = "", files)


  ## create list of file
  prefix1 <- prefix[1]
  prefix <- prefix[-1]
  list.file <- tempfile(tmpdir=".", fileext=".txt")
  for (p in prefix) {
    line <- paste(paste0(p, ".bed"), paste0(p, ".bim"), paste0(p, ".fam"))
    write(line, list.file, append = TRUE)
  }

  ## cmd
  cmd <- paste("plink",
               "--bfile",
               prefix1,
               "--merge-list",
               list.file,
               "--make-bed --out", "1000GenomePhase3_CQ")

  system(cmd)
#+end_src

#+RESULTS: code:1000g_concat
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile ALL.chr1.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded
    --make-bed
    --merge-list ./file5534632e75c3.txt
    --out 1000GenomePhase3_CQ

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  Performing single-pass merge (2504 people, 5398440 variants).
  Merged fileset written to 1000GenomePhase3_CQ-merge.bed +
  1000GenomePhase3_CQ-merge.bim + 1000GenomePhase3_CQ-merge.fam .
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ.bed + 1000GenomePhase3_CQ.bim +
  1000GenomePhase3_CQ.fam ... done.
#+end_example

****** Vérification
#+NAME: code:1000g_test
#+CAPTION: Dépend de [[code:1000g_concat]]
#+begin_src shell :session *ssh krakenator* :results output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3
  grep "rs6658405" -R *_excluded.bim
  grep "\." -R *_excluded.bim
  grep "rs145926341" -R *_excluded.bim
  grep "rs141927528" -R *_excluded.bim
#+end_src

#+RESULTS: code:1000g_test
: ALL.chr16.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:16	rs66584058	0	25445314	G	A
: ALL.chr5.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes_CQ_excluded.bim:5	rs66584056	0	36516119	T	A
***** DONE Élagage (LD pruning)
CLOSED: [2017-07-27 jeu. 15:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 15:01]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

****** DONE LD report
CLOSED: [2017-08-17 jeu. 11:23]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:23]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:01]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 10:59]
- State "TODO"       from              [2017-08-17 jeu. 10:32]
:END:

#+NAME: code:1000g_ld_report
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :session *ssh krakenator* :result output
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --r2 --ld-window 10 --ld-window-kb 10 --ld-window-r2 0.1 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --ld-window 10
    --ld-window-kb 10
    --ld-window-r2 0.1
    --r2
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --r2 to plink.ld ... done.
#+end_example

#+NAME: code:1000g_ld_report_R
#+CAPTION: Dépend de [[code:1000g_ld_report]]
#+begin_src R 
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")

  ld.df <- data.table::fread("plink.ld", data.table = FALSE) %>% as_tibble()

  toplot <- ld.df %>%
    transmute(pb = abs(BP_A - BP_B), r2 = R2)
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_summary_bin(fun.y = mean, bins = 20, geom = "point")
  save_plot_png(pl, "1000g_ld_report_bin.png")
  pl <- ggplot(toplot, aes(x = pb, y = r2)) +
    stat_smooth()
  save_plot_png(pl, "1000g_ld_report_smooth.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ld_report_bin.png]]
[[./OUTPUT/Rplots/1000g_ld_report_smooth.png]]

****** DONE LD pruning
CLOSED: [2017-08-17 jeu. 11:01]
:LOGBOOK:
- State "DONE"       from              [2017-08-17 jeu. 11:01]
:END:

On fait un filtrage des SNPs (voir [[https://www.cog-genomics.org/plink/1.9/ld#indep][doc plink]])
#+NAME: code:1000g_prunning
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 100 1 0.2 --out 1000GenomePhase3_CQ --threads 8
  plink --bfile 1000GenomePhase3_CQ --extract 1000GenomePhase3_CQ.prune.in --make-bed --out 1000GenomePhase3_CQ_prunned --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 100 1 0.2
    --out 1000GenomePhase3_CQ
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 383854 variants from chromosome 1, leaving 26678.
  Pruned 409475 variants from chromosome 2, leaving 25894.
  Pruned 362867 variants from chromosome 3, leaving 22968.
  Pruned 376230 variants from chromosome 4, leaving 22182.
  Pruned 321811 variants from chromosome 5, leaving 20210.
  Pruned 347157 variants from chromosome 6, leaving 20619.
  Pruned 305597 variants from chromosome 7, leaving 19301.
  Pruned 277562 variants from chromosome 8, leaving 17319.
  Pruned 221173 variants from chromosome 9, leaving 15777.
  Pruned 261581 variants from chromosome 10, leaving 17242.
  Pruned 252405 variants from chromosome 11, leaving 15927.
  Pruned 242512 variants from chromosome 12, leaving 16836.
  Pruned 187679 variants from chromosome 13, leaving 12203.
  Pruned 162767 variants from chromosome 14, leaving 11502.
  Pruned 142011 variants from chromosome 15, leaving 11294.
  Pruned 155528 variants from chromosome 16, leaving 12316.
  Pruned 131567 variants from chromosome 17, leaving 11638.
  Pruned 147436 variants from chromosome 18, leaving 11099.
  Pruned 119524 variants from chromosome 19, leaving 10009.
  Pruned 107571 variants from chromosome 20, leaving 9079.
  Pruned 72922 variants from chromosome 21, leaving 5601.
  Pruned 67200 variants from chromosome 22, leaving 6317.
  Pruning complete.  5056429 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ.prune.in and
  1000GenomePhase3_CQ.prune.out .


  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --extract 1000GenomePhase3_CQ.prune.in
    --make-bed
    --out 1000GenomePhase3_CQ_prunned
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned.nosex .
  --extract: 342011 variants remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned.bed + 1000GenomePhase3_CQ_prunned.bim
  + 1000GenomePhase3_CQ_prunned.fam ... done.

#+end_example

***** DONE Filtrage des individus trop apparenté
CLOSED: [2017-07-27 jeu. 16:21]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-07-27 jeu. 16:21]
- Note taken on [2017-07-26 mer. 19:21] \\
  c'est la que ca commence !! il faut que je remplace par les vrais appel de plink !!!
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

On filtre les individus trop apparenté (voir [[https://www.cog-genomics.org/plink/1.9/ibd][doc de plink]]).


****** DONE On commence par calculer la proportion d'IBD.
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:
#+NAME: code:1000g_ibd
#+CAPTION: Dépend de [[code:1000g_prunning]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3

  ## ibd
  plink -bfile 1000GenomePhase3_CQ_prunned --genome --min 0.08 --threads 8
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to plink.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --genome
    --min 0.08
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to plink.nosex .
  Using up to 8 threads (change this with --threads).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999908.
  342011 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  IBD calculations complete.  
  Finished writing plink.genome .

#+end_example

****** DONE On visualise la proportion d'IBD
CLOSED: [2017-08-14 lun. 13:55]
:LOGBOOK:
- State "DONE"       from              [2017-08-14 lun. 13:55]
- Note taken on [2017-07-28 ven. 14:37] \\
  RMK: le dataframe ne contient bien pas les apparentement symétrique !!!
:END:
#+NAME: code:1000g_ibd_visu
#+CAPTION: Dépend de [[code:1000g_ibd]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  library(tidyverse)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3")

  ibd.df <- data.table::fread("plink.genome", data.table = FALSE) %>% as_tibble()

  pl.hist <- ggplot(ibd.df, aes(PI_HAT)) +
    geom_histogram()
  pl.hist
  save_plot_png(pl.hist, "1000g_ibd.png")


  ## We filter PI_HAT > 0.125
  out.indiv.df <- ibd.df %>%
    dplyr::filter(PI_HAT > 0.125) %>%
    dplyr::select(FID1, IID1) %>%
    group_by(FID1, IID1) %>%
    summarise()
  write.table(out.indiv.df, "out.indif.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/1000g_ibd.png]]

On va filter les pour une proportion d'ibd à 0.125 (ca correspond à cousin au 3
ième degré).

****** DONE On filtre les individus trop apparentés
CLOSED: [2017-08-16 mer. 17:52]
:LOGBOOK:
- State "DONE"       from              [2017-08-16 mer. 17:52]
:END:

#+NAME: code:1000g_ibd_filter
#+CAPTION: Dépend de [[code:1000g_ibd_visu]]
#+begin_src shell :session *ssh krakenator* :results output 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ_prunned --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_prunned_norel

  plink --bfile 1000GenomePhase3_CQ --remove out.indif.txt --make-bed --out 1000GenomePhase3_CQ_norel
#+end_src

#+RESULTS:
#+begin_example
  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_prunned_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ_prunned
    --make-bed
    --out 1000GenomePhase3_CQ_prunned_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  342011 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_prunned_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.99989.
  342011 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_prunned_norel.bed +
  1000GenomePhase3_CQ_prunned_norel.bim + 1000GenomePhase3_CQ_prunned_norel.fam
  ... done.

  PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_norel.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --make-bed
    --out 1000GenomePhase3_CQ_norel
    --remove out.indif.txt

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_norel.nosex .
  --remove: 1758 people remaining.
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 1758 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate in remaining samples is 0.999904.
  5398440 variants and 1758 people pass filters and QC.
  Note: No phenotypes present.
  --make-bed to 1000GenomePhase3_CQ_norel.bed + 1000GenomePhase3_CQ_norel.bim +
  1000GenomePhase3_CQ_norel.fam ... done.
#+end_example

***** DONE Conversion dans format utilisable en R
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-08-03 jeu. 11:37]
- State "TODO"       from              [2017-07-26 mer. 18:17]
:END:

Nous avons utilisé le package bigsnpr pour convertir les données du format
=.bed= à un format de matrice R. 

****** DONE Données non prunnées
CLOSED: [2017-08-14 lun. 14:14]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:11]
- Note taken on [2017-08-03 jeu. 14:14] \\
  ca a bugger le pense ...a voir.
- State "TODO"       from "RUNNING"    [2017-08-03 jeu. 14:14]
- State "RUNNING"    from "DONE"       [2017-08-03 jeu. 13:26]
- State "DONE"       from "RUNNING"    [2017-08-02 mer. 16:51]
- Note taken on [2017-08-02 mer. 16:11] \\
  il ne veux pas mettre de nom au ligne et colonnes .... je sais pas pk mais c'est
  pas si grave !!
- State "RUNNING"    from              [2017-08-02 mer. 15:59]
:END:

#+NAME: code:1000g_G_bigsnpr
#+CAPTION: Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_norel.bed"

  snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")

  G <- snp_attach("bigsnpr_G/G.rds")
  ## G <- readRDS("bigsnpr_G/G.rds")
  dim(G$genotypes)

  ## G.r <- readRDS("G.rds")
  G.r <- attach.BM(G$genotypes)[,]
  ## rownames(G.r) <- G$fam$sample.ID
  ## attr(G.r, "rownames") <- G$fam$sample.ID
  ## colnames(G.r) <- G$map$marker.ID
  ## attr(G.r, "colnames") <- G$map$marker.ID

  saveRDS(G.r, "G.rds")
  #+END_SRC

#+RESULTS:
#+begin_example
  > snp_readBed(bedfile, "G", backingpath = "bigsnpr_G")
  Creating directory "bigsnpr_G" which didn't exist..
  Read 5398440 rows and 6 (of 6) columns from 0.142 GB file in 00:00:22
  [1] "bigsnpr_G/G.rds"
  > 
  > G <- snp_attach("bigsnpr_G/G.rds")
  > dim(G$genotypes)
  [1]    1758 5398440
  > rownames(G.r) <- G$fam$sample.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
  > colnames(G.r) <- G$map$marker.ID
  Erreur : impossible d'allouer un vecteur de taille 70.7 Go
#+end_example

****** DONE Données prunnées
CLOSED: [2017-08-14 lun. 14:38]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 14:38]
- State "TODO"       from "DONE"       [2017-08-09 mer. 15:18]
- State "DONE"       from "TODO"       [2017-07-27 jeu. 17:17]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

#+NAME: code:1000g_G_prunned_bigsnpr
#+CAPTION: On converti les données prunnées en un format R. Dépend de [[code:1000g_ibd_filter]]
#+BEGIN_SRC R
  library(bigsnpr)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  bedfile <- "1000GenomePhase3_CQ_prunned_norel.bed"

  snp_readBed(bedfile, "G_prunned", backingpath = "bigsnpr_G_prunned")

  G <- snp_attach("bigsnpr_G_prunned/G_prunned.rds")
  dim(G$genotypes)

  G.r <- attach.BM(G$genotypes)[,]
  typeof(G.r)
  rownames(G.r) <- G$fam$sample.ID
  colnames(G.r) <- G$map$marker.ID
  saveRDS(G.r, "G_prunned.rds")
  rm(G.r)
  gc()


  ## We only keep first chromosomes 1 and 2 for simulation numerique
  in.id <- which(G$map$chromosome %in% c(1,2))
  G.r <- readRDS("G_prunned.rds")
  G.numVal <- G.r[,in.id]
  saveRDS(G.numVal, "G_prunned_chr12.rds")


  ## save indiv data frame
  saveRDS(G$fam, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/indiv_df.rds")
  #+END_SRC

***** DONE Données utilisées pour la validation numérique lfmm
CLOSED: [2017-07-27 jeu. 17:26]
:LOGBOOK:
- State "DONE"       from              [2017-07-27 jeu. 17:26]
:END:
#+NAME: code:1000g_G_valNum
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- readRDS("G_prunned_chr12.rds")
  anyNA(G)
  G.noNa <- preprocessing_filter_na(G)
  anyNA(G.noNa)
  G.scale <- scale(G.noNa)
  saveRDS(G.scale, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/G_valNum.rds")
#+end_src

#+RESULTS:
#+begin_example
  proportion of removed loci = 0.00686677318724797
#+end_example

***** DONE Filtrage des individus pour la GEAS
CLOSED: [2017-08-14 lun. 15:37]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-14 lun. 15:37]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:28]
- State "DONE"       from "TODO"       [2017-07-28 ven. 14:18]
- State "TODO"       from              [2017-07-28 ven. 11:46]
:END:

Nous ne gardons que les individus non métisses.

#+NAME: code:eas_indiv_df
#+CAPTION: Dépend de [[code:1000g_G_prunned_bigsnpr]] [[code:1000g_ibd_visu]]
#+begin_src R
  library(MaTheseR)

  indiv.df <- readRDS("./Data/1000Genomes/Phase3/indiv_df.rds") %>% as_tibble()
  indiv.df

  ## keep only indiv with no rel
  out.indif <- read_delim(file = "./Data/1000Genomes/Phase3/out.indif.txt", delim = " ",
                          col_names = FALSE, col_types = cols(.default = col_character()))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(sample %in% out.indif$X1))
  indiv.df

  ## retrieve pop

  ## indiv metadata
  indiv.df <- indiv.df %>%
    dplyr::filter(super_pop %in% c("EUR", "SAS", "AFR", "EAS"))
  indiv.df <- indiv.df %>%
    dplyr::filter(!(pop %in% c("ASW", "ACB")))
  indiv.df

  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
#+end_src

#+RESULTS: code:eas_indiv_df
#+begin_example
# A tibble: 2,504 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00103   GBR       EUR   male
 8 HG00105   GBR       EUR   male
 9 HG00106   GBR       EUR female
10 HG00107   GBR       EUR   male
# ... with 2,494 more rows
# A tibble: 1,758 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,748 more rows
# A tibble: 1,409 x 4
    sample   pop super_pop gender
     <chr> <chr>     <chr>  <chr>
 1 HG00096   GBR       EUR   male
 2 HG00097   GBR       EUR female
 3 HG00099   GBR       EUR female
 4 HG00100   GBR       EUR female
 5 HG00101   GBR       EUR   male
 6 HG00102   GBR       EUR female
 7 HG00105   GBR       EUR   male
 8 HG00106   GBR       EUR female
 9 HG00107   GBR       EUR   male
10 HG00108   GBR       EUR   male
# ... with 1,399 more rows
#+end_example

***** DONE Scaling des données et valeurs manquantes pour GEAS

CLOSED: [2017-08-16 mer. 15:44]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:44]
- State "TODO"       from              [2017-07-13 jeu. 12:29]
:END:

****** DONE Données non prunnées 
CLOSED: [2017-08-16 mer. 15:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:29]
- State "TODO"       from              [2017-07-28 ven. 10:34]
:END:

#+NAME: code:1000g_G_noNA_scaled
#+CAPTION: Dépend de [[code:1000g_G_bigsnpr]] [[code:eas_indiv_df]]
#+begin_src R 
  library(bigsnpr)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G <- snp_attach("bigsnpr_G/G.rds")
  G.r <- attach.BM(G$genotypes)
  dim(G.r) ## [1]    1758 5398440

  ## indiv to keep
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")
  kept.indiv.id <- G$fam$sample %in% eas.indiv.df$sample

  ## NA mu sds
  nas <- 1:ncol(G.r)
  mus <- 1:ncol(G.r)
  sds <- 1:ncol(G.r)
  pb <- txtProgressBar(min = 1, max = ncol(G.r))
  for(j in 1:ncol(G.r)) {
    aux <- as.double(G.r[kept.indiv.id,j])
    nas[j] <- mean(is.na(aux))
    mus[j] <- mean(aux, na.rm = TRUE)
    sds[j] <- sd(aux, na.rm = TRUE)
    setTxtProgressBar(pb, j)
  }
  close(pb)

  ## test
  quantile(nas)
  quantile(mus)
  quantile(sds)
  sum(nas > 0.0)
  sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)

  ## filter
  col.ids <- which(sds > 0.095) 

  ## size matrix file 1409x5397214
  ## save col and row name
  saveRDS(G$fam$sample.ID[kept.indiv.id], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  saveRDS(G$map$marker.ID[col.ids], "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")

  ## export to bin
  con <- file("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin", 'wb')
  for(j in col.ids) {
    aux <- as.double(G.r[kept.indiv.id,j])
    writeBin((aux - mus[j]) / sds[j], con)
  }
  flush(con)
  close(con)

  ############################################################################################
  ## matter matrix
  library(matter)

  setwd("~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/")
  G.big <- readRDS("bigsnpr_G/G.rds")
  row.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.rownames.rds")
  col.names <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.colnames.rds")
  eas.indiv.df <- readRDS("~/Projects/Thesis/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds")

  G.matter <- matter_mat(paths="~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.bin",
                         nrow = length(row.names),
                         ncol = length(col.names),
                         datamode = "double")
  rownames(G.matter) <- row.names
  colnames(G.matter) <- col.names

  ## test
  dim(G.matter)
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  G.matter[1409,5397214]

  saveRDS(G.matter, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

#+end_src

#+RESULTS:
#+begin_example
  > quantile(nas)
    0%  25%  50%  75% 100% 
     0    0    0    0    0 
  > quantile(mus)
         0%       25%       50%       75%      100% 
  0.9254791 1.3584102 1.6217175 1.7934705 2.0539390 
  > quantile(sds)
         0%       25%       50%       75%      100% 
  0.0000000 0.4419241 0.5679660 0.6762505 0.8825680 
  > sum(nas > 0.0)
  [1] 0
  > sum(sds < 0.095) ## 2 * 0.05 * (1 - 0.05)
  [1] 1226

#+end_example
****** DONE Données prunnées
CLOSED: [2017-08-16 mer. 15:40]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:40]
- State "TODO"       from "DONE"       [2017-08-14 lun. 14:19]
- State "DONE"       from "TODO"       [2017-07-28 ven. 11:01]
- State "TODO"       from              [2017-07-27 jeu. 17:29]
:END:

On fait un pruning plus fort que celui de [[code:1000g_prunning]]

#+NAME: code:1000g_prunning_more
#+CAPTION: Dépend de [[1000g_concat]]
#+begin_src shell :results output :exports both 
  cd ~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/
  plink --bfile 1000GenomePhase3_CQ --indep-pairwise 5000 1 0.2 --out 1000GenomePhase3_CQ_more --threads 8
#+end_src


#+RESULTS:
#+begin_example
  (C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
  Logging to 1000GenomePhase3_CQ_more.log.
  Options in effect:
    --bfile 1000GenomePhase3_CQ
    --indep-pairwise 5000 1 0.2
    --out 1000GenomePhase3_CQ_more
    --threads 8

  193793 MB RAM detected; reserving 96896 MB for main workspace.
  5398440 variants loaded from .bim file.
  2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
  Ambiguous sex IDs written to 1000GenomePhase3_CQ_more.nosex .
  Using 1 thread (no multithreaded calculations invoked).
  Before main variant filters, 2504 founders and 0 nonfounders present.
  Calculating allele frequencies... done.
  Total genotyping rate is 0.999922.
  5398440 variants and 2504 people pass filters and QC.
  Note: No phenotypes present.
  Pruned 387086 variants from chromosome 1, leaving 23446.
  Pruned 413054 variants from chromosome 2, leaving 22315.
  Pruned 366259 variants from chromosome 3, leaving 19576.
  Pruned 379840 variants from chromosome 4, leaving 18572.
  Pruned 324752 variants from chromosome 5, leaving 17269.
  Pruned 350848 variants from chromosome 6, leaving 16928.
  Pruned 308455 variants from chromosome 7, leaving 16443.
  Pruned 280143 variants from chromosome 8, leaving 14738.
  Pruned 223125 variants from chromosome 9, leaving 13825.
  Pruned 263958 variants from chromosome 10, leaving 14865.
  Pruned 254728 variants from chromosome 11, leaving 13604.
  Pruned 244633 variants from chromosome 12, leaving 14715.
  Pruned 189373 variants from chromosome 13, leaving 10509.
  Pruned 164213 variants from chromosome 14, leaving 10056.
  Pruned 143194 variants from chromosome 15, leaving 10111.
  Pruned 156696 variants from chromosome 16, leaving 11148.
  Pruned 132527 variants from chromosome 17, leaving 10678.
  Pruned 148556 variants from chromosome 18, leaving 9979.
  Pruned 120363 variants from chromosome 19, leaving 9170.
  Pruned 108299 variants from chromosome 20, leaving 8351.
  Pruned 73482 variants from chromosome 21, leaving 5041.
  Pruned 67649 variants from chromosome 22, leaving 5868.
  Pruning complete.  5101233 of 5398440 variants removed.
  Marker lists written to 1000GenomePhase3_CQ_more.prune.in and
  1000GenomePhase3_CQ_more.prune.out .
#+end_example

#+NAME: code:1000g_G_noNA_scaled_prunned
#+CAPTION: On scale et enlève les données manquantes. Dépend de [[code:1000g_G_noNA_scaled]] [[code:1000g_prunning_more]]
#+begin_src R :session *krakR* :results output :dir /scp:cayek@krakenator:~/Projects/Thesis/MaThese/
  library(MaTheseR)
  prune.in <- read_delim(file = "~/Projects/Thesis/MaThese/Data/1000Genomes/Phase3/1000GenomePhase3_CQ_more.prune.in", delim = " ", col_names = FALSE, col_types = cols(col_character()))

  library(matter)
  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")

  ## test
  sd(G.matter[,5397214])
  mean(G.matter[,5397214])
  dim(G.matter)

  ## prunning
  keep.id <- colnames(G.matter) %in% prune.in$X1
  saveRDS(which(keep.id), "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")
  G.prunned <- G.matter[,keep.id]

  ## test
  length(colnames(G.prunned))
  dim(G.prunned)

  saveRDS(G.prunned, "~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds")
#+end_src

#+RESULTS:
#+begin_example
> dim(G.prunned)
[1]   1409 296948
#+end_example

***** DONE Annotation VEP
CLOSED: [2017-08-31 jeu. 13:30]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 13:30]
- State "RUNNING"    from "DONE"       [2017-08-31 jeu. 11:09]
- State "DONE"       from "RUNNING"    [2017-08-29 mar. 14:51]
- State "RUNNING"    from "DONE"       [2017-08-29 mar. 08:35]
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 15:31]
- State "RUNNING"    from "TODO"       [2017-08-22 mar. 12:41]
- State "TODO"       from              [2017-08-22 mar. 11:53]
:END:

vep cache : [[https://www.ensembl.org/info/docs/tools/vep/script/vep_cache.html#cache][here]]

#+NAME: code:1000g_vep_cache
#+CAPTION: Dépend de 
#+begin_src R 
  cd $HOME/.vep
  curl -O ftp://ftp.ensembl.org/pub/release-89/variation/VEP/homo_sapiens_vep_89_GRCh37.tar.gz
  tar -xvf homo_sapiens_vep_89_GRCh37.tar.gz
#+end_src

vep input format : [[http://www.ensembl.org/info/docs/tools/vep/vep_formats.html#input][here]]

#+NAME: code:1000g_vep_input
#+CAPTION: On creer un fichier input pour vep. Dépend de [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(matter)
  library(tidyverse)

  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")
  snps.info <- readRDS("./Data/1000Genomes/Phase3/bigsnpr_G/G.rds")$map
  snps.info <- snps.info %>%
    dplyr::filter(marker.ID %in% colnames(G.matter))

  vep.input <- snps.info %>%
    transmute(chromosome = chromosome,
              start = physical.pos,
              end = physical.pos,
              allele = paste0(allele1,"/", allele2),
              strand = NA,
              identifier = marker.ID)

  write.table(vep.input, file = "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.input.txt",
              row.names = FALSE, col.names = FALSE, na = "", quote = FALSE)

#+end_src

run vep option : [[http://www.ensembl.org/info/docs/tools/vep/script/vep_options.html][here]]

#+NAME: code:1000g_vep_run
#+CAPTION: Dépend de [[code:1000g_vep_input]]
#+begin_src shell
  cd ~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/
  vep --cache --species homo_sapiens --assembly GRCh37 --offline -i vep.input.txt -o vep.output.txt --force --variant_class --sift b
#+end_src

#+NAME: code:1000g_vep_output
#+CAPTION: Dépend de [[code:1000g_vep_run]]
#+begin_src R 
  vep.output <- data.table::fread("./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.txt", skip = "#Uploaded_variation", data.table = FALSE, na.strings = "-")

  vep.output <- vep.output %>% as_tibble()

  ## add column
  library(stringr)

  IMPACT <- vep.output$Extra %>%
    str_match(pattern = "IMPACT=([:alnum:]*);?")
  unique(IMPACT[,2])
  anyNA(IMPACT[,2])

  SIFT <- vep.output$Extra %>%
    str_match(pattern = "SIFT=([:alpha:]*)\\((.*)\\)[;]?")

  vep.output <- vep.output %>%
    mutate(IMPACT = as.factor(IMPACT[,2])) %>%
    mutate(SIFT.score = as.numeric(SIFT[,3]),
           SIFT.prediction = as.factor(SIFT[,2]))

  pl <- ggplot(vep.output, aes(SIFT.score)) +
    geom_histogram()


  ## add snps name
  G.matter <- readRDS("~/Projects/Thesis/MaThese/Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds")
  snps.info <- readRDS("./Data/1000Genomes/Phase3/bigsnpr_G/G.rds")$map %>% as_tibble()
  snps.info <- snps.info %>%
    dplyr::filter(marker.ID %in% colnames(G.matter))
  snps.info <- snps.info %>%
    transmute(Location = paste0(chromosome,":",physical.pos),
              snps = marker.ID)

  vep.output <- left_join(vep.output, snps.info, by = c('Location'))

  saveRDS(vep.output, "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  summary(vep.output)
#+end_src

#+RESULTS: code:1000g_vep_output
#+begin_example
[1] "MODIFIER" "HIGH"     "LOW"      "MODERATE"
[1] FALSE
 #Uploaded_variation   Location            Allele              Gene          
 Length:17113181     Length:17113181    Length:17113181    Length:17113181   
 Class :character    Class :character   Class :character   Class :character  
 Mode  :character    Mode  :character   Mode  :character   Mode  :character  
                                                                             
                                                                             
                                                                             
                                                                             
   Feature          Feature_type       Consequence        cDNA_position     
 Length:17113181    Length:17113181    Length:17113181    Min.   :     1    
 Class :character   Class :character   Class :character   1st Qu.:   333    
 Mode  :character   Mode  :character   Mode  :character   Median :   917    
                                                          Mean   :  1685    
                                                          3rd Qu.:  2171    
                                                          Max.   :107492    
                                                          NA's   :16762390  
  CDS_position      Protein_position   Amino_acids           Codons         
 Min.   :     1     Min.   :    1      Length:17113181    Length:17113181   
 1st Qu.:   288     1st Qu.:   96      Class :character   Class :character  
 Median :   741     Median :  247      Mode  :character   Mode  :character  
 Mean   :  1544     Mean   :  515                                           
 3rd Qu.:  1602     3rd Qu.:  534                                           
 Max.   :107267     Max.   :35756                                           
 NA's   :17017945   NA's   :17017945                                        
 Existing_variation    Extra                IMPACT           SIFT.score      
 Mode:logical       Length:17113181    HIGH    :    1535   Min.   :0         
 NA's:17113181      Class :character   LOW     :   68224   1st Qu.:0         
                    Mode  :character   MODERATE:   42072   Median :1         
                                       MODIFIER:17001350   Mean   :1         
                                                           3rd Qu.:1         
                                                           Max.   :1         
                                                           NA's   :17106978  
    SIFT.prediction         snps          
 deleterious:     538   Length:17113181   
 tolerated  :    5665   Class :character  
 NA's       :17106978   Mode  :character
#+end_example


Understanding variant consequence: 
- [[https://www.ensembl.org/info/genome/variation/predicted_data.html#consequences][Ensembl Variation - Predicted data]]
- [[http://gemini.readthedocs.io/en/latest/content/functional_annotation.html#columns-populated-by-snpeff-vep-tools][Annotation with snpEff or VEP]]

***** DONE Calcule du gradient climatique
CLOSED: [2017-08-17 jeu. 11:52]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-17 jeu. 11:52]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "TODO"       [2017-08-16 mer. 15:57]
- State "TODO"       from              [2017-08-06 Sun 14:47]
- State "TODO"       from "DONE"       [2017-08-03 jeu. 17:26]
- State "DONE"       from "TODO"       [2017-07-28 ven. 15:58]
- State "TODO"       from "DONE"       [2017-07-28 ven. 11:46]
- State "DONE"       from "STARTED"    [2017-06-27 mar. 17:56]
- Note taken on [2017-06-27 mar. 12:02] \\
  On va ajouter les html widget a l'export html :D, voir: http://rmarkdown.rstudio.com/developer_html_widgets.html
- State "STARTED"    from              [2017-06-27 mar. 12:02]
:END:

Afin de calculer un gradient climatique avec partir des positions géographique
des individus nous avons choisi d'utiliser la base wordclim
#+NAME: code:eas_climatic_gradient
#+CAPTION: Dépend de [[code:eas_indiv_df]]
#+begin_src R 
  library(tidyverse)
  library(MaTheseR)

  ## get pop information
  library(rvest)

  pop.tbl <- read_html("http://www.internationalgenome.org/faq/which-populations-are-part-your-study/")%>%
    html_nodes("table") %>%
    html_table() %>%
    .[[1]]

  head(pop.tbl)
  names(pop.tbl)[1] <- "pop"


  ## pop location
  library(ggmap)

  indiv.df <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df.rds") %>% as_tibble()
  indiv.df <-indiv.df %>% inner_join(pop.tbl)

  indiv.df


  ## match pop localisation
  indiv.df <- indiv.df %>%
    mutate(citie = NA)
  indiv.df[indiv.df$pop == "IBS",]$citie = "Spain"
  indiv.df[indiv.df$pop == "PJL",]$citie = "Pakistan"
  indiv.df[indiv.df$pop == "GWD",]$citie = "Gambia"
  indiv.df[indiv.df$pop == "BEB",]$citie = "Bangladesh"
  indiv.df[indiv.df$pop == "MSL",]$citie = "Sierra Leone"
  indiv.df[indiv.df$pop == "STU",]$citie = "Sri Lanka"
  indiv.df[indiv.df$pop == "ITU",]$citie = "Telangana"
  indiv.df[indiv.df$pop == "CEU",]$citie = "United Kingdom"
  indiv.df[indiv.df$pop == "LWK",]$citie = "Kenya"
  indiv.df[indiv.df$pop == "JPT",]$citie = "Japan"
  indiv.df[indiv.df$pop == "YRI",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "TSI",]$citie = "Italia"
  indiv.df[indiv.df$pop == "GIH",]$citie = "Gujarat"
  indiv.df[indiv.df$pop == "ESN",]$citie = "Nigeria"
  indiv.df[indiv.df$pop == "FIN",]$citie = "Finland"
  indiv.df[indiv.df$pop == "GBR",]$citie = "England"

  ## cities
  indiv.df %>%
    dplyr::select(pop, `Population Description`, citie) %>%
    group_by(pop, `Population Description`, citie) %>%
    summarise() %>%
    print.data.frame()


  ## get location
  cities <- indiv.df %>% dplyr::group_by(pop) %>%
    dplyr::filter(row_number() == 1) %>%
    ungroup() %>%
    dplyr::select(citie, pop, `Population Description`)
  cities <- cbind(cities, geocode(cities$citie))

  ## plot with leaflet
  ## library(leaflet)
  ## m <- leaflet() %>%
  ##   addTiles() %>%  # Add default OpenStreetMap map tiles
  ##   addMarkers(lng = cities$lon, lat = cities$lat, popup = cities$`Population Description`)
  ## ## m  # Print the map
  ## ## to render in rstudio....
  ## save_expr(m, "eas_map.rds")
  ## ## save widget
  ## library(htmlwidgets)
  ## saveWidget(m, "~/Projects/Thesis/MaThese/OUTPUT/Rplots/eas_map.html", selfcontained = FALSE)

  ## plot map
  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  map.world <- get_map(location = "world")
  pl <- ggplot(cities, aes(x = lon, y = lat, color = `Population Description`)) +
    mapWorld +
    geom_point() +
    theme(legend.position='bottom')
  pl
  save_plot_png(pl, "eas_map_ggplot.png", 1000, 600)

  ## compute X
  library(raster)
  climate <- getData('worldclim', var='bio', res = 2.5)
  bio <- extract(climate, y = as.matrix(cities[c("lon","lat")]))
  pc.bio <- prcomp(bio,scale = T)
  plot(pc.bio$sdev)
  X <- pc.bio$x[,1]

  cities <- cbind(cities, X)


  ## add to indiv
  indiv.df <- indiv.df %>%
    inner_join(cities)

  ## scale
  indiv.df$X <- scale(indiv.df$X)

  ## X for EAS
  X.eas <- as.matrix(indiv.df$X)
  dim(X.eas)

  ## save
  saveRDS(indiv.df, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  saveRDS(X.eas, "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds")

  ## plot X
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, size = X, text = `Population Description`)) +
    mapWorld + 
    geom_point()
  pl
  save_plot_png(pl, "X_eas.png")

  ## try plotly :D
  library(plotly)
  ggplotly(pl)

#+end_src

#+RESULTS: code:eas_climatic_gradient
[[./OUTPUT/Rplots/X_eas.png]]
#+begin_example
Le chargement a nécessité le package : xml2

Attachement du package : ‘rvest’

The following object is masked from ‘package:readr’:

    guess_encoding
  Population Code
1             CHB
2             JPT
3             CHS
4             CDX
5             KHV
6             CEU
                                             Population Description
1                                      Han Chinese in Bejing, China
2                                          Japanese in Tokyo, Japan
3                                              Southern Han Chinese
4                               Chinese Dai in Xishuangbanna, China
5                                 Kinh in Ho Chi Minh City, Vietnam
6 Utah Residents (CEPH) with Northern and Western European Ancestry
  Super Population Code Sequence Data Available Alignment Data Available
1                   EAS                       1                        1
2                   EAS                       1                        1
3                   EAS                       1                        1
4                   EAS                       1                        1
5                   EAS                       1                        1
6                   EUR                       1                        1
  Variant Data Available
1                      1
2                      1
3                      1
4                      1
5                      1
6                      1
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation('ggmap') for details.

Attachement du package : ‘ggmap’

The following object is masked from ‘package:magrittr’:

    inset
Joining, by = "pop"
# A tibble: 1,409 x 9
    sample   pop super_pop gender        `Population Description`
     <chr> <chr>     <chr>  <chr>                           <chr>
 1 HG00096   GBR       EUR   male British in England and Scotland
 2 HG00097   GBR       EUR female British in England and Scotland
 3 HG00099   GBR       EUR female British in England and Scotland
 4 HG00100   GBR       EUR female British in England and Scotland
 5 HG00101   GBR       EUR   male British in England and Scotland
 6 HG00102   GBR       EUR female British in England and Scotland
 7 HG00105   GBR       EUR   male British in England and Scotland
 8 HG00106   GBR       EUR female British in England and Scotland
 9 HG00107   GBR       EUR   male British in England and Scotland
10 HG00108   GBR       EUR   male British in England and Scotland
# ... with 1,399 more rows, and 4 more variables: `Super Population
#   Code` <chr>, `Sequence Data Available` <int>, `Alignment Data
#   Available` <int>, `Variant Data Available` <int>
   pop                                            Population Description
1  BEB                                           Bengali from Bangladesh
2  CEU Utah Residents (CEPH) with Northern and Western European Ancestry
3  ESN                                                   Esan in Nigeria
4  FIN                                                Finnish in Finland
5  GBR                                   British in England and Scotland
6  GIH                               Gujarati Indian from Houston, Texas
7  GWD                        Gambian in Western Divisions in the Gambia
8  IBS                                       Iberian Population in Spain
9  ITU                                         Indian Telugu from the UK
10 JPT                                          Japanese in Tokyo, Japan
11 LWK                                            Luhya in Webuye, Kenya
12 MSL                                             Mende in Sierra Leone
13 PJL                                     Punjabi from Lahore, Pakistan
14 STU                                      Sri Lankan Tamil from the UK
15 TSI                                                 Toscani in Italia
16 YRI                                         Yoruba in Ibadan, Nigeria
            citie
1      Bangladesh
2  United Kingdom
3         Nigeria
4         Finland
5         England
6         Gujarat
7          Gambia
8           Spain
9       Telangana
10          Japan
11          Kenya
12   Sierra Leone
13       Pakistan
14      Sri Lanka
15         Italia
16        Nigeria
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=England&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Finland&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Spain&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Pakistan&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gambia&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Bangladesh&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sierra%20Leone&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Sri%20Lanka&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Telangana&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=United%20Kingdom&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Nigeria&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Kenya&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Japan&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Italia&sensor=false
.Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=Gujarat&sensor=false

Attaching package: ‘maps’

The following object is masked from ‘package:purrr’:

    map
Map from URL : http://maps.googleapis.com/maps/api/staticmap?center=world&zoom=10&size=640x640&scale=2&maptype=terrain&language=en-EN&sensor=false
Information from URL : http://maps.googleapis.com/maps/api/geocode/json?address=world&sensor=false
[[./OUTPUT/Rplots/eas_map_ggplot.png]]
Le chargement a nécessité le package : sp

Attachement du package : ‘raster’

The following object is masked from ‘package:magrittr’:

    extract

The following object is masked from ‘package:dplyr’:

    select

The following object is masked from ‘package:tidyr’:

    extract
Joining, by = c("pop", "Population Description", "citie")
[1] 1409    1

Attachement du package : ‘plotly’

The following object is masked from ‘package:raster’:

    select

The following object is masked from ‘package:ggmap’:

    wind

The following object is masked from ‘package:stats’:

    filter

The following object is masked from ‘package:graphics’:

    layout

The following object is masked from ‘package:ggplot2’:

    last_plot
We recommend that you use the dev version of ggplot2 with `ggplotly()`
Install it with: `devtools::install_github('hadley/ggplot2')`
#+end_example

***** DONE Scree plot
CLOSED: [2017-08-28 lun. 15:48]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-28 lun. 15:48]
- State "RUNNING"    from "DONE"       [2017-08-28 lun. 15:23]
- State "DONE"       from "RUNNING"    [2017-08-22 mar. 09:31]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from "DONE"       [2017-08-21 lun. 17:19]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 13:25]
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 12:11]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "RUNNING"    [2017-08-16 mer. 17:24]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 16:03]
- Note taken on [2017-07-25 mar. 17:52] \\
  faut que je reance avec lambda
- State "TODO"       from "RUNNING"    [2017-07-25 mar. 17:49]
- Note taken on [2017-07-25 mar. 17:46] \\
  tail -f /home/cayek/tmp/Logfiles/ewas_screeplot.y2017_m07_d25_17h_37.log
- State "RUNNING"    from "DONE"       [2017-07-25 mar. 17:46]
- Note taken on [2017-07-11 mar. 12:01] \\
  K = 7 ca semple bien :D
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 12:00]
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "DONE"       [2017-07-11 mar. 11:53]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 19:24]
- State "RUNNING"    from "DONE"       [2017-06-27 mar. 18:01]
- State "DONE"       from "RUNNING"    [2017-06-27 mar. 17:52]
- State "RUNNING"    from "STARTED"    [2017-06-27 mar. 16:51]
- State "STARTED"    from "TODO"       [2017-06-27 mar. 16:42]
- State "TODO"       from              [2017-06-27 mar. 16:42]
:END:

#+NAME: code:eas_screeplot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds"
  X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
  ## dat
  dat <- ExpRsampler_trueData(Y = Y, X = X, outlier = NULL) %>% ExpRmouline()

  ## projection
  P.list <- lfmm::compute_P(dat$X, lambda = 0.0)
  Y <- P.list$sqrt.P %*% dat$Y
  rm(P.list)
  rm(dat)
  gc()

  ## PCA
  svd.res <- svd(Y,0,0)
  df.res <- tibble(index = seq_along(svd.res$d), singular.value = svd.res$d) %>%
    mutate(var.expl = singular.value / sum(singular.value))
  save_expr(df.res, "geas_screeplot_expr.rds")

  ## plot
  pl <- ggplot(df.res, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,100))
  save_plot_png(pl, "geas_screeplot.png")

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_screeplot.png]]

***** DONE Validation croisée du modèle lfmmRidge
CLOSED: [2017-08-17 Thu 18:09]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-17 Thu 18:09]
- State "RUNNING"    from "DONE"       [2017-08-17 jeu. 16:49]
- State "DONE"       from "RUNNING"    [2017-08-17 jeu. 16:47]
- Note taken on [2017-08-17 jeu. 13:58] \\
  Faut que je relance eas_CV_lambda pour etre sur
- State "RUNNING"    from "TODO"       [2017-08-17 jeu. 13:26]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 11:47]
- State "DONE"       from "STARTED"    [2017-08-17 jeu. 08:52]
- State "STARTED"    from "RUNNING"    [2017-08-16 mer. 18:55]
- State "RUNNING"    from "TODO"       [2017-08-16 mer. 17:23]
- State "TODO"       from "DONE"       [2017-08-06 Sun 14:48]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 14:36]
- Note taken on [2017-07-11 mar. 14:36] \\
  Mdr ca a pas changé grand chose !!!! Du coup on prend ce que donne le scree plot
  et un lambda petit !!!
- Note taken on [2017-07-11 mar. 11:04] \\
  C'est reparti, le pb c'était les snps sans variance !!
- Note taken on [2017-07-11 mar. 10:07] \\
  ca plante, je sais pas pk !! la ca tourne !!
- State "RUNNING"    from "DEBUG"      [2017-07-11 mar. 10:07]
- State "DEBUG"      from "DONE"       [2017-07-11 mar. 09:35]
- State "DONE"       from "RUNNING"    [2017-07-11 mar. 09:35]
- Note taken on [2017-07-11 mar. 09:10] \\
  je refait avec X et G scaled
- State "RUNNING"    from "DONE"       [2017-07-11 mar. 09:10]
- Note taken on [2017-07-10 lun. 09:07] \\
  Il y a trop de bruit par rapport au signal !! La validation croisée ne permet
  rien de dire ! On va se baser sur le scree plot et sur ce qu'on sait a priorie
  (peut d'outlier)
- State "DONE"       from "RUNNING"    [2017-07-10 lun. 09:07]
- State "RUNNING"    from "TODO"       [2017-07-03 lun. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 16:43]
- Note taken on [2017-06-29 jeu. 16:37] \\
  Il y a trop peut de structure !!! Je pense que la structure est porté par trop
  peut de snps !!! Du coup le modèle n'est partinent que pour trop peu de snps et
  donc on arrive pas a cross valider !!!
- State "RUNNING"    from "TODO"       [2017-06-29 jeu. 14:39]
- State "TODO"       from "RUNNING"    [2017-06-29 jeu. 10:12]
- State "RUNNING"    from "TODO"       [2017-06-28 mer. 20:37]
- State "TODO"       from              [2017-06-27 mar. 15:29]
:END:

#+NAME: code:eas_CV
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  ## samplers
  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-5)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "geas_CV_lfmm.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  save_plot_png(pl, "geas_CV_lfmm_lambda.png")
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/geas_CV_lfmm_K.png]]

#+NAME: code:eas_CV_encore
#+CAPTION: Dépend de [[eas_CV]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                                X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                                outlier = NULL) %>%
      ExpRmouline()

  lambdas <- c(1e10)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = 1:15)

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)


  ## retrieve expr
  res.cv.other <- readRDS("./OUTPUT/Expr/geas_CV_lfmm.rds")
  res.cv$errs <- rbind(res.cv$errs,
                       res.cv.other$errs)
  save_expr(res.cv, "geas_CV_lfmm_encore.rds")

  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "K")
  save_plot_png(pl, "geas_CV_lfmm_K_encore.png")
#+end_src

#+NAME: code:eas_CV_lambda
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]]
#+begin_src R 
  library(MaTheseR)

  dat <- ExpRsampler_trueData(Y = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled_prunned.rds",
                              X = "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds",
                              outlier = NULL) %>%
    ExpRmouline()

  n <- nrow(dat$Y)

  lambdas <- c(1e-10, 1e-5, 1, 1e10, 1e20)
  nb.cluster <- 8
  cv <- method_CV_ridgeLFMM(n.fold.col = 2, n.fold.row = 5,
                            lambdas = lambdas,
                            Ks = c(4,5,6))

  ## run
  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  res.cv <- ExpRmouline(cv, dat)
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)

  ## save expr
  save_expr(res.cv, "eas_CV_lambda_lfmm.rds")

  ## plot
  pl <- plot_CV_ridgeLFMM(res.cv$errs, major = "lambda")
  pl
  save_plot_png(pl, "eas_CV_lambda_lfmm_lambda.png")
#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_CV_lambda_lfmm_lambda.png]]

***** TODO Étude du jeu de données
:LOGBOOK:
- State "TODO"       from "RUNNING"    [2017-08-21 lun. 16:48]
- State "RUNNING"    from "DONE"       [2017-08-21 lun. 16:48]
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 16:41]
- State "RUNNING"    from "STARTED"    [2017-08-17 Thu 18:13]
- State "STARTED"    from "RUNNING"    [2017-08-17 jeu. 12:11]
- State "RUNNING"    from "STARTED"    [2017-08-17 jeu. 09:11]
- State "STARTED"    from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from "RUNNING"    [2017-07-12 mer. 09:48]
- Note taken on [2017-07-11 mar. 16:30] \\
  ca tourne sur krak !!
- State "RUNNING"    from "TODO"       [2017-07-11 mar. 16:30]
- State "TODO"       from              [2017-07-10 lun. 09:06]
:END:
****** DONE Run all methods
CLOSED: [2017-08-31 jeu. 08:34]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 08:34]
- State "RUNNING"    from "DONE"       [2017-08-30 mer. 12:06]
- State "DONE"       from "RUNNING"    [2017-08-21 lun. 17:28]
- State "RUNNING"    from "TODO"       [2017-08-21 lun. 16:49]
- State "TODO"       from              [2017-08-21 lun. 16:48]
:END:

#+NAME: code:eas_expr
#+CAPTION: Dépend de [[code:eas_climatic_gradient]] [[code:1000g_G_noNA_scaled_prunned]] [[code:1000g_G_noNA_scaled]]
#+begin_src R 
  library(MaTheseR)
  library(lfmm)
  library(matter)
  library(foreach)
  library(doParallel)

  rerun <- FALSE
  nb.cluster <- 1
  ## param
  param <- list(K.method = 9,
                lambda = 1e-5,
                nozero.prop = 0.01,
                lambda.num = 25,
                relative.err.epsilon = 1e-6)


  ## methods
  methods <- list()
  methods$m.lm <- method_lm()
  methods$m.ridgeLfmm <- method_ridgeLFMM(K = param$K.method, lambda = param$lambda)
  methods$m.pca <- method_PCAlm(K = param$K.method)
  methods$m.cate <- method_cate(K = param$K.method)
  methods$m.lasso <- method_lassoLFMM(K = param$K.method,
                                      nozero.prop = param$nozero.prop,
                                      lambda.num = param$lambda.num,
                                      relative.err.epsilon = param$relative.err.epsilon)

  run_eas <- function(m) {
    message("=============== ", m$name)
    ## dat
    Y <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_G_noNA_scaled.matter.rds"
    X <- "./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_X.rds"
    outlier <- c()
    dat <- MaTheseR::LfmmMatterDat(Y, X, outlier)
    col.mask <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_ind_pruning.rds")
    out.file.res.df <- paste0("./OUTPUT/Expr/Eas_df","_", m$name)
    out.file.U <- paste0("./OUTPUT/Expr/Eas_U","_", m$name)

    if (!exist_res(m, out.file.res.df) && !rerun) {
      ## mask data
      message("mask data")
      dat.masked <- lfmm::LfmmDat(Y = NULL, X = dat$X, missing = FALSE)
      dat.masked$Y <- dat$Y[,col.mask]

      ## compute lattente variable
      message("computing U")
      if (!exist_res(m, out.file.U)) {
        m.U <- ExpRmouline(m, dat.masked)
        save_res(m, m.U, out.file.U)
      } else {
        m.U <- retrieve_res(m, out.file.U)
      }

      ## unmask
      message("unmask data")
      rm(dat.masked)
      gc()

      ## run HP
      message("running HP")
      m.res <- m
      X <- cbind(dat$X, m.U$U)
      d <- ncol(dat$X)
      hp <- lfmm::hypothesis_testing_lm(dat, X)
      m.res$score <- hp$score[,1:d, drop = FALSE]
      m.res$pvalue <- hp$pvalue[,1:d, drop = FALSE]
      m.res$B.hp <- hp$B[,1:d, drop = FALSE]
      ## saving res
      message("saving res.df")
      df <- ExpRextractor_pvalue1_calibrated(dat, m.res, 1, 1)
      save_res(m, df, out.file.res.df)
    } else {
      message("res.df exist !! ")
    }
  }


  cl <- parallel::makeCluster(nb.cluster, outfile = "")
  doParallel::registerDoParallel(cl)
  foreach(m = methods) %dopar% {
    run_eas(m)
  }
  doParallel::stopImplicitCluster()
  parallel::stopCluster(cl)


  ## cbind res
  res.df <- tibble()
  for (m in methods) {
    out.file.res.df <- paste0("./OUTPUT/Expr/Eas_df","_", m$name)
    if (exist_res(m, out.file.res.df)) {
      message("=============== ", m$name)
      res.df <- res.df %>%
        rbind(retrieve_res(m, out.file.res.df))
    }
  }

  save_expr(res.df, "eas_all_df.rds")

#+end_src

****** DONE compute qvalue
CLOSED: [2017-08-21 lun. 17:57]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-21 lun. 17:57]
- State "TODO"       from              [2017-08-21 lun. 16:42]
:END:
#+NAME: code:eas_qvalue
#+CAPTION: Dépend de [[code:eas_expr]]
#+BEGIN_SRC R
  library(MaTheseR)
  res.df <- readRDS("./OUTPUT/Expr/eas_all_df.rds")

  qval.df <- res.df %>%
    group_by(method) %>%
    dplyr::mutate(qvalue = qvalue::qvalue(calibrated.pvalue)$qvalues) %>%
    ungroup()

  save_expr(qval.df, "eas_all_qvalue_df.rds")
#+END_SRC

****** load expr res
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_load_res
#+CAPTION: Dépend de [[code:eas_qvalue]]
#+BEGIN_SRC R
  library(MaTheseR)
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
#+END_SRC


#+RESULTS: code:eas_load_res

****** DONE Que donne la calibration ?
CLOSED: [2017-08-22 mar. 09:36]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:36]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:
#+NAME: code:eas_calibration
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  qval.df %>%
    group_by(method) %>%
    summarise(mad = mad[1], median = median[1])
#+END_SRC

#+RESULTS: code:eas_calibration
: # A tibble: 5 x 3
:      method      mad     median
:       <chr>    <dbl>      <dbl>
: 1      cate 1.580635 0.11340787
: 2 lassoLFMM 1.224637 0.08467967
: 3        lm 8.760657 0.38152482
: 4     PCAlm 1.046560 0.01363840
: 5 ridgeLFMM 1.587502 0.11969276

****** TODO Les qqplots ?
:LOGBOOK:
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_qqplot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- qval.df %>%
    mutate(pvalue = calibrated.pvalue) %>%
    dplyr::filter(method %in% c("cate", "PCAlm", "ridgeLFMM", "lassoLFMM"))

  ## all on the same graph
  pll <- ggplot(toplot, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0)
  save_plot_png(pll, "EAS_qqplots2.png")
#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/EAS_qqplots2.png]]

****** TODO Comparaison des top listes
:LOGBOOK:
- State "TODO"       from "DONE"       [2017-08-31 jeu. 08:53]
- State "DONE"       from "TODO"       [2017-08-22 mar. 09:41]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_top
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- res.df %>%
    dplyr::mutate(pvalue = calibrated.pvalue) %>%
    group_by(method) %>%
    filter_candidates_top(30)

  pl <- plot_intersection(toplot, by = "colname", plot = "tile")
  save_plot_png(pl, "eas_top_inter.png")
#+END_SRC

#+RESULTS: code:eas_top
[[./OUTPUT/Rplots/eas_top_inter.png]]

****** DONE Comparaison des listes avec contrôle du FDR à $0.01$ and venn diag
CLOSED: [2017-08-31 jeu. 10:14]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-31 jeu. 10:14]
- State "TODO"       from              [2017-08-17 jeu. 09:31]
:END:

#+NAME: code:eas_fdr
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  toplot <- qval.df %>%
    dplyr::filter(qvalue <= 0.01)

  ## matrix
  pl <- plot_intersection(toplot, by = "colname", plot = "point")
  save_plot_png(pl, "eas_fdr01_inter.png")

  ## venn diagram
  sets <- list(lm = toplot$index[toplot$method == "lm"],
               cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"]
               )


  out <- plot_venn(sets[2:5])

  save_plot_png(out, "eas_fdr01_venn.png")

#+END_SRC

#+RESULTS:
[[./OUTPUT/Rplots/eas_fdr01_venn.png]]
[[./OUTPUT/Rplots/eas_fdr01_inter.png]]

****** TODO Annotation Biomart
:LOGBOOK:
- State "TODO"       from "TODO"       [2017-08-30 mer. 10:22]
- State "TODO"       from "DONE"       [2017-07-12 mer. 11:10]
- State "DONE"       from              [2017-07-12 mer. 11:10]
:END:

#+NAME: code:eas_annotation
#+CAPTION: Dépend de [[code:eas_load_res]]
#+BEGIN_SRC R
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation union ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()


  message("== annotation lfmmRidge ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("ridgeLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation cate ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("cate")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation lasso ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("lassoLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

  message("== annotation PCAlm ==")
  aux <- res.df %>%
    mutate(snps = colname) %>%
    dplyr::filter(method %in% c("PCAlm")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate_annotation(snp.db)
  aux %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    dplyr::filter(phenotype_name != "" | phenotype_description != "") %>%
    print.data.frame()

#+END_SRC

#+NAME: code:eas_annotation_inter
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  require(biomaRt)
  require(MaTheseR)

  ## annotation
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)

  message("== annotation inter ==")
  aux <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)
  inter.list <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- list(lm = aux$index[aux$method == "lm"],
               cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  sets <- sets[2:5]
  candidates.snps.df <- aux %>%
    dplyr::filter(index %in% inter.list(1,2,3,4))
  length(unique(candidates.snps.df$colname))
  aux2 <- candidates.snps.df %>%
    mutate(snps = colname) %>%
    mutate_annotation(snp.db)
  aux2 %>%
    dplyr::select(phenotype_description, phenotype_name) %>%
    print.data.frame()


#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_inter_manhattan.png]]

****** TODO Annotation Vep
:LOGBOOK:
- State "TODO"       from              [2017-08-22 mar. 11:46]
:END:

#+NAME: code:eas_annotation_vep
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  vep.output$Consequence %>% table()
  vep.output$IMPACT %>% table() / nrow(vep.output)

  message("== vep annotation union ==")
  res.df.union <- res.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))


  res.df.union$IMPACT %>% table() / nrow(res.df.union)
  res.df.union$Consequence %>% table()

  message("== annotation lfmmRidge ==")
  res.df.union <- res.df %>%
    dplyr::filter(method %in% c("ridgeLFMM")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))

  res.df.union$IMPACT %>% table() / nrow(res.df.union)

  message("== annotation cate ==")
  res.df.union <- res.df %>%
    dplyr::filter(method %in% c("cate")) %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname) %>%
    dplyr::left_join(vep.output, by = c('snps'))

  res.df.union$IMPACT %>% table() / nrow(res.df.union)
#+end_src

****** TODO Annotation de l'intersection
:LOGBOOK:
- State "TODO"       from              [2017-08-30 mer. 10:15]
:END:

#+NAME: code:eas_inter_annotation
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)
  library(stringr)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  ## filter FDR 1%
  aux <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  ## intersection
  inter.list <- function(...) {
    id <- list(...)
      res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    res
  }
  sets <- list(cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  inter.candidates.df <- aux %>%
    dplyr::filter(index %in% inter.list(1,2,3,4),
                  method == "cate") 
  ## 14 candidates
  length(inter.candidates.df$colname)

  ## vep annotation
  inter.candidates.df.vep <- inter.candidates.df %>%
    dplyr::left_join(vep.output, by = c('snps')) %>%
    mutate(chrm = str_replace(Location, ":[:digit:]*",""),
           pos = str_replace(Location, "[:digit:]*:",""))


  inter.candidates.df.vep$chrm
  inter.candidates.df.vep$pos
  inter.candidates.df.vep$IMPACT %>% table()
  inter.candidates.df.vep$Gene %>% table()
  inter.candidates.df.vep$Consequence %>% table()

  inter.candidates.df.vep %>% dplyr::filter(IMPACT == "MODERATE") %>%
    dplyr::select(IMPACT, Consequence)

  ## plot
  pl <- ggplot(inter.candidates.df.vep, aes(x = pos, y = -log10(pvalue))) +
    geom_point() +
    facet_grid(~ chrm, scales = "free")
  save_plot_png(pl, "eas_inter_manhattan.png")

  ## biomart
  require(biomaRt)
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")

  inter.candidates.df.biomart <- inter.candidates.df %>%
    mutate_annotation(snp.db)

  inter.candidates.df.vep$phenotype_name

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_inter_manhattan.png]]

****** DONE Annotation de l'union
CLOSED: [2017-09-01 ven. 13:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:11]
- State "TODO"       from              [2017-08-31 jeu. 13:56]
:END:
#+NAME: code:eas_inter_annotation
#+CAPTION: Dépend de [[code:eas_load_res]] [[code:1000g_vep_output]]
#+begin_src R 
  require(MaTheseR)
  library(stringr)

  vep.output <- readRDS( "./Data/ThesisDataset/3Article/1000GenomesPhase3/vep.output.rds")

  ## contingency IMPACT
  impact.all <- vep.output %>%
    distinct(snsp, keep_all = TRUE) %>%
    dplyr::select(IMPACT)
  cont.impact.all <- impact.all$IMPACT %>% table()

  ## filter FDR 1%
  aux <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  ## union
  union.list <- function(...) {
    id <- list(...)
      res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::union(res, sets[[i]])
    }
    res
  }
  sets <- list(cate = aux$index[aux$method == "cate"],
               lassoLFMM = aux$index[aux$method == "lassoLFMM"],
               ridgeLFMM = aux$index[aux$method == "ridgeLFMM"],
               PCAlm = aux$index[aux$method == "PCAlm"]
               )
  union.candidates.df <- aux %>%
    dplyr::filter(index %in% union.list(1,2,3,4))
  message("== number of SNPS detected ==")
  length(unique(union.candidates.df$colname))

  ## vep annotation
  union.candidates.df.vep <- union.candidates.df %>%
    dplyr::left_join(vep.output, by = c('snps')) %>%
    mutate(chrm = str_replace(Location, ":[:digit:]*",""),
           pos = str_replace(Location, "[:digit:]*:",""))

  ## over representation of HIGH
  library(broom)
  cont <- rbind(union = union.candidates.df.vep$IMPACT %>% table(), cont.impact.all)
  over.test.res <- tibble()
  f.aux <- function(lvl) {
    cont.lvl <- cbind(lvl = cont[,lvl], other = rowSums(cont[,!(colnames(cont) %in% lvl)]))
    over.test.res <<- fisher.test(cont.lvl, alternative="greater") %>% tidy() %>%
      mutate(lvl = lvl) %>%
      rbind(over.test.res)
  }
  message("== over representation tests ==")
  f.aux(lvl = "HIGH")
  f.aux(lvl = "LOW")
  f.aux(lvl = "MODERATE")
  over.test.res %>%
    transmute(odds.ratio = estimate,
                pvalue = p.value,
                lvl = lvl) %>%
    knitr::kable()

  ## biomart
  require(biomaRt)
  biomaRt::listMarts()
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  ## listFilters(snp.db)
  ## listAttributes(snp.db)

  union.candidates.df.biomart <- union.candidates.df %>%
    mutate_annotation(snp.db)

  ## tab
  message("== phenotype description in union union ==")
  union.candidates.df.biomart %>%
    dplyr::filter(phenotype_description != "") %>%
    group_by(phenotype_description) %>%
    dplyr::summarise(methods = paste0(unique(method), collapse=", "),
                     spns = paste0(unique(snps), collapse=", ")) %>%
    knitr::kable()

  ## amiGo2
  message("== panther input ==")
  (union.candidates.df.vep %>%
    distinct(Gene))$Gene %>%
    paste0(collapse=" ")
#+end_src

#+RESULTS: code:eas_inter_annotation
#+begin_example
== number of SNPS detected ==
[1] 836
== over representation tests ==


| odds.ratio|    pvalue|lvl      |
|----------:|---------:|:--------|
|   7.922087| 0.0000000|MODERATE |
|   1.706059| 0.0026103|LOW      |
|  22.281430| 0.0000000|HIGH     |
               biomart               version
1 ENSEMBL_MART_ENSEMBL      Ensembl Genes 90
2   ENSEMBL_MART_MOUSE      Mouse strains 90
3     ENSEMBL_MART_SNP  Ensembl Variation 90
4 ENSEMBL_MART_FUNCGEN Ensembl Regulation 90
== phenotype description in union union ==


|phenotype_description                                                                                     |methods                    |spns                                                  |
|:---------------------------------------------------------------------------------------------------------|:--------------------------|:-----------------------------------------------------|
|Alcoholism (heaviness of drinking)                                                                        |ridgeLFMM, cate            |rs10908907                                            |
|Body Height                                                                                               |lassoLFMM                  |rs10496731                                            |
|Caffeine metabolism (plasma 13-dimethylxanthine (theophylline) level)                                     |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Caffeine metabolism (plasma 137-trimethylxanthine (caffeine) level)                                       |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Caffeine metabolism (plasma 17-dimethylxanthine (paraxanthine) to 137-trimethylxanthine (caffeine) ratio) |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Cholesterol total                                                                                         |ridgeLFMM, cate, lassoLFMM |rs2256175                                             |
|Coffee consumption (cups per day)                                                                         |ridgeLFMM, cate, lassoLFMM |rs2472297                                             |
|Congenital lactase deficiency                                                                             |lassoLFMM                  |rs2278544, rs2322659                                  |
|Corneal structure                                                                                         |ridgeLFMM, cate, lassoLFMM |rs4954218                                             |
|Electrocardiographic traits                                                                               |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Electrocardiography                                                                                       |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Giant cell arteritis                                                                                      |ridgeLFMM, cate, lassoLFMM |rs2256175                                             |
|Height                                                                                                    |ridgeLFMM, cate, lassoLFMM |rs2256175, rs6085576, rs2104012, rs1983716, rs2853977 |
|Hematocrit                                                                                                |ridgeLFMM, cate, lassoLFMM |rs6430549                                             |
|Lactose intolerance                                                                                       |lassoLFMM                  |rs2278544, rs2322659                                  |
|Multiple sclerosis                                                                                        |ridgeLFMM, cate, lassoLFMM |rs882300                                              |
|Neuroblastoma                                                                                             |ridgeLFMM, cate, lassoLFMM |rs1123848                                             |
|Obesity-related traits                                                                                    |lassoLFMM                  |rs17158483                                            |
== panther input ==
[1] "ENSG00000171735 ENSG00000270171 ENSG00000270035 ENSG00000269978 NA ENSG00000138071 ENSG00000152127 ENSG00000152128 ENSG00000224043 ENSG00000153086 ENSG00000263783 ENSG00000082258 ENSG00000176601 ENSG00000115850 ENSG00000226806 ENSG00000076003 ENSG00000115866 ENSG00000231890 ENSG00000227347 ENSG00000216081 ENSG00000229568 ENSG00000221762 ENSG00000144229 ENSG00000228043 ENSG00000144227 ENSG00000231567 ENSG00000223921 ENSG00000168702 ENSG00000128645 ENSG00000224189 ENSG00000155657 ENSG00000144749 ENSG00000172340 ENSG00000075651 ENSG00000249782 ENSG00000230873 ENSG00000204536 ENSG00000238211 ENSG00000206337 ENSG00000204520 ENSG00000184465 ENSG00000048052 ENSG00000234336 ENSG00000127957 ENSG00000200874 ENSG00000008277 ENSG00000253350 ENSG00000148429 ENSG00000183621 ENSG00000183801 ENSG00000251364 ENSG00000255191 ENSG00000150676 ENSG00000149972 ENSG00000182667 ENSG00000181234 ENSG00000256630 ENSG00000151952 ENSG00000177596 ENSG00000226240 ENSG00000102466 ENSG00000232662 ENSG00000206190 ENSG00000261401 ENSG00000248334 ENSG00000156642 ENSG00000167508 ENSG00000260630 ENSG00000176890 ENSG00000176912 ENSG00000263727 ENSG00000142544 ENSG00000229876 ENSG00000157933 ENSG00000175130 ENSG00000116478 ENSG00000004455 ENSG00000236065 ENSG00000233047 ENSG00000121957 ENSG00000162641 ENSG00000143442 ENSG00000143627 ENSG00000117523 ENSG00000162779 ENSG00000143839 ENSG00000152104 ENSG00000134121 ENSG00000234661 ENSG00000144645 ENSG00000154175 ENSG00000181804 ENSG00000163347 ENSG00000197283 ENSG00000264085 ENSG00000146416 ENSG00000217648 ENSG00000131018 ENSG00000170632 ENSG00000233025 ENSG00000105939 ENSG00000173068 ENSG00000106804 ENSG00000130713 ENSG00000165695 ENSG00000065665 ENSG00000165609 ENSG00000122958 ENSG00000233163 ENSG00000205339 ENSG00000110318 ENSG00000187151 ENSG00000139151 ENSG00000255993 ENSG00000065150 ENSG00000150403 ENSG00000238737 ENSG00000242502 ENSG00000261739 ENSG00000103742 ENSG00000140443 ENSG00000048471 ENSG00000126856 ENSG00000072849 ENSG00000167842 ENSG00000263433 ENSG00000264734 ENSG00000136450 ENSG00000266086 ENSG00000186111 ENSG00000105072 ENSG00000269058 ENSG00000141979 ENSG00000131943 ENSG00000099904 ENSG00000188424 ENSG00000235578 ENSG00000198089 ENSG00000236052 ENSG00000116288 ENSG00000233008 ENSG00000135845 ENSG00000180999 ENSG00000228098 ENSG00000144224 ENSG00000131389 ENSG00000204681 ENSG00000223702 ENSG00000225851 ENSG00000230994 ENSG00000265294 ENSG00000185920 ENSG00000171811 ENSG00000134873 ENSG00000246877 ENSG00000260288 ENSG00000256530 ENSG00000152217 ENSG00000101384 ENSG00000117154 ENSG00000173406 ENSG00000237262 ENSG00000227149 ENSG00000135931 ENSG00000206527 ENSG00000239523 ENSG00000114544 ENSG00000251297 ENSG00000249462 ENSG00000271307 ENSG00000234745 ENSG00000271581 ENSG00000269964 ENSG00000106069 ENSG00000237065 ENSG00000235669 ENSG00000136193 ENSG00000253260 ENSG00000165185 ENSG00000252730 ENSG00000110057 ENSG00000110721 ENSG00000236267 ENSG00000258118 ENSG00000153575 ENSG00000104044 ENSG00000141429 ENSG00000266312 ENSG00000268184 ENSG00000241604"
#+end_example

****** CANCELLED Meta analysis
CLOSED: [2017-09-12 mar. 19:57]
:LOGBOOK:
- State "CANCELLED"  from "DEFERRED"   [2017-09-12 mar. 19:57]
- State "DEFERRED"   from "TODO"       [2017-09-12 mar. 19:57]
- State "TODO"       from              [2017-09-12 mar. 15:22]
:END:
#+NAME: code:eas_meta_analysis
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  require(MaTheseR)


  ## we want to have independant statistic
  method <- c("ridgeLFMM", "lassoLFMM", "cate")
  calibrated.score.mat <- NULL
  for (m in method) {
    message(m)
    calibrated.score.mat <- calibrated.score.mat %>%
      cbind(qval.df[qval.df$method == m,]$calibrated.score)
  }

  pca.res <- prcomp(calibrated.score.mat, center = FALSE, scale. = FALSE)
  pca.res$sdev

  ## combination
  pca.res$x[,1] %>% hist() ## il sont pas normal
  pca.res$x[,2] %>% hist()
  pca.res$x[,3] %>% hist()
#+end_src

****** DONE Clumping list with fdr controled to 1%
CLOSED: [2017-09-12 mar. 17:04]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 17:04]
- State "TODO"       from              [2017-09-12 mar. 15:56]
:END:
#+NAME: code:eas_clumping
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  library(MaTheseR)

  methods <- (qval.df$method %>% unique())
  methods

  ## clumping with plink
  res <- tibble()
  for (m in methods) {
    tmp.file <- tempfile()
    qval.df %>% dplyr::filter(method == m) %>%
      dplyr::transmute(P = qvalue, SNP = colname) %>%
        readr::write_delim(path = tmp.file, delim = "\t")
    plink.cmd <- paste("~/BiocompSoftware/plink/plink",
                       "--bfile ~/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ",
                       "--clump",
                       tmp.file,
                       "--clump-p1 0.01", ## FDR control to 1%
                       "--clump-p2 1.0",
                       "--clump-r2 0.50",
                       "--clump-kb 250",
                       "--out plink.clump",
                       "--threads 8")
    system(plink.cmd)

    clumping.res <- data.table::fread(file = "~/Projects/Thesis/MaThese/plink.clump.clumped",
                                      data.table = FALSE) %>% as_tibble()

    res <- clumping.res %>%
      mutate(method = m) %>%
      rbind(res)

    file.remove(tmp.file)
  }

  save_expr(res, "eas_all_clumps.rds")
#+end_src

#+RESULTS: code:eas_clumping
#+begin_example
[1] "lm"        "ridgeLFMM" "PCAlm"     "cate"      "lassoLFMM"
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea27d82590
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
Warning: No significant --clump results.  Skipping.
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69eae397bd3
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 88 clumps formed from 482 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea58a6d150
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 57 clumps formed from 90 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea185529f6
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 111 clumps formed from 538 top variants.
Results written to plink.clump.clumped .
PLINK v1.90b4.3 64-bit (9 May 2017)            www.cog-genomics.org/plink/1.9/
(C) 2005-2017 Shaun Purcell, Christopher Chang   GNU General Public License v3
Logging to plink.clump.log.
Options in effect:
  --bfile /home/cayek/Projects/Thesis/Data/1000Genomes/Phase3/1000GenomePhase3_CQ
  --clump /home/cayek/tmp/RtmpzLiLyv/file69ea410344c5
  --clump-kb 250
  --clump-p1 0.01
  --clump-p2 1.0
  --clump-r2 0.50
  --out plink.clump
  --threads 8

193793 MB RAM detected; reserving 96896 MB for main workspace.
5398440 variants loaded from .bim file.
2504 people (0 males, 0 females, 2504 ambiguous) loaded from .fam.
Ambiguous sex IDs written to plink.clump.nosex .
Using 1 thread (no multithreaded calculations invoked).
Before main variant filters, 2504 founders and 0 nonfounders present.
Total genotyping rate is 0.999922.
5398440 variants and 2504 people pass filters and QC.
Note: No phenotypes present.
--clump: 103 clumps formed from 606 top variants.
Results written to plink.clump.clumped .
Expr save in ./OUTPUT/Expr/eas_all_clumps.rds
#+end_example

****** DONE Annotation of the union of the clumps
CLOSED: [2017-09-12 mar. 19:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 19:11]
- State "TODO"       from "CANCELLED"  [2017-09-12 mar. 18:39]
- Note taken on [2017-09-12 mar. 18:38] \\
  c'est bizare en gros je trouve les mêmes chose de toute facon !!
- State "CANCELLED"  from "TODO"       [2017-09-12 mar. 18:38]
- State "TODO"       from              [2017-09-12 mar. 17:05]
:END:
#+NAME: code:eas_clumps_annotation
#+CAPTION: Dépend de [[code:eas_clumping]]
#+begin_src R 
  library(MaTheseR)
  library(stringr)
  clumps.df <- readRDS("./OUTPUT/Expr/eas_all_clumps.rds")
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")

  ## fdr control
  controled.qval.df <- qval.df %>%
    dplyr::filter(qvalue <= 0.01) %>%
    mutate(snps = colname)

  message("unique clumps")
  clumps.df$SNP %>% unique() %>% length()

  ## explode clumps
  exploded.clumps.df <- tibble()
  for (i in 1:nrow(clumps.df)) {
    SNP <- clumps.df$SNP[i]
    SP2 <- clumps.df$SP2[i] %>% str_split(",", simplify = TRUE) %>%
      str_replace("\\(1\\)", "") %>%
      str_split(";", simplify = TRUE)
    SP2 <- c(SP2, SNP)
    exploded.clumps.df <- exploded.clumps.df %>%
      rbind(tibble(snps = SP2, clump.snps = SNP))
  }

  ## biomart annotation
  require(biomaRt)
  snp.db = biomaRt::useMart("ENSEMBL_MART_SNP", dataset="hsapiens_snp")
  listFilters(snp.db)
  listAttributes(snp.db)
  attributes = c("refsnp_id",
                 "refsnp_source",
                 "chr_name",
                 "chrom_start",
                 'phenotype_name',
                 "phenotype_description",
                 "ensembl_gene_stable_id")

  the.snps <- unique(exploded.clumps.df$snps)
  nt.biomart <- biomaRt::getBM(attributes = attributes,
                               filters = "snp_filter",
                               values = the.snps,
                               mart = snp.db)
  nt.biomart <- nt.biomart %>%
    dplyr::mutate(snps = refsnp_id)
  nt.biomart <- left_join(exploded.clumps.df,nt.biomart, by = "snps")

  ## lil test
  nt.biomart$clump.snps %in% controled.qval.df$snps %>% mean()

  save_expr(nt.biomart, "eas_annotation_clumps.rds")
#+end_src

****** DONE Tableau de l'annotation des clumps
CLOSED: [2017-09-12 mar. 20:22]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-12 mar. 20:22]
- State "TODO"       from              [2017-09-12 mar. 19:12]
:END:
#+NAME: code:eas_clumps_tab
#+CAPTION: Dépend de [[code:eas_clumps_annotation]]
#+begin_src R 
  library(MaTheseR)

  clumps.df <- readRDS("./OUTPUT/Expr/eas_all_clumps.rds")
  qval.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
  nt.biomart <- readRDS("./OUTPUT/Expr/eas_annotation_clumps.rds")

  clumps.df$SNP %in% controled.qval.df$snps %>% mean()

  ## On regroupe le tout
  aux <- qval.df %>%
    transmute(clump.snps = colname,
              pvalue = calibrated.pvalue,
              method = method)
  aux <- left_join(nt.biomart, aux, by = "clump.snps")
  aux <- aux %>%
    transmute(snps = snps,
              clump.snps = clump.snps,
              pvalue = pvalue,
              method = method,
              gene = ensembl_gene_stable_id,
              phenotype_name= phenotype_name,
              phenotype_description = phenotype_description)

  res.df <- aux %>%
    dplyr::filter(phenotype_description != "") %>%
    group_by(clump.snps, method, pvalue) %>%
    summarise(genes = paste0(unique(gene), collapse = ", "),
              phenotype_names = paste0(unique(phenotype_name), collapse = ", "),
              phenotype_descriptions = paste0(unique(phenotype_description), collapse = ", "),
              snp.in.clump = paste0(unique(snps), collapse = ", ")) %>%
    tidyr::spread(key = method, value = pvalue) %>%
    ungroup()

  ## tabble
  res.df %>%
    dplyr::select(cate, lassoLFMM, lm, PCAlm, clump.snps, phenotype_descriptions) %>%
    knitr::kable()

#+end_src

#+RESULTS: code:eas_clumps_tab
#+begin_example
[1] 1


|      cate| lassoLFMM|        lm|     PCAlm|clump.snps |phenotype_descriptions                                                                                                                                                                                                                                                                   |
|---------:|---------:|---------:|---------:|:----------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 0.0000003| 0.0039447| 0.0151267| 0.6393762|rs10908907 |Alcoholism (heaviness of drinking)                                                                                                                                                                                                                                                       |
| 0.0000000| 0.0000000| 0.0614097| 0.0001885|rs12691876 |Electrocardiography, Multiple sclerosis, Electrocardiographic traits                                                                                                                                                                                                                     |
| 0.0000000| 0.0000000| 0.0830381| 0.0000022|rs1470457  |Congenital lactase deficiency, Lactose intolerance                                                                                                                                                                                                                                       |
| 0.0000000| 0.0000000| 0.0566630| 0.0000000|rs1530559  |Hematocrit                                                                                                                                                                                                                                                                               |
| 0.0000822| 0.0000000| 0.2876809| 0.0000003|rs17158483 |Obesity-related traits                                                                                                                                                                                                                                                                   |
| 0.0000654| 0.0000005| 0.1190359| 0.0000228|rs17228197 |Cholesterol HDL, Exercise Test                                                                                                                                                                                                                                                           |
| 0.0000002| 0.0000250| 0.1364597| 0.1167581|rs1983716  |Height                                                                                                                                                                                                                                                                                   |
| 0.0000028| 0.0000003| 0.1936770| 0.0001651|rs2256174  |Height, Behcet Syndrome, Lupus Erythematosus Systemic, Cholesterol total, Cervical Cancer                                                                                                                                                                                                |
| 0.0000002| 0.0000003| 0.2245867| 0.0001560|rs2256175  |Cholesterol total, Height, Behcet Syndrome, Giant cell arteritis                                                                                                                                                                                                                         |
| 0.0000003| 0.0000007| 0.0204494| 0.0027263|rs2472297  |Coffee consumption (cups per day), Caffeine metabolism (plasma 17-dimethylxanthine (paraxanthine) to 137-trimethylxanthine (caffeine) ratio), Caffeine metabolism (plasma 13-dimethylxanthine (theophylline) level), Caffeine metabolism (plasma 137-trimethylxanthine (caffeine) level) |
| 0.0002303| 0.0000011| 0.0054879| 0.0000242|rs2727791  |High-density lipoprotein cholesterol, Apolipoprotein A-IV levels                                                                                                                                                                                                                         |
| 0.0000000| 0.0093811| 0.1221122| 0.8835068|rs3101270  |Response to antipsychotic treatment                                                                                                                                                                                                                                                      |
| 0.0000009| 0.0012005| 0.0406157| 0.1291847|rs35731977 |CELIAC DISEASE                                                                                                                                                                                                                                                                           |
| 0.0000392| 0.0000007| 0.0137603| 0.0000908|rs4466389  |Multiple myeloma (IgH translocation)                                                                                                                                                                                                                                                     |
| 0.0000004| 0.0000000| 0.0484197| 0.0000494|rs4954218  |Corneal structure                                                                                                                                                                                                                                                                        |
| 0.0000000| 0.0000000| 0.2562551| 0.0000113|rs4954567  |Neuroblastoma                                                                                                                                                                                                                                                                            |
| 0.0338803| 0.0000083| 0.4738190| 0.0000000|rs62056344 |Vitamin K                                                                                                                                                                                                                                                                                |
| 0.0000001| 0.0000001| 0.0085463| 0.0001146|rs66733621 |Cardiovascular phenotype, Hypertrophic cardiomyopathy, Dilated Cardiomyopathy Dominant, Hereditary Myopathy with Early Respiratory Failure, Limb-Girdle Muscular Dystrophy Recessive, Myopathy early-onset with fatal cardiomyopathy, Distal myopathy Markesbery-Griggs type             |
| 0.0000000| 0.0000000| 0.1304925| 0.0000049|rs6716987  |Neuroblastoma, Electrocardiography, Multiple sclerosis, Electrocardiographic traits                                                                                                                                                                                                      |
| 0.0000000| 0.0000000| 0.0119291| 0.0000002|rs6730196  |Congenital lactase deficiency, Lactose intolerance                                                                                                                                                                                                                                       |
| 0.0005657| 0.0000008| 0.5858195| 0.0000005|rs7259739  |Capecitabine sensitivity                                                                                                                                                                                                                                                                 |
| 0.0000001| 0.0000000| 0.1888716| 0.0000588|rs766271   |Body Height, Blood metabolite levels                                                                                                                                                                                                                                                     |
| 0.0000004| 0.0000473| 0.0195241| 0.0615935|rs9267897  |Prostate Cancer                                                                                                                                                                                                                                                                          |
| 0.0000004| 0.0000498| 0.0187989| 0.0626544|rs9267907  |Prostate Cancer                                                                                                                                                                                                                                                                          |
| 0.9524410| 0.0046970| 0.1427599| 0.0000001|rs9927276  |Subjective well-being                                                                                                                                                                                                                                                                    |
#+end_example

Mouais c'est pas forcément très fair de faire remonter le phénotype de la touffe avec la pvaleur max de celle ci ....
a mediter

****** TODO manhattan plot
:LOGBOOK:
- State "TODO"       from              [2017-07-12 mer. 11:11]
:END:

#+NAME: code:eas_manhattan_plot
#+CAPTION: Dépend de [[code:eas_load_res]]
#+begin_src R 
  toplot <- expr$df.res %>%
    dplyr::filter(method == "lassoLFMM")

  pl <- ggplot(toplot, aes(x = index, y = -log(pvalue))) +
    geom_point()
  pl
  ggplot(toplot, aes(pvalue)) +
    geom_histogram()
#+end_src
***** DONE Plot
CLOSED: [2017-09-01 ven. 13:11]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-09-01 ven. 13:11]
- State "TODO"       from              [2017-08-17 jeu. 14:32]
:END:

****** DONE Gradient climatique
CLOSED: [2017-08-29 mar. 11:46]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-29 mar. 11:46]
- State "TODO"       from              [2017-08-21 lun. 14:48]
:END:
#+NAME: code:eas_climatic_gradient_plot
#+CAPTION: Dépend de [[code:eas_climatic_gradient]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  library(ggmap)
  MaTheseR.params <- get_MaTheseRparams()


  mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
  indiv.df <- readRDS("./Data/ThesisDataset/3Article/1000GenomesPhase3/EAS_indiv_df_2.rds")
  pl <- ggplot(indiv.df, aes(x = lon, y = lat, color = X, text = `Population Description`)) +
    mapWorld + 
    geom_point() +
    MaTheseR.params$gtheme +
    scale_size_continuous(guide = FALSE) +
    xlab("Longitude") +
    ylab("Latitude")
  pl
  save_plot_MaTheseR(pl, "eas_climatic_gradient.pdf.png",
                     height = 0.4 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)



#+end_src

#+RESULTS: code:eas_climatic_gradient_plot
#+begin_example
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation('ggmap') for details.

Attaching package: ‘ggmap’

The following object is masked from ‘package:cowplot’:

    theme_nothing

The following object is masked from ‘package:magrittr’:

    inset

Attaching package: ‘maps’

The following object is masked from ‘package:purrr’:

    map
[[./OUTPUT/Rplots/eas_climatic_gradient.pdf.png]]
#+end_example

****** DONE Choix des paramètres
CLOSED: [2017-08-28 lun. 16:07]
:LOGBOOK:
- State "DONE"       from "TODO"       [2017-08-28 lun. 16:07]
- State "TODO"       from "DONE"       [2017-08-17 jeu. 16:47]
- State "DONE"       from "TODO"       [2017-08-17 jeu. 16:46]
- State "TODO"       from              [2017-08-17 jeu. 14:33]
:END:

#+NAME: code:eas_screeplot_CV
#+CAPTION: Dépend de [[code:eas_screeplot]] [[code:eas_CV]] [[code:eas_CV_lambda]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(latex2exp)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()

  ## screeplot
  expr <- readRDS("./OUTPUT/Expr/geas_screeplot_expr.rds")
  plA <- ggplot(expr, aes(x = index, y = var.expl)) +
    geom_point() +
    coord_cartesian(xlim = c(1,15)) +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Variance\nexpliquée") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) +
    scale_y_continuous(labels=percent) +
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.6))
  save_plot_png(plA, "eas_screeplot.png")

  ## cross validation K
  expr <- readRDS("./OUTPUT/Expr/geas_CV_lfmm_encore.rds")
  toplot <- expr$errs %>%
    mutate(lambda = as.factor(lambda)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plB <- ggplot(toplot, aes(x = K, y = err.mean, color = lambda)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 0.5)) +
    geom_line() +
    xlab(TeX("Nombre de variables latentes ($K$)")) +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    scale_color_discrete(name = TeX("$\\lambda$")) + 
    geom_vline(xintercept = 9, linetype = "dashed") +
    theme(legend.position=c(0.8, 0.8))
  save_plot_png(plB, "eas_CV_K.png")

  ## cross validation lambda
  expr <- readRDS("./OUTPUT/Expr/eas_CV_lambda_lfmm.rds")
  toplot <- expr$errs %>%
    mutate(K = as.factor(K)) %>%
    group_by(lambda, K) %>%
    summarise(err.mean = mean(err), N = length(err), sd = sd(err), se = sd / sqrt(N)) %>%
    ungroup()
  plC <- ggplot(toplot, aes(x = lambda, y = err.mean, color = K)) +
    geom_point() + 
    geom_errorbar(aes(ymin = err.mean - se,
                      ymax = err.mean + se,
                      width = 1)) +
    geom_line() +
    xlab(TeX("Paramètre de regularisation $L_{2}$ en échelle logarithmique ($\\lambda$)")) +
    scale_x_log10() +
    geom_vline(xintercept = 1e-5, linetype = "dashed") +
    ylab("Erreur de\nprédiction") +
    MaTheseR.params$gtheme +
    theme(legend.position=c(0.8, 0.2))
  save_plot_png(plC, "eas_CV_lambda.png")

  ## gather plot
  pl <- plot_grid(plA, plB, plC, ncol = 1, labels = c("A", "B", "C"))

  save_plot_MaTheseR(pl, "eas_hyperparams.pdf.png",
                     height = 0.9 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)
#+end_src

#+RESULTS: code:eas_screeplot_CV
: [[./OUTPUT/Rplots/eas_screeplot.png]]
: [[./OUTPUT/Rplots/eas_CV_K.png]]
: [[./OUTPUT/Rplots/eas_CV_lambda.png]]
****** DONE qqplot and venn diagram
CLOSED: [2017-08-31 jeu. 12:12]
:LOGBOOK:
- State "DONE"       from "RUNNING"    [2017-08-31 jeu. 12:12]
- State "RUNNING"    from "DONE"       [2017-08-31 jeu. 08:57]
- State "DONE"       from "RUNNING"    [2017-08-30 mer. 08:42]
- State "RUNNING"    from "TODO"       [2017-08-29 mar. 16:24]
- State "TODO"       from              [2017-08-21 lun. 16:50]
:END:

#+NAME: code:eas_ggplot_venn
#+CAPTION: Dépend de [[code:eas_qvalue]]
#+begin_src R 
  library(MaTheseR)
  library(cowplot)
  library(gridExtra)
  library(scales)
  MaTheseR.params <- get_MaTheseRparams()
  method.ordered <- MaTheseR.params$method.ordered
  color.values <- MaTheseR.params$color.values
  gtheme <- MaTheseR.params$gtheme

  res.df <- readRDS("./OUTPUT/Expr/eas_all_qvalue_df.rds")
  ## filter and order method
  res.df <- res.df %>%
    transmute(method = factor(article3_method_name(method), method.ordered),
              index = index,
              pvalue = pvalue,
              calibrated.pvalue = calibrated.pvalue,
              qvalue = qvalue)
  res.df$method %>% unique()

  #############################################################################
  ## qqplot

  pl.qq <- ggplot(res.df, aes(sample = -log10(pvalue), color = method)) +
    stat_qq(distribution = stats::qexp, dparams = list(rate = log(10))) +
    geom_abline(slope = 1, intercept = 0) +
    gtheme +
    scale_color_manual(name = "Méthodes", values = color.values) + 
    theme(legend.position="bottom") +
    xlab("Quantiles théoriques") +
    ylab("Quantiles observés")

  ## pl.qq
  save_plot_png(pl.qq, filename = "eas_qqplot_notcalibrated_all.png")
  save_plot_MaTheseR(pl.qq, "eas_qqplot_notcalibrated_all.pdf.png",
                       height = 0.5 * MaTheseR.params$textheightcm,
                       width = MaTheseR.params$textwidthcm)

  #############################################################################
  ## venn

  toplot <- res.df %>%
    dplyr::filter(qvalue <= 0.01)
  sets <- list(cate = toplot$index[toplot$method == "cate"],
               lassoLFMM = toplot$index[toplot$method == "lassoLFMM"],
               ridgeLFMM = toplot$index[toplot$method == "ridgeLFMM"],
               PCAlm = toplot$index[toplot$method == "PCAlm"])

  ## VennDiagram
  inter <- function(...) {
    id <- list(...)
    res <- sets[[id[[1]]]]
    for (i in id) {
      res <- base::intersect(res, sets[[i]])
    }
    length(res)
  }

  venn <- VennDiagram::draw.quad.venn(
                         area1 = inter(1),
                         area2 = inter(2),
                         area3 = inter(3),
                         area4 = inter(4),
                         n12 = inter(1,2),
                         n13 = inter(1,3),
                         n14 = inter(1,4),
                         n23 = inter(2,3),
                         n24 = inter(2,4),
                         n25 = inter(2,5),
                         n34 = inter(3,4),
                         n123 = inter(1,2,3),
                         n124 = inter(1,2,4),
                         n134 = inter(1,3,4),
                         n234 = inter(2,3,4),
                         n245 = inter(2,4,5),
                         n1234 = inter(1,2,3,4),
                         category = names(sets),
                         fill = color.values[names(sets)],
                         cat.col = color.values[names(sets)],
                         cat.cex = 1.2,
                         margin = 0.07,
                         ind = TRUE
                       )

  save_plot_png(venn, filename = "eas_venn.png")
  save_plot_MaTheseR(venn, "eas_venn.pdf.png",
                     height = 0.5 * MaTheseR.params$textheightcm,
                     width = MaTheseR.params$textwidthcm)

#+end_src

#+RESULTS:
[[./OUTPUT/Rplots/eas_venn.png]]
[[./OUTPUT/Rplots/eas_qqplot_notcalibrated_all.png]]

** Discussion
Les études d'association sont largement utilisées en biologie pour trouver des
liens de corrélation entre des variables. Cependant une corrélation n'est pas
une lien de causalité. Nous nous sommes intéressé dans ce chapitre à la
situation où des variables non observées explique une partie de variations de
$\Y$ et sont corrélé à la variable explicative $\X$. Dans nos résultats la
méthodes lm ne prend pas en compte les facteurs latents. Nous avons observé une
forte inflation des \pvalues retrouné par lm sur les données simulées (Figure
ref:fig:method_comp C et D) ainsi que dans l'EWAS (Figure
ref:fig:ewas_qqplot_top A) et la GEAS (Figure ref:fig:geas_qqplot A) que nous
avons présentés dans ce chapitre. En plus de la forte inflation des \pvalues on
observe également que lm ne permet pas de trouver les bonnes associations, on
observe ainsi dans les données simulées que l'AUC obtenu par lm est largement
inférieur à celui de la méthode oracle qui connait les vrais facteur latents
(Figure ref:fig:method_comp A et B). Enfin pour les études d'associations à
partir de données réelle lm donne les moins bon résultat quand il s'agit de
retrouver les candidats pour l'association trouvés par ailleurs dans la
littérature (Figure ref:fig:ewas_qqplot_top B et Figure ref:fig:gwas_qqplot_top
B).

Une méthode de correction pour les facteurs de confusion consiste à utiliser les
scores de l'ACP pour apprendre les facteurs de confusions; nous l'avons nommée
dans ce chapitre PCAlm. Sur les simulations numériques PCAlm renvoie des
\pvalues bien calibrées (Figure ref:fig:method_comp C et D) mais l'AUC de PCAlm
décroit avec le nombre de variables associées et la corrélation entre les
variables latentes et la variable explicative (Figure ref:fig:method_comp A et
B). On retrouve le fait que les \pvalues sont bien calibrées dans les études
d'association sur des vrais données (Figure ref:fig:ewas_qqplot_top A, Figure
ref:fig:gwas_qqplot_top A et ref:fig:geas_qqplot). Les candidats trouvé par
d'autre méthodes sont bien retrouvés par PCAlm (Figure ref:fig:ewas_qqplot_top B
et Figure ref:fig:gwas_qqplot_top B). On peut supposer que PCAlm donne de bonne
performance sur la GWAS et l'EWAS car il y à peu de variables à détecter. De
plus certain candidats trouvés dans d'autre étude ont trouvé avec des méthodes
similaires à PCAlm comme Refactor de cite:Rahmani_2016 ou EIGENSTRAT de
cite:Price_2006.

Les deux méthodes SVA comparées dans ce chapitre donnent des résultats
similaires à PCAlm sur les simualtions numériques (Figure ref:fig:method_comp).
La méthode sva-two-step donne des résultats très similaires à PCAlm sur l'EWAS
alors que sva-two-step donne des résultats très atypique comparées aux autres
méthodes considérées pour l'EWAS. Avec les bons hyper paramètres, il est
possible que sva-irw donne des résultats comparables aux autres méthodes.
Cependant il n'y a aucun garantit sur la convergence de sva-irw ce qui rend
compliqué l'exploration pour trouver les bons hyper paramètres.

Nous avons proposé dans ce chapitre deux méthodes, ridgeLFMM et lassoLFMM, de
correction des études d'association pour les facteurs latents qui reposent sur
les solutions optimales de problèmes de moindres carré régularisés. Sur les jeux
de données simulées ces méthodes ont les mêmes performances que la méthode
oracle qui connait les facteurs de confusions (Figure ref:fig:method_comp),
elles sont bien calibré sur les vrais jeux de données (Figure
ref:fig:ewas_qqplot_top A, Figure ref:fig:gwas_qqplot_top A et
ref:fig:geas_qqplot) et on retrouve les candidats validés par la littératures
(Figure ref:fig:ewas_qqplot_top B et ref:fig:gwas_qqplot_top B). Les
performances globales de ces méthodes sont très comparable à la méthode cate.
Bien que cate, ridgeLFMM et lassoLFMM ont des performances très similaires pour
nos critères d'évaluation il existe tout de même des différences entre les
listes de candidats renvoyés pas ces trois méthodes (Figure ref:fig:ewas_venn,
Figure ref:fig:gwas_venn et Figure ref:fig:geas_venn). Il serait intéressant de
mettre en évidence des situations mettant en défaut une méthode par rapport à
une autre. Par ailleurs, il existe des techniques permettant de combiner les
résultats venant de plusieurs méthodes pour tester l'association, cela permet de
d'augmenter la confiance que l'on a en les résultats d'une étude d'association.
Nous avons utilisé l'union dans l'étude entre génome et environnement pour
combiner les résultats mais il existe des techniques plus sophistiquées pour
combiner des \pvalues venant de plusieurs test d'hypothèse comme par exemple
celle utilisée dans cette étude cite:sniekers2017genome.

Dans les études d'association considérées ici il n'y pas de vérité terrain et
une méthode peut toujours donner de meilleurs résultats qu'une autre sur des
simulations bien choisis cite:Wolpert_1997. Ces deux nouvelles méthodes
s'ajoutent à l'arsenal des méthodes permettant de corriger pour les facteurs de
confusion les test d'association statistique pour les facteurs de confusion.

** SANDBOX                                                        :noexport:
:PROPERTIES:
:header-args: :cache no :eval no-export :results output :exports none
:END:
*** CANCELLED ridgeLFMM et cate quand B et V sont corrélé :D
CLOSED: [2017-08-07 lun. 14:32]
:LOGBOOK:
- Note taken on [2017-08-07 lun. 16:22] \\
  cate marche bien, la regression robuste va eviter ce cas la !!!
- State "CANCELLED"  from              [2017-08-07 lun. 14:32]
:END:

Que se passe-t-il quand B et V sont corrélé :D

#+begin_src R :results output :exports both
  sampler
#+end_src

Voir cahier le 7/08/2017

* Perspectives et conclusion 
:LOGBOOK:
- Note taken on [2017-08-30 mer. 11:58] \\
  Le choix de K dans les étude d'association c'est ca le vrai pb !! une petite
  experience qui montre que ca fait n'imp ?? genre sur la GEAS on augment K et on
  compare les liste controlé à 1% ?
- Note taken on [2017-08-10 jeu. 12:05] \\
  Les données manquante :D il y en a beaucoups dans les gandes données ! tess3r
  devrais être quand il y a des données manquante. Enfin si il prennait en compre
  correctement les NA. Faire une petite simu d'un tess qui prend en compre bien
  les missing data :D !!!!
- Note taken on [2017-07-31 lun. 10:20] \\
  on va parler de : 
  - vers le big data ? (valeurs manquantes, données pas loadé en mémoire)
  - est ce que le modèle est polygénique ?
  - théorie stat (cf cate)
  - matrice de dosage
  - lien autre que linéaire ? (lien logistique)
- Note taken on [2017-07-30 Sun 13:56] \\
  matrice de dosage
- State "TODO"       from              [2017-07-20 Thu 17:49]
- Note taken on [2017-07-18 Tue 15:49] \\
  strategie: il faut que je finisse tout le reste avec les versions actuelles
  (tess3r, et ce que j'ai fait pour le moment d'lfmm). Quand tout sera fini ! Je
  repenserai l'archi de tess3r (tout en R et une seul data en mémoire). Je pense
  que je n'arriverais pas faire de l'acces de très grosse données depui un fichier
  et la gestion des NA en même temps. Mais je peux montrer les deux séparément,
  cad on montre que on arrive a faire un algo robuste au NA pour tess3r et lfmm
  mais c'est pas complétement implémenté. ET on montre sur un très gros dataset
  une analyse complete pop et lfmm (le 1001 génome est top pour ca car on a une
  matrice imputé :D)
- Note taken on [2017-07-18 Tue 10:57] \\
  - traitement des données manquantes
  - acess au données (pas dans la ram, je peux parler des infracstructure big data
    classique)
  - si j'ai le temps j'implémente ces 2 feature cad: 
    - NA -> comparaison avec et sans NA et procedure naive
    - matrice en mémoriedans un BED -> on a seulement besoin du produit par X ! 
  
  c'est la suite logique de ma problématique cad : 
  - data de plus en plus grosse donc on veut pas les dupliquer, il y a des données
    manquantes
  - mon taf c'est de fournir des logicielles !
  
  
  Je peux ecrire cette partie comme un mini article ! cad
  intro 
  methode
  resultats
  discution 
  conclusion

- Note taken on [2017-05-26 Fri 15:49] \\
  Je pense que je ne vais pas pouvoir développer la crossvalidation et les données
  manquante. 
  
  Par contre je peux montrer que si la cross validation est mal faite
  ca abouti a des mauvais choix de parametre (exemple)
  
  Pareil pour les données manquantes. 
  
  Après dans mes application il n'y a jamais trop de données manquantes, donc peut
  être que c'est pas la peine de se prendre la tête... Surtout que la cross
  validation j'en aurai deja parlé !
:END:

bibliographystyle:apalike
bibliography:../biblio.bib
* Soutenance                                                       :noexport:
:LOGBOOK:
- Note taken on [2017-09-05 mar. 10:31] \\
  Je vais suivre le plan de la thèse: 
  - une intro pour le context, très générals, présentation de quelque
    problématique importante en génétique de populations en association.
  - Problématique
  - Plan
    celui de la thèse
  - developpement des deux axes
  - Conclusion et résumé de la thèse
:END:
** FAQ                                                            :noexport:
*** tess3
**** Pourquoi cette fonction de poid pour le graphe ? Tester d'autre ?
**** Quelle est l'influence de $\sigma$ sur les estimations ?
**** Quelle est l'influence de $\alpha$ sur les estimations ?
**** Pourquoi une matrice laplacienne apparait ici ?
C'est purement numérique... j'ai pas d'intuition.
*** lfmm
